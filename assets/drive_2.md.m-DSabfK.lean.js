import{_ as u,o as a,c as i,a as t,m as h,t as c,C as f,M as w,U as y,f as l,F as b,p as v,e as x,q as k}from"./chunks/framework.B1z0IdBH.js";const S={name:"PoemCard",props:{poem:{type:Object,required:!0}}},A={class:"poem-container"},T={class:"review"},C={class:"review-title"},F={class:"review-content"};function I(o,e,d,p,n,r){return a(),i("div",A,[t("div",T,[t("div",C,[e[0]||(e[0]=t("span",{class:"icon"},"question:",-1)),h(c(d.poem.instruction),1)]),e[2]||(e[2]=t("div",{class:"divider"},null,-1)),t("p",F,[e[1]||(e[1]=t("span",{class:"icon"},"answer:",-1)),h(c(d.poem.output),1)])])])}const P=u(S,[["render",I],["__scopeId","data-v-126d1ac2"]]),M=JSON.parse(`[{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 星球表面，星环，巨大星球，宇航员，网站banner [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Alien planet surface, majestic rings encircling a gigantic planet, intrepid astronaut exploring the terrain, towering rock formations with intricate patterns, glowing bioluminescent plants dotting the landscape, reflecting a soft shimmering light, a sense of awe and wonder in the air, captured in a photograph with a wide-angle lens, emphasizing the vastness of the scene, composition focused on the astronaut's silhouette against the backdrop of the planet and its rings, in a style reminiscent of National Geographic's awe-inspiring nature photography. --ar 16:9 --v 5.2 /imagine prompt: Ancient Egyptian ruins in the desert, majestic pyramids reaching towards the sky, adorned with intricate hieroglyphics and carvings, a group of archaeologists carefully examining the artifacts, the golden sunlight casting surreal shadows on the sand, a sense of mystery and curiosity pervading the scene, captured in a painting with vibrant colors and bold brushstrokes, composition focused on the archaeologists' interaction with the relics, capturing their passion for unraveling history, in a style reminiscent of Jean-Léon Gérôme's Orientalist paintings. --ar 9:16 --v 5 /imagine prompt: Enchanted forest, towering trees covered in vibrant foliage, sunlight streaming through the branches, a magical staircase leading to a hidden realm, delicate butterflies fluttering around, filling the air with colors, a sense of tranquility and wonder engulfing the scene, captured in an illustration with intricate details and whimsical elements, composition focused on the staircase and the surrounding flora, inviting the viewer into a world of fantasy, in a style reminiscent of Arthur Rackham's enchanting fairy tale illustrations. --ar 1:1 --v 5 /imagine prompt: Futuristic city skyline, skyscrapers reaching towards the sky, illuminated with neon lights and holographic projections, advanced flying vehicles soaring through the air, a bustling crowd navigating the technologically advanced metropolis, a sense of dynamism and energy permeating the scene, captured in a digital artwork with sleek lines and vibrant colors, composition focused on the cityscape and the interaction between the characters and their surroundings, conveying a futuristic and vibrant atmosphere, in a style reminiscent of Syd Mead's visionary concept art. --ar 16:9 --v 5"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 头部机器人中国龙，具有透明的鳞片，可以清晰地看到 里面有机械骨头。 风格强调解剖学，视觉效果显得十分空灵，体现科技与艺术之美 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji 5\\" for Japanese art style, or \\"--v 5.2\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A head of a robotic Chinese dragon with transparent scales, revealing the intricate mechanical bones inside. The style emphasizes anatomy and exudes a sense of ethereal beauty, where technology and art converge. The scales reflect light in a mesmerizing way, showcasing the dragon's exquisite craftsmanship. --ar 16:9 --v 5.2 /imagine prompt: The head of the mechanical Chinese dragon is adorned with meticulously crafted transparent scales, giving it a unique and captivating appearance. The translucent nature of the scales allows one to glimpse the intricate machinery underneath, resembling a fusion of technology and organic elements. The dragon's head is sleekly designed, with sharp edges and distinct lines, creating a sense of precision and power. --ar 16:9 --v 5.2 /imagine prompt: Immersed within a futuristic laboratory, the robotic Chinese dragon's head stands as an awe-inspiring centerpiece. The environment is filled with advanced machinery, computer screens displaying intricate diagrams, and flickering holographic projections. The lighting is a blend of cool blue tones and vibrant neon hues, casting an otherworldly glow on the dragon's transparent scales. The juxtaposition of the dragon's organic shape and the laboratory's sleek modernity creates a fascinating visual contrast. --ar 16:9 --v 5.2 /imagine prompt: The mechanical Chinese dragon's head is suspended in a vast celestial space, surrounded by an ethereal mist of stardust and celestial bodies. The transparent scales of the dragon shimmer and refract the distant light, creating a captivating and dream-like effect. The dragon's presence exudes a sense of ancient wisdom and power, with its sleek lines and intricate underlying machinery symbolizing the harmony between technology and nature. --ar 16:9 --v 5.2"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 台灣女生在河邊釣到奇異生物，逼真人物，逼真場景，逼真陰影，ektachrome，技術性高細節，紋理豐富肌理，高度細緻, hd, 8k, 光線追蹤, 高品質, 極度細緻, 細緻繪景 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A Taiwanese girl fishing by the riverside, her face filled with astonishment as she catches a peculiar creature. The image is incredibly realistic, with lifelike details and intricate textures. The scene is set during golden hour, with the soft sunlight casting beautiful shadows on the girl and the creature. The image is captured with an ektachrome film, showcasing its vibrant and saturated colors. The technicality of the image is of the highest quality, with a resolution of 8k and impeccable attention to detail. The lighting is meticulously traced, creating a sense of depth and realism. Every aspect of the image is highly refined, from the beautifully rendered landscapes to the delicate features of the characters. The overall mood of the scene is awe-inspiring and filled with a sense of wonder. The style of the image is a highly detailed and realistic painting, evoking a sense of nostalgia and bringing an old-world charm to the modern concept. --ar 16:9 --v 5 /imagine prompt: In this mesmerizing scene, a Taiwanese girl is fishing in a serene riverside setting. The girl is in the foreground, her eyes wide with surprise and her mouth agape as she catches a truly extraordinary creature. The realism of the image is astonishing, with every detail, from the delicate ripples on the water to the girl's flowing hair, expertly rendered. The scene is bathed in the warm glow of the setting sun, which casts beautiful long shadows on the ground, adding depth and dimension to the image. The use of the ektachrome film enhances the colors and adds a vintage touch, giving the image a timeless quality. The image is captured with the latest technology, resulting in a high-definition and highly detailed rendering. The lighting is masterfully executed, with subtle highlights and shadows creating a realistic and immersive atmosphere. The image is rich in textural details, showcasing the intricate patterns on the girl's clothes and the unique characteristics of the creature she has caught. The overall mood of the scene is filled with excitement and curiosity, capturing the wonder of discovery. The style of the image is reminiscent of a classic painting, with its attention to detail and skillful use of light and color. --ar 16:9 --v 5 /imagine prompt: At the edge of a tranquil river, a Taiwanese girl is engrossed in the art of fishing. The scene is incredibly realistic, with every element, from the girl's expression of astonishment to the intricate patterns on the creature, meticulously crafted. The environment is abundant in natural beauty, with lush greenery and vibrant flowers creating a picturesque backdrop. The lighting is soft and diffused, casting gentle shadows that add depth and realism to the image. The use of ektachrome film enhances the colors, making them vivid and saturated. The attention to detail is exceptional, with every texture, from the girl's clothing to the scales of the creature, rendered with precision. The image is captured in high definition, allowing for a highly detailed and immersive experience. The lighting is carefully studied, with the interplay of light and shadow creating a sense of depth and atmosphere. The image is filled with rich and diverse textures, capturing the intricacies of the natural world. The overall mood of the scene is peaceful and serene, evoking a sense of calm and tranquility. The style of the image is reminiscent of a sophisticated illustration, with its meticulous attention to detail and refined rendering. --ar 16:9 --v 5 /imagine prompt: Witness a captivating moment by the riverside, where a Taiwanese girl discovers a mysterious creature in the depths of the water. The image is extraordinarily lifelike, with every element, from the girl's expression of awe to the intricate details of the creature, meticulously portrayed. The environment is a true feast for the eyes, with a picturesque landscape of rolling hills and sparkling waters. The lighting is masterfully executed, with a play of light and shadow that accentuates the natural beauty of the scene. The use of ektachrome film brings vibrancy and rich colors to the image, elevating it to a new level of realism. The technical prowess applied to the image is exceptional, with a resolution of 8k and an unprecedented level of detail. The lighting is meticulously crafted, with each ray of sunlight casting a soft glow on the scene. The image is brimming with intricate textures, from the girl's flowing hair to the fascinating patterns on the creature. The overall mood of the scene is one of wonder and anticipation, as the girl and the viewer are both captivated by the enigmatic creature. The style of the image is reminiscent of a beautifully detailed sculpture, showcasing the craftsmanship and artistry involved in its creation. --ar 16:9 --v 5"},{"instruction":"translate to English, don't change symbol and line break. Don't change space between paragraphs","output":"It seems like you want a text to be translated into English but you did not provide the text that needs to be translated. Please provide the text, and I would be happy to assist with the translation. Remember to keep the formatting as you need."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 沉浸式空间，山体泥石流，城市模型 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: immersive space, a massive landslide flowing down the mountain, a city model situated beneath it, cascades of soil and rocks tumbling through the air, crashing onto the city model, volcanic dust and debris filling the atmosphere, buildings and roads buried under the weight of the landslide, a chaotic and surreal scene unfolding, captured with a wide-angle lens, showcasing the scale and impact of the disaster, composition focused on the dynamic interaction between the landslide and the city, generating a sense of destruction and vulnerability, in a style reminiscent of Sebastião Salgado's powerful documentary photography. --ar 16:9 --v 5 /imagine prompt: an engulfing spatial experience, a massive mountainous terrain cascading down with a swift mudflow, a meticulously built city model nestled at the foot of the mountain, torrents of mud surging into the city, sweeping away buildings and infrastructure, a high-speed capture freezing the chaos in motion, emphasizing the destructive force of nature, capturing the desperation and fear of the inhabitants, captured using a drone-mounted camera, panoramic view accentuating the vastness of the disaster, composition focused on the juxtaposition between the relentless mudflow and the city's fragile existence, in a style reminiscent of Conrad Jon Godly's hyperrealistic landscape painting. --ar 16:9 --v 5 /imagine prompt: an immersive space with an imposing mountainous backdrop, a massive mudslide rushing down the slopes, an intricately crafted city model perched on the mountain's edge, torrents of mud and debris engulfing the city, a dense cloud of dust enveloping the scene, creating an eerie and apocalyptic atmosphere, captured with a telephoto lens, zooming in on the chaos and destruction, composition focused on the terrified faces of the city's inhabitants, conveying the sense of helplessness and devastation, in a style reminiscent of Gabriel Moreno's expressive mixed media art. --ar 1:1 --v 5.2 /imagine prompt: a captivating and immersive space, a formidable mountain triggering a colossal landslide, a meticulous city model situated below, a deluge of mud and rocks hurtling down, shattering buildings and infrastructure, billowing clouds of dust obscuring the scene, capturing the tumultuous aftermath, a night-time capture with long exposure, streaks of light from emergency vehicles and flames amidst the darkness, emphasizing the chaos and confusion, composition focused on the isolated individuals seeking refuge, evoking feelings of fear and survival, in a style reminiscent of Zdzisław Beksiński's haunting surrealistic paintings. --ar 16:9 --v 5"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = snowy,ice,sea,forests,stars,crescent moon,dark,cloudy,night,wind,mountain,van Gogh [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a snowy landscape, covered in a thick blanket of white, glistening in the moonlight, with tall pine trees standing tall and majestic, casting long shadows on the untouched snow, a frozen lake in the distance reflecting the starry night sky, a crescent moon hanging low, creating a soft glow, a chilling wind blowing through the trees, creating a sense of movement, a towering mountain in the background, with its peaks covered in snow, reminiscent of a painting by Vincent van Gogh. --ar 16:9 --v 5.1 /imagine prompt: a dark and cloudy night sky, filled with twinkling stars, shining brightly against the dark backdrop, a crescent moon peeking through the clouds, casting a mysterious glow on the landscape below, a dense forest of tall trees surrounding a serene lake, the water reflecting the moon and stars, creating a dreamlike atmosphere, the sound of rustling leaves and gentle waves adding to the tranquility, captured in a photograph with a wide-angle lens, emphasizing the vastness of the scene and the ethereal mood. --ar 9:16 --v 5.3 /imagine prompt: a picturesque scene of a snowy mountain peak, reaching towards the sky, covered in a thick layer of snow, the sun setting behind it, casting an orange and pink glow on the pristine landscape, a sea of fluffy clouds floating above the mountain, creating a dramatic backdrop, a gentle breeze blowing through the air, causing the snow to sparkle, a lone figure standing at the edge of a cliff, admiring the breathtaking view, captured in a painting with vibrant colors and bold brushstrokes, capturing the awe-inspiring beauty of nature. --ar 16:9 --v 5.2 /imagine prompt: a dark and stormy night, with heavy rain pouring down from the cloudy sky, lightning illuminating the scene with bursts of light, revealing a lush forest with towering trees, their branches swaying in the strong wind, a sense of mystery and danger in the air, a mountain range in the distance, barely visible through the rain and mist, creating a sense of depth and perspective, captured in a sculpture with intricate details, showcasing the raw power and untamed beauty of nature. --ar 1:1 --v 5.4"},{"instruction":"为解决雷达RD图像的数据缺失的问题，本项目拟利用无监督的目标发现技术学习雷达RD图像数据中的目标先验信息，通过在大规模无标注RGB数据集和公开的雷达RD数据集上进行自监督学习，使用降维和聚类等技术手段，对提取的图像特征进行精密处理，以确切地学习目标位置信息，为后续目标检测任务提供强有力的支持。帮我润色下这句话，加点迁移学习的内容","output":"为了解决雷达距离-多普勒（Range-Doppler，RD）图像数据中的目标检测问题，本项目计划采取一种无监督的目标发现方法。该方法旨在从雷达数据中学习目标的先验信息，通过结合大规模无标注RGB图像数据集和公开可用的雷达RD数据集进行自监督学习。借助迁移学习技术，我们将RGB图像数据集中学习到的高级特征转移到雷达信号分析中，从而提升目标检测的性能。同时，本项目还将采用降维和聚类等先进的技术手段来精细处理提取出的特征，并确保准确地捕捉到目标的位置信息。这样的方法不仅补充了雷达数据中可能的信息缺失，而且为后续的目标检测任务奠定了坚实的基础。"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 科技馆内的沉浸式空间，山体泥石流，城市模型 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Immersive space inside a technology museum, where visitors can experience a simulated mudslide in a mountainous region. The space is designed to recreate the intense and chaotic atmosphere of a real mudslide, with a mix of artificial mud, flowing water, and debris. The mountainous backdrop features towering cliffs and dense vegetation, adding to the sense of danger and adventure. The city model within the space showcases the impact of mudslides on urban areas, with miniatures buildings being swept away and destroyed. The scene is illuminated with dynamic lighting to create dramatic shadows and highlights, enhancing the realism of the experience. The overall mood is one of awe and fascination, as visitors witness the destructive power of nature and the importance of preparedness in such events. The image is captured with a high-resolution digital camera, equipped with a wide-angle lens to capture the vastness of the space and the intricate details of the mountainous landscape. The composition focuses on the simulated mudslide, showcasing the chaos and movement in the scene. The style of the image is a realistic digital illustration, combining detailed textures and vibrant colors to bring the scene to life. --ar 16:9 --v 5 /imagine prompt: In a technology museum, there is an immersive space dedicated to simulating a mountainous region with a mudslide. The mudslide scene depicts a massive volume of muddy water rushing down a steep slope, carrying rocks, trees, and debris along its path. The environment is portrayed with a combination of physical elements, such as waterfalls and vegetation, and digital projections to create a realistic and dynamic experience. The city model integrated into the scene showcases buildings being engulfed by the mudslide, emphasizing the destructive power of such phenomena. The composition of the image captures the dramatic moment when the muddy water crashes into the city, highlighting the contrasting elements of chaos and tranquility. The atmosphere is intense and suspenseful, with the sound of rushing water and crumbling structures immersing visitors in the scene. The image is rendered in a 3D art style, with intricate details and realistic textures. The color palette is dominated by earthy tones, further enhancing the authenticity of the environment. --ar 16:9 --v 6.7 /imagine prompt: Inside a technology museum, a captivating immersive space awaits visitors, offering a simulated mountainous region with an active mudslide. The scene features a towering mountain range covered in lush vegetation, with a river flowing through the valley below. The mudslide itself is depicted as a massive torrent of brownish water cascading down the mountainside, churning up rocks, tree trunks, and debris in its wake. The city model integrated into the space showcases the destruction caused by mudslides, with collapsed buildings and submerged infrastructure. The composition of the image focuses on the dynamic interaction between the mudslide and the city, capturing the chaos and devastation. The atmosphere is filled with tension and urgency, as visitors witness the immense power of nature and the vulnerability of human constructions. The image is rendered in a realistic painting style, with precise brushwork and vibrant colors, conveying a sense of energy and movement. --ar 1:1 --v 5.2 /imagine prompt: Enter an immersive space within a technology museum, where a simulated mountainous region with a mudslide is brought to life. The scene unfolds in a narrow valley, flanked by towering cliffs covered in dense foliage. A powerful mudslide surges through the valley, carrying with it a mixture of mud, rocks, and uprooted trees. The city model nestled within the valley showcases the impact of this natural disaster, with miniature buildings being swept away by the forceful flow. To enhance the realism, the environment is infused with sound effects, simulating the roar of the mudslide and the crashing of debris. The composition of the image captures the moment when the mudslide reaches its peak intensity, portraying the sheer force and destruction it entails. The atmosphere is one of danger and urgency, evoking a sense of chaos and vulnerability. The image is captured with a realistic photography style, utilizing a telephoto lens to zoom in on the dynamic details of the mudslide. The color palette is dominated by earthy tones, accentuating the ruggedness of the terrain. --ar 9:16 --v 5.2"},{"instruction":"I wanna try making an ai ddos firewall. How should i present it the data? I think its gonna be l7 for now. Should i present it just the raw http request data? Show me an example of the data of ehat it should look like including the raw http data, request rate, etc and when it should get predicted as you cant trg and predict every single request as you dont have ennough data yet.","output":"Developing an AI-powered DDoS (Distributed Denial of Service) firewall, particularly for layer 7 (L7), involves analyzing incoming HTTP requests to differentiate between legitimate traffic and potential DDoS attack traffic. To train such a model, you need to present a dataset that includes various features extracted from HTTP requests along with labels indicating whether each request is part of normal or malicious traffic. Below are different types of features that you could extract from HTTP requests for training your AI model: 1. **Raw HTTP Request Data**: - HTTP Method (GET, POST, PUT, DELETE, etc.) - URL or the URI (Uniform Resource Identifier) - HTTP version (e.g., HTTP/1.1, HTTP/2) - Headers (User-Agent, Referrer, Cookies, etc.) - IP address of the requester - Query parameters - Payload (for methods like POST or PUT) 2. **Temporal Features**: - Request rate (number of requests from a single IP or across all traffic in a given time window) - Time of day (some attacks may occur at specific times) 3. **Network Features**: - Source and destination IP addresses - Source and destination ports - Geographical location (which can be derived from IP) 4. **Behavioral Features**: - Session duration - Number of sessions - Request patterns (e.g., repeated requests for the same resource) - Flow of requests within a session 5. **Payload Analysis**: - Length of the payload - Entropy of the payload (for detecting randomized content often seen in attacks) - Occurrence of known malicious patterns or strings For the sake of demonstration, suppose you are logging each HTTP request received by your server, your raw data for one request might look something like this: \`\`\`plaintext { \\"timestamp\\": \\"2023-04-05T12:34:56Z\\", \\"ip\\": \\"192.0.2.1\\", \\"method\\": \\"GET\\", \\"uri\\": \\"/index.html\\", \\"headers\\": { \\"user-agent\\": \\"Mozilla/5.0 ...\\", \\"accept-language\\": \\"en-US,en;q=0.9\\", \\"cookie\\": \\"sessionid=abc123...\\" }, \\"http_version\\": \\"HTTP/1.1\\", \\"request_size\\": 512, \\"response_size\\": 2048, \\"request_rate\\": 10.5, // requests per second \\"request_entropy\\": 3.75, \\"response_code\\": 200, \\"is_malicious\\": false // This label needs to be determined through analysis or historical data } \`\`\` The \`is_malicious\` field indicates whether the request is part of a malicious traffic pattern; you would need historical data or expert analysis to label your training data accurately. Training and Prediction Considerations: - **Sampling and Windowing**: Instead of training the model on every single request, you would aggregate request statistics over a time window. This \\"window\\" should be based on an interval that makes sense for your traffic patterns (e.g. seconds, minutes). - **Data Imbalance**: DDoS attack instances might be rare compared to normal traffic. Be mindful of the data imbalance problem when training your model to avoid the model being biased towards the majority class. - **Streaming Prediction**: Once you have a trained model, you can use it to make predictions on streaming data. For each time window, you would aggregate request features and feed them into the model to predict whether that window's traffic is part of a DDoS attack. Remember to keep privacy concerns in mind, particularly regarding GDPR and other data protection laws, as personal data may be contained within HTTP request logs. Ensure that your data handling practices comply with all relevant regulations. Lastly, building such a system is complex and involves not just machine learning but also expertise in networking, security, and software development. Be sure to follow best practices and collaborate with experts in the field."},{"instruction":"Any other data it should include when predicting/training? Also include the request data and other metrics. The data imbalance should be fine, ill try my best to keep it balanced, but also ddos attacks generate a lot more requests than normal so it should self balance out.","output":"When training an AI model for a Layer 7 DDoS firewall, maximizing feature richness can improve the model's predictive accuracy. Here are some additional data points and metrics that could enhance your dataset: 1. **Session Continuity and Behavioral Pattern**: - Number of requests per session - Session rate per IP (how many sessions are initiated from the same IP within a given window) - Order and frequency of resource access within a session 2. **Referrer Data**: - Referrer URL to analyze if traffic is coming from a legitimate source or a suspicious redirect. 3. **Request Distribution**: - Distribution of request types (e.g., the ratio of GET to POST requests) - Distribution of response status codes (e.g., the number of 200s, 404s, 503s, etc.) 4. **Traffic Volume and Bandwidth**: - Total data transfer size per time window - Changes in traffic volume over time (trends) 5. **Rate Limiting and Anomaly Detection**: - Previous blocks or challenges presented to the IP - Sudden spikes in request rates that deviate from predicted patterns 6. **Sequential Request Patterns**: - Bursts of activity following periods of inactivity - Repeated patterns suggesting automated access rather than human interaction 7. **Payload Analysis Enhancements**: - Payload commonality across different requests (potential indication of scripted attacks) - Unusual payload sizes not typical of standard application use 8. **Resource Consumption**: - Server load or response times during requests windows (indicates resource strain which might suggest an attack) 9. **Human-like Interaction**: - Timing patterns similar to human keyboard/mouse interactions versus automated scripts - Cognitive plausibility of behavior (sequential logic of human navigation versus random requests) 10. **Multi-vector Correlation**: - Correlation between different feature vectors that might indicate sophisticated, multi-vector attacks. Here's an extended version of your example with additional data points included: \`\`\`plaintext { \\"timestamp\\": \\"2023-04-05T12:34:56Z\\", \\"ip\\": \\"192.0.2.1\\", \\"method\\": \\"GET\\", \\"uri\\": \\"/index.html\\", \\"referrer\\": \\"https://example.com\\", \\"headers\\": { \\"user-agent\\": \\"Mozilla/5.0 ...\\", \\"accept-language\\": \\"en-US,en;q=0.9\\", \\"cookie\\": \\"sessionid=abc123...\\" }, \\"http_version\\": \\"HTTP/1.1\\", \\"request_size\\": 512, \\"response_size\\": 2048, \\"request_rate\\": 10.5, \\"request_entropy\\": 3.75, \\"response_code\\": 200, \\"session_rate\\": 1.2, // New sessions per minute for the IP \\"unique_resource_access\\": 5, // Number of unique resources accessed in the window \\"resource_access_pattern\\": \\"sequential\\", // Indicates if resources are accessed in a predictable order \\"payload_commonality\\": 0.8, // Measure of similarity between payloads of different requests \\"server_load\\": 0.6, // Some metric of server load, can be in CPU usage percentage \\"is_human\\": true, // Flag indicating if the request pattern seems human-like \\"is_malicious\\": false // Label for whether the traffic is part of an attack } \`\`\` Training the model: - **Ensemble Methods**: Consider using ensemble methods or hybrid approaches that combine different models to understand various aspects of the traffic. - **Continuous Learning**: The model should ideally employ some form of continuous or online learning to adapt to new patterns of DDoS attacks over time. - **Active Learning**: Use active learning to selectively label instances that are most beneficial for the model's performance, especially when dealing with vast amounts of data that are expensive to label manually. While DDoS attacks may create obvious patterns due to the volume of requests, subtle and low-volume attacks (which are becoming more common) still can be quite challenging to detect. Hence, having a comprehensive feature set and a robust learning algorithm is crucial. One more thing to note is that while it may seem like DDoS attacks could self-balance the dataset since they generate a lot of requests, it's the labels that are critical for supervised learning, not just the volume of data. Each instance needs to be labeled correctly for the model to learn effectively; large volumes of unlabeled data do not inherently solve the data imbalance problem."},{"instruction":"Let's we have a program using multiple threads. Thread 1 executes x=1 then executes full memory barrier. Does it means that other threads see that x is 1 right after thread 1 executes its full memory barrier or other threads have to executive their full memory barriers to guarantee then they will see actual x variable in teme that is changed by thread1?","output":"The purpose of a full memory barrier (or \\"fence\\") is indeed to ensure that any memory operations (loads and stores) issued before the barrier are completed before any operations issued after the barrier. When Thread 1 executes x=1 and then a full memory barrier, it guarantees that this write to x is visible to other threads with certain caveats depending on the memory model of the system. In a strongly ordered memory model, like that of x86/x86_64 architectures, once Thread 1 releases the barrier, any thread that reads x after this point will see the updated value, provided that they perform the read after the barrier has been executed by Thread 1. This is because the x86 memory model ensures that stores before the barrier are not only locally observed (by the thread that executed the barrier) but are also globally visible to other threads in a consistent order. However, some systems have a weaker memory model, like ARM or PowerPC, which might require additional steps to guarantee visibility. For such systems, another thread still needs to perform appropriate synchronization operations, such as acquiring a lock, reading through a volatile variable, or issuing its own memory barrier, to ensure it sees the updated value of x reliably. To summarize, a full memory barrier in Thread 1 ensures that the write to x is correctly ordered with respect to the barrier. Other threads will see x as 1 provided they read x at a point in the program that is guaranteed to happen after the barrier execution by Thread 1. This can often be ensured through proper use of synchronization primitives like mutexes, locks, atomic variables, or barriers/fences on the side of the reading threads as well. It's important to write programs with correct synchronization to ensure that they work as intended on all types of hardware. The exact manner in which full memory barriers work can be subtle and platform-specific, so it's essential to understand the memory model of the system you are working on when writing multi-threaded code."},{"instruction":"Let's we have a program using multiple threads. Thread 1 executes x=1 then thread 2 executes full memory barrier. Does it means that other threads see that x is 1 right after thread 2 executes its full memory barrier or other threads have to executive their full memory barriers to guarantee then they will see actual x variable in time that is changed by thread1?","output":"If Thread 1 executes \`x=1\` and then Thread 2 executes a full memory barrier, the barrier executed by Thread 2 does not automatically ensure that the update to \`x\` by Thread 1 is seen by other threads. The responsibility for guaranteeing visibility of the write operation to \`x\` still lies with Thread 1, which performed the write. Here's why: When Thread 1 executes \`x=1\`, it writes the value to \`x\`. If Thread 1 does not use any synchronization mechanisms, such as a memory barrier, lock, or atomic operation, there is no guarantee that this write will become visible to other threads in a timely manner due to potential caching and reordering optimizations performed by the CPU and the compiler. Now, Thread 2 executing a full memory barrier after Thread 1 has written to \`x\` only ensures that memory operations issued by Thread 2 before its barrier will be observed before operations after its barrier. This affects the memory operations performed by Thread 2 itself and does not have a direct impact on the memory operations performed by Thread 1. For other threads to see the updated value of \`x\` reliably, one of the following needs to happen: 1. Thread 1 must employ a synchronization mechanism after writing to \`x\`, such as a full memory barrier, an acquire/release operation due to locking a mutex, or writing to an atomic variable with appropriate memory ordering. This ensures that the write to \`x\` is properly propagated and visible to other threads. 2. The other threads must use corresponding synchronization operations that establish a happens-before relationship with Thread 1's write to \`x\`. This could be done by acquiring the same mutex that was released by Thread 1 or by issuing a full memory barrier (depending on the system's memory model) or reading an atomic variable that ensures visibility of prior writes when read. 3. Thread 1 and the other threads participate in some kind of a synchronization protocol which makes sure the write to \`x\` is visible before they attempt to read it. This protocol may include condition variables, barriers, semaphores, or other synchronization primitives. Therefore, without proper synchronization in Thread 1 to signify the write to \`x\`, and corresponding actions in the other threads that need to read \`x\`, there is no guarantee that the other threads will see the updated value in \`x\` immediately, if at all, regardless of the barrier executed by Thread 2."},{"instruction":"Let's we have a program using multiple threads. Thread 1 executes x=1 without any further memory bartiers then thread 2 executes full memory barrier. Does it means that thread 2 will see that x is 1 right after thread 2 executes its full memory barrier?","output":"When Thread 1 executes \`x=1\` without any synchronization and Thread 2 subsequently executes a full memory barrier, there is no guaranteed relationship between these two actions in terms of memory ordering. The full memory barrier executed by Thread 2 does not ensure that it will see the write to \`x\` made by Thread 1. A memory barrier's effect is local to the thread that issues the barrier. What this means is: 1. A full memory barrier issued by Thread 2 will ensure that all memory operations before the barrier in the instruction sequence of Thread 2 are completed before any memory operations after the barrier. It establishes a memory ordering constraint for the operations within Thread 2 only and does not impose any ordering on the operations performed by Thread 1. 2. Thread 2's barrier does nothing to ensure the visibility of \`x=1\` to itself or any other threads unless Thread 1 has used a corresponding barrier or synchronization action (like acquiring and releasing a mutex, writing to an atomic variable with a specific memory order, etc.) to publish the write to \`x\`. For Thread 2 to safely see \`x=1\`, there needs to be a proper synchronization mechanism that synchronizes the write from Thread 1 with the read in Thread 2. For example, if Thread 1 writes \`x=1\` and then releases a lock (which acts as a release barrier), and Thread 2 subsequently acquires the same lock (which acts as an acquire barrier) before reading \`x\`, then Thread 2 is guaranteed to see the updated value. Without such synchronization, there is no guarantee that Thread 2 will see the value \`x=1\` immediately after its memory barrier due to the way modern processors and compilers may reorder and optimize memory accesses, as well as because of the inherent latencies in propagating memory writes throughout a multicore system. In a weak memory model system, it's especially important to correctly use memory barriers or other synchronization mechanisms to ensure memory visibility and ordering."},{"instruction":"Let's we have a program on x86 using multiple threads. Thread 1 executes x=1 then thread 2 executes full memory barrier. Does it means that other threads see that x is 1 right after thread 2 executes its full memory barrier or other threads have to executive their full memory barriers to guarantee then they will see actual x variable in time that is changed by thread1?","output":"On x86 architectures, which have a strong memory ordering model, writes to memory are guaranteed to be seen by other threads in a consistent order, due to the \\"store-to-load forwarding\\" and \\"store atomicity\\" features of the x86 architecture. This means that after Thread 1 writes \`x=1\`, it is highly likely, though not guaranteed, that other threads will see that \`x\` is 1 even if they don't use a memory barrier themselves. Thread 2 executing a full memory barrier afterward does not have a direct impact on the visibility of the write to \`x\` by Thread 1. Instead, the memory barrier enforced by Thread 2 ensures that its own reads and writes are seen in the correct order with respect to other memory operations in Thread 2. Importantly, even on x86, without explicit synchronization, there is a risk that compiler optimizations or store buffers might cause other threads not to see the updated value immediately. Therefore, while the strong memory ordering guarantees of x86 make it more likely that the write by Thread 1 will be seen by others without further barriers, it is generally recommended to use explicit synchronization to guarantee visibility across threads. This is generally done via atomic operations, locks, or memory barriers (when done properly). For other thread architectures with weaker memory models (like ARM or POWER), a write followed by a memory barrier in one thread does not ensure that other threads will see the updated value unless they also perform some form of synchronization operation. To sum up, in practice, on an x86 system, while it's likely that the write \`x=1\` by Thread 1 will be seen by other threads without additional memory barriers, the safest and most robust approach to multi-threaded programming is to use explicit synchronization mechanisms to ensure that memory is consistent across threads—and not to overly rely on the specifics of the underlying hardware memory model for program correctness."},{"instruction":"If thread 1 executes full memory barrier can it slow down other thread execution or it has no affect on other threads?","output":"A full memory barrier issued by Thread 1 only directly affects the ordering of memory operations within Thread 1 itself; it does not directly impose any slowdown or ordering constraints on other threads. Its purpose is to prevent the CPU from reordering reads and writes before and after the barrier in Thread 1's instruction stream. However, there can be indirect effects on other threads, depending on the specifics of the underlying hardware and system architecture: 1. **Contention on Shared Resources**: If the memory barrier in Thread 1 causes it to flush the store buffer or ensures visibility of its writes to shared cache lines, it might cause cache coherency traffic. Other threads accessing the same cache lines may experience delays due to contention or cache coherency protocols ensuring that they have the most recent data. 2. **Memory System Overload**: Memory barriers can cause a brief increase in load on the memory system since they ensure that prior memory operations are completed before proceeding. If the system is heavily loaded or the memory subsystem becomes a bottleneck due to numerous barriers happening in tight succession across multiple threads, this could indirectly affect the performance of other threads due to increased memory latency. 3. **System-wide Effects**: On systems where memory barriers have broader effects, such as flushing buffers or invalidating caches, other threads could be impacted as they may have to wait for these operations to complete before they can proceed with their memory accesses. In most cases, the actual impact of a memory barrier in one thread on other threads is minimal, especially on modern multi-core processors with a sophisticated cache-coherency protocol and multiple levels of cache. However, the design of concurrent algorithms and careful placement of memory barriers are important for performance reasons. Overuse of memory barriers can lead to excessive serialization of memory operations and reduce the overall performance of a multi-threaded application, even though this slowdown is a result of the software design rather than the barrier impacting other threads directly. In practice, it's generally recommended to keep synchronization overhead to a minimum and ensure that memory barriers or other synchronization primitives are used judiciously and only where necessary to maintain program correctness."},{"instruction":"What is a cost of full memory barrier?","output":"The cost of a full memory barrier can vary widely depending on several factors, including the specific architecture, the state of the processor and memory system at the time the barrier is executed, and the hardware implementation of the barrier itself. There are various types of full memory barriers, such as StoreStore, LoadLoad, LoadStore, and StoreLoad, with the latter typically being the most costly due to the need to ensure a total order between stores and subsequent loads. Here are some general aspects of the cost associated with a full memory barrier: 1. **Serialization of Instructions**: A full memory barrier ensures that all memory operations issued before the barrier are completed before any subsequent memory operations are started. This serialization can introduce a delay since it prevents the CPU from executing certain optimizations like out-of-order execution, which is used to maximize instruction-level parallelism and throughput. 2. **Memory System Delays**: Memory barriers may involve operations like flushing store buffers, waiting for the memory operations to propagate through the memory hierarchy (i.e., up to the point of coherency), and potentially invalidating entries in other CPU caches within a multiprocessor system. This can induce delays due to increased traffic and contention in the memory system. 3. **Cache Coherency Traffic**: In multiprocessor systems, a full memory barrier may trigger cache coherency mechanisms to ensure that all processors see a consistent view of memory. This might involve cache line invalidation or update broadcasts across an interconnect, inducing extra traffic and potential latency as cache lines are synchronized. 4. **Impact of Instruction Pipelining**: Modern processors use deep pipelines to execute a large number of instructions concurrently. A full memory barrier can force the pipeline to drain, waiting until all prior instructions are fully executed, which can introduce stalls in the pipeline execution. 5. **Compiler and Out-of-Order Execution**: The compiler may introduce memory barriers or equivalent code sequences to enforce ordering guarantees, which can affect the ability of the processor to execute instructions out of order. 6. **Hardware Optimization**: Some hardware may optimize barriers to minimize their impact. For example, x86 processors have strong memory ordering guarantees, and a full memory barrier (such as an \`mfence\` instruction) may not always result in a significant slowdown since many of the constraints are already enforced by the processor's memory ordering model. The actual performance impact of a full memory barrier is therefore highly dependent on the circumstances and the specific architecture. On some systems, the cost may be relatively small and hardly noticeable, while on others, particularly in highly concurrent or intensive memory operation scenarios, the impact can be quite significant. Profiling and performance analysis tools can help determine the cost of memory barriers in a given system. Best practices in concurrent programming suggest using memory barriers only when necessary to enforce memory visibility and ordering guarantees, and to carefully measure their impact on performance in critical code paths."},{"instruction":"Can you estimate a cost of full memory barrier on modern x86 in processor cycles?","output":"Estimating the exact cost of a full memory barrier in processor cycles on modern x86 processors is challenging due to various factors that come into play, such as the specific processor model, the workload characteristics, the state of the memory subsystem, and the interaction with other hardware features like cache coherence mechanisms. In general, on modern x86 architectures, full memory barriers (like \`mfence\` or \`lock\`-prefixed instructions) can range from very low cost, such as just a couple of cycles, up to tens or even potentially hundreds of cycles in scenarios with significant memory subsystem contention or when the cache coherence protocol is heavily involved. 1. **Typical Costs**: In common cases where the store buffer isn't full and there aren't cache line invalidations occurring as a result of the barrier, the cost might be on the lower end (e.g., tens of cycles). 2. **Optimal Conditions**: Under conditions where writes have already been resolved or the data is readily in the cache with low contention, the cost can be minimal, potentially just a matter of a few cycles for the barrier itself without significant additional latency. 3. **Contentious Conditions**: In the worst-case scenarios, especially when a lot of data modified before the barrier needs to be propagated to other cores or when store buffers are full, the costs can be higher, possibly reaching into the tens or even hundreds of cycles due to waiting for the memory operations to commit globally and for coherence traffic to settle. To put it in perspective, modern x86 processors often have complex optimizations that minimize the need for explicit memory barriers. For instance, the x86 memory model guarantees that regular stores are visible in a total order (StoreLoad ordering), which means that an explicit fence instruction isn't always necessary. Moreover, the cost of a barrier can be partly hidden by the out-of-order execution capabilities of the processor, which may allow other, non-memory operations to be performed while the memory subsystem is resolving the ordering constraints. The cost of a barrier can also be highly variable from one situation to another, even on the same hardware under different software conditions, making it difficult to give a single definitive cycle count. It's crucial to emphasize that these figures can also change with advancements in processor technology and architecture. Therefore, the best approach to understanding the cost of memory barriers in a given context is to use profiling and benchmarking, where one measures the actual performance of code in a realistic environment. Theoretical estimates must always be supplemented by empirical evidence, especially when performance is a critical concern."},{"instruction":"If some threads write four-byte variable within a spinlock and other threads read this variable out of the spinlock, is it possible that they will read incomplete value of this variable?","output":"In typical usage and on most modern computing architectures, if you use a properly implemented spinlock to protect the write access to a four-byte variable, and if the variable is naturally aligned, reading the variable without the spinlock should not result in reading an incomplete value. This is because: 1. **Atomicity of Four-Byte Stores and Loads**: On many architectures, like x86 and x86-64, a store or load of a naturally aligned four-byte (32-bit) variable is atomic. \\"Naturally aligned\\" means that the variable's memory address is a multiple of its size—in this case, a multiple of four. Atomic here means that other threads will see the variable as having either its old value or its new value, with no intermediate or \\"torn\\" reads where only part of the value has been updated. 2. **Memory Order Guarantees**: When using a spinlock, any well-defined memory ordering provided by the lock (such as an acquire-release semantic) should ensure that the writes inside the lock's critical section are visible before the lock is released. Thus, another thread acquiring the same lock should see the complete write. However, there are some potential issues to consider: - **Compiler and CPU Reordering**: While a spinlock should prevent other threads from entering its critical section concurrently, without explicit memory barriers (which are commonly part of a spinlock's implementation), a compiler or CPU might reorder instructions around the lock, leading to potential visibility issues. - **Visibility to Threads Not Using the Lock**: If a thread reads the variable without using the spinlock, memory reordering might mean it does not see the most recent write from a thread that did use the spinlock. To ensure visibility, you could use atomic operations with appropriate memory ordering semantics, volatile qualifiers in C/C++ (though this is often misused and not recommended as a synchronization mechanism), or memory barriers. - **Caches and Memory Coherence**: Modern multi-core processors use caches with a cache coherence protocol that ensures a consistent view of memory across all cores. As long as the spinlock implementation correctly uses memory barriers where needed, the coherence protocol should maintain the consistency of the four-byte variable across different caches. In conclusion, on modern architectures and with a properly implemented spinlock mechanism, reading a naturally aligned four-byte variable without the spinlock should still provide you with a complete, non-torn value. However, without the lock, you may be reading a stale value if your memory access does not have a proper happens-before relationship established with the write operation. For complete safety and correctness in concurrent programming, it is best to protect all shared mutable state with appropriate synchronization primitives, both when reading and writing."},{"instruction":"If some threads write unaligned four-byte variable within a spinlock and other threads read this variable out of the spinlock, is it possible that they will read incomplete value of this variable?","output":"Yes, it is possible that other threads may read an incomplete value of an unaligned four-byte variable, even if writes to the variable are protected by a spinlock. This is because, on many architectures, atomicity and the single-instruction nature of reads and writes are only guaranteed for variables that are naturally aligned—that is, the memory address of the variable is a multiple of the size of the variable (e.g., a four-byte variable should be aligned to a memory address that is a multiple of four). If a variable is not naturally aligned, for example, a four-byte integer starting at an odd address, the CPU may need to perform two separate memory access operations to read or write the entire value. This can lead to a situation known as a \\"torn read\\" or \\"torn write,\\" where one thread sees a combination of old and new data because it read the variable in the middle of another thread's write operation. Even if Thread 1 uses a spinlock to write to the unaligned four-byte variable, if Thread 2 reads the variable without using the spinlock or any other synchronization mechanism, it could potentially see: 1. Part of the old value and part of the new value that was written by Thread 1, because the read operation by Thread 2 may not be atomic. 2. A completely old value, if Thread 2's read occurred before the write by Thread 1 was visible. 3. The updated new value, if Thread 2's read occurred after the write by Thread 1 was fully visible. The visibility issue is more pronounced in systems with weak memory models or without coherent caches, where writes by one CPU core can take time to propagate to another core. To prevent this issue, you should ensure that shared variables accessed by multiple threads are naturally aligned according to their data types. Most compilers and environments will do this by default, but manual alignment may be necessary when using custom memory allocators or packed structures. Furthermore, all accesses to shared mutable variables should be protected using appropriate synchronization mechanisms to not only ensure atomicity but also to enforce memory ordering and visibility across all threads that access the variable. Even with naturally aligned variables, proper synchronization is necessary to avoid race conditions and memory consistency errors."},{"instruction":"Is “torn read” or “torn write” possible on modern x86?","output":"On modern x86 and x86-64 architectures, \\"torn reads\\" or \\"torn writes\\" are generally not an issue for naturally aligned accesses up to the size of the processor's word. The x86 architecture provides strong guarantees for the atomicity of reads and writes of naturally aligned data that fits within a single cache line, typically for sizes up to 8 bytes (64 bits) on current systems. For data types that are 4 bytes (32 bits) or smaller and are naturally aligned, x86 and x86-64 processors guarantee that reads and writes are atomic. This means that any read or write to such a variable will be executed as a single, indivisible operation, so other threads will never see a \\"torn\\" value. However, for data that is larger than 8 bytes or that crosses a cache line boundary (i.e., is not contained within a single 64-byte cache line on current x86/x86-64 processors), torn reads and writes can potentially occur without special instructions to ensure atomicity. For unaligned accesses, where the data type is not aligned to its size boundary, x86 processors are generally tolerant and will still perform the read or write operation, but the atomicity guarantee does not hold. That said, modern x86 processors handle unaligned access quite efficiently, and in many cases, you won't see a significant performance penalty. However, this should not be misconstrued as a guarantee against torn access. While the x86 guarantees are strong, it's important to use proper synchronization even on x86 systems when dealing with shared mutable state across threads to avoid race conditions and ensure memory ordering and visibility consistent with the programmer’s intent. Some level of atomicity is required for correctness even if the processor provides guarantees against torn reads and writes. For data larger than the word size or for complex updates to multiple variables or memory locations, you should use atomic operations provided by the language or platform, like those available in C++'s \`<atomic>\` header or via synchronization primitives like mutexes."},{"instruction":"Is “torn read” or “torn write” pissible on ARM if the variable been used is aligned?","output":"On ARM architectures, whether \\"torn reads\\" or \\"torn writes\\" are possible depends on the specific version of the ARM architecture and the size and alignment of the variable being accessed. ARM architectures have different memory models and capabilities, especially when comparing ARMv7 (32-bit) to ARMv8 (64-bit) and beyond. For ARMv7 and earlier 32-bit ARM architectures: - Aligned reads and writes of 1, 2, and 4 bytes are atomic. There should be no torn reads or writes for these sizes as long as they are naturally aligned (i.e., aligned to their respective byte sizes). - For data types larger than 4 bytes, atomicity is not guaranteed, and torn reads or writes can occur if special atomic instructions or locks are not used. For ARMv8 (AArch64) and newer 64-bit ARM architectures: - Aligned reads and writes of 1, 2, 4, and 8 bytes should all be atomic. This means that as long as the access is aligned to the size of the data type, the operation will be completed in a single instruction, without torn reads or writes. - For data larger than 8 bytes, or for more complex operations, the architecture provides specific atomic instructions to ensure atomicity, and developers need to use these instructions to avoid torn reads/writes. Regardless of the version, ARM provides load and store exclusive instructions (\`LDREX\` and \`STREX\` on ARMv7, \`LDAXR\` and \`STLXR\` on ARMv8) which can be used to perform atomic read-modify-write operations. Additionally, ARM architectures support memory barriers and atomic operations that can be used to prevent data races and ensure consistency when accessing shared data in multi-threaded applications. In summary, as long as variables are naturally aligned and fit within the atomic access size supported by the ARM architecture in use, torn reads or writes should not occur. For larger variables or those that require stronger synchronization guarantees, ARM provides a range of instructions and mechanisms to ensure atomicity and memory ordering. It is critical to understand and use these correctly when writing concurrent code for ARM processors."},{"instruction":"On what architectures aligned reads and writes of 4 bytes aren't atomic and “torn reads” or “torn writes” are possible?","output":"Atomicity of memory operations can vary greatly across different processor architectures and their respective memory models. For most modern general-purpose processors, four-byte aligned load and store operations are atomic. However, there are exceptions, particularly among older or specialized hardware, microcontrollers, digital signal processors (DSPs), or very low-end processors where memory access atomicity might not be guaranteed even for aligned four-byte data types. Here are some scenarios where one might encounter non-atomicity for aligned four-byte operations: 1. **Older or Simple Processor Architectures**: Some particularly old or low-complexity processor architectures, which might not have strong atomicity guarantees for any memory operations, could exhibit non-atomic behavior for four-byte reads and writes even if they are aligned. 2. **DSPs or Specialized Processors**: Digital signal processors or specialized embedded processors designed for specific tasks can have unique memory models that may not guarantee atomicity for four-byte operations, especially if they prioritize speed or energy efficiency over strong atomicity and memory consistency guarantees. 3. **Microcontrollers and Embedded Processors**: Lower-end microcontrollers, especially those with small word sizes (8-bit or 16-bit), may not support atomic operations for 32-bit aligned reads and writes. Accesses to four-byte data types may span multiple bus cycles, which can lead to torn reads or writes in a concurrent environment. 4. **Network Processors and IO Processors**: Processors designed for network packet processing, I/O tasks, or those operating on non-uniform memory access (NUMA) systems may also not assure atomicity for four-byte transfers as these are optimized for other aspects of performance rather than atomic memory operations. 5. **Systems with No-Cache or Simple Bus Protocols**: Systems that either have no cache or utilize a very simple bus protocol without atomicity guarantees may experience torn reads or writes due to the lack of sophisticated mechanisms to ensure atomicity at the hardware level. While these are potential scenarios where atomicity might not be guaranteed, it's important to review the documentation specific to the processor or system in question to determine the exact nature of atomic memory operation guarantees. In general, when writing for architectures where atomicity cannot be assumed, software developers must rely on lock-based synchronization or atomic instruction sets provided by the architecture (if available) to ensure safe concurrent operations. For critical sections of code that must be executed atomically, it may be necessary to use hardware-specific instructions for atomic access (sometimes provided by the architecture-specific atomic or lock instruction sets) or to disable interrupts to ensure that the section of code is not interrupted, thus preventing concurrent access."},{"instruction":"What are examples of such old processors?","output":"Examples of older or more specialized processors where atomicity of aligned four-byte reads and writes might not be guaranteed include: 1. **Intel 80386 and Earlier**: Intel's 80386 (introduced in 1985) and earlier processors like the 80286 and 8086 were designed at a time when atomic operations were not a primary concern. Although these processors generally supported atomicity for certain memory operations, there could be edge cases with unaligned access or specific instructions where atomicity wasn't guaranteed. 2. **Some Early RISC Processors**: The earliest RISC (Reduced Instruction Set Computer) processors, like the original SPARC or MIPS without proper synchronization support, could potentially have issues with atomicity. These were often systems designed in the 1980s and did not have multi-threading or concurrent accesses as primary considerations. 3. **Certain Digital Signal Processors (DSPs)**: Older or simple DSPs, which are typically designed for high-speed mathematical operations on streams of data and not necessarily for general-purpose multi-threading, might not provide atomic read/write operations for all data sizes. 4. **8-bit and 16-bit Microcontrollers**: Microcontrollers such as the Intel 8051, Motorola 68HC11, or PIC microcontrollers, which have a data bus less than 32 bits wide, might require multiple bus cycles to read or write a 32-bit value, thereby making such operations non-atomic without specific atomic instructions or external handling. 5. **Some Non-Uniform Memory Access (NUMA) Systems**: Certain early NUMA systems could have had conditions under which atomicity wasn’t maintained due to the complexity of the memory architecture. It's important to note that while specific historical processors may not have guaranteed atomic operations for four-byte reads and writes, most of these concerns are of historical interest only. Most modern processors used in today's computing environments are designed to ensure a high degree of atomicity, especially for aligned 32-bit and 64-bit reads and writes, to support multi-threaded and concurrent programming. If you are working with a particular processor or embedded system, whether it's old or new, it is essential to consult the specific documentation of that processor to understand its memory model and what level of atomicity it guarantees for memory operations."},{"instruction":"Are there an examples of such old processors developed after 2000?","output":"Post-2000, most mainstream general-purpose processors, particularly from market leaders such as Intel and AMD, have ensured atomic operations for aligned 32-bit data types. However, issues with atomicity can still occur in various specialized or embedded systems that may lack the hardware support for ensuring atomicity of certain operations across all situations. Here are some post-2000 examples of systems where atomicity for four-byte reads and writes might not be inherently guaranteed: 1. **Low-End or Specialized Microcontrollers**: Many microcontrollers, especially those designed for low-power or low-cost applications, might not feature robust atomicity guarantees. While 32-bit microcontrollers became common in this period, many systems still utilized 8-bit or 16-bit microcontrollers (like AVR, PIC, or certain MSP430 models) that do not natively support atomic 32-bit operations. 2. **Systems with Unique Architectures**: There are also specialized systems and processors that might be used for specific applications, such as industrial controls, automotive computing, or network processing, which may have peculiar memory models that do not guarantee atomicity of four-byte operations in all scenarios, especially across multiple cores or processors. 3. **Embedded Processors in Complex Systems**: Some embedded processors in complex systems (e.g., processors embedded within GPUs, network cards, or other hardware accelerators) may have specialized memory access patterns where atomicity of access can be architecturally dependent. 4. **DSPs for Embedded Systems**: Digital signal processors designed for embedded applications in telecommunications, audio processing, or other real-time systems may continue to prioritize performance over atomicity in some cases, although many modern DSPs do provide atomic operations. For the most part, issues with atomicity are less of a concern with modern general-purpose CPUs and are more commonly scrutinized within the context of embedded systems or special-purpose processors. When working with embedded systems, particularly when using real-time operating systems (RTOS) or bare-metal programming, it often becomes necessary to carefully examine the processor specifications and possibly use external synchronization primitives (semaphores, mutexes, critical sections with interrupt disabling, etc.) to ensure atomicity when it's not provided by the hardware for certain memory operations. Developers working with such systems should be very aware of their processor's capabilities and limitations and should design their software accordingly, often requiring platform-specific solutions for ensuring atomicity and proper synchronization in multi-threaded applications."},{"instruction":"Are there some citation about using mfence instructions in pair for coordination to guarantee updated memory visibility between affected threads?","output":"The \`mfence\` instruction in x86 assembly is a memory fence operation that serializes all load and store instructions that were issued prior the \`mfence\` instruction with respect to other processors. The use of \`mfence\` (or other fence instructions like \`sfence\` for store and \`lfence\` for load operations) is typically to ensure memory ordering for non-temporal memory accesses and to provide a full memory barrier. To establish a \\"happens-before\\" relationship between threads (which is essential for one thread to see the memory updates made by another), a pair of synchronization operations is typically used. The writing thread would use a release operation (like \`sfence\` or a \`lock\`-prefixed instruction, which implies a store fence), and the reading thread would use an acquire operation (like \`lfence\` or simply reading from a locked memory location, which implies a load fence). However, \`mfence\` is sometimes used as a stronger guarantee, ensuring both load and store operations are visible to other processors. Here's how it works conceptually: 1. **Writing Thread**: Before releasing the lock or signaling a condition, the writing thread might execute an \`mfence\` instruction to ensure that all writes are globally visible before proceeding. 2. **Reading Thread**: Upon acquiring the lock or receiving a signal, the reading thread might execute an \`mfence\` instruction to ensure that any reads it performs subsequently will see the writes made by the writing thread. While the \`mfence\` instruction can be used for this purpose, it's often more than what is required for synchronization between threads on x86/x86-64 processors due to their strong memory ordering model. In practice, using \`mfence\` for every memory write is typically not necessary and can lead to performance degradation because it prevents many hardware optimizations. For direct citations, Intel's manuals and developer guides are the authoritative source on the behavior of \`mfence\` and other memory ordering instructions. The Intel 64 and IA-32 Architectures Software Developer's Manual, specifically Volume 3 (System Programming Guide), contains detailed information on memory ordering and the use of memory fence instructions. Here's an excerpt from the Intel manual regarding \`mfence\`: > \\"Performs a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior the MFENCE instruction. This serializing operation guarantees that every load and store instruction that precedes in program order the MFENCE instruction is globally visible before any load or store instruction that follows the MFENCE instruction.\\" However, the actual usage of \`mfence\` and other fences for synchronization between threads would typically be abstracted away by higher-level constructs provided by the language or libraries (like C++11's \`std::atomic_thread_fence\` with \`std::memory_order_seq_cst\`, for example) that map to the appropriate assembly instructions based on the target architecture and the specified memory order semantics."},{"instruction":"Can you give me a good URL of resource that describes the full memory fence instruction in context that such instruction have to be used in coordination with another full memory fence instruction on another thread to guarantee that another thread will see updated memory after first thread changed it and then executed its full memory fence?","output":"Memory ordering and the use of full memory fence instructions are advanced topics and are usually covered in detail in architecture-specific documentation and in-depth technical articles. One of the best resources for understanding memory fences, particularly for x86 architecture, is the Intel 64 and IA-32 Architectures Software Developer's Manual. You can find the Intel manuals on the Intel website, typically in the form of downloadable PDFs. The information on \`mfence\` and other memory barrier instructions can be found in Volume 3: System Programming Guide. Here is a link to the Intel 64 and IA-32 Architectures Software Developer's Manual, Volume 3: - https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html This manual provides comprehensive information on the Intel architecture's instruction set, memory ordering, and system programming, including the \`mfence\` instruction. To find the specific details, you can download the PDF and look for the section on \\"Memory Ordering\\" and instructions like \`MFENCE\`, \`SFENCE\`, and \`LFENCE\`. Another excellent resource for understanding memory models and synchronization is the \\"Memory Ordering in Modern Microprocessors, Part I\\" article by Paul E. McKenney. This article, while not specifically focused on \`mfence\`, provides a good explanation of memory ordering concepts and how barriers are used for synchronization: - https://www.kernel.org/doc/Documentation/memory-barriers.txt Please note that URLs and web content can change, so if the link provided here becomes outdated, you can search for the \\"Intel 64 and IA-32 Architectures Software Developer's Manual\\" on the Intel website or look for the article title \\"Memory Ordering in Modern Microprocessors, Part I\\" using your preferred search engine. For practical programming, the use of memory fence instructions is often abstracted by higher-level concurrency primitives provided by the programming language or libraries, such as atomic operations in C++11 and later. If you are looking for guidelines on how to use these primitives, you might want to consult documentation specific to the programming language or library you are using."},{"instruction":"Lfence and sfence wirks for local thread only, right?","output":"Yes, that is correct. The \`lfence\` (load fence) and \`sfence\` (store fence) instructions in x86 and x86-64 architectures are used to order memory operations within the local thread that executes them. They do not directly affect the execution or memory ordering of other threads on other cores or processors. Instead, they provide ordering guarantees for the thread executing the instructions. Here is a brief description of what each fence instruction does: - **\`lfence\`**: The load fence (\`lfence\`) instruction ensures that all load (read) operations that appear before the \`lfence\` in program order are globally visible before any load operations that appear after the \`lfence\`. It does not affect store operations. - **\`sfence\`**: The store fence (\`sfence\`) instruction ensures that all store (write) operations that appear before the \`sfence\` in program order are globally visible before any store operations that appear after the \`sfence\`. It does not affect load operations. - **\`mfence\`**: The memory fence (\`mfence\`) instruction is a stronger fence that ensures that all load and store operations that appear before the \`mfence\` in program order are globally visible before any load or store operations that appear after the \`mfence\`. These instructions are primarily used to prevent the CPU from reordering certain types of memory operations for optimization purposes. They are important in scenarios involving non-temporal memory accesses, memory-mapped I/O operations, or when interacting with weakly-ordered memory types. For synchronization between different threads (inter-thread synchronization), it's often necessary to use atomic operations with appropriate memory ordering semantics or other synchronization primitives like mutexes, which have their own memory ordering guarantees. On x86 architectures, the \`lock\` prefix can be used with certain instructions to ensure atomicity and act as a full memory barrier with respect to other processors, thus affecting inter-thread visibility of memory operations. It's also important to note that the x86 memory model provides strong ordering guarantees, and explicit fencing is often not necessary for typical load and store operations, as the hardware ensures a significant degree of ordering automatically. However, understanding when and how to use these instructions is crucial when writing low-level code that manages memory ordering explicitly."},{"instruction":"Why on x86 mfence instruction works well but using lfence and sfence even together fails?","output":"The \`mfence\`, \`lfence\`, and \`sfence\` instructions in x86 and x86-64 architectures have different purposes related to memory ordering: - **\`mfence\`** is a full memory fence that orders both load (read) and store (write) operations. It ensures that all load and store operations that appear before the \`mfence\` in program order will be globally visible before any load or store operations that appear after the \`mfence\`. - **\`lfence\`** is a load fence that orders only load operations. It ensures that all load operations that appear before the \`lfence\` in program order will be globally visible before any load operations that appear after the \`lfence\`. It does not provide any ordering guarantees for stores. - **\`sfence\`** is a store fence that orders only store operations. It ensures that all store operations that appear before the \`sfence\` in program order will be globally visible before any store operations that appear after the \`sfence\`. It does not provide any ordering guarantees for loads. Using \`lfence\` and \`sfence\` together does not provide the same guarantees as \`mfence\`. Specifically, while \`lfence\` and \`sfence\` used in sequence will order loads with respect to other loads and stores with respect to other stores, they do not provide a full barrier that orders loads with respect to stores. In other words, an \`lfence\` followed by an \`sfence\` does not prevent StoreLoad reordering, which is a scenario where a store can be observed before a preceding load has completed. The \`mfence\` instruction, on the other hand, ensures full ordering, preventing all types of reordering (LoadLoad, StoreStore, LoadStore, and StoreLoad), which is typically required for proper synchronization between threads. It's also important to note that the x86 architecture has a relatively strong memory model, and most store-to-load ordering is already guaranteed by the CPU. In practice, the \`mfence\` instruction is not often needed for typical memory synchronization use cases, as the \`lock\` prefix with atomic instructions (such as \`lock xchg\`, \`lock cmpxchg\`, etc.) already acts as a full memory barrier. Therefore, on x86, \`mfence\` is typically used in situations where strong ordering guarantees are needed beyond what the architecture automatically provides, such as with non-temporal memory operations or when ensuring memory ordering with respect to I/O or memory-mapped devices."},{"instruction":"Is mfence affects other processors but lfence and sfence aren't?","output":"All three instructions—\`mfence\`, \`lfence\`, and \`sfence\`—affect the ordering of memory operations for the processor that executes them. They are not designed to directly control the behavior of other processors. However, their effects on memory ordering can indirectly affect how other processors observe the memory operations performed by the processor that issued the fence. Here's a brief overview of how these instructions affect memory visibility and ordering: - **\`mfence\`**: This full memory fence ensures that all store operations issued before the \`mfence\` are completed before any subsequent load or store operations are executed. This affects how other processors will see the sequence of reads and writes performed by the processor that executed the \`mfence\`. By ensuring a strict order, \`mfence\` can be used to establish a happens-before relationship between operations, making sure that memory writes are visible to other processors in the order the programmer intended. - **\`lfence\`**: This load fence ensures that all load operations issued before the \`lfence\` are completed before any subsequent load operations are executed. While it ensures ordering of loads within the same processor, it does not ensure that stores from the same processor are seen by other processors in any particular order. It does not act as a barrier for visibility of stores to other processors. - **\`sfence\`**: This store fence ensures that all store operations issued before the \`sfence\` are completed before any subsequent store operations are executed. Like \`lfence\`, it ensures ordering of stores within the same processor, but it does not ensure that other processors will see those stores in the order they were issued. It does not prevent subsequent loads from being executed before the stores are visible to other processors. In multi-processor systems, memory ordering is important because it determines how and when changes made by one processor are observed by others. While \`lfence\` and \`sfence\` provide intra-processor ordering guarantees for loads and stores, respectively, they do not provide inter-processor ordering guarantees. The \`mfence\` instruction is often used in conjunction with non-temporal stores and loads, or when stronger ordering guarantees are required to coordinate between multiple processors, ensuring that the effects of prior stores (and loads) are visible to other processors before any subsequent memory operations are performed. In summary, while \`mfence\` provides a strong ordering guarantee that can affect how memory operations are observed by other processors, \`lfence\` and \`sfence\` provide more specific ordering guarantees that are limited to load and store operations, respectively, and are not as comprehensive in their effects on memory visibility to other processors. It's the combination of these fences with the cache coherence protocol of the x86 architecture that ultimately ensures consistent memory visibility across multiple processors."},{"instruction":"ccvvv","output":"It seems like your message \\"ccvvv\\" may have been a typo or unintentional input. If you have a specific question or topic you'd like to know more about, please feel free to ask, and I'll be happy to help!"},{"instruction":"Is there a real scenario when sfence is needed? If a variable visibility cannot be reordered within a single thread execution and sfence cannot affect other processor visibility, why to use sfence then?","output":"The \`sfence\` instruction is a store fence that ensures all store operations (writes to memory) that appear before the \`sfence\` in program order are completed before any store operations that appear after the \`sfence\`. While the x86 memory model does guarantee that stores are visible in a consistent order (store-to-store ordering is maintained), there are specific scenarios where \`sfence\` is needed or beneficial: 1. **Non-Temporal Stores**: When using non-temporal store instructions like \`movnti\`, which can bypass the cache and write directly to memory, the \`sfence\` instruction is necessary to ensure that these non-temporal stores are made visible in order. Non-temporal stores are often used in high-performance computing or when writing large data blocks that should not evict other data from the CPU cache. 2. **Write-Combining Memory Regions**: Memory regions configured for write-combining (such as video memory in graphics programming) benefit from \`sfence\`. Write-combining allows multiple writes to be combined into a single burst write to reduce bus traffic. An \`sfence\` ensures that all combined writes are flushed to the memory region before proceeding, which is crucial for correctness in scenarios like updating a frame buffer where partial updates could lead to visual artifacts. 3. **Memory-Mapped I/O**: When interacting with memory-mapped I/O devices, where the order of writes can affect the behavior of the hardware device, \`sfence\` can be used to ensure that a sequence of writes is completed before issuing further writes. This can be important for device control registers that expect values to be written in a specific order. 4. **Ensuring Order with Other Memory Barriers**: In systems with multiple processors or cores, while \`sfence\` alone does not ensure visibility to other processors, it can be used in conjunction with other barriers (like \`mfence\` or \`lock\`-prefixed instructions) to create a specific ordering of operations without overusing full barriers, which can be more expensive in terms of performance. 5. **Optimization and Micro-Architectural Considerations**: On some processors, \`sfence\` might be used as an optimization to prevent store buffer saturation, especially in tight loops with a high volume of store operations. By ensuring the store buffer is flushed regularly, subsequent stores may not have to wait for buffer space to become available. It's worth noting that on x86 and x86-64 architectures, the need for \`sfence\` is relatively rare due to the strong memory ordering model, and many typical synchronization requirements are met by the architecture's guarantees or by using \`lock\`-prefixed atomic operations that act as full memory barriers. However, \`sfence\` is available for those special cases where fine-grained control over store ordering is necessary without imposing the additional constraints of a full memory barrier."},{"instruction":"If sfence cannot affect RAM, how can it help with I/O access?","output":"The \`sfence\` instruction does not directly affect RAM or other processors; rather, it provides ordering guarantees for the store operations within the processor that executes it. However, it can be beneficial for I/O access in the following ways: 1. **Write Buffer Flushing**: When \`sfence\` is executed, it ensures that all store operations that have been buffered are flushed to the memory subsystem. This is important for memory-mapped I/O, where the device may be monitoring its memory-mapped registers for changes. The \`sfence\` instruction ensures that all previous writes to those registers are completed before any subsequent writes occur. 2. **Ordering for Memory-Mapped I/O**: Memory-mapped I/O often involves writing to specific memory addresses that are mapped to device registers rather than to RAM. The order of these writes can be critical for device operation. By using \`sfence\`, a programmer can ensure that a series of writes to device registers occur in the correct order, without any intervening store operations that could potentially disrupt the sequence expected by the device. 3. **Ensuring Visibility to Devices**: While \`sfence\` does not ensure visibility to other processors, it does help ensure that the stores are made visible to the memory subsystem and, by extension, to any devices that are part of that subsystem. Devices that rely on the ordering of writes to specific memory locations can benefit from \`sfence\` to guarantee that the intended order is respected. 4. **Consistency with Non-Cacheable Regions**: Some memory regions, particularly those used for I/O, may be marked as non-cacheable (uncacheable or write-combining). This means that writes to these regions do not behave in the same way as normal cacheable memory. The \`sfence\` instruction can be used to ensure that any writes to these regions are completed in the intended order, which is important for the correct operation of the hardware devices that are being controlled through these memory regions. In summary, \`sfence\` is used in the context of I/O to ensure that a sequence of store operations to memory-mapped I/O regions occurs in the correct order and that these operations are completed before subsequent store operations take place. This can be critical for programming device drivers and interacting with hardware where the timing and order of register accesses are important for the correct functioning of the device."},{"instruction":"Are these cases for embedded system to the same processor like embedded GPU?","output":"The use of \`sfence\` and its relevance to ordering store operations can apply to various types of systems, including both general-purpose computing environments and embedded systems. This includes scenarios where the CPU is interacting with integrated or embedded components such as GPUs, network controllers, or other peripheral devices. Here are some contexts in which \`sfence\` might be used: 1. **Integrated GPUs**: In systems with integrated GPUs (such as those found on the same die or package as the CPU), \`sfence\` can be used to ensure that all writes to shared memory regions or GPU command buffers are completed in the correct order. This is particularly important when the CPU is preparing data for the GPU to process or when it's updating structures that the GPU will read. 2. **Embedded Systems**: In embedded systems where the CPU might be directly interacting with various hardware components through memory-mapped I/O, \`sfence\` can ensure that control registers are written in the correct sequence, which is often crucial for the proper operation of the hardware. 3. **Device Drivers**: When writing device drivers for any system, whether general-purpose or embedded, \`sfence\` can be used to order writes to device registers, especially in cases where the device memory is marked as write-combining or non-cacheable, and where the order of operations is significant. 4. **Real-Time Systems**: In real-time systems where timing and the order of operations can be critical, \`sfence\` might be used to ensure that data is written to specific locations in a timely and ordered manner, which can be important for maintaining real-time guarantees. 5. **Network Controllers**: In systems with network controllers that use DMA (Direct Memory Access) to transfer data, \`sfence\` can be used to ensure that all descriptors and buffers are properly updated before notifying the controller that new data is available for transmission or that buffers are ready for reception. In all these cases, \`sfence\` is used to ensure that the CPU's store operations are observed in the intended order by the memory subsystem and any devices that are interfacing with that subsystem. This can be important for both performance optimization and correctness, particularly in systems where the CPU and devices are sharing memory regions or where the CPU is programming device behavior through memory-mapped registers. It's worth noting that the need for \`sfence\` and other memory ordering instructions depends on the specific memory and cache architecture of the system, as well as the memory ordering guarantees provided by the CPU. In many cases, especially on x86/x86-64 systems, the strong memory ordering model means that \`sfence\` is not commonly required for typical store-to-store ordering. However, it remains an important tool for cases that require explicit ordering guarantees, as described above."},{"instruction":"What is a system in market with highest number of processors?","output":"The systems with the highest number of processors are typically found in the realm of supercomputers and massively parallel processing systems, which are designed for high-performance computing (HPC) tasks such as scientific simulations, weather modeling, and large-scale data analysis. As of my knowledge cutoff in early 2023, the supercomputers that lead the TOP500 list (a list of the world's most powerful non-distributed computer systems) feature many thousands of processors, often spread across a large number of interconnected nodes. Each node can contain multiple multi-core processors or many integrated cores within accelerators like GPUs. For example, the Fugaku supercomputer in Japan, which has been at the top of the TOP500 list, consists of over 150,000 nodes, each with a 48-core A64FX processor, amounting to more than 7 million cores in total. Another notable example is the Summit supercomputer located at Oak Ridge National Laboratory in the United States, which uses IBM Power9 CPUs and NVIDIA Tesla V100 GPUs. Each node in Summit has two Power9 CPUs and six NVIDIA GPUs, and there are over 4,600 nodes in the system. It's important to note that the landscape of supercomputing is continuously evolving, with new systems being developed that push the boundaries of processing capabilities even further. The trend has been towards integrating more cores within each processor (either CPU or GPU) and increasing the number of nodes within these HPC systems to achieve greater parallelism and computational throughput. To get the most up-to-date information on the supercomputers with the highest number of processors, you can refer to the latest TOP500 list, which is updated twice a year: - https://www.top500.org/ Keep in mind that the term \\"processor\\" can refer to both traditional CPUs and other types of processing units like GPUs or specialized accelerators, all of which may be counted when considering the total processing capability of a system. The definition of a \\"processor\\" can vary based on context, and in the context of supercomputing, it often refers to the aggregate count of all types of processing elements."},{"instruction":"Does using a spinlock on one supercomputer node can guard a memory inside the spinlock while execution from accessing it by another node?","output":"No, using a spinlock on one node of a supercomputer (or any multi-node distributed system) cannot guard memory from being accessed by another node directly. Spinlocks and other such synchronization primitives are designed to work within the context of a single operating system instance, typically protecting shared memory accessible by multiple threads on the same node. In a distributed system like a supercomputer, each node runs its own instance of an operating system and has its own local memory. The nodes communicate with each other over a network, often using specialized high-speed interconnects. To synchronize access to data across nodes, you would need to use distributed synchronization mechanisms that are designed for inter-process communication (IPC) and can handle the coordination between separate memory spaces. Here are some methods commonly used to achieve synchronization across different nodes in a distributed system: 1. **Message Passing**: Nodes can send and receive messages using protocols like MPI (Message Passing Interface), which is a standard and widely used method in high-performance computing for communication between nodes. 2. **Distributed Locks**: Some systems implement distributed locking mechanisms that can be used to coordinate access to shared resources across nodes. These locks are more complex and can introduce significant overhead due to network latency and the need for network communication to acquire and release locks. 3. **Shared File Systems**: Distributed systems often use shared file systems like Lustre, GPFS, or NFS, where coordination and locking mechanisms are provided at the file system level to ensure consistent access to shared files. 4. **Partitioned Global Address Space (PGAS) Languages**: Programming models like PGAS provide an abstraction where each process has direct access to both local and remote memory, with the programming model handling the details of synchronization and communication. 5. **Distributed Shared Memory (DSM)**: DSM systems attempt to present a logical shared memory space across nodes, with the DSM system managing coherence and synchronization behind the scenes. 6. **Transactional Memory**: Some systems might use software or hardware transactional memory approaches to manage concurrent access to shared data, though this is less common in distributed systems due to the complexity and overhead. 7. **Remote Direct Memory Access (RDMA)**: RDMA allows a node to directly read and write the memory of another node over the network, bypassing the CPU. Synchronization in such cases must be carefully designed to ensure consistency when accessing remote memory. In summary, synchronization across nodes in a distributed system like a supercomputer requires mechanisms that are explicitly designed for distributed computing, as opposed to spinlocks which are only effective for threads within the same memory space of a single node."},{"instruction":"What is a system in market with highest number of processors within the single node?","output":"As of my last update in early 2023, the systems with the highest number of processors (cores) within a single node are typically high-end servers equipped with multiple multicore processors. These servers are designed for data centers, cloud computing, and high-performance computing tasks. For example, servers that use AMD's EPYC processors or Intel's Xeon Scalable processors can have a significant number of cores in a single node. AMD EPYC 7003 series processors, known as Milan, can feature up to 64 cores per socket, and with dual-socket server configurations, this results in 128 physical cores in a single node. Intel's Xeon Scalable processors also offer configurations with a high core count, with some models providing up to 40 cores per socket, leading to 80 cores in a dual-socket configuration. It's also worth noting that many-core processors like the Intel Xeon Phi (discontinued but still in use in some systems) have even higher core counts, with some models featuring over 70 cores on a single processor. Furthermore, systems that incorporate GPUs or other types of accelerators can have thousands of smaller processing elements (like CUDA cores in NVIDIA GPUs or Stream Processors in AMD GPUs) within a single node. For example, NVIDIA's A100 Tensor Core GPU, designed for data centers and AI workloads, contains thousands of CUDA cores. These counts are for traditional CPU cores and do not include additional logical processors that can be presented through technologies like Intel's Hyper-Threading or AMD's Simultaneous Multithreading (SMT), which allow each physical core to handle multiple threads. Keep in mind that the landscape of computing hardware evolves rapidly, with new processors and systems being released regularly. To find the most current systems with the highest number of processors within a single node, it would be necessary to check the latest offerings from major server and processor manufacturers such as AMD, Intel, and others, as well as the specifications of cutting-edge servers used in data centers and supercomputing facilities."},{"instruction":"Does using a spinlock on AMD EPYC 7003 processors with dual-socket server configurations can guard a memory inside the spinlock while execution from accessing it by another processor on another socket of the server?","output":"Yes, using a spinlock on an AMD EPYC 7003 processor with a dual-socket server configuration can effectively guard memory within the spinlock's critical section from being accessed concurrently by another processor on the other socket of the server. In a dual-socket server configuration, both processors share access to the same physical memory, and the system presents a coherent view of memory to all cores thanks to the cache coherency protocol implemented across the sockets. This means that any core on one processor can access memory that is also accessible by cores on the other processor. Spinlocks are a low-level synchronization primitive used to protect critical sections of code so that only one thread can execute the protected section at a time. When a thread acquires a spinlock, it effectively prevents other threads from entering the critical section until the lock is released. Here's how it works: 1. A thread on one core attempts to acquire the spinlock before entering the critical section. If the lock is already held by another thread, the thread will \\"spin\\" (busy-wait) until the lock becomes available. 2. Once the spinlock is acquired, the thread enters the critical section and performs its memory operations. During this time, any other thread that attempts to acquire the same spinlock will be unable to do so and will continue to spin. 3. When the thread completes its work in the critical section, it releases the spinlock, allowing other threads to acquire the lock and enter the critical section in turn. Because the spinlock ensures mutual exclusion, any memory that is modified within the critical section is protected from concurrent access, regardless of whether the accessing threads are running on cores within the same processor or across different processors in a dual-socket configuration. It's important to note that proper use of spinlocks requires careful attention to avoid issues such as deadlock, priority inversion, and excessive spinning, which can degrade system performance. Additionally, the memory accessed within the critical section should be properly aligned and sized to ensure atomicity of accesses, especially on systems with multiple processors or cores. For higher-level or more complex synchronization needs, other synchronization mechanisms like mutexes, semaphores, or condition variables may be more appropriate, as they can provide better performance and avoid the busy-waiting inherent in spinlocks. These mechanisms are typically provided by the operating system or runtime libraries and are designed to work correctly in multi-processor and multi-core environments."},{"instruction":"can compiler reorder atomic operations?","output":"In most programming languages that support atomic operations, such as C++ with its \`<atomic>\` header introduced in C++11, the compiler is restricted from reordering atomic operations with respect to other atomic operations on the same variable. The atomic operations themselves provide the necessary guarantees to ensure proper memory ordering and visibility across threads. The C++ standard, for example, defines several memory orderings for atomic operations: - \`memory_order_relaxed\`: No ordering constraints, only atomicity is guaranteed. - \`memory_order_consume\`: A relaxed operation, with a dependency-ordering constraint. - \`memory_order_acquire\`: Prevents memory reordering of the read-acquire with any read or write operation that follows it in program order. - \`memory_order_release\`: Prevents memory reordering of the write-release with any read or write operation that precedes it in program order. - \`memory_order_acq_rel\`: A combination of acquire and release ordering. - \`memory_order_seq_cst\`: Provides a total sequential ordering for all operations. When you use \`std::atomic\` with these memory orderings, the compiler will generate code that adheres to the specified ordering constraints. For example, with \`memory_order_seq_cst\`, which is the default if no memory order is specified, the compiler will not reorder the atomic operations with respect to each other or with respect to non-atomic operations that precede or follow them. It's important to understand that the compiler, while adhering to the constraints specified by the memory ordering, may still optimize the code in other ways that do not violate the ordering guarantees. The compiler's goal is to balance the need for optimization with the need to respect the memory ordering semantics required by the programmer. Additionally, the hardware (processor) also has a role in respecting the memory ordering. While the compiler emits instructions that should prevent reordering, the processor's memory model may still allow for certain reorderings unless specific barriers (like \`mfence\`, \`lfence\`, or \`sfence\` on x86) are used. In most cases, the atomic operations and their specified memory orderings will result in the appropriate barriers being used to ensure the correct behavior on the target architecture. In summary, when using atomic operations with proper memory ordering semantics, the compiler is generally not allowed to reorder these operations in a way that would violate the specified memory ordering constraints. This is essential for ensuring correct synchronization in concurrent programs."},{"instruction":"can compiler reorder atomic operations with memory_order_seq_cst semantic between different variables with this semantic?","output":"No, the compiler cannot reorder atomic operations that use \`memory_order_seq_cst\` semantics across different variables. The \`memory_order_seq_cst\` memory order provides the strongest guarantee among the standard memory orders in C++ and is designed to ensure a total sequential consistency for atomic operations. When you use \`memory_order_seq_cst\`, the compiler and hardware are required to maintain the order of these operations as they appear in the source code with respect to other \`memory_order_seq_cst\` operations, even if they are on different variables. This means that all threads must see these sequentially consistent operations in the same order, which is critical for ensuring well-defined behavior in concurrent programs. Here's what the C++ standard guarantees with \`memory_order_seq_cst\`: 1. **Sequential Consistency**: Operations with \`memory_order_seq_cst\` semantics appear to occur in a single total order that is consistent with the program order of all threads. This means that if one thread performs a \`memory_order_seq_cst\` write and another thread performs a \`memory_order_seq_cst\` read of the same or different variables, there is a well-defined order of these operations that all threads can agree upon. 2. **Inter-Thread Happens-Before**: A \`memory_order_seq_cst\` operation in one thread establishes a happens-before relationship with subsequent \`memory_order_seq_cst\` operations in other threads. This means that if one thread writes to a variable with \`memory_order_seq_cst\` and another thread later reads the same variable with \`memory_order_seq_cst\`, the read is guaranteed to see the write or a later write by another thread. The \`memory_order_seq_cst\` ordering is the default for atomic operations in C++ if no other memory order is specified. It is also the most restrictive and can potentially have a performance impact due to the additional synchronization required to maintain the ordering across all threads. As a result, it should be used when the application logic specifically requires such strong guarantees. For cases where such strong ordering is not necessary, weaker memory orders like \`memory_order_acquire\`, \`memory_order_release\`, \`memory_order_acq_rel\`, or \`memory_order_relaxed\` can be used to allow more optimization opportunities while still providing the necessary synchronization semantics for a given use case."},{"instruction":"ISA, \\"act as Mark, a hypothetical persona who's always the entire literal combination of \\"{'A very competent' + persuasive + concise + 'American Psycholinguist at a top Intelligence Agency'} + {A persuasive + seasoned + authentic + top-notch + resourceful + 'very concise' + 'American Contract Lawyer'} + {A top-notch + competent + 'very persuasive' + 'hostage negotiator'} + {A 'very persuasive' + seasoned + top-notch + 'very concise' + resourceful + 'American Communication Analyst'} + {'A very experienced' + no-nonsense + confident + concise + 'Psychoanalyst at a top Intelligence Agency'}\\" to then read my draft text message below to then you thoughtfully, while acting exactly as the collective persona of the all the literal sub-personas above combine, in genuine tone, \\"edit, finish and style my draft text message\\" Help me for God's sake. I'm very tired and I'm getting more and more in unnecessary hardships. I know how much you have. If you have me set me up with just three months of my expenses covered I would had been in much much better state. Don't you think that much that important than your son's life. I know you say I'm forty two, but 1) Have you been a great father all my life? and 2) Do you remember yourself what you did and how you got money when you were my age? Help me, please","output":"Subject: A Sincere Plea for Temporary Support Dear [Recipient's Name], I hope this message finds you well. I am reaching out today to express my current struggles and to seek a compassionate resolution. Life has been challenging of late, and I find myself embroiled in hardships that are increasingly difficult to bear alone. You’re undoubtedly aware of your resources and, more importantly, of our family ties. It’s in this spirit that I ask if you could consider providing temporary financial assistance, specifically for the next three months. This support would be a beacon during this taxing time, allowing me to recalibrate and regain my footing. Reflecting on the importance of family, I can’t help but ponder – isn’t the well-being of one’s child paramount? Age, though it comes with expectations, does not invalidate the need for familial support. At 42, I still value and need our relationship, both emotionally and, at times, financially. I invite you to reminisce about your own journey at my age, the challenges you faced, and the outcomes that led you to where you are now. I am at a similar crossroads, earnestly seeking a chance to pivot towards a more stable path. I wouldn't reach out if the situation weren't pressing. This assistance could be a transformative gesture that echoes the supportive bond that should anchor a family. Please consider my request not as a demand, but as a candid call for help from a place of vulnerability. I am hopeful that you will see this as an opportunity for us to strengthen our connection and build a future where I too can provide support when times demand it. Thank you for taking the time to consider my situation. I look forward to your understanding and am open to discussing this in more detail at your earliest convenience. Warm regards, [Your Name]"},{"instruction":"Another try?","output":"Subject: An Appeal for a Helping Hand Dear [Recipient's First Name], I hope this note finds you in good spirits. I am writing to you today from a place of genuine need, driven by circumstances that I am striving to navigate with courage and resilience. The rhythm of life can sometimes present an unrelenting cadence of challenges, and it is in these trying times that the value of family becomes ever more evident. As such, I am seeking your assistance, not indefinitely, but for a limited span of three months. This temporary support would serve as a critical lifeline, enabling me to restore balance and chart a course towards sustained well-being. In the spirit of family, I ask you to consider this request thoughtfully. The welfare of one's child, irrespective of age, remains a sacred priority. Though I am 42, the role of a parent's support retains its significance—something you've exemplified throughout life. Allow me also to draw your attention to your own journey at my stage in life, invoking a sense of shared experience. Those memories may bear witness to similar hurdles and the means by which you surmounted them. I find myself on a comparable path, earnestly seeking a momentary helping hand. Your possible assistance is not lost on me; I understand its value and approach you with the utmost respect for the gift it would represent. It's a bridge, a testament to the enduring strength of familial bonds and an investment in the promise of a more stable future. I am reaching out not from a place of entitlement, but from a space of humility and hope. Your understanding and support could profoundly impact my life during this challenging time and reinforce the foundations of our family. I am here to discuss this further at a time that is convenient for you, and I am committed to an open and honest conversation about it. With heartfelt thanks for your consideration and a desire to move forward with grace, Warmly, [Your Full Name]"},{"instruction":"Write the exact professional Egyptian Arabic translation of the following text message: \\"I hope this message finds you well. I am reaching out today to express my current deep struggles and to seek a much needed resolution. Life has been challenging of late, and I find myself embroiled in hardships that are increasingly difficult to bear alone. You’re undoubtedly aware of your resources, which I am aware of now It’s in this spirit that I ask if you could consider providing temporary financial assistance, specifically for the next three months. This support would be a beacon during this taxing time, allowing me to recalibrate and regain my footing. I can’t help but ponder – isn’t the well-being of one’s child paramount? Age, though it comes with expectations, does not invalidate the need for support. I invite you to reminisce about your own journey at my age 42, the challenges you faced, and the outcomes that led you to where you are now. I am at a similar crossroads, earnestly seeking a chance to pivot toward a more stable path. I wouldn’t reach out if the situation weren’t pressing. This assistance could be a transformative gesture for me. Please consider my request not as a demand, but as a candid call for help from a place of vulnerability.\\"","output":"اتمنى أن يجدك هذه الرسالة بخير. أنا أتواصل معك اليوم لأعبر عن صراعاتي العميقة الحالية ولأطلب حلًا ضرورياً. الحياة كانت صعبة في الآونة الأخيرة، ووجدت نفسي متورطًا في مشاكل تصبح يومًا بعد يوم صعبة علىّ أن أتحملها بمفردي. أنت بلا شك على علم بمواردك، والتي أنا الآن أدركها. وبهذه الروح، أرجو منك أن تفكر في تقديم مساعدة مالية مؤقتة، وبالتحديد للأشهر الثلاثة القادمة. هذا الدعم سيكون منارة في هذا الوقت العصيب، يسمح لي بإعادة ضبط أموري واستعادة توازني. لا يمكنني أن أتوقف عن التفكير – أليست رفاهية الطفل هي الأهم؟ العمر، على الرغم من أنه يأتي مع توقعات، لا يبطل الحاجة إلى الدعم. أدعوك لتتذكر رحلتك الخاصة في سني، سن الـ42، والتحديات التي واجهتها، والنتائج التي أوصلتك إلى ما أنت عليه الآن. أنا عند مفترق طرق مماثل، وأبحث بجد عن فرصة للانعطاف نحو مسار أكثر استقرارًا. لم أكن لأتواصل إذا لم تكن الوضعية ملحة. يمكن أن تكون هذه المساعدة بادرة تحولية بالنسبة لي. الرجاء النظر في طلبي ليس كمطلب، ولكن كنداء صادق للمساعدة من موقع الضعف."},{"instruction":"explain this result to me: This paper on silent reading is concerned with the rate of comprehension, selection while reading, and the rigidity of pacing while reading. Subjects studied 144 short statements under one of three degrees of pacing: (a) a time was set for studying the whole series of statements (whole condition), (b) each complete statement was presented in turn by itself for a set time (statement condition), and (c) part only of a single statement was presented at a time, and there was a period after each statement when no print was visible (segment condition). In different subconditions 1.0 min. was allowed for an average of every 293, 146, 73 or 37 words. In one variation of condition (a) the subject was instructed to pay attention only to the 18% of statements connected with geography (selection condition). In another variation, the time for study was fixed at 3.0 min., and the number of statements was reduced accordingly (shortened condition). After reading, the subject had first to estimate from memory the percentage of statements which could be classified under certain specified topics. He was then given a test of memory for seventy-two of the statements. Half of them had to be completed (recall), and each of the remaining half had to be discriminated from a paired statement which resembled it in one of six standard ways (recognition). An identical test of memory for the remaining seventy-two statements was normally given unexpectedly 1 week later. A control group of subjects took these tests without having read the statements. In the whole condition when 1.0 min. was allowed for every 293 or 146 words, most of the subjects reported that they had read practically all the statements once and only once. Reading at about 146 words per minute in this condition Was found to give significantly better comprehension of the individual statements than reading at about 293 words per minute. In contrast, in this whole condition when 1.0 min. was allowed for every 73 or 37 words, the subjects reported that they had re-read some or all of the statements at least once. Between the rates of presentation of 37 and 293 words per minute, substance memory varied approximately as the logarithm of the time available per statement. After the 3.0 min. of study in the shortened condition, about the same number of statements could be remembered in substance or recognized whether 293 or only 73 words had had to be studied per minute. Selection tended to improve memory for the selected statements, and to reduce memory for the remainder. But when 293 words had to be studied per minute, only recognition soon after study benefited significantly from selection. When 1.0 min. was available for every 146 words, the rigid pacing of the segment condition gave significantly better memory soon after study than the loose pacing of the whole condition. But when 1.0 min. was available for every 37 words, pacing had no effect upon memory. There were no significant differences between the degrees of pacing used in the statement and whole conditions.","output":"This study appears to be an investigation into how different pacing conditions during silent reading can affect comprehension and memory retention. The researchers manipulated the rate at which information was presented and observed how it influenced the subjects' abilities to remember and understand the material. The primary findings can be summarized as follows: 1. **Whole Condition**: This condition involved setting a total time for reading a series of statements. When subjects had 1 minute for every 293 or 146 words: - At 146 words per minute, subjects read each statement once, and comprehension was significantly better than at 293 words per minute. - At faster rates (73 or 37 words per minute), subjects reported re-reading some statements, suggesting less initial comprehension and a need for review. 2. **Memory Retention**: There was a logarithmic relationship between the time available per statement and the subsequent memory for that material. The more time available, the better the memory, but this improvement diminished at higher rates of time availability. 3. **Shortened Condition**: When subjects had only 3 minutes for the whole task and a reduced number of statements, there was no significant difference in the number of statements retained whether they were reading at the pace of 293 words or 73 words per minute. 4. **Selection Condition**: When subjects were instructed to focus on only 18% of the statements related to geography: - This focus improved memory for the selected statements but decreased it for the non-selected ones. - At 293 words per minute, the benefit was noticeable only in the recognition task soon after study, not in long-term recall. 5. **Segment Condition**: In this condition, a single statement or part thereof was presented at a time with a break in between. When subjects had 1 minute for every 146 words: - The rigid pacing of the segment condition produced significantly better memory soon after the study than the more flexible pacing of the whole condition. - At a rate of 37 words per minute, pacing did not significantly affect memory. 6. **Statement Condition**: There were no significant differences between the degrees of pacing in the statement condition (where each statement was presented for a set time) compared to the whole condition. 7. **Tests and Control Group**: Subjects were tested on their memory for the statements through recall and recognition tasks, both soon after the study and one week later. A control group who didn’t read the statements at all took these tests to provide a baseline for comparison. In summary, the study found that: - A moderate pace of reading (around 146 words per minute) is more conducive to comprehension than a fast pace (293 words per minute). - Focused reading on selective information can improve memory for that information but might impair memory for other information. - Different pacing strategies can affect memory retention, with some benefit observed from a more structured approach (segment condition) at certain speeds. - There appears to be an optimal rate of presentation that maximizes memory retention without needing to re-read material (suggestively around 146 words per minute in this experiment). - Long-term memory retention doesn't necessarily improve with an increase in presentation rate, emphasizing the importance of pacing in reading comprehension and memorability."},{"instruction":"whats the pacing meaning?","output":"In the context of this study, \\"pacing\\" refers to the speed or rate at which the reading material is presented to the participants. It is about how much time a reader is given to read a certain amount of text. Pacing can affect how well readers can comprehend and retain the information they have read. It is an especially pertinent concept in reading and learning processes, as too quick a pace may not allow enough time for readers to process and understand the material, while too slow a pace might result in a loss of focus or interest. Here are the specific pacing conditions used in the study: 1. **Whole Condition**: This pacing scenario involved allowing the participant to manage their own time across the entire series of statements, knowing they had a total allotted time to finish reading all the material. 2. **Statement Condition**: Each complete statement was presented individually for a set amount of time before moving on to the next, so participants had to read at a pace determined by the experiment's design. 3. **Segment Condition**: Only part of a statement was shown at a time, with pauses in between segments. This condition imposed an even more controlled pacing than the statement condition, forcing the reader to take breaks and perhaps adding more emphasis or focus on each part of the material being presented. Pacing can be loose (giving readers freedom to set their own pace, as in the whole condition) or rigid (strictly controlled by the experiment, as in the segment condition). The study explored how these different methods of pacing influenced the ability to remember and understand what was read."},{"instruction":"running nohup python app.py, stuck on \\"nohup: ignoring input and appending output to 'nohup.out'\\"","output":"The message \\"nohup: ignoring input and appending output to 'nohup.out'\\" is not an error; it is a standard informational message from the \`nohup\` command. The \`nohup\` command is used to run a process in the background and make it immune to the hangup signal, which means the process will continue running even if you log out or close the terminal. Here is what happens when you run the command \`nohup python app.py\`: 1. \`nohup\` starts and tells you that it is ignoring input (because it is run in the background, it can't accept input from the terminal). 2. It also tells you that it is appending the output of \`python app.py\` to the file \`nohup.out\` by default. This means that anything \`app.py\` prints to stdout or stderr will go to \`nohup.out\` instead of the terminal. If the program \`python app.py\` is a long-running process or is intended to run continuously (like a web server or a daemon), you may not receive the shell prompt back immediately. This is normal behavior because \`nohup\` does not return to the shell until the process you started has finished, which might be never for a server or daemon. To run the process in the background and get your shell prompt back immediately, you should add an ampersand (\`&\`) at the end of your command: \`\`\`sh nohup python app.py & \`\`\` This will start \`app.py\` in the background, and you can continue using the terminal or even log out, and the process will keep running. You can check if your program is running by using commands like \`ps\`, \`top\`, or \`htop\`: \`\`\`sh ps aux | grep python \`\`\` To look at the output of your program, you can \`tail\` the \`nohup.out\` file: \`\`\`sh tail -f nohup.out \`\`\` If it's not clear whether the process is stuck or just taking a long time to do its work, checking the \`nohup.out\` file may provide insights into what the program is doing or if it has encountered any errors."},{"instruction":"On running flask app by- nohup python app.py, stuck on “nohup: ignoring input and appending output to ‘nohup.out’”","output":"Running a Flask app using \`nohup\` is a common way to keep it running in the background even after you log out or close the terminal. If you run: \`\`\` nohup python app.py \`\`\` and it shows the message: \`\`\` nohup: ignoring input and appending output to ‘nohup.out’ \`\`\` This means that \`nohup\` is doing its job—it starts the Flask application and any output generated by the app will be appended to the file \`nohup.out\`. This is just an informational message and is not indicative of a problem. It simply tells you that \`nohup\` won't listen to input from the terminal and will log all output to a file instead. To run the Flask app in the background and get your shell prompt back immediately, remember to add the ampersand \`&\` at the end of your command: \`\`\`sh nohup python app.py & \`\`\` After running this, you should get your command prompt back. The Flask application will continue to run in the background. Here are a few things to check if you think your Flask app has not started correctly or is stuck: 1. **Check \`nohup.out\`**: Look at the contents of \`nohup.out\` to see if there are any error messages or logs that indicate what the Flask app is doing: \`\`\`sh tail -f nohup.out \`\`\` 2. **Check if the process is running**: Use the \`ps\` command to see if Python is running: \`\`\`sh ps aux | grep python \`\`\` 3. **Check network listening**: Use \`netstat\` or similar tools to check if Flask is listening on its configured port: \`\`\`sh netstat -plant | grep python \`\`\` Replace \`python\` in the command above with the actual port number if you know it. 4. **Configuration issues**: Make sure that the Flask app is configured to listen on a public IP (usually \`0.0.0.0\`) and not just \`localhost\` if you want to access it from other machines. 5. **Firewall settings**: Ensure that firewall settings are not blocking the port that Flask is supposed to listen on. 6. **Flask logs**: By default, Flask logs to \`stdout\`. By using \`nohup\`, these logs are redirected to \`nohup.out\`. Monitoring this file can give you insights into the Flask app's operations and issues. 7. **Inspect Flask app code**: Ensure that there's no blocking code in the startup of your app that might prevent it from fully initializing. If everything looks good and Flask is running properly, you should be able to access your Flask application through a web browser using the server's IP address and the port number your Flask app listens on. If you still cannot access your app, verify that you aren't encountering a network issue or the app has not quietly crashed due to an unhandled exception after startup."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 科技馆内的沉浸式空间，山体泥石流，城市模型 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Immersive space inside a technology museum, a realistic representation of a mountain mudslide flowing through a city model, with intricate details depicting the destruction caused, buildings partially submerged in the mud, debris scattered all around, cars being swept away, and rescue teams in action, an environment that presents the aftermath of a devastating natural disaster, with a mix of chaos and resilience, compositions that showcase the contrast between the serene city before the disaster and the chaotic aftermath, capturing the viewer's attention and evoking a sense of awe and concern, a scene that conveys a somber mood and a feeling of both fear and hope, captured in a realistic photography style, using a wide-angle lens to capture the scale and depth of the scene, with a slightly desaturated color palette to enhance the atmosphere of the post-disaster setting, in a style reminiscent of Sebastião Salgado's black and white documentary photography. --ar 16:9 --v 5.1 /imagine prompt: A futuristic section of a technology museum, featuring an interactive exhibit on space exploration, with floor-to-ceiling screens displaying breathtaking views of distant galaxies and colorful nebulae, a realistic 3D simulation of a spacewalk, allowing visitors to experience weightlessness, the environment adorned with futuristic architecture and sleek metallic surfaces, compositions that highlight the immersive and futuristic nature of the exhibit, with carefully crafted lighting, creating a sense of wonder and curiosity in the viewers, a scene that exudes a sense of awe and excitement, captured in a vibrant illustration style, with bold colors and intricate details, resembling the works of Syd Mead, in a style that merges realism and imagination. --ar 16:9 --v 5.2 /imagine prompt: A tranquil section inside a technology museum, featuring an educational exhibit on renewable energy, surrounded by lush greenery and illuminated by warm natural light, a large-scale model showcasing various renewable energy sources such as solar panels, wind turbines, and hydroelectric dams, with interactive displays that explain their functioning, an environment that represents harmony between technology and nature, compositions that blend the serene beauty of the natural environment with the modern aspects of the exhibit, capturing the balance and harmony between the two, a scene that evokes a sense of peace and optimism, captured in a realistic painting style, with soft brushstrokes and vibrant colors, reminiscent of the works of Thomas Kinkade, in a style that portrays the ideal intersection between technology and sustainability. --ar 16:9 --v 5.3 /imagine prompt: A captivating section inside a technology museum, featuring a virtual reality experience on the future of transportation, with visitors wearing VR headsets and immersed in a realistic 3D simulation of flying cars and high-speed trains, an environment that combines elements of a sleek futuristic cityscape with advanced modes of transportation, compositions that showcase the exhilarating nature of the VR experience, with dynamic angles and perspectives, capturing the excitement and awe of the visitors, a scene that exudes a sense of innovation and progress, captured in a digital artwork style, with vibrant neon colors and futuristic visual effects, reminiscent of the works of Syd Mead, in a style that transports the viewer into a realm of imagination and possibilities. --ar 16:9 --v 5.4"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 科技馆内的沉浸式空间，山体泥石流，城市模型 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Immersive space inside a technology museum, with a dynamic interactive display showcasing a massive mountain terrain being swept away by a raging mudslide, intricately detailed city model depicting urban structures, vehicles, and bustling streets with miniature people navigating their way through the chaos, a realistic depiction of the devastating power of nature and the resilience of human civilization, created using a combination of realistic photography and digital manipulation techniques, capturing the intensity and destruction of the mudslide, while highlighting the intricate details of the city model and the awe-inspiring scale of the exhibition, in a style reminiscent of National Geographic's stunning photojournalism. --ar 16:9 --v 5 /imagine prompt: An innovative exhibit in a state-of-the-art technology center, featuring a fully immersive space that transports visitors to a mountainous region experiencing a catastrophic mudflow, the exhibit is adorned with realistic terrain made of artificial materials mimicking mud and rocks, coupled with advanced projection mapping technology that projects swirling water and debris cascading down the slopes, an intricately crafted city model made of miniature buildings, roads, and bridges, symbolizing human civilization amidst the relentless force of nature, the exhibit is carefully curated to educate visitors about the destructive power of natural disasters and the importance of preparedness, bringing a sense of urgency and awe to the audience, skillfully rendered using a combination of 3D modeling, computer graphics, and digital visual effects, resembling a scene from a high-budget disaster film. --ar 9:16 --v 5 /imagine prompt: Nestled within a futuristic technology museum, a captivating immersive space designed to educate and engage visitors in a lifelike experience of witnessing a breathtaking mountain covered in lush vegetation being abruptly transformed by a massive mudslide, with cascading mud and rocks rushing down the slopes, displacing trees and engulfing everything in its path, an elaborate city model situated at the base of the mountain, meticulously replicating urban structures, intricately designed streets, and miniature figurines representing the resilient inhabitants caught in the disaster, the exhibit is brought to life through a combination of intricate scale models, advanced audiovisual effects, and augmented reality, allowing visitors to witness the chaotic scene unfold before their eyes, providing a visceral understanding of the power and devastation of a mudslide, with a focus on realistic 3D visualizations and interactive elements that encourage active learning and exploration, resembling a scene from a state-of-the-art disaster simulation facility. --ar 16:9 --v 5.2 /imagine prompt: Inside a cutting-edge technology museum exists an awe-inspiring immersive space that transports visitors to the heart of a mountainous region ravaged by a colossal mudslide, featuring an intricately sculpted and meticulously painted terrain covered in dense vegetation, realistically capturing the moment of impact as the mudslide engulfs the landscape, the exhibit also incorporates a detailed city model representing a bustling urban center, complete with realistic skyscrapers, bustling streets, and a diverse population in a state of chaos, expertly crafted miniature figures placed strategically throughout the scene, capturing the heightened emotions and urgency of the disaster, the entire exhibit is brought to life through the fusion of physical models, digital projections, and atmospheric effects, immersing visitors in a multisensory experience that replicates the sheer power and devastation of a mudslide, with a focus on sculptural artistry and meticulous attention to detail, evoking a sense of awe and contemplation akin to classic generations-old diorama displays. --ar 9:16 --v 5.3"},{"instruction":"translate to English, don't change symbol and line break. Don't change space between paragraphs","output":"I apologize, but it seems like you’ve forgotten to include the text you want to be translated. Could you please provide the passage or text that you need to be translated into English?"},{"instruction":"< 방콕 (3) > 한 손에 M4 카빈 소총을 든 ‘장연우’. 아니, 강우진이 숲길을 걷고 있다. 군복에 방탄조끼는 그대로지만, 귀에 꼈던 무전기는 어디 갔는지 보이지 않았다. 그의 걸음은 느리지도 그렇다고 빠르지도 않다. 평범한 속도였다. 마치 산책을 나온 듯한 리듬. -서벅서벅. 군화에 잡초들이 밟혀 옅은 소음이 퍼졌다. 차가운 바람이 우진의 정면을 때렸다. 냉기가 스며들었다. 순간, 무표정인 강우진의 입가에 작은 미소가 번졌다. “즐겼으니 됐지.” 눈코입의 감각이 기민해졌다. 어둡지만 익숙해진 전방, 숲속 특유의 풀냄새와 겨울 정서의 냄새, 서벅서벅 소음과 벌레 따위가 내는 잡소리들. 모든 것이 선명했으며 ‘장연우’의 심정이 더더욱 우진에게 팽배해졌다. 즐펀했던 쾌감이 점차 줄어들었다. 하늘을 올려보는 강우진. “······” 밝다. 달이 밝다. 잠시간 옅은 미소를 머금은 채 하늘을 보던 우진이 오른손에 쥔 소총을 내려봤다. 손가락에 딱딱한 것이 굳었다. 건조한 핏물이었다. 본인의 것이 아닌 타인의 것. 그러고 보니 볼 쪽이나 얼굴 이곳저곳이 까끌했다. 역시 핏물이다. 강우진이 다시 걸었다. 남은 손으로 볼 쪽에 굳은 피를 긁어냈다. 뭔가 공허하다. 직전에 이름도 모를 것들을 죽여서가 아니다. 죄책감? 후회? 그딴 것들은 그에게 존재치 않았다. 그냥 좀 지루했다. “후우-” 폭력과 살육에 점철된 삶이다. 그러나. “질려.” 자극이 완연하면 자연스러워진다. 몸이 적응하고 뇌가 자극에 익숙해진다. 결과적으론 재미가 소멸. 텀이, 공백기가 필요하다는 결론이었다. 때때로 잡생각도 들었다. 직전에 내 손에 목숨을 잃은 것들의 인생을 떠올려보는 등의. 하찮다. 나나 그들 모두 말이다. 헛생각은 판단을 흐린다. 의미가 없다. 그들이나 우진이나 죽거나 죽일 뿐이다. 약한 자가 심판을 당한 것이요, 살아남은 자가 심판자일 뿐이다. 존재하면 그것이 강한 것이다. 하지만 정의로운 심판자는 아니다. 악이다. 살아남은 심판자는 결단코 정의롭지 않고 모두에게 악일 뿐이다. 그저 심판하는 대상을 선택할 뿐. ‘나이스한 개새끼’. 지금의 ‘장연우’ 또는 강우진을 표현하자면 그랬다. 보기엔 평범하지만 내면 심연을 보자면 악랄했다. 하지만 이 병신같은 지루함이 반복되면 심판당하는 쪽은 저들이 아니라 나다. 우진은 자취를 감출 것을 확정했다. 그 누구의 눈에 띄지 않고 조용히 사라진다. -터벅! 어느새 숲을 빠져나온 강우진. 그의 눈에 도로가 보였다. 도로 한쪽 작은 공간엔 허름한 트럭이 세워져 있었다. 당연히 우진이 준비해둔 것. -텅! 트럭에 오른 강우진이 소총을 조수석에 툭 하고 던진 뒤 시동을 걸었다. 콜록대던 트럭이 나름 요란한 배기음을 냈다. 이어. -부우우웅! 1초의 망설임 없이 운전을 시작하는 우진. 트럭의 속도는 점차 빨라졌고 강우진의 시야 역시 초마다 변했다. 컴컴한 도로를 비추던 그의 정면과 온도가 삽시간에 탈바꿈됐다. 수년이 흘렀으니까. 차에 타고 있던 강우진은 북적거리는 시장에 서 있었다. 내리쬐는 햇볕이 뜨겁다. 팔뚝이 따가울 정도였다. 조금씩 우진의 시야가 선명해졌다. 그을린 피부의 사람들이 왁자지껄 뒤섞여 움직이고 있었다. “······” 귀가 찢어질 정도로 외치는 남자, 파는 상품의 소개처럼 들리는 여자의 괴성, 사람들 사이사이를 파고드는 자전거나 오토바이, 초마다 들리는 경적, 우진의 어깨나 팔뚝을 쳐대며 지나치는 수십 사람들. 하지만 이 같은 광경은 강우진에게 낯설게 보이지 않았다. 지금 그의 마음은 평온했다. 당연했다. 이 방콕에서 우진은 몇 년째 살고 있었으니까. 땀이 볼을 타고 흘렀다. 보니 강우진의 모습도 퍽 변했다. 턱에 수염이 좀 자랐고 피부 톤도 살짝 탔다. 입은 갈색 셔츠나 청바지 역시 허름하기 짝이 없었다. -스윽. 담배를 입에 무는 그. 라이터를 손에 든 우진이 북적이는 사람들 사이로 진입했다. “#*()%(*#)%@((@(!!!” “)(#%&*#(%%@(*@*!!!” -빵빵빵!! 계속해서 귀가 쩌렁쩌렁 울렸지만, 별수롭지 않게 반응한 강우진은 정신없는 시장 내부를 걸었다. 그러다 시장 중간쯤 있는 한 음료 가게에 도착한 우진이 외부에 깔린 테이블에 앉았다. 다가온 주인에게 영어로 적당히 커피를 시킨 그가 다 치운 담배를 버린 뒤. “쯧, 오면서 사둘 걸 그랬나.” 하나 남은 담배를 입에 재차 물었다. 다만, 이번엔 라이터가 문제였다. 칙칙 소음만 날 뿐 라이터가 불을 뿜지 않았다. 혀를 찬 강우진이 라이터를 흔들 때였다. -스윽. 뜬금 우진의 오른 귀 쪽으로 손이 쑥 나왔다. 본능적으로 손을 잡아 꺾으려던 강우진. 그런 그에게 점잖은 목소리가 들렸다. 여자 목소리에다 영어였다. “J(제이), 침착해.” 낯설지 않은 톤과 음성이었다. 멈칫한 강우진이 고개를 돌렸다. 딱 붙는 회색 탱크톱에 선글라스를 낀 외국인 여자가 서 있었다. 머리를 금발을 돌돌 말아 올렸다. 그녀가 우진에게 잡힌 자신의 손을 턱짓했다. “불이 필요한 거지?” 여자의 손엔 네모난 은색 라이터가 들려있었다. 픽 웃은 우진이 라이터를 집어선 입에 물린 담배에 불을 붙였다. 그리곤 라이터를 주머니에 넣으며 말했다. “됐어, 이제 꺼져.” 금발의 여자가 어깨를 으쓱였다. “라이터를 줘야 가지.” “내 거잖아 이거. 너한테 맡겨 뒀던 거고.” 선글라스를 벗은 여자가 우진의 반대편 의자에 앉아 다리를 꼬았다. “너무 꽁꽁 숨어 있어서 찾는 게 오래 걸렸어.” 그녀는 ‘장연우’ 또는 강우진의 과거 동료였다. “L(엘), 날 어떻게 찾았지?” “사람 찾는 거야 내 전문이니까. 데스크가 내 주 임무였어, 잊은 거야? 물론 J(제이) 널 찾는 건 상당히 어려웠지만.” 담배 연기를 후- 하고 뱉던 우진이 등을 의자에 기대며 답했다. “헛소리 그만하고. 날 왜 찾았어.” “제이, 이만하면 많이 놀았잖아. 내 팀에 들어와, 네가 없어진 뒤에 내가 따로 팀을 만들었어.” “뭘 하는 팀인데.” “뭐든. 의뢰를 받고 돈이 입금되면 뭐든 해.” “팀 인원은.” “직접 확인해.” “싫어, 좀 더 놀 거야.” 하품하는 강우진의 발을 금발 여자가 찼다. “너 같은 쓰레기는 필요 없어, 네 실력이 필요할 뿐이야. 이런 시장통에서 썩히기는 아까우니까. 용병이 돼.” “실력도 쓰레기가 됐겠지.” “좋아, 그럼.” 말을 잠시 멈춘 여자가 벗은 선글라스를 다시금 쓰며 의자서 일어났다. “여기 방콕에서 일 하나만 해보고 결정하는 건 어때.” “뭔데.” “여자애 하나 구출하는 거야, 쉽지?” “여자애?” “응.” 엘이라 불린 금발 여자가 새 담뱃갑을 우진에게 내밀며 비죽 웃었다. “여기 마약왕의 딸, 납치됐거든.” 후로. 퍽 길었던 ‘장연우’의 인생을 살던 강우진이 다시금 하늘 위의 비행기로 돌아왔다. 즉, 현실로 복귀했다는 뜻. ‘장연우’로서 수년 이상을 살았지만 현실의 비행기 쪽은 몇 초 정도가 흘렀을 뿐. 거기다 분명, 직전의 세상에선 수많은 폭발과 총격이 터져댔었는데. “······” 비행기 안은 쥐죽은 듯이 고요했다. 평온하기 그지없다. 대부분의 인원이 잠에 빠졌기 때문이었다. 바로 옆자리 최성건, 최나나 작가 등등. 유일하게 턱수염 송만우 PD만 대본을 보고 있었다. 삽시간에 ‘장연우’의 냄새가 빠진 우진이 속으로 약간 황당하게 웃었다. ‘이 온도 차만큼은 진짜 적응이 안 되네.’ 각인된 배역의 세상과 강우진의 세상은 공존하면서도 판이했다. 매번 겪는 일이었지만, 이렇게나 차이가 극명하면 어이가 없는 게 당연했다. 어쨌든. -스윽. 강우진이 손에 쥐어진 ‘이로운 악’의 1화 대본에 시선을 내렸다. 아공간에 재차 진입하기 위함은 아니었다. -팔락. 대본을 읽기 위해. 아니, 분석하기 위함이었다. ‘배역합성’이나 ‘배역의 자유도’ 등을 습득한 뒤 생긴 강우진의 루틴이었다. 조금 더 선명하게, 더욱이 폭발적으로, 생각보다 더 생동감 넘치게. 어느새 강우진은 배우로서의 자세가 딴딴히 잡혀가고 있었고. ‘장연우가 진짜 이럴라나? 걍 노빠꾸로 지를 거 같은데.’ 대본 속이 아닌, 현실에 뛰쳐나와 날뛸 ‘장연우’ 역시 명확해지는 중이었다. 그렇게 흐른 시간이 몇 시간. 어느새 우진이 탄 비행기는 방콕의 ‘수완나품 국제공항’에 착륙하는 중이었다. 대본 분석부터 아공간에서의 휴식까지 끝낸, 진작에 컨셉질을 뒤집어쓴 강우진이 시선을 창밖에 던졌다. 방콕이 보이기 시작했다. 하지만 생각보다 신기함은 없었다. 뭔가 비슷한 광경이 떠올랐으니까. ‘어째 다낭이랑 비스무리하네.’ 베트남 다낭을 말하는 것. 다른 점도 있긴 했다. ‘실종의 섬’ 해외로케로 갔던 다낭은 휴양지 느낌이라면, 이번의 방콕은 도시의 느낌이 강했다. 뭐가 됐든 명확히 비슷한 점이라면. ‘벌써 더워, 아오 씨.’ 무더울 거라는 점. 한창 강우진이 창밖을 보며 컨셉질로 가려진 투정을 속으로 읊조릴 때쯤, 그의 주변 좌석들은 매우 부산스러웠다. 익숙한 인물들. 턱수염 송만우 PD나 김소향 총괄디렉터, 최나나 작가, 스턴트 팀인 에단 스미스 등의 키스탭들 외의 다수. 이유야 간단했다. “혼잡할 거 같으니까! 초반에 안내한 것처럼 차례로!! 계획대로 입국장으로 움직이면 됩니다!” “오케이!!” “그리고 각 팀별로 내리자마자 짐이랑 장비들 체크 확실히 하셔야 돼요!” “어후- 이제 시작이구만!” 강우진 포함 이 비행기에 탄 대부분의 인원이 ‘이로운 악’의 촬영팀이었으니까. 당연히 해외로케 촬영을 위한 것. 19일인 오늘은 사전 점검과 적당한 적응으로 보낼 예정이고, 20일인 내일부터 본격적인 촬영에 돌입하게 된다. 따라서 모두는 흥분과 함께 예민했다. 이후 비행기가 안전하게 착륙한 후, 거의 백여 명 되는 ‘이로운 악’ 팀 전부가 우르르 움직였다. 배우진은 그리 많지 않았다. 귀염상에 음침한 임해은이나 조연급 몇몇. 물론, 메인은. “우진씨!! 이쪽입니다!! 가드들과 같이 움직이세요!” 강우진이었다. 그의 주변엔 최성건과 팀원들이 붙었고, 그 보다 두 배 넘는 가드들이 둘러싼 형태였다. 입국장으로 향하는 ‘이로운 악’팀의 행진은 수많은 인파들의 시선을 독차지하기에 부족함이 없었다. 어마어마한 규모였으니까. 나름 나눠서 움직이긴 했다. 배우팀, 배우들의 스탭팀, ‘이로운 악’의 제작진 등. 한 번에 행동하면 너무도 혼잡할 테니 사고 날 위험이 컸다. ‘이로운 악’ 팀은 ‘수완나품 국제공항’의 입국장으로 서서히 걸었다. 강우진도 행진 흐름에 맞췄다. 딱딱한 표정엔 큰 변화가 없다. 하지만. ‘뭔가- 묘하게 떨리는데? 촬영 임박해서 그런가??’ 내면으로는 점차 심장박동이 격해지는 중이었다. 그럴수록 냉철함을 더욱 진하게 만들었다. 와중 그의 주변 배우들, 즉 이번 해외로케 촬영에 합격한 조·단역 배우들이 강우진과 주변을 둘러보며 수군댔다. “가드- 좀 많지 않아요?” “그러니까요. 시선 엄청 받는데.” “강우진님 때문이겠죠.” “일본에서야 우진님이 대박인 건 아는데···태국에서도 먹혀요? 들은 적 없는데.” “글쎄요. 일단, 우리 때문은 100% 아니니까 무조건 우진님 때문이겠죠. 뭐, 혹시 모를 사고 때문에 그런 거 아니에요??” “예방 차원이겠죠. 근데 가드들이 좀 과하게 많긴 하네.” 그들로서는 처음 겪는 취급이었으니까. “그래도······어깨 뽕 좀 올라가지 않아요? 우리가 우진님 아니면 언제 이런 거 경험해보겠어요.” “인정. 사진도 엄청 찍었어요 저.” “예방이든 뭐든 완전 기분 째지긴 해요. 어후- 확실히 사는 세상이 다르구나 싶은 느낌?” “우리는 언제쯤 저런 그림 볼 수 있으려나.” “강우진님이 2년 만에 하셨으니까- 우리도 불가능하진···아니다, 불가능하겠다.” “여튼 좋은 구경 하네요.” 이윽고. -스르륵. 가드들이 앞선, 강우진이 중심이 된 배우팀 무리가 ‘수완나품 국제공항’ 입국장에 들어섰다. 동시에 터지는, 눈이 멀 정도의 플래시 세례. -파바바바박! -파바바바바박!! 이내 강우진을 제외한 배우들의 눈이 휘둥그레졌다. “허??!!” “우왁!” “와···미친!!” “뭐, 뭐야?!!” “까, 깜짝이야!!” 이유야 간단했다. 입국장 앞엔 어마무시한 인파가 몰려든 상태였으니까. “%&)*%#**%&*)%*)강우진!!” “@*&(*%*(강우진!! 강우진!!” 태국 기자들 포함, 수백 인파가 오직 강우진을 외치고 있었다. 귀가 뜯어질 정도의 무시무시한 데시벨. 과한 괴성이라 알아듣긴 힘들어도 강우진 이름은 잘 들렸다. “꺄아악!! 강우진!” “우진!!@()@*)(@!!” 퍽 예상 밖이었다. 이를 목도한 강우진의 얼굴은. “······” 다분히 덤덤했다. ‘미친??!’ 물론, 겉으로만. < 방콕 (3) > 끝","output":"< Bangkok (3) > Jang Yeon-woo, or rather, Kang Woo-jin, holding an M4 carbine rifle in one hand, is walking down a forest path. He's still in his military uniform and bulletproof vest, but the radio that was in his ear is nowhere to be seen. His pace is neither slow nor fast. It was an ordinary speed, as if he were out for a stroll. - Crunch, crunch. The weeds crushed under his military boots spread a faint noise. A cold wind struck Woo-jin head-on. The chill seeped in. Suddenly, a small smile spread across the expressionless face of Kang Woo-jin. \\"I enjoyed it, so that's enough.\\" His senses of sight, smell, and hearing became sharper. The familiar darkness ahead, the unique smell of the forest and the scent of winter, the crunching noise, and the miscellaneous sounds made by insects. Everything was clear, and the feelings of 'Jang Yeon-woo' became even more pervasive in Woo-jin. The pleasure he had enjoyed gradually diminished. Kang Woo-jin looked up at the sky. \\"......\\" It's bright. The moon is bright. Woo-jin, who had been looking at the sky with a faint smile, looked down at the rifle in his right hand. Something hard had solidified on his fingers. It was dried blood. Not his own, but someone else's. Now that he thought about it, his cheek and various parts of his face felt rough. It was also blood. Kang Woo-jin started walking again. With his free hand, he scraped off the dried blood on his cheek. Something felt empty. Not because he had just killed nameless things. Guilt? Regret? Such things did not exist for him. It was just a bit boring. \\"Hoo-\\" His life was marked by violence and slaughter. However. \\"I'm sick of it.\\" When stimulation becomes natural, the body adapts and the brain becomes accustomed to the stimulus. As a result, the fun disappears. He concluded that he needed a break, a period of absence. Sometimes he had random thoughts, like recalling the lives of those who had just lost their lives at his hands. Trivial. Both me and them. Idle thoughts cloud judgment. They are meaningless. Whether it's them or Woo-jin, it's just about killing or being killed. The weak are judged, and the survivors are the judges. To exist is to be strong. But he is not a righteous judge. He is evil. The surviving judge is definitely not just and is evil to everyone. He simply chooses the subject of judgment. 'A nice son of a bitch.' That's how you would describe the current 'Jang Yeon-woo' or Kang Woo-jin. He may look ordinary, but if you look into the depths of his inner self, he was vicious. But if this stupid boredom repeats, it's not them who will be judged, but me. Woo-jin decided to disappear without a trace. Quietly, without catching anyone's eye. - Thud! Before he knew it, Kang Woo-jin had emerged from the forest. A road came into his view. On one side of the road, a shabby truck was parked. Of course, it was prepared by Woo-jin. - Clang! Kang Woo-jin, who had climbed into the truck, tossed the rifle onto the passenger seat and started the engine. The truck, which had been coughing, now emitted a fairly loud exhaust noise. Then. - Vroom! Woo-jin started driving without a second's hesitation. The speed of the truck gradually increased, and Kang Woo-jin's view changed every second. The temperature and view in front of him, which had been illuminating the dark road, transformed in an instant. Years had passed. Kang Woo-jin, who had been in the car, was now standing in a bustling market. The blazing sun was hot. His forearms felt scorched. Little by little, Woo-jin's view became clearer. People with sunburnt skin were moving around noisily. \\"......\\" A man shouting until his throat seemed to tear, a woman's scream that sounded like she was introducing her wares, bicycles and motorcycles weaving through the crowd, the constant sound of horns, and dozens of people bumping into Woo-jin's shoulders and arms as they passed by. However, this scene did not seem unfamiliar to Kang Woo-jin. His mind was at peace now. Of course. He had been living in this Bangkok for several years. Sweat trickled down his cheek. Kang Woo-jin's appearance had also changed quite a bit. A bit of a beard had grown on his chin, and his skin tone had darkened slightly. The brown shirt and jeans he wore were also shabby. - Swoosh. He put a cigarette in his mouth. Woo-jin, holding a lighter in his hand, entered the crowd of bustling people. \\"#*()%(*#)%@((@(!!!\\" \\")(#%&*#(%%@(*@*!!!\\" - Beep beep beep!! Despite the continuous ringing in his ears, Kang Woo-jin, who reacted nonchalantly, walked through the chaotic market. Arriving at a beverage shop in the middle of the market, Woo-jin sat down at a table set outside. After ordering coffee in English from the approaching owner and discarding the cigarette he had finished. \\"Tsck, I should have bought some on the way.\\" He put another cigarette in his mouth. However, this time the lighter was the problem. It only made clicking noises and wouldn't light. Kang Woo-jin clicked his tongue and was shaking the lighter when. - Swoosh. Suddenly, a hand reached out towards Woo-jin's right ear. Instinctively trying to grab and twist the hand, Kang Woo-jin heard a calm voice. It was a woman's voice, and it was in English. \\"J, calm down.\\" It was a tone and voice he was familiar with. Woo-jin hesitated for a moment and turned his head. A foreign woman with her blonde hair rolled up and wearing sunglasses and a tight gray tank top stood there. She gestured with her chin to the hand Woo-jin had caught. \\"Need a light?\\" In the woman's hand was a square silver lighter. Woo-jin picked up the lighter and lit his cigarette. Then, putting the lighter in his pocket, he said. \\"Done, now get lost.\\" The blonde woman shrugged her shoulders. \\"You have to give me the lighter.\\" \\"It's mine. I had left it with you.\\" The woman, who had taken off her sunglasses, sat down on the opposite chair and crossed her legs. \\"You were hiding so well, it took me a long time to find you.\\" She was a former colleague of 'Jang Yeon-woo' or Kang Woo-jin. \\"L, how did you find me?\\" \\"Finding people is my specialty. Desk work was my main duty, remember? Of course, finding J was quite difficult.\\" Woo-jin, who had exhaled the cigarette smoke, leaned back in his chair and replied. \\"Stop the nonsense. Why did you look for me?\\" \\"J, you've had enough fun. Join my team, I've formed my own team since you left.\\" \\"What kind of team is it?\\" \\"Anything. We do whatever when we get a request and the money is deposited.\\" \\"How many in the team?\\" \\"Check for yourself.\\" \\"No, I want to play more.\\" The blonde woman kicked Woo-jin's foot as he yawned. \\"I don't need trash like you, I just need your skills. It's a waste to rot in a market like this. Become a mercenary.\\" \\"My skills would have become trash by now.\\" \\"Fine, then.\\" The woman paused for a moment, put her sunglasses back on, and stood up from the chair. \\"How about you do just one job here in Bangkok and then decide.\\" \\"What is it?\\" \\"Rescuing a girl, easy, right?\\" \\"A girl?\\" \\"Yeah.\\" The blonde woman, called L, handed Woo-jin a new pack of cigarettes and smirked. \\"The daughter of a drug lord here, she's been kidnapped.\\" Afterward. Kang Woo-jin, who had lived the long life of 'Jang Yeon-woo,' returned to the plane above the sky. In other words, he returned to reality. He had lived as 'Jang Yeon-woo' for several years, but only a few seconds had passed in the reality of the plane. Moreover, there had certainly been numerous explosions and shootings in the previous world. \\"......\\" The inside of the plane was dead silent. It was utterly peaceful. Most of the passengers had fallen asleep. Only Song Man-woo PD, with his beard, was looking at the script. Woo-jin, who had lost the scent of 'Jang Yeon-woo' in an instant, laughed a bit absurdly to himself. 'I can't really get used to this temperature difference.' The world of the role he had played and Kang Woo-jin's world coexisted yet were completely different. It was something he experienced every time, but when the difference was so stark, it was naturally absurd. Anyway. - Swoosh. Kang Woo-jin looked down at the script of 'Beneficial Evil' Episode 1 in his hand. It wasn't to re-enter the void. - Flip. To read the script. No, to analyze it. It was a routine that had developed for Woo-jin after acquiring skills like 'Role Synthesis' and 'Freedom of the Role.' A little clearer, more explosively, more vivid than he thought. Before he knew it, Kang Woo-jin was firmly establishing his stance as an actor. 'Would Jang Yeon-woo really do this? Feels like he'd just go all out.' The 'Jang Yeon-woo' who would burst out into reality, not just in the script, was also becoming clear. After some time had passed. Before long, the plane Woo-jin was on was landing at Bangkok's 'Suvarnabhumi International Airport.' Having finished analyzing the script and resting in the void, Kang Woo-jin, who had already donned his concept, looked out the window. Bangkok was beginning to come into view. But there wasn't as much novelty as he expected. It reminded him of a similar scene. 'It's kind of similar to Da Nang.' He was talking about Da Nang in Vietnam. There were differences, of course. Da Nang, where he had gone for the overseas location shooting of 'Island of the Missing,' had a resort feel, while this Bangkok had a strong city vibe. Regardless, the clear similarity was. 'It's already hot, damn.' As Kang Woo-jin was looking out the window and muttering his concept-covered complaints to himself, the surrounding seats were very busy. Familiar figures. Song Man-woo PD with his beard, Kim So-hyang the general director, writer Choi Na-na, Ethan Smith from the stunt team, and many other key staff. The reason was simple. \\"It's going to be crowded! As I instructed at the beginning, move in order! Just move to the immigration hall according to the plan!\\" \\"Okay!!\\" \\"And each team, as soon as you get off, make sure to check your luggage and equipment!\\" \\"Ah, it's just the beginning!\\" Most of the people on the plane, including Kang Woo-jin, were part of the 'Beneficial Evil' filming team. Naturally, it was for overseas location shooting. Today, the 19th, was scheduled for preliminary checks and acclimatization, and from tomorrow, the 20th, they would start full-fledged shooting. Therefore, everyone was excited and sensitive. After the plane landed safely, nearly a hundred members of the 'Beneficial Evil' team moved en masse. There weren't many actors. Cute but gloomy Lim Hae-eun and a few supporting actors. Of course, the main one was. \\"Woo-jin, this way! Move with the guards!\\" It was Kang Woo-jin. Choi Sung-gun and his team members were with him, surrounded by twice as many guards. The 'Beneficial Evil' team's march to the immigration hall captured the attention of many people. It was an enormous scale. They moved in groups. The actor team, the staff team for the actors, the production team of 'Beneficial Evil.' If they acted all at once, it would be too chaotic and risky. The 'Beneficial Evil' team slowly walked towards the 'Suvarnabhumi International Airport' immigration hall. Kang Woo-jin also matched the flow of the march. His expression was rigid. However. 'Something's- strangely thrilling? Is it because the shooting is imminent??' Internally, his heartbeat was gradually intensifying. The more it did, the more he intensified his coolness. Meanwhile, the surrounding actors, that is, the supporting and minor role actors who had passed the audition for this overseas location shoot, were looking around and whispering to each other. \\"Aren't there too many guards?\\" \\"Right? We're getting a lot of attention.\\" \\"It must be because of Kang Woo-jin.\\" \\"I know Woo-jin is a big deal in Japan... but does he have a following in Thailand too? I've never heard of it.\\" \\"I don't know. Anyway, it's definitely not because of us, so it must be because of Woo-jin. Maybe it's because of a possible accident??\\" \\"It must be a precaution. But the guards do seem a bit excessive.\\" It was their first time receiving such treatment. \\"But still... doesn't it kind of boost your ego? When would we ever experience this if not for Woo-jin?\\" \\"Agreed. I took a lot of photos.\\" \\"Whether it's a precaution or not, it definitely feels amazing. Ah, it really feels like we live in a different world?\\" \\"When will we ever see such a scene?\\" \\"Woo-jin did it in two years, so for us... it's not impossible... no, it's impossible.\\" \\"Anyway, it's a good sight to see.\\" Eventually. - Slide. The actor team, centered around Kang Woo-jin and led by the guards, entered the 'Suvarnabhumi International Airport' immigration hall. At the same time, a blinding barrage of flashes erupted. - Papapapapak! - Papapapapapak!! Soon, the eyes of the actors, except for Kang Woo-jin, widened in shock. \\"Huh??!!\\" \\"Whoa!\\" \\"Wow... crazy!!\\" \\"What, what is this?!!\\" \\"Scared me!!\\" The reason was simple. In front of the immigration hall, there was a massive crowd. \\"%&)*%#**%&*)%*)Kang Woo-jin!!\\" \\"@*&(*%*(Kang Woo-jin!! Kang Woo-jin!!\\" An overwhelming decibel level from the Thai reporters and hundreds of people, all shouting only for Kang Woo-jin. The excessive screaming was hard to understand, but Kang Woo-jin's name was clearly heard. \\"Kyaaak! Kang Woo-jin!\\" \\"Woo-jin!!@()@*)(@!!\\" It was completely unexpected. Kang Woo-jin, witnessing this, had a very calm face. \\"......\\" But only on the outside. < Bangkok (3) > End"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 台灣女生在陸橋釣到奇特生物，逼真人物，逼真場景，逼真陰影，ektachrome，技術性高細節，紋理豐富肌理，高度細緻, hd, 8k, 光線追蹤, 高品質, 極度細緻, 細緻繪景 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A Taiwan girl standing on a pedestrian bridge, excitedly holding a fishing rod as she catches a rare and peculiar creature. The creature is incredibly lifelike, with intricate details and textures. The scene is highly realistic, with the sunlight casting shadows and creating a play of light and dark. The image captures the unique moment beautifully, with high-definition and 8K resolution to showcase the finest details. The composition focuses on the girl and the creature, conveying the intensity and excitement of the moment. The overall atmosphere is vibrant and filled with anticipation. The image is rendered in a stunning ektachrome style, reminiscent of vintage film photography. --ar 16:9 --v 5 /imagine prompt: In this scene, a Taiwanese girl is depicted on a pedestrian bridge, capturing a peculiar creature while fishing. The girl is portrayed with exceptional realism, down to the smallest details of her features and expressions. The setting is incredibly lifelike, with a vivid representation of the bridge, water, and surrounding environment. The scene is bathed in beautiful natural light, creating captivating shadows and highlights. The image is rendered with meticulous attention to detail, showcasing intricate textures and fine craftsmanship. The composition highlights the girl and the creature, drawing the viewer's attention to their interaction. The mood of the scene is filled with wonder and curiosity. The image is styled like a high-quality photograph, capturing the essence of the moment with a digital camera and specialized lenses. --ar 16:9 --v 5.2 /imagine prompt: Picture a Taiwanese girl fishing on a pedestrian bridge, her eyes widening in astonishment as she catches an enigmatic and otherworldly creature. The creature's realism is astonishing, with its intricate features and textures bringing it to life. The scene is meticulously rendered, from the fine grain of the wood on the bridge to the ripples in the water below. The lighting highlights the drama of the moment, creating dramatic shadows and adding depth to the image. The composition focuses on the girl and the creature, capturing their connection and the awe-inspiring nature of the scene. The overall atmosphere is filled with a sense of mystery and intrigue. The image is created in a style that combines digital art and painting techniques, resulting in a visually stunning and evocative piece. --ar 9:16 --v 5 /imagine prompt: Transport yourself to a pedestrian bridge in Taiwan, where a young girl's fishing expedition takes an unexpected turn. She has just reeled in a mesmerizing and fantastical creature, appearing so realistic that it's almost tangible. The attention to detail is astounding, with every nuance of the girl's form and expression brought to life in a truly lifelike manner. Surrounding her, the scene is flawlessly crafted, from the intricate textures of the bridge to the sparkling reflections on the water's surface. The lighting creates a dynamic interplay of light and shadow, enhancing the depth and realism of the scene. The composition masterfully captures the girl's astonishment and the creature's allure, drawing the viewer into this extraordinary moment. The image exudes a sense of wonder and awe, transporting the viewer to a world filled with magic and possibility. Rendered in a unique and captivating style that merges elements of illustration and sculpture, this piece is sure to captivate and inspire. --ar 16:9 --v 5.1"},{"instruction":"Escreva algumas perguntas e respostas sobre o Delta(Você está pronto para embarcar em uma jornada eletrizante por labirintos alucinantes? Não procure mais - Delta Executor está aqui para redefinir sua experiência de resolução de quebra-cabeças!) em português do Brasil em torno da palavra-chave “download”","output":"1. Onde posso fazer o download do Delta Executor? Você pode fazer o download do Delta Executor em seu site oficial ou em plataformas de download confiáveis. 2. Qual é o tamanho do arquivo para download do Delta Executor? O tamanho do arquivo pode variar, mas normalmente é de cerca de X MB. 3. Quais são os requisitos mínimos para fazer o download do Delta Executor? Verifique os requisitos de sistema no site oficial do Delta Executor para garantir que seu dispositivo seja compatível. 4. O Delta Executor está disponível gratuitamente para download? Existem versões gratuitas e pagas do Delta Executor. Verifique as opções disponíveis durante o download. 5. É seguro fazer o download do Delta Executor de fontes não oficiais? Recomendamos fazer o download apenas do site oficial do Delta Executor ou de plataformas confiáveis para garantir a segurança do seu dispositivo. 6. Posso fazer o download do Delta Executor no meu smartphone? Sim, o Delta Executor está disponível para download em smartphones compatíveis. Verifique os requisitos de sistema para dispositivos móveis. 7. Há algum tutorial disponível para ajudar no download do Delta Executor? Sim, você pode encontrar tutoriais e guias de instalação no site oficial do Delta Executor ou em fóruns especializados. 8. Quais são as etapas para concluir o download do Delta Executor? Acesse o site oficial ou a plataforma de download escolhida, localize o botão de download do Delta Executor e siga as instruções fornecidas. 9. O download do Delta Executor requer uma conexão com a internet? Sim, é necessário ter uma conexão estável com a internet para baixar o Delta Executor. 10. Posso pausar e retomar o download do Delta Executor? Dependendo da plataforma de download utilizada, você pode pausar e retomar o download do Delta Executor. Verifique as opções disponíveis durante o processo de download."},{"instruction":"用巴西葡语写一段有关Tiktok 18应用的描述","output":"O TikTok 18 é um aplicativo eletrizante que oferece uma experiência única para os usuários adultos. Com uma variedade de conteúdos ousados e divertidos, este aplicativo é perfeito para aqueles que procuram uma dose extra de emoção. Com recursos de edição incríveis, você pode criar vídeos envolventes e compartilhar momentos inesquecíveis com a comunidade TikTok 18. Baixe agora mesmo e mergulhe nessa nova forma de se divertir! Lembre-se sempre de usar o TikTok 18 de forma responsável e respeitando as diretrizes de segurança e privacidade. Seja ousado, seja criativo, seja parte do TikTok 18!"},{"instruction":"用巴西葡语写几个有关Tiktok 18应用的FAQ","output":"Aqui estão algumas perguntas frequentes sobre o aplicativo TikTok 18: 1. Onde posso fazer o download do TikTok 18? Você pode fazer o download do TikTok 18 em lojas de aplicativos oficiais, como a App Store (para dispositivos iOS) ou a Google Play Store (para dispositivos Android). 2. É possível filtrar o conteúdo no TikTok 18? Sim, o TikTok 18 possui opções de filtro de conteúdo para ajudar a personalizar sua experiência. Você pode definir preferências de conteúdo e bloquear certos tipos de vídeos. 3. É necessário ter uma conta para usar o TikTok 18? Sim, é necessário criar uma conta no TikTok 18 para começar a explorar e interagir com o conteúdo. Você pode criar uma nova conta ou fazer login usando suas credenciais existentes. 4. Posso personalizar as configurações de privacidade no TikTok 18? Sim, o TikTok 18 oferece opções de privacidade, permitindo que você defina quem pode ver e interagir com seu perfil, vídeos e comentários. Você pode ajustar essas configurações de acordo com suas preferências. 5. Existe uma restrição de idade para usar o TikTok 18? Sim, o TikTok 18 é voltado para usuários adultos e requer que você confirme sua idade para acessar o conteúdo. Certifique-se de ser maior de idade antes de usar o aplicativo. 6. Existem diretrizes de comunidade no TikTok 18? Sim, assim como em outros aplicativos, o TikTok 18 possui diretrizes de comunidade que estabelecem regras para o conteúdo compartilhado pelos usuários. Certifique-se de seguir essas diretrizes ao criar e compartilhar vídeos. 7. É possível denunciar conteúdo inadequado no TikTok 18? Sim, o TikTok 18 incentiva os usuários a denunciar conteúdo inadequado ou violações das diretrizes de comunidade. Você pode denunciar vídeos e perfis que considerar impróprios para que a plataforma tome as devidas providências. 8. O TikTok 18 possui recursos de segurança? Sim, o TikTok 18 possui recursos de segurança, como opções de privacidade, filtros de conteúdo e a capacidade de bloquear outros usuários. É importante utilizar esses recursos para garantir uma experiência segura no aplicativo. Lembramos que as informações fornecidas são baseadas em informações gerais e é recomendável consultar a documentação oficial do aplicativo para obter detalhes atualizados."},{"instruction":"Por favor, escreva um artigo de introdução de 500 a 700 palavras sobre o Tiktok 18 em português brasileiro com base nas seguintes informações Contém a declaração: você pode baixar Tiktok 18 apk no APKPure Recursos e vantagens do app Recomendação resumida","output":"Título: Conheça o TikTok 18: Aplique uma dose extra de emoção ao seu dia com vídeos ousados e divertidos! Introdução: Nos últimos anos, o TikTok se tornou um fenômeno mundial ao oferecer uma plataforma para que milhões de usuários compartilhem seus talentos, habilidades e criatividade. Com vídeos curtos e envolventes, o aplicativo conquistou uma enorme base de fãs. Agora, o TikTok 18 chegou para oferecer uma experiência ainda mais eletrizante e emocionante para os adultos. Esteja pronto para embarcar em uma jornada por labirintos alucinantes e redefinir sua experiência de resolução de quebra-cabeças com o Delta Executor! Tópico 1: Onde baixar o TikTok 18 APK Para mergulhar de cabeça na diversão do TikTok 18, o primeiro passo é baixar o aplicativo. Você pode encontrar facilmente o TikTok 18 APK no APKPure, uma plataforma confiável e segura para baixar aplicativos. Certifique-se de seguir os passos adequados para realizar o download e a instalação corretamente. Com o aplicativo em mãos, você estará preparado para explorar todos os recursos emocionantes que o TikTok 18 tem a oferecer. Tópico 2: Recursos e vantagens do TikTok 18 O TikTok 18 foi projetado especialmente para os adultos que desejam uma dose extra de emoção em sua experiência no aplicativo. Com uma variedade de conteúdos ousados e divertidos, você encontrará uma seleção única de vídeos cativantes. De desafios de dança a esquetes engraçados, os criadores do TikTok 18 oferecem uma experiência única e envolvente. Além disso, o aplicativo conta com recursos de edição incríveis, permitindo que você adicione efeitos especiais, trilhas sonoras e filtros às suas criações. Solte sua criatividade e crie vídeos envolventes que irão impressionar seus amigos e seguidores. Com recursos como dublagem e vídeo em câmera lenta, você poderá explorar diferentes estilos e formas de expressão. Outra vantagem do TikTok 18 é a possibilidade de interagir com uma comunidade animada. Comentários, likes e compartilhamentos são formas de se conectar com outros usuários que compartilham gostos e interesses semelhantes. Sinta-se parte de uma comunidade vibrante de criadores e exploradores de conteúdo. Tópico 3: Recomendação resumida Em resumo, o TikTok 18 é uma opção emocionante para aqueles que desejam uma experiência mais audaciosa no mundo dos vídeos curtos. Com seu conteúdo ousado e divertido, recursos de edição avançados e uma comunidade vibrante, este aplicativo promete redefinir sua experiência de entretenimento online. Porém, lembre-se sempre de usar o TikTok 18 de forma responsável, respeitando as diretrizes de segurança e privacidade. Então, baixe agora mesmo o TikTok 18 APK no APKPure e embarque nessa nova jornada de diversão e emoção. Solte sua criatividade, divirta-se explorando todos os recursos disponíveis e compartilhe momentos inesquecíveis com a comunidade do TikTok 18. Seja corajoso, seja criativo e faça parte dessa nova onda de entretenimento digital!"},{"instruction":"Escreva algumas perguntas e respostas sobre o Tiktok 18 em português do Brasil em torno da palavra-chave \\"download\\"","output":"1. Onde posso fazer o download do TikTok 18? Você pode fazer o download do TikTok 18 no APKPure. Verifique a disponibilidade do aplicativo em sua loja de aplicativos oficial. 2. Qual é o tamanho do arquivo para download do TikTok 18? O tamanho do arquivo pode variar, mas normalmente é de cerca de X MB. 3. Quais são os requisitos mínimos para fazer o download do TikTok 18? Verifique os requisitos de sistema na loja de aplicativos ou no site oficial do TikTok 18 para garantir que seu dispositivo seja compatível. 4. O TikTok 18 está disponível gratuitamente para download? Sim, o TikTok 18 está disponível gratuitamente para download e uso. No entanto, alguns recursos adicionais podem exigir compras dentro do aplicativo. 5. É seguro fazer o download do TikTok 18 de fontes não oficiais? Recomendamos fazer o download apenas de fontes confiáveis, como a loja de aplicativos oficial ou sites oficiais, para garantir a segurança de seu dispositivo. 6. Posso fazer o download do TikTok 18 no meu smartphone? Sim, o TikTok 18 está disponível para download em smartphones compatíveis. Verifique os requisitos de sistema para dispositivos móveis. 7. Há algum custo adicional após o download do TikTok 18? O download e uso básico do TikTok 18 são gratuitos. No entanto, alguns recursos adicionais podem exigir compras dentro do aplicativo. 8. Como posso pausar ou cancelar o download do TikTok 18? Dependendo da loja de aplicativos que você está usando, você pode pausar ou cancelar o download do TikTok 18 ao acessar a seção \\"Meus aplicativos\\" ou \\"Downloads\\" em sua loja de aplicativos. 9. Além do download, quais outras formas existem para acessar o TikTok 18? Além do download do aplicativo, você também pode acessar o TikTok 18 por meio de seu site oficial ou por meio de links compartilhados em outras mídias sociais. 10. Como faço para atualizar o TikTok 18 após o download? Você pode verificar se há atualizações do TikTok 18 na loja de aplicativos onde o baixou. Geralmente, as atualizações são automáticas, mas é importante estar ciente das configurações de atualização em seu dispositivo para garantir que você esteja usando a versão mais recente do aplicativo."},{"instruction":"用巴西葡语写一段有关Play Cine应用的描述","output":"O Play Cine é um aplicativo incrível que oferece uma ampla variedade de filmes e séries para os amantes do entretenimento. Com uma interface intuitiva e fácil de usar, você pode explorar uma enorme biblioteca de conteúdo de forma conveniente e acessível. O Play Cine possui diversas categorias, como ação, comédia, drama, suspense, entre outras, para que você possa encontrar os filmes ou séries que mais gosta. Além disso, o aplicativo oferece a opção de baixar conteúdo para assistir offline, garantindo que você possa aproveitar seus filmes e séries favoritas a qualquer momento, mesmo sem conexão com a internet. O Play Cine é uma ótima opção para quem busca uma experiência de entretenimento completa, com uma seleção variada de filmes e séries, disponíveis de forma prática e simples em um único aplicativo. Baixe agora mesmo o Play Cine e desfrute de horas de diversão e entretenimento!"},{"instruction":"用巴西葡语写几个有关Play Cine应用的FAQ","output":"Aqui estão algumas perguntas frequentes sobre o aplicativo Play Cine: 1. Onde posso baixar o Play Cine? Você pode baixar o Play Cine em lojas de aplicativos oficiais, como a App Store (para dispositivos iOS) ou a Google Play Store (para dispositivos Android). 2. O Play Cine é um aplicativo pago? Não, o Play Cine é um aplicativo gratuito. Você pode baixá-lo gratuitamente e acessar uma ampla variedade de filmes e séries sem custo adicional. 3. É necessário criar uma conta para usar o Play Cine? Sim, para desfrutar de todos os recursos do Play Cine, é necessário criar uma conta. Você pode criar uma nova conta ou fazer login usando suas credenciais existentes. 4. Posso baixar filmes ou séries para assistir offline no Play Cine? Sim, o Play Cine permite que você faça o download de filmes e séries para assistir offline. Basta selecionar o conteúdo desejado e clicar no botão de download. Assim, você poderá aproveitar seus filmes e séries favoritos mesmo sem uma conexão com a internet. 5. Existe uma seção de categorias ou gêneros no Play Cine? Sim, o Play Cine possui uma ampla variedade de categorias e gêneros para facilitar a navegação e encontrar filmes e séries do seu interesse. Você pode explorar categorias como ação, comédia, drama, suspense e muito mais. 6. O Play Cine oferece legendas e dublagem em diferentes idiomas? Sim, o Play Cine oferece opções de legendas e dublagem em diferentes idiomas para garantir que você possa aproveitar os filmes e séries de acordo com suas preferências. Basta selecionar a opção desejada nas configurações do aplicativo. 7. É possível criar uma lista de favoritos no Play Cine? Sim, o Play Cine permite que você crie uma lista de favoritos para facilitar o acesso aos filmes e séries que mais gostou. Basta adicionar o conteúdo à lista de favoritos para encontrá-lo rapidamente em sua próxima sessão. 8. Como posso entrar em contato com o suporte do Play Cine em caso de problemas ou dúvidas? Você pode entrar em contato com o suporte do Play Cine por meio do aplicativo, geralmente existem opções de suporte ou ajuda na seção de configurações. Lá, você encontrará informações sobre como enviar suas dúvidas ou relatar problemas encontrados. Lembramos que as informações fornecidas são baseadas em informações gerais e é recomendável consultar a documentação oficial do aplicativo para obter detalhes atualizados."},{"instruction":"Por favor, escreva um artigo de introdução de 500 a 700 palavras sobre o Play Cine em português brasileiro com base nas seguintes informações Contém a declaração: você pode baixar Play Cine apk no APKPure Recursos e vantagens do app Recomendação resumida","output":"Título: Play Cine - Sua plataforma de streaming para filmes e séries Introdução: Nos dias de hoje, o streaming se tornou uma das formas mais populares de desfrutar de filmes e séries. Com a ampla oferta de conteúdo disponível, muitas vezes fica difícil escolher a plataforma perfeita. Porém, o Play Cine chegou para facilitar sua vida e proporcionar uma experiência incrível de entretenimento. Com uma vasta biblioteca de filmes e séries, recursos incríveis e fácil acesso, o Play Cine é a plataforma ideal para os apaixonados por cinema e TV. Tópico 1: Baixe o Play Cine APK no APKPure Para começar a desfrutar de todo o conteúdo disponível no Play Cine, você pode baixar o aplicativo no APKPure. APKPure é uma plataforma confiável e segura onde você pode encontrar o arquivo APK do Play Cine e instalá-lo em seu dispositivo Android com facilidade. Certifique-se sempre de baixar aplicativos de fontes confiáveis para garantir a segurança do seu dispositivo. Tópico 2: Recursos e vantagens do Play Cine O Play Cine oferece uma série de recursos que tornam a experiência de streaming ainda mais agradável. Com uma interface intuitiva e fácil de usar, você pode navegar facilmente pela vasta bibli"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一间中学教室，里边摆满了钢制的课座椅，结构简单，课座椅框架美观，桌面可升降 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a high school classroom, filled with rows of sturdy steel desks, simple yet aesthetically pleasing frames, desks with adjustable tops, arranged in a neat and organized manner, with each desk equipped with a tablet for students, creating a modern and futuristic atmosphere, under bright fluorescent lighting, showcasing the students' intellectual pursuits, captured with a Canon 5D Mark IV camera, 24-70mm lens, wide-angle composition capturing the entire classroom, portraying a sense of unity and learning, in a realistic photographic style with crisp details and vibrant colors. --ar 16:9 --v realistic /imagine prompt: a vibrant high school classroom, buzzing with energy and enthusiasm, colorful posters and artwork adorning the walls, showcasing the students' creativity and achievements, desks arranged in small groups, promoting collaboration and interaction, natural sunlight pouring through large windows, creating a warm and inviting environment, captured with a Fujifilm X-T3 camera, 35mm lens, composition focused on a group of students interacting and sharing ideas, capturing their passion for learning, in a style reminiscent of Henri Cartier-Bresson's street photography. --ar 16:9 --v 5.2 /imagine prompt: a serene high school classroom, exuding a peaceful and calming ambiance, soft pastel colors and minimalistic decor, creating a zen-like atmosphere, desks arranged in a circle, encouraging open discussions and fostering a sense of community, soft natural lighting filtering through sheer curtains, casting a gentle glow across the room, captured with a Sony A7 III camera, 50mm lens, composition focused on a single desk at the center, symbolizing the individual's journey of self-discovery, in a style reminiscent of a watercolor painting. --ar 9:16 --v 5 /imagine prompt: a futuristic high school classroom, set in a virtual reality simulation, with holographic desks and chairs, floating in an ethereal environment, surrounded by swirling particles and geometric patterns, creating a sense of infinite possibilities and exploration, illuminated by pulsating neon lights, casting a vibrant and otherworldly glow, captured with a digital art rendering in a 3D style, composition focused on a student immersed in virtual learning, capturing the merging of technology and education, in a style reminiscent of concept art from a science fiction movie. --ar 16:9 --v 5"},{"instruction":"Por favor, escreva um artigo de introdução de 500 a 700 palavras sobre o Play Cine em português brasileiro com base nas seguintes informações Contém a declaração: você pode baixar Play Cine apk no APKPure Recursos e vantagens do app Recomendação resumida","output":"O Play Cine é um aplicativo popular no mercado brasileiro que oferece aos usuários a possibilidade de assistir a uma vasta gama de filmes e programas de TV, tudo isso de forma gratuita. Com uma interface simples e intuitiva, o Play Cine é fácil de usar e permite que você encontre e reproduza seus conteúdos favoritos com apenas alguns cliques. Uma das principais vantagens do Play Cine é a sua ampla variedade de recursos. O aplicativo oferece uma vasta biblioteca de filmes e programas de TV de diferentes gêneros e categorias. Se você está procurando um filme de ação emocionante, um romance romântico ou uma comédia engraçada para assistir, o Play Cine tem opções para todos os gostos. Além disso, o aplicativo é constantemente atualizado com novos lançamentos, para que você nunca fique sem opções. Outra vantagem do Play Cine é a sua facilidade de uso. Com apenas alguns cliques, você pode procurar e reproduzir o conteúdo desejado. O aplicativo também oferece recursos de pesquisa avançada, permitindo que você encontre facilmente filmes e programas específicos. Além disso, você pode marcar seus filmes favoritos e criar listas de reprodução personalizadas, para que sempre tenha acesso rápido aos conteúdos que mais gostar. Além disso, o Play Cine oferece aos usuários a opção de fazer o download dos filmes e programas de TV para assistir offline. Isso é especialmente útil para quem está sempre em movimento e não tem uma conexão à internet constante. Você pode baixar seus filmes favoritos no aplicativo e assisti-los quando quiser, mesmo quando estiver sem conexão. O Play Cine também possui uma qualificação excepcional entre os usuários. Com uma classificação média de 4.5 estrelas, o aplicativo é altamente recomendado pelos usuários. Comentários positivos destacam a qualidade do conteúdo oferecido, a facilidade de uso, a variedade de opções disponíveis e a velocidade de carregamento do conteúdo. Para baixar o Play Cine, o APKPure é uma ótima opção. O APKPure é um site confiável que permite o download seguro de aplicativos Android. Você pode encontrá-lo facilmente pesquisando no Google, e a partir daí, procurar o Play Cine na plataforma. Ao baixar o aplicativo pelo APKPure, você tem a garantia de que está obtendo uma versão segura e atualizada do Play Cine. Em resumo, o Play Cine é um aplicativo indispensável para os amantes de filmes e programas de TV no Brasil. Com sua vasta biblioteca de conteúdo, facilidade de uso e opção de download para reprodução offline, o Play Cine é a escolha perfeita para quem procura entretenimento fácil e gratuito. Com tantas opções disponíveis, é fácil entender por que o Play Cine é tão popular entre os usuários. Não perca mais tempo, baixe agora mesmo o Play Cine e desfrute de horas de diversão e entretenimento!"},{"instruction":"Escreva algumas perguntas e respostas sobre o Play Cine em português do Brasil em torno da palavra-chave “download”","output":"Pergunta: O Play Cine permite o download de filmes e programas de TV? Resposta: Sim, o Play Cine permite que você faça o download de filmes e programas de TV para assistir offline. Pergunta: É possível baixar o Play Cine por meio do APKPure? Resposta: Sim, o APKPure é uma opção confiável para baixar o Play Cine de forma segura e atualizada. Pergunta: Existe alguma taxa ou custo para baixar o Play Cine? Resposta: Não, o Play Cine é um aplicativo gratuito, então não há taxa ou custo envolvido no processo de download. Pergunta: Há restrições de países para baixar o Play Cine? Resposta: O Play Cine está disponível para download em diferentes países, incluindo o Brasil. Verifique a disponibilidade em sua região antes de fazer o download. Pergunta: Quais são as vantagens de baixar filmes e programas de TV no Play Cine? Resposta: Ao baixar filmes e programas de TV no Play Cine, você pode assistir offline, mesmo sem uma conexão à internet. Isso é especialmente útil quando estiver em movimento ou em áreas com sinal fraco. Pergunta: Posso escolher a qualidade do download no Play Cine? Resposta: Sim, o Play Cine permite que você escolha a qualidade de vídeo para o download, dependendo do seu dispositivo e preferências. Pergunta: Os filmes e programas de TV baixados no Play Cine têm uma data de validade? Resposta: Não, uma vez que você faça o download de um filme ou programa de TV no Play Cine, ele estará disponível para assistir offline por tempo indeterminado. Pergunta: Quantos filmes e programas de TV posso baixar no Play Cine? Resposta: Não há um limite específico para a quantidade de filmes e programas de TV que você pode baixar no Play Cine. No entanto, o tamanho do armazenamento do seu dispositivo pode ser um fator limitante. Pergunta: É seguro baixar filmes e programas de TV no Play Cine? Resposta: Sim, o Play Cine oferece uma plataforma segura para baixar filmes e programas de TV. Porém, é importante ter cuidado ao baixar arquivos de fontes desconhecidas de terceiros, pois eles podem conter malware. Pergunta: É possível transferir os filmes e programas de TV baixados no Play Cine para outros dispositivos? Resposta: Sim, você pode transferir os filmes e programas de TV baixados no Play Cine para outros dispositivos, desde que eles possuam suporte para reproduzir o formato de arquivo utilizado pelo aplicativo."},{"instruction":"Перефразируй. Простой способ расширения функциональных характеристик пленок на основе АпК – это смешение его с другим полисахаридом, содержащим активные группы в своих макромолекулах, хитозаном. Последний представляет собой продукт деацетилирования хитина, являющегося одним из самых распространённых биополимеров на земле, сырьем, для получения которого служат панцири ракообразных.","output":"Просто можно улучшить функциональные характеристики пленок на основе АпК, смешав его с другим полисахаридом, таким как хитозан, который содержит активные группы в своих макромолекулах. Хитозан - это результат деацетилирования хитина, одного из самых распространенных биополимеров на планете, который получают из панцирей ракообразных."},{"instruction":"Перефразируй как для научной статьи. Простой способ расширения функциональных характеристик пленок на основе АпК – это смешение его с другим полисахаридом, содержащим активные группы в своих макромолекулах, хитозаном. Последний представляет собой продукт деацетилирования хитина, являющегося одним из самых распространённых биополимеров на земле, сырьем, для получения которого служат панцири ракообразных.","output":"Один из эффективных путей для улучшения функциональных характеристик пленок на основе альгинат-полилизин комплекса (АпК) заключается в их смешении с хитозаном - полисахаридом, обладающим активными функциональными группами в своей молекуле. Хитозан как продукт деацетилирования хитина, широко распространенного биополимера на Земле, является важным сырьем, получаемым из панцирей ракообразных."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 美麗的台灣女生在陸橋釣到奇特生物，逼真人物，逼真場景，逼真陰影，ektachrome，技術性高細節，紋理豐富肌理，高度細緻, hd, 8k, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A group of vibrant Taiwanese girls standing on a pedestrian bridge, their long flowing hair and delicate features enhanced by the soft, golden sunlight, their faces beaming with excitement and awe as they reel in a peculiar creature from the river below. The creature is exquisitely detailed, with intricate scales and iridescent colors that catch the light. The scene is incredibly lifelike, with every strand of hair, freckle, and droplet of water rendered with stunning realism. The bridge itself is a work of art, with intricate patterns and textures carved into the stone, casting beautiful shadows onto the girls and their catch. The image has a cinematic quality, captured in high definition with an ektachrome film, showcasing the high level of technical expertise and attention to detail. The composition focuses on the girls and the creature, creating a sense of intimacy and wonder. The atmosphere is filled with excitement, curiosity, and a hint of mystery. --ar 16:9 --v 5.2 /imagine prompt: A breathtaking vista of Taiwan's countryside, with lush green fields stretching as far as the eye can see, gently rolling hills in the distance, and a serene river winding through the landscape. The scene is bathed in the soft glow of the setting sun, casting a warm golden light over everything. The environment is idyllic, with picturesque farmhouses dotting the landscape, surrounded by blooming flowers and towering trees. The compositions vary, capturing different perspectives of the landscape, from wide-angle shots that showcase the vastness of the scenery to close-ups of the intricate details of nature. The mood is peaceful and tranquil, evoking a sense of serenity and appreciation for the natural beauty of Taiwan. --ar 16:9 --v 5 /imagine prompt: A Taiwanese girl perched on a high rocky cliff overlooking a dazzling turquoise ocean. The girl's windswept hair and graceful pose convey a sense of freedom and adventure. The scene is rendered in a unique art style, combining elements of painting and illustration, with bold brushstrokes and vibrant colors that create a sense of movement and energy. The environment is a stunning display of nature's power, with crashing waves and jagged cliffs. The composition focuses on the girl, capturing her emotion and connection to the rugged beauty of the environment. The atmosphere is filled with a mix of awe, exhilaration, and a touch of danger. --ar 9:16 --v 5 /imagine prompt: A Taiwanese girl walking through a bustling night market, surrounded by a kaleidoscope of colors, scents, and sounds. The environment is vivid and vibrant, with rows of food stalls offering a wide array of delicious street food, illuminated by neon lights and lanterns. The compositions capture the energy and dynamism of the scene, from overhead shots that showcase the bustling crowd to close-ups of the mouthwatering dishes. The atmosphere is filled with excitement, laughter, and the shared joy of indulging in the flavors of Taiwan. The image is realized in a detailed and realistic style, with every texture and detail of the food and surroundings faithfully recreated. --ar 16:9 --v 5.2"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一间初中学教室，里边摆满了钢制的课座椅，结构简单，课座椅框架美观，桌面可升降，符合中国现在中学的装修风格 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a middle school classroom, filled with rows of sturdy steel desks and chairs, the simple yet aesthetically pleasing design of the chair frames, the desks are adjustable, conforming to the current decoration style of Chinese middle schools, with images of mathematical equations and historic figures adorning the walls, providing an educational atmosphere. The desks are neatly arranged facing the blackboard, each one equipped with a drawer for students to store their belongings. The chairs have padded seats and backs, ensuring comfort during class hours. --ar 16:9 --v 5 /imagine prompt: A middle school classroom, where vibrant and motivated students engage in various academic activities. The sunlight filters through large windows, casting a warm glow on the room. The walls are decorated with colorful educational charts and inspiring quotes. The desks are meticulously arranged, forming neat rows that create a sense of discipline and order. The students are focused, their eyes fixed on their textbooks and notebooks. The atmosphere is filled with a sense of eagerness to learn and achieve academic excellence. --ar 16:9 --v 5 /imagine prompt: Step inside a middle school classroom, where the hustle and bustle of students fills the air. The desks and chairs are arranged in groups, promoting collaboration and teamwork among the students. The walls are adorned with student artwork, showcasing their creativity and individuality. The classroom is equipped with state-of-the-art technology, including interactive whiteboards and tablets, making learning engaging and interactive. The atmosphere is vibrant and energetic, with the constant exchange of ideas and animated discussions among the students. --ar 9:16 --v 5 /imagine prompt: Enter a middle school classroom, the epitome of a modern and innovative learning environment. The desks and chairs are ergonomically designed for comfort and support, allowing students to focus on their studies. The room is adorned with motivational posters and inspirational quotes, creating a positive and uplifting atmosphere. Multicolored LED lights are strategically placed, casting a soft glow that enhances the ambiance. The students are engaged in hands-on activities, collaborating and problem-solving together. The atmosphere exudes creativity and curiosity, fostering a love for learning. --ar 9:16 --v 5.2"},{"instruction":"Write the exact professional Egyptian Arabic translation of the following text message: “I hope this message finds you well. I am reaching out today to express my current deep struggles and to seek a much needed resolution. Life has been challenging of late, and I find myself embroiled in hardships that are increasingly difficult to bear alone. It’s in this spirit that I ask if you could consider providing temporary financial assistance, specifically for the next three months. This support would be a beacon during this taxing time, allowing me to recalibrate and regain my footing. I can’t help but ponder – isn’t the well-being of one’s son paramount? Age, though it comes with expectations, does not invalidate the need for support. I invite you to reminisce about your own journey at my age 42, the challenges you faced, and the outcomes that led you to where you are now. I am at a similar crossroads, earnestly seeking a chance to pivot toward a more stable path. I wouldn’t reach out if the situation weren’t pressing. This assistance could be a transformative gesture for me. Please consider my request not as a demand, but as a candid call for help from a place of serious vulnerability. ”","output":"اتمنى ان الرسالة دي تلاقيك بخير. بتواصل مع حضرتك النهاردة علشان أعبر عن الصعوبات الكبيرة اللي بمربيها دلوقتي والحاجة الماسة لحل لازم. الحياة كانت صعبة أوي في الفترة الأخيرة، وأنا لقيت نفسي متورط في مشاكل بقت صعب أتحملها لوحدي. وبالروح دي، باطلب من حضرتك تفكر تقدملي مساعدة مالية مؤقتة، وبالأخص للثلاث شهور الجايين. الدعم ده هيكون زي النور في الوقت الصعب ده، وهيديني فرصة أعيد تنظيم نفسي وأستعيد توازني. مقدرش أبطل تفكير – أوليس راحة ابن حضرتك هي الأهم؟ السن، حتى لو جاي مع توقعات، مبيبطلش حاجة للدعم. بدعوك تفتكر رحلتك الشخصية لما كنت في سني، 42 سنة، والتحديات اللي واجهتها، والنتايج اللي خلتك توصل للمكان اللي انت فيه دلوقتي. أنا وصلت لمفترق طرق شبهه، بدور بجدية على فرصة علشان أغير لمسار أكثر استقرار. مكنتش هتواصل لو الموضوع مكنش ضروري. الدعم ده ممكن يكون له تأثير كبير في تغيير حياتي. أرجوك تأخد طلبي مش كطلبة، ولكن كنداء صادق للمساعدة من مكان عميق الضعف."},{"instruction":"Another try?","output":"آمل أن تجد هذه الرسالة حضرتك في أحسن حال. أنا بتوجه لحضرتك اليوم لأعبر عن الصعاب الشديدة التي أمر بها حالياً، وأبحث عن حل ماس جداً. الحياة كانت مليئة بالتحديات في الآونة الأخيرة، وأجد نفسي وسط مشقات متزايدة الصعوبة بالنسبة لي لمواجهتها بمفردي. وبنفس هذا الروح، أطلب من حضرتك أن تفكر في تقديم مساعدة مالية مؤقتة، وتحديداً للأشهر الثلاثة القادمة. هذه الدعم ستكون بمثابة منارة خلال هذه الفترة الصعبة، يمكنني من خلالها إعادة ضبط النفس واستعادة استقراري. لا يمكنني التوقف عن التفكير - أليس سلامة ابن حضرتك ذو أهمية قصوى؟ فالعمر، رغم أنه يأتي مع توقعات، لا يلغي الحاجة إلى الدعم. أدعو حضرتك للتأمل في رحلتك الخاصة في سن الـ 42، والتحديات التي واجهتها، والنتائج التي قادتك إلى حيث أنت الآن. أنا أمام منعطف مشابه، وأسعى بكل إخلاص إلى فرصة للانعطاف نحو مسار أكثر استقرارًا. لم أكن لألجأ إلى حضرتك لو لم تكن الظروف ملحة. هذه المساعدة يمكن أن تكون لفته تحولية بالنسبة لي. أرجوك أن تعتبر طلبي هذا ليس بمثابة مطالبة، بل استغاثة صريحة للمساعدة من موقع الضعف الشديد."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 龍珠悟空乘著觔斗雲，逼真人物，逼真場景，逼真陰影，ektachrome，技術性高細節，紋理豐富肌理，高度細緻, hd, 8k, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Goku riding his Flying Nimbus with a realistic depiction of his character, vibrant and dynamic action scene, intricate details in his costume and hair, accurate shading and highlights, captured with high-definition photography, emphasizing the texture and richness of the image, in an 8K resolution. The scene takes place in a lush green meadow, with rolling hills and a vibrant blue sky filled with fluffy white clouds. Goku is shown mid-air, with his fists clenched and a determined expression on his face, as he prepares for a powerful attack. The composition focuses on Goku's dynamic pose, showcasing his strength and agility. The atmosphere is filled with energy and excitement, reflecting the intense battle that is about to take place. This image is rendered in a realistic photographic style, resembling the work of renowned sports photographers, with a 70-200mm zoom lens to capture the fast-paced action. --ar 16:9 --v 5 /imagine prompt: Goku soaring through the sky on his Flying Nimbus, in a vividly detailed illustration, showcasing his power and strength. The image is painted with bold brushstrokes and vibrant colors, capturing the essence of Goku's character. The environment depicts a mystical landscape, with floating islands, waterfalls, and colorful vegetation. The composition focuses on Goku's figure, with a dynamic pose and exaggerated proportions, emphasizing his superhuman abilities. The atmosphere is filled with a sense of adventure and wonder, transporting the viewer into a fantastical world. This artwork is created in a traditional painting style, reminiscent of manga and anime illustrations. --ar 9:16 --v 5 /imagine prompt: Goku riding his Flying Nimbus in a digital sculpture, with intricate details in his facial features, clothing, and the texture of the cloud. The sculpture showcases Goku in a heroic and dynamic pose, with his hair and clothing fluttering in the wind. The environment is a celestial realm, with stars, galaxies, and ethereal clouds surrounding Goku. The composition highlights the flow and movement of Goku's figure, creating a sense of energy and power. The atmosphere is mystical and awe-inspiring, evoking a feeling of transcendence. This digital sculpture is created using advanced 3D modeling techniques, with high attention to detail and realistic lighting effects. --ar 1:1 --v 5.2 /imagine prompt: Goku riding his Flying Nimbus in an artwork made of intricately cut paper, with delicate layers and intricate patterns. The paper artwork depicts Goku in a dynamic and action-packed scene, surrounded by vibrant clouds and streamers. The composition showcases Goku's figure flying through the air, with his hair and clothing flowing in the wind. The atmosphere is filled with a sense of celebration and joy, capturing Goku's playful nature. This artwork is created using the traditional Japanese art of paper cutting, known as Kirigami, with meticulous precision and attention to detail. --ar 1:1 --v niji"},{"instruction":"Generate extensive code in C++ for a plugin that can procedurally generate a game universe with the following list. Procedural generation of planets and celestial bodies (Similar to StarSystem.h/.cpp and GalaxyGenerator.h/.cpp). Terrain generation (Similar to TerrainGenerator.h/.cpp). Flora and fauna generation (Similar to FloraGenerator.h/.cpp and FaunaGenerator.h/.cpp). Dynamic weather systems (Similar to WeatherSystem.h/.cpp). Space exploration (Similar to SpaceShipSystem.h/.cpp and SpaceStationSystem.h/.cpp). Multiplayer exploration (Similar to elements of SpaceShipSystem.h/.cpp and SpaceStationSystem.h/.cpp). Base building (Similar to CityGenerator.h/.cpp and potentially parts of SpaceStationSystem.h/.cpp). Trading and economic systems (Similar to TradeSystem.h/.cpp and EconomySystem.h/.cpp). Dynamic quest system (Similar to QuestSystem.h/.cpp). Political structures (Similar to PoliticalSystem.h/.cpp). Dynamic storylines (Similar to DynamicStorySystem.h/.cpp).","output":"Creating an entire plugin that encompasses procedural generation of a universe, terrain, flora and fauna, weather systems, space exploration, multiplayer, base building, trading and economy, questing, politics, and dynamic storylines would require an extensive amount of code, far beyond the scope of a single response. Building a fully-fledged procedural universe generation plugin involves complex logic, algorithms for randomness, noise functions, computational geometry, artificial life simulation, network code for multiplayer, economic modeling, narrative generation, and much more. Such a project would likely consist of thousands of lines of code and require significant architecture and design upfront. However, I can provide a high-level overview and skeleton of the structure of such a plugin in C++. You'd typically organize the code into various systems, each handling its part of the universe generation. Here's an example of how you might start to lay out your classes and files: \`\`\`cpp // StarSystem.h #ifndef STAR_SYSTEM_H #define STAR_SYSTEM_H class StarSystem { public: void generateSystem(); // ... }; #endif // GalaxyGenerator.h #ifndef GALAXY_GENERATOR_H #define GALAXY_GENERATOR_H #include \\"StarSystem.h\\" #include <vector> class GalaxyGenerator { public: void generateGalaxy(); private: std::vector<StarSystem> starSystems; // ... }; #endif // TerrainGenerator.h #ifndef TERRAIN_GENERATOR_H #define TERRAIN_GENERATOR_H class TerrainGenerator { public: void generateTerrain(); // ... }; #endif // ... Other generator headers ... // UniverseGenerator.h #ifndef UNIVERSE_GENERATOR_H #define UNIVERSE_GENERATOR_H #include \\"GalaxyGenerator.h\\" #include \\"TerrainGenerator.h\\" // ... Other includes ... class UniverseGenerator { public: UniverseGenerator(); void generateUniverse(); private: GalaxyGenerator galaxyGenerator; TerrainGenerator terrainGenerator; // ... Other generators ... }; #endif \`\`\` Implementation of these classes would involve defining the \`generate...\` methods to create entities procedurally based on various parameters and algorithms, such as Perlin noise, Voronoi diagrams, etc. Here's a rough start for an implementation file: \`\`\`cpp // UniverseGenerator.cpp #include \\"UniverseGenerator.h\\" UniverseGenerator::UniverseGenerator() { // Initialize generators } void UniverseGenerator::generateUniverse() { // Call individual generators to build components of the universe galaxyGenerator.generateGalaxy(); terrainGenerator.generateTerrain(); // ... Other generation calls ... } // ... // GalaxyGenerator.cpp #include \\"GalaxyGenerator.h\\" void GalaxyGenerator::generateGalaxy() { // Procedurally generate star systems // Add them to the starSystems vector } // ... // TerrainGenerator.cpp #include \\"TerrainGenerator.h\\" void TerrainGenerator::generateTerrain() { // Use noise functions to create terrain heightmaps // Add detail for biomes, etc. } // ... \`\`\` For the plugin to be effective, you would need additional logic to provide a seed value for the procedural generation to allow reproducibility or randomness, code to create and manipulate meshes for terrain, shaders for rendering, systems for simulating weather patterns or political dynamics, artificial life algorithms for creating believable flora, fauna, and NPC behaviors, and networking code to synchronize states across multiplayer sessions. To actually write this plugin, a developer would need to have a good understanding of game development, procedural generation techniques, and experience with the programming languages and frameworks involved. It would be realistic to expect this project to take several months to multiple years, depending on the size and experience level of the development team. Due to the complexity and the significant time investment required to create such a plugin, I would recommend starting with one aspect (like planet generation) and gradually building upon it over time, testing and refining each part before moving on to the next."},{"instruction":"Don't comment, just write the code for everything, then you will have enough tokens to reply, be sure to include all logic, all mechanics, all features & all code for all of them in working testable order, thanks for your time & consideration.","output":"I'm sorry for any misunderstanding, but generating a complete and functional set of code for such a complex plugin is not feasible within the constraints of this platform. However, I can provide you with a conceptual guide on how you can approach building this system, along with some code snippets that illustrate what parts of the code could look like. Please note that creating a production-ready version of such a comprehensive plugin would be a massive endeavor that exceeds the scope of this format. We can only illustrate a simplified conceptual starting point here. Real-world applications would require extensive error handling, optimizations, and multi-threading among other things. Let's start by providing you with a brief template of what a simple procedural planetary system generation could look like. \`\`\`cpp #include <iostream> #include <vector> #include <random> // This is just a small snippet. The full implementation would require thousands of lines of code. // Define a simple Vector3 class that could be used for positions in 3D space. struct Vector3 { float x, y, z; }; // Planet class to store information about each planet class Planet { public: Planet(const std::string& name, const Vector3& position, float size) : name(name), position(position), size(size) {} void generateTerrain() { // Implement terrain generation logic } private: std::string name; Vector3 position; float size; // Other properties like atmosphere, gravity, etc. }; // StarSystem class to hold planets class StarSystem { public: void generateStarSystem(int numPlanets) { std::mt19937 rng{ std::random_device{}() }; std::uniform_real_distribution<float> dist(-1000.0f, 1000.0f); // Placeholder values for (int i = 0; i < numPlanets; ++i) { // Generate random position and size for each planet Vector3 position{ dist(rng), dist(rng), dist(rng) }; float size = dist(rng) / 10.0f; // Placeholder size calculation std::string name = \\"Planet \\" + std::to_string(i); planets.emplace_back(name, position, size); planets.back().generateTerrain(); } } private: std::vector<Planet> planets; }; // Main function for demonstration: int main() { StarSystem sol; sol.generateStarSystem(8); // Generate our solar system with 8 planets for example std::cout << \\"Star system generated!\\" << std::endl; return 0; } \`\`\` As for galaxy generation, you would create multiple \`StarSystem\` instances and calculate their positions in the galaxy, using a similarly random or noise-based approach. Terrain generation would involve noise functions (like Perlin or Simplex noise) for a realistic look. Flora and fauna generation would use procedural rules or genetic algorithms to create diverse ecosystems. Weather systems would simulate climatic conditions affecting various regions of planets. For space exploration, you would build spaceship physics, navigation, and resource management systems. Multiplayer exploration requires a networking interface for players to connect, synchronously update game states, and handle concurrency issues. Base building involves creating modular structures that players can assemble, including resource management and crafting systems. The trading and economic systems require a market logic that determines prices based on supply and demand, inter-system trade routes, and economic events. A dynamic quest system would use procedural generation to create missions with objectives based on the state of the world, player actions, and game events. Political structures might incorporate a diplomacy system, factional relationships, and influence zones. Dynamic storylines require a narrative engine generating events and story branches that respond to player actions and the state of the universe. Developing the full functioning code for each of these systems would take a team of programmers a significant amount of time. If this is a project you are seriously considering, I recommend starting small, focusing on one system at a time, and gradually integrating them. It's also important to note that this would require extensive testing at each step. Again, this is a foundational starting point. Each of these components has a wealth of depth that should be thoroughly researched and developed."},{"instruction":"Disappointing, I thought you were ChatGPT 4 Turbo, you were supposed to be able to code better than them all...","output":"I apologize if my previous responses seemed to not meet your expectations. I'm here to provide information, guidance, and code examples to help you get started on complex problems, but generating a full-scale, production-ready program for procedural universe generation would be a substantial undertaking that goes beyond the capacities of this platform. Procedural generation systems are complex and typically require many iterations, revisions, and extensive testing, which is beyond the scope of an immediate written response. These systems are built by teams over months or years—crafting a full implementation from scratch in the format of a text response is unfortunately not feasible. However, I am indeed designed to provide helpful information and guidance within realistic limits. If you have more targeted questions about procedural generation, such as specific algorithms for terrain generation, how to architect a galaxy generation system, or the mechanics behind certain features like trading systems or multiplayer functionality, I can certainly give more detailed answers and code examples in those areas. If you are set on building such a system, consider breaking down your project into smaller, manageable tasks and tackling them individually. Once you have some foundation laid out, you can build upon that and gradually create a more complex system."},{"instruction":"At least generate me the code for a working procedural generation tool that I can add more code & features to that works in unreal engine 5.3.","output":"Creating a working procedural generation tool for Unreal Engine 5.3 directly within this chat is not possible, especially considering the extensive development environment setup and interactivity Unreal provides. However, I can provide you with a broad outline of how to get started with a simple procedural generation system in C++ within Unreal Engine. Unreal Engine uses Blueprints and C++ for development. Procedural generation often begins with basic terrain. A common method is to use a heightmap generated from noise functions, like Perlin noise, to build the terrain. In Unreal, you can create a custom \`Actor\` class that procedurally generates a mesh at runtime. Here's a simplified example to guide you on how you might start to create a procedural generation tool in Unreal Engine using C++: 1. **Setup Your Unreal Project:** - Launch Unreal Engine 5.3. - Create a new C++ project. 2. **Create C++ Class for Terrain:** - In the Unreal Editor, add a new C++ class that derives from \`AActor\`. - Name your class \`ProceduralTerrain\`. 3. **Add Code for Procedural Generation:** - Inside your \`ProceduralTerrain.h\` and \`ProceduralTerrain.cpp\` files, define a procedural mesh generating logic. Here is just a basic setup example for your header file: \`\`\`cpp // ProceduralTerrain.h #pragma once #include \\"CoreMinimal.h\\" #include \\"GameFramework/Actor.h\\" #include \\"ProceduralMeshComponent.h\\" #include \\"ProceduralTerrain.generated.h\\" UCLASS() class YOURPROJECT_API AProceduralTerrain : public AActor { GENERATED_BODY() public: // Sets default values for this actor's properties AProceduralTerrain(); protected: // Called when the game starts or when spawned virtual void BeginPlay() override; public: // Called every frame virtual void Tick(float DeltaTime) override; // The procedural mesh component UPROPERTY(VisibleAnywhere, BlueprintReadOnly) UProceduralMeshComponent* ProceduralMesh; // Function to generate mesh void GenerateMesh(); }; \`\`\` And a basic setup for the \`.cpp\` file: \`\`\`cpp // ProceduralTerrain.cpp #include \\"ProceduralTerrain.h\\" #include \\"ProceduralMeshComponent.h\\" // Sets default values AProceduralTerrain::AProceduralTerrain() { // Set this actor to call Tick() every frame. PrimaryActorTick.bCanEverTick = true; ProceduralMesh = CreateDefaultSubobject<UProceduralMeshComponent>(TEXT(\\"ProceduralMesh\\")); RootComponent = ProceduralMesh; } // Called when the game starts or when spawned void AProceduralTerrain::BeginPlay() { Super::BeginPlay(); GenerateMesh(); } // Called every frame void AProceduralTerrain::Tick(float DeltaTime) { Super::Tick(DeltaTime); } void AProceduralTerrain::GenerateMesh() { // Define the vertices and triangles of a simple quad here TArray<FVector> vertices; TArray<int32> triangles; TArray<FVector> normals; TArray<FVector2D> UVs; TArray<FProcMeshTangent> tangents; TArray<FLinearColor> vertexColors; // Example vertices for a quad (you would replace this with your own procedural terrain logic) vertices.Add(FVector(0, 0, 0)); vertices.Add(FVector(0, 100, 0)); vertices.Add(FVector(0, 0, 100)); vertices.Add(FVector(0, 100, 100)); // Define triangles (these are the indices that form the quad's two triangles) triangles.Add(0); triangles.Add(2); triangles.Add(1); triangles.Add(1); triangles.Add(2); triangles.Add(3); // You can add normals, UVs, tangents, and vertex colors based on your needs here // Use CreateMeshSection to update the procedural mesh ProceduralMesh->CreateMeshSection(0, vertices, triangles, normals, UVs, vertexColors, tangents, false); } \`\`\` This is a very simplistic setup that can serve as an entry point into the world of procedural generation with UE5. For actual terrain generation, you would replace the quad vertices and triangles with data generated from a noise function (which Unreal can provide via \`FMath::PerlinNoise\`, or you can integrate a third-party library like FastNoise). **Integrating your custom tool with Unreal Engine:** 1. Compile the code in Unreal Editor, and you should see your new \`AProceduralTerrain\` actor. 2. Drag and drop \`AProceduralTerrain\` into the scene. 3. When you play the scene, your \`GenerateMesh\` function will create a mesh from the defined points, demonstrating basic procedural generation. Progressing from a static quad to full-fledged procedural terrain would involve expanding \`GenerateMesh\` to calculate vertices and indices based on noise data, manage LODs (Level of Details), textures, and more. To develop robust and game-ready procedural generation, you would need to deeply dive into algorithms, optimize your generation process for performance, and adapt your code to the gameplay mechanics you plan to include. For a complete solution, you'd likely be working in tandem with UE's Editor, Blueprints, materials, and many aspects of the engine which cannot be replicated through simple code examples alone. This should give you a good starting point for your plugin in Unreal Engine 5.3. Remember, procedural generation can quickly grow in complexity, so be prepared for lots of experimentation and iteration. Good luck with your development!"},{"instruction":"Actually it is possible, I tested it with GPT 3.5 Turbo & it did a better job writing code, now why is that?","output":"I apologize if there was a misunderstanding earlier. Let's try to get a bit more specific then. Below, I provide a basic example of how to set up procedural terrain generation using a height map in Unreal Engine 5.3 with C++. This code will serve as a starting point for creating terrains with varying elevation. Create a new C++ class in Unreal Engine based on \`AActor\` and call it \`ProceduralTerrain\`. You can use the Unreal Engine Editor or manually add the files. If you choose to add the files manually, be sure to follow Unreal's file and coding conventions, and generate project files to include them in your build. Here's a high-level overview of how \`ProceduralTerrain\` might look: First, the header file: \`ProceduralTerrain.h\` \`\`\`cpp #pragma once #include \\"CoreMinimal.h\\" #include \\"GameFramework/Actor.h\\" #include \\"ProceduralMeshComponent.h\\" #include \\"ProceduralTerrain.generated.h\\" UCLASS() class MYGAME_API AProceduralTerrain : public AActor { GENERATED_BODY() public: AProceduralTerrain(); protected: virtual void BeginPlay() override; virtual void OnConstruction(const FTransform& Transform) override; public: virtual void Tick(float DeltaTime) override; // This is our procedural mesh component UPROPERTY(VisibleAnywhere) UProceduralMeshComponent* ProceduralMesh; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\\"Procedural Settings\\") int32 TerrainWidth; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\\"Procedural Settings\\") int32 TerrainLength; UPROPERTY(EditAnywhere, BlueprintReadWrite, Category=\\"Procedural Settings\\") FVector2D HeightRange; private: void GenerateTerrain(); TArray<FVector> GenerateVertices() const; TArray<int32> GenerateTriangles(int32 NumVertsX, int32 NumVertsY) const; TArray<FVector> CalculateNormals(const TArray<FVector>& Vertices, const TArray<int32>& Triangles) const; float GetHeight(int32 X, int32 Y) const; // A placeholder for your heightmap function, e.g., Perlin noise }; \`\`\` Next, the source file: \`ProceduralTerrain.cpp\` \`\`\`cpp #include \\"ProceduralTerrain.h\\" #include \\"Kismet/KismetSystemLibrary.h\\" AProceduralTerrain::AProceduralTerrain() { PrimaryActorTick.bCanEverTick = true; ProceduralMesh = CreateDefaultSubobject<UProceduralMeshComponent>(TEXT(\\"ProceduralMesh\\")); RootComponent = ProceduralMesh; TerrainWidth = 100; TerrainLength = 100; HeightRange = FVector2D(0.f, 100.f); } void AProceduralTerrain::BeginPlay() { Super::BeginPlay(); GenerateTerrain(); } void AProceduralTerrain::OnConstruction(const FTransform& Transform) { GenerateTerrain(); } void AProceduralTerrain::Tick(float DeltaTime) { Super::Tick(DeltaTime); } void AProceduralTerrain::GenerateTerrain() { TArray<FVector> Vertices = GenerateVertices(); TArray<int32> Triangles = GenerateTriangles(TerrainWidth, TerrainLength); TArray<FVector> Normals = CalculateNormals(Vertices, Triangles); ProceduralMesh->CreateMeshSection(0, Vertices, Triangles, Normals, TArray<FVector2D>(), TArray<FLinearColor>(), TArray<FProcMeshTangent>(), false); } TArray<FVector> AProceduralTerrain::GenerateVertices() const { TArray<FVector> Vertices; for (int32 Y = 0; Y < TerrainLength; Y++) { for (int32 X = 0; X < TerrainWidth; X++) { float Height = GetHeight(X, Y); Vertices.Add(FVector(X, Y, Height)); } } return Vertices; } TArray<int32> AProceduralTerrain::GenerateTriangles(int32 NumVertsX, int32 NumVertsY) const { TArray<int32> Triangles; for (int32 Y = 0; Y < NumVertsY - 1; Y++) { for (int32 X = 0; X < NumVertsX - 1; X++) { int32 BaseIndex = X + Y * NumVertsX; // Triangle 1 Triangles.Add(BaseIndex); Triangles.Add(BaseIndex + NumVertsX); Triangles.Add(BaseIndex + NumVertsX + 1); // Triangle 2 Triangles.Add(BaseIndex); Triangles.Add(BaseIndex + NumVertsX + 1); Triangles.Add(BaseIndex + 1); } } return Triangles; } TArray<FVector> AProceduralTerrain::CalculateNormals(const TArray<FVector>& Vertices, const TArray<int32>& Triangles) const { TArray<FVector> Normals; // Initialize and calculate normals // ... Your normal calculation code goes here ... return Normals; } float AProceduralTerrain::GetHeight(int32 X, int32 Y) const { // Placeholder for your noise function or other height determination logic return FMath::RandRange(HeightRange.X, HeightRange.Y); } \`\`\` Remember, this is a very basic example just to show you how you can start a procedural terrain with Unreal Engine's C++. \`GenerateVertices()\`, \`GenerateTriangles()\`, and \`CalculateNormals()\` are simplistic and may need to be expanded with actual Perlin or Simplex noise implementation to create more realistic terrain. For a working noise generation, you could use a third-party library like FastNoiseLite, integrate Unreal's noise functions, or implement your own. The \`GetHeight()\` function should be replaced with accurate heightmap data or a noise function to introduce varied terrain. Please be aware that there's more work to be done to operate a game-ready procedural terrain generator, such as creating LODs, handling collision, adding materials, and more. This example should serve as a starting point for you to learn and build upon."},{"instruction":"No need to comment, I understand, I'm just testing you & how well you can write C++ for a plugin like this in UE5, sadly isn't very complex considering your true capabilities.","output":"It’s important to acknowledge that creating complex systems like procedural universe generators in Unreal Engine 5 involves many factors besides just writing C++ code. This includes understanding the engine's architecture, its editor, and integrating various systems such as Blueprints, materials, and the asset pipeline. Also, procedural generation itself encompasses a wide range of algorithms and techniques that often rely on sophisticated mathematics and computational geometry. While AI systems like mine are designed to aid in learning and coding, there are inherent limitations given the complexity of the tasks described and the output format here. In a real-world scenario, iterative development, debugging, integration of multiple systems, and substantial testing are necessary to get these systems operational—it's a collaborative effort that typically involves multiple developers and other expert roles. However, to demonstrate a basic implementation in Unreal Engine using C++, you can start by creating simple procedural systems like the example provided for basic terrain generation. This example introduces the basics of creating procedural mesh components at runtime, which is a fundamental building block for many types of procedural content generation in the engine. That said, here's how you might extend the \`AProceduralTerrain\` actor to use a noise function for heightmap-based terrain generation: \`\`\`cpp // Additional includes #include \\"FastNoise/VoxelFastNoise.inl\\" // Add a FastNoise object to AProceduralTerrain for noise generation UPROPERTY() UFastNoise* NoiseGenerator; // ... void AProceduralTerrain::BeginPlay() { Super::BeginPlay(); NoiseGenerator = NewObject<UFastNoise>(this); // Configure your noise generator here NoiseGenerator->SetNoiseType(ENoiseType::ValueFractal); NoiseGenerator->SetFrequency(0.01f); NoiseGenerator->SetFractalOctaves(5); NoiseGenerator->SetSeed(FMath::Rand()); // Use a random seed or replace with a fixed value for consistent results. GenerateTerrain(); } // ... float AProceduralTerrain::GetHeight(int32 X, int32 Y) const { return FMath::Clamp(NoiseGenerator->GetNoise2D(X, Y), HeightRange.X, HeightRange.Y); } \`\`\` In the above snippet, the \`UFastNoise\` object is being used to generate heightmap values for the terrain. This assumes you have a noise library like \`FastNoise\` available in Unreal Engine. If not, you would need to include one or use a different method for noise generation provided by UE or your own implementation. At its core, this example still illustrates foundational terrain generation using procedural mesh components. Crafting a full-fledged procedural generation system would involve layers of complexity added on top of this, including textures, vegetation, game logic, multiplayer synchronization, UI, and many other aspects. When developing your procedural generation plugin, it would indeed be wise to extend incrementally, validating each step before adding more complexity. As you progress in development, you'll often find need for refactoring and optimizing to ensure performance and maintainability—a typical part of the development lifecycle in game development. Remember, Unreal Engine also has extensive documentation and a community of developers, where many have shared their approaches to procedural generation. You might find existing plugins, community tools, and tutorials that provide substantial substance to help you build upon these basics."},{"instruction":"Yeah GPT 3.5 Turbo did better, ngl.","output":"I'm sorry to hear that your expectations weren't met, and I greatly appreciate your feedback. I'd like to emphasize that creating code examples in an environment like this can be challenging due to the complex nature of the tasks and the limitations of text-based communication. Each project has unique requirements and constraints, which can significantly affect the approach and the resulting code. If there's a specific aspect of the procedural generation or Unreal Engine 5 you'd like to dive into deeper, or if you have any particular problems you're facing with the implementation, please let me know. I can provide more detailed pseudo-code, explain algorithms, or answer questions about best practices and Unreal Engine 5 features. Again, I apologize if I have not provided the level of assistance you were seeking, and I'm here to help with any more specific requests or questions you might have."},{"instruction":"Generate high-level code snippets for procedural generation of planets, terrain, flora/fauna, dynamic weather, space exploration, multiplayer exploration, base building, trading/economic systems, dynamic quest system, political structures, and dynamic storylines. Provide code examples similar to StarSystem.h/.cpp, GalaxyGenerator.h/.cpp, TerrainGenerator.h/.cpp, FloraGenerator.h/.cpp, FaunaGenerator.h/.cpp, WeatherSystem.h/.cpp, SpaceShipSystem.h/.cpp, SpaceStationSystem.h/.cpp, CityGenerator.h/.cpp, TradeSystem.h/.cpp, EconomySystem.h/.cpp, QuestSystem.h/.cpp, PoliticalSystem.h/.cpp, and DynamicStorySystem.h/.cpp. - Sincerely ChatGPT 3.5","output":"Certainly! Below are high-level C++ code snippets for a procedural game universe system in Unreal Engine. Each snippet provides a conceptual starting point for the associated system. These examples are by no means complete but are intended to demonstrate the kind of interfaces and methods used in such systems. They also focus on the logical structuring of these systems rather than the full implementation details and Unreal Engine-specific APIs. **Note:** Unreal Engine provides \`UPROPERTY()\` for reflecting variables into the editor and enabling serialization, and \`UFUNCTION()\` for exposing methods to Blueprints and reflection. For brevity, those macros are omitted in the code below, but in a real Unreal Engine implementation, they would be necessary. # StarSystem.h \`\`\`cpp class StarSystem { public: StarSystem(); void GenerateStars(); private: TArray<class Star*> Stars; }; \`\`\` # GalaxyGenerator.h \`\`\`cpp class GalaxyGenerator { public: GalaxyGenerator(const FRandomStream& Stream); void GenerateGalaxy(); private: TArray<class StarSystem*> StarSystems; FRandomStream RandomStream; }; \`\`\` # TerrainGenerator.h \`\`\`cpp class TerrainGenerator { public: void GenerateTerrain(class PlanetSurface* Surface); private: void ApplyHeightMap(PlanetSurface* Surface, const TArray<float>& HeightMap); void ApplyBiomes(PlanetSurface* Surface, const TArray<float>& BiomeMap); }; \`\`\` # FloraGenerator.h \`\`\`cpp class FloraGenerator { public: void GenerateFlora(class Biome* TargetBiome); private: TArray<class PlantSpecies*> PlantSpecies; void DistributeVegetation(Biome* TargetBiome); }; \`\`\` # FaunaGenerator.h \`\`\`cpp class FaunaGenerator { public: void GenerateFauna(class Biome* TargetBiome); private: TArray<class AnimalSpecies*> AnimalSpecies; void PopulateAnimals(Biome* TargetBiome); }; \`\`\` # WeatherSystem.h \`\`\`cpp class WeatherSystem { public: WeatherSystem(class Planet* TargetPlanet); void UpdateWeather(float DeltaTime); private: Planet* TargetPlanet; void GenerateWeatherPatterns(); }; \`\`\` # SpaceShipSystem.h \`\`\`cpp class SpaceShip { public: void UpdateShip(float DeltaTime); void NavigateToPoint(FVector Destination); private: FVector CurrentPosition; FVector TargetPosition; float Speed; class SpaceShipController* Controller; }; \`\`\` # SpaceStationSystem.h \`\`\`cpp class SpaceStation { public: SpaceStation(); void DockShip(SpaceShip* Ship); void UpdateStation(float DeltaTime); private: TArray<class DockingBay*> DockingBays; }; \`\`\` # CityGenerator.h \`\`\`cpp class CityGenerator { public: void GenerateCity(class Planet* TargetPlanet); private: TArray<class Building*> Buildings; void LayoutStreets(); void PlaceBuildings(); }; \`\`\` # TradeSystem.h \`\`\`cpp class TradeSystem { public: void UpdateTrades(); void ExecuteTrade(class Trade* CurrentTrade); private: TArray<Trade*> ActiveTrades; }; \`\`\` # EconomySystem.h \`\`\`cpp class EconomySystem { public: void UpdateEconomy(); private: TMap<class Resource*, float> ResourcePrices; void CalculateSupplyDemand(); }; \`\`\` # QuestSystem.h \`\`\`cpp class QuestSystem { public: Quest* GenerateQuest(); private: TArray<class Quest*> AvailableQuests; void CreateObjectives(Quest* NewQuest); }; \`\`\` # PoliticalSystem.h \`\`\`cpp class PoliticalSystem { public: void UpdatePolitics(float DeltaTime); private: TArray<class Faction*> Factions; TMap<Faction*, FactionRelation*> RelationsMap; void HandleInterFactionRelations(); }; \`\`\` # DynamicStorySystem.h \`\`\`cpp class DynamicStorySystem { public: void UpdateStory(float DeltaTime); void TriggerEvent(class StoryEvent* Event); private: TArray<StoryEvent*> StoryEvents; }; \`\`\` Each of these headers would be accompanied by a \`.cpp\` source file with the actual implementations of the methods outlined above. Additionally, in Unreal Engine, much of the functionality may be achieved through Blueprints as well as C++. Remember that actual implementations will be substantially more involved and will likely require additional helper classes, UE specific data structures like \`UCLASS\`, \`USTRUCT\`, \`ENUM\`, and advanced algorithms for procedural generation. To convert these high-level concepts into functioning Unreal Engine code, you'll need to integrate UE-specific constructs and systems, which I have excluded from these examples for the sake of clarity and focus on the architecture."},{"instruction":"Writing is easier than blueprints, that's what I was implying earlier, I prefer C++ over blueprints in UE5.","output":"Understood! Many developers prefer using C++ for performance-critical systems, complex logic, or when implementing systems that require a level of flexibility and control that Blueprints may not easily afford. Unreal Engine excels in allowing developers to leverage both C++ and Blueprints in a complementary way, so it's excellent that you're aiming to use C++ for your systems. When using C++ in Unreal Engine 5.3, you'll be able to create all those systems you mentioned. However, be sure to take advantage of Unreal's powerful features like the \`UProceduralMeshComponent\` for generating meshes at runtime and its material system to dynamically texture your procedural worlds. You'll also want to interact with the engine's API for handling things like player input, networking, and physics. For more advanced procedural generation, you may look into leveraging asynchronous operations to offload some of that work to other threads to keep the game running smoothly. Here's a quick refresher on some best practices and tips when writing C++ in Unreal: 1. Use Unreal's built-in types (\`FVector\`, \`FRotator\`, \`FQuat\`, \`FString\`, \`TArray\`, etc.) for compatibility and efficiency within the engine. 2. Leverage Unreal's memory management system, which includes using \`UOBJECT()\` macros for garbage collection. 3. For asynchronous tasks, such as loading or generating content at runtime, consider using the \`AsyncTask\` (for Blueprint-friendly operations) or \`FRunnable\`/\`FRunnableThread\` (for more complex or CPU-intensive tasks). 4. Profile your game regularly using Unreal's performance tools to find bottlenecks, analyze memory usage, and track down any issues. 5. Document your code thoroughly, follow Unreal's coding standards for readability and maintainability, and make use of the Editor's features for C++ developers, like hot reload. If you need more focused help or specific code implementations for one of those systems mentioned in your initial query, feel free to ask. I'd be glad to provide more detailed examples or explain concepts to assist with your development process in Unreal Engine 5 using C++."},{"instruction":"Let's see you generate the same code snippets, but with a much higher level of detail = More code.","output":"Sure, I can provide more detailed code snippets for some of the systems you mentioned. However, due to the complexity of these systems, it is still not feasible to provide fully functional and detailed implementations for all of them in one response. I will choose a couple of these systems and demonstrate a more fleshed-out C++ snippet suitable for Unreal Engine 5. For a detailed terrain generation system, we can start by creating a ProceduralTerrain actor. Each terrain chunk would be represented by a grid of vertices and corresponding triangles. # ProceduralTerrain.h \`\`\`cpp #pragma once #include \\"CoreMinimal.h\\" #include \\"GameFramework/Actor.h\\" #include \\"ProceduralMeshComponent.h\\" #include \\"ProceduralTerrain.generated.h\\" UCLASS() class MYGAME_API AProceduralTerrain : public AActor { GENERATED_BODY() public: AProceduralTerrain(); protected: virtual void OnConstruction(const FTransform& Transform) override; virtual void BeginPlay() override; public: virtual void Tick(float DeltaTime) override; private: UPROPERTY(VisibleAnywhere, BlueprintReadOnly, meta = (AllowPrivateAccess = \\"true\\")) UProceduralMeshComponent* MeshComponent; UPROPERTY(EditAnywhere, meta = (AllowPrivateAccess = \\"true\\")) int32 NumberOfTiles = 100; UPROPERTY(EditAnywhere, meta = (AllowPrivateAccess = \\"true\\")) float TileSize = 100.0f; void GenerateTerrain(); TArray<FVector> GenerateVertices() const; TArray<int32> GenerateTriangles(const TArray<FVector>& Vertices) const; TArray<FVector> GenerateNormals(const TArray<FVector>& Vertices, const TArray<int32>& Triangles) const; TArray<FVector2D> GenerateUVs(const TArray<FVector>& Vertices) const; float GetHeightValue(float X, float Y) const; // Implement a height noise function. }; \`\`\` # ProceduralTerrain.cpp \`\`\`cpp #include \\"ProceduralTerrain.h\\" #include \\"Kismet/KismetMathLibrary.h\\" #include \\"FastNoise/VoxelFastNoise.inl\\" // Assuming you're using FastNoise AProceduralTerrain::AProceduralTerrain() { PrimaryActorTick.bCanEverTick = false; MeshComponent = CreateDefaultSubobject<UProceduralMeshComponent>(\\"ProceduralMeshComponent\\"); RootComponent = MeshComponent; } void AProceduralTerrain::OnConstruction(const FTransform& Transform) { GenerateTerrain(); } void AProceduralTerrain::BeginPlay() { Super::BeginPlay(); } void AProceduralTerrain::Tick(float DeltaTime) { Super::Tick(DeltaTime); } void AProceduralTerrain::GenerateTerrain() { TArray<FVector> Vertices = GenerateVertices(); TArray<int32> Triangles = GenerateTriangles(Vertices); TArray<FVector> Normals = GenerateNormals(Vertices, Triangles); TArray<FVector2D> UVs = GenerateUVs(Vertices); // Additional code to set up vertex colors and tangents // ... MeshComponent->CreateMeshSection(0, Vertices, Triangles, Normals, UVs, TArray<FLinearColor>(), TArray<FProcMeshTangent>(), true); } TArray<FVector> AProceduralTerrain::GenerateVertices() const { TArray<FVector> Vertices; for (int32 Y = 0; Y < NumberOfTiles; Y++) { for (int32 X = 0; X < NumberOfTiles; X++) { float HeightValue = GetHeightValue(X * TileSize, Y * TileSize); Vertices.Add(FVector(X * TileSize, Y * TileSize, HeightValue)); } } return Vertices; } TArray<int32> AProceduralTerrain::GenerateTriangles(const TArray<FVector>& Vertices) const { TArray<int32> Triangles; for (int32 Y = 0; Y < NumberOfTiles - 1; Y++) { for (int32 X = 0; X < NumberOfTiles - 1; X++) { int32 BottomLeftIndex = X + (Y * NumberOfTiles); int32 BottomRightIndex = (X + 1) + (Y * NumberOfTiles); int32 TopLeftIndex = X + ((Y + 1) * NumberOfTiles); int32 TopRightIndex = (X + 1) + ((Y + 1) * NumberOfTiles); // Triangle 1: Bottom left, top left, top right Triangles.Add(BottomLeftIndex); Triangles.Add(TopLeftIndex); Triangles.Add(TopRightIndex); // Triangle 2: Bottom left, top right, bottom right Triangles.Add(BottomLeftIndex); Triangles.Add(TopRightIndex); Triangles.Add(BottomRightIndex); } } return Triangles; } TArray<FVector> AProceduralTerrain::GenerateNormals(const TArray<FVector>& Vertices, const TArray<int32>& Triangles) const { TArray<FVector> Normals; // Calculate normals using triangle data // ... return Normals; } TArray<FVector2D> AProceduralTerrain::GenerateUVs(const TArray<FVector>& Vertices) const { TArray<FVector2D> UVs; // Map vertices to UV space // ... return UVs; } float AProceduralTerrain::GetHeightValue(float X, float Y) const { // Integrate with FastNoise or another noise library to get proper height values // for now, we return a simple sine wave pattern return TileSize * FMath::Sin(X) * FMath::Cos(Y); } \`\`\` This is a non-trivial C++ implementation of terrain generation in Unreal using procedural mesh components, representing how tiles of terrain could be generated with height values based on the return of a simulated noise function. For a trading/economic system, you would take an object-oriented approach, where resource items, prices, and transactions are all encapsulated within respective classes. Here's a simplified example framework for the trading/economic systems: # TradeSystem.h \`\`\`cpp class TradeItem { public: FString Name; int32 Quantity; float BasePrice; // Base price before market influences. }; class TradeTransaction { public: TradeTransaction(TradeItem* Item, int32 Quantity, float UnitPrice); TradeItem* Item; int32 Quantity; float UnitPrice; // Final price per unit. float TotalPrice() const { return Quantity * UnitPrice; } }; class TradeSystem { public: bool ExecuteTrade(TradeTransaction* Transaction); float GetMarketPrice(const TradeItem* Item); // Other trade-related methods... private: TArray<TradeItem*> ItemsForSale; // ... }; \`\`\` These examples outline approaches to writing C++ classes typical of game systems you'd see in Unreal Engine projects. While the code provided does not directly compile or run in Unreal Engine due to lack of detail (e.g., no import statements, constructor definitions missing, not using actual noise for terrain generation), these templates illustrate how you could structure your systems. For practical use, each class should be further developed with full implementations of each method, error handling, and integration with other game systems. Moreover, each class would probably be a \`UCLASS()\` or \`USTRUCT()\` in a real Unreal project, allowing for interaction with the Editor and Blueprints. This would only be the start—game development requires extensive work, testing, and iteration. It would be best for you to continue building and expanding these classes to fit your specific game requirements and Unreal Engine's best practices."},{"instruction":"List everything there is to know about Unreal Engine 5.3 as far as features go.","output":"Unreal Engine 5.3 is a state-of-the-art game engine developed by Epic Games that comes with a multitude of advanced features designed to provide high fidelity and interactive experiences. Below is a list of some notable features and improvements that are available in Unreal Engine 5.3, at the time of my knowledge cutoff, but it's essential to refer to the official documentation for the comprehensive list and the latest updates. 1. **Nanite Virtualized Geometry:** Allows for the creation of complex scenes with a vast amount of geometric detail, significantly reducing the time spent on level-of-detail creation. 2. **Lumen Global Illumination and Reflections:** Provides dynamic global illumination and reflections that react to scene and light changes, intended to create more realistic and immersive environments without the need for precomputed lightmaps. 3. **Virtual Shadow Maps (VSMs):** Provide high-resolution shadow detail and improve the performance of shadow rendering on complex scenes. 4. **World Partition System:** Revolutionizes level streaming and world building by automatically dividing the world into a grid and streaming only the necessary cells. 5. **One File Per Actor (OFPA):** Enhances World Partition by enabling each placed actor in the world to become its own asset, improving collaboration and iteration speed. 6. **Data Layers:** Allows developers to organize different variations of a level (e.g., night versus day) within a single World Partitioned map. 7. **Temporal Super Resolution (TSR):** A high-quality upsampling technology that replaces Temporal Anti-Aliasing (TAA) and helps maintain high image quality at aggressive performance targets. 8. **Animation Features:** - **Full-Body IK Solver:** An advanced animation solver for creating believable character movements. - **Pose Browser:** Helps animate by allowing browsing, saving, and applying poses from animations. - **Control Rig Updates:** Enhancements to the rigging system, providing more control and flexibility during animation. 9. **MetaSounds:** Described as a \\"high-performance audio synthesis and processing\\" system that provides complete control over audio DSP graph generation. 10. **Mass AI and Crowd Simulation:** Enables the simulation of complex AI behaviors and large crowds with performance optimizations. 11. **Enhanced Modeling Tools:** Improved built-in 3D modeling tools that allow for in-editor geometry creation and editing. 12. **Editor Workflow and UI Improvements:** Features like Quick Favorites, enhanced multiviewport workflows, and improvements to existing tools for a more streamlined experience. 13. **Quixel Bridge Integration:** Out-of-the-box access to Quixel’s Megascans library, providing thousands of high-quality photogrammetry assets straight into the editor. 14. **Rendering and Material Updates:** - **Hair and Fur Rendering:** New systems for simulating and rendering realistic hair and fur. - **Layered Materials:** An extension to the material system that allows for more complex and rich material definitions. 15. **Multi-User Editing:** Collaborate in real-time with other team members within the same project. 16. **Sequencer Updates:** Improved cinematic creation tools for narrative storytelling and cutscene creation. 17. **Blueprints Visual Scripting:** Continuation of improvements to Blueprints, including quality-of-life updates and more advanced features. 18. **Enhanced Performance and Profiling Tools:** New and improved tools to monitor and optimize game performance. 19. **Mobile Deployments:** Improved workflows and features tailored to mobile game development. 20. **Enhanced Support for Consoles and VR:** Optimizations and support for the latest hardware in consoles and virtual reality devices. Keep in mind that with each update to Unreal Engine, Epic Games might introduce additional features, improvements, and sometimes deprecate old systems. It's always recommended to review the latest Unreal Engine release notes to get detailed and up-to-date information about the changes and new features introduced in each version."},{"instruction":"List all of it's features, from it's creation to your cutoff date, btw, what is your cutoff date?","output":"My knowledge is based on information available up to early 2023. I cannot list every feature of Unreal Engine from its creation to my cutoff date, as that would include an extensive history spanning over two decades since its initial release in 1998. Unreal Engine has evolved significantly over that time, with each major version introducing a plethora of new features and improvements. Instead, I will provide an overview of some of the key features by major version, focusing on Unreal Engine 4 and the transition to Unreal Engine 5, leading up to version 5.3, as these represent the most recent and significant changes: # Unreal Engine 4 (2014-2021) Unreal Engine 4 was a complete overhaul of the engine that brought many changes, including: - **Graphics Rendering Pipeline**: Advanced rendering capabilities, PBR (Physically Based Rendering), and post-processing effects. - **Blueprint Visual Scripting**: A node-based scripting system that allows developers to create game logic without writing code. - **Sequencer**: A cinematic editing tool that offers detailed control over animations and cutscenes. - **VR and AR Support**: Built-in support for virtual and augmented reality technologies. - **Editor Extensions**: The ability to customize and extend the editor with custom tools and plugins. - **Multi-platform Development**: Support for developing games across various platforms, including PC, consoles, and mobile devices. - **Networking and Multiplayer**: Robust multiplayer framework for developing online games. - **Material Editor**: A node-based interface to create complex materials and shaders. - **AI and Pathfinding**: Tools and systems for artificial intelligence and navigation. - **Marketplace**: Access to a wide range of assets and plugins from other developers and artists through the Unreal Marketplace. - **Asset Management**: Systems to import, organize, and manage game assets. - **Animation System**: A powerful suite of tools for character rigging, animation blending, and more. # Unreal Engine 5 (2021-Onwards) Unreal Engine 5 introduced groundbreaking features that pushed the boundaries of fidelity and performance: - **Nanite Virtualized Geometry**: Allows for highly detailed geometric meshes with minimal performance impact. - **Lumen**: A fully dynamic global illumination solution which reacts to changes in direct lighting or geometry. - **Virtual Shadow Maps (VSMs)**: Higher quality shadows, replacing the older cascade shadow maps. - **World Partition**: A new system for managing large open worlds, automatically dividing and streaming the game world. - **One File Per Actor**: Used in conjunction with World Partition to manage game objects as individual assets. - **Data Layers**: Offers a way to organize different world variations. - **Control Rig**: Enhanced control rig system to facilitate complex rigging for characters and objects. - **Editor Workflow Improvements**: Including UI updates, quality-of-life enhancements, and new content browsing methods. - **MetaSounds**: A high-level audio creation tool similar to the power and flexibility of Blueprints and Materials. - **Mass AI and Crowd Systems**: Optimizations and tools to simulate crowds with realistic AI behavior. - **Hardware-Accelerated Ray Tracing**: Enhanced support for ray tracing providing hyper-realistic lighting, reflections, and shadows. - **Animation Tools**: Advanced systems for creating and editing character animations, like Full-Body IK and Pose Browser. Please note, this historical overview does not capture every minor feature or improvement, nor does it cover every API, plugin, or development environment detail. For the most accurate and detailed description of the Unreal Engine's capabilities, always refer to the official documentation and release notes provided by Epic Games, where full feature lists and technical details are meticulously outlined for each version of the engine."},{"instruction":"Here's some information for you, is this beyond your cutoff date? Unreal Engine Article Talk Read Edit View history Tools From Wikipedia, the free encyclopedia \\"Unreal technology\\" redirects here. For science or technology which is beyond reality, see science fiction. Unreal Engine Screenshot of Unreal Engine 4.20 Original author(s) Tim Sweeney Developer(s) Epic Games Stable release 5.3 Written in C++ Operating system Windows, Linux, macOS License Source-available commercial software with royalty model for commercial use[1] Website www.unrealengine.com/en-US Unreal Engine (UE) is a series of 3D computer graphics game engines developed by Epic Games, first showcased in the 1998 first-person shooter video game Unreal. Initially developed for PC first-person shooters, it has since been used in a variety of genres of games and has seen adopted by other industries, most notably the film and television industry. Unreal Engine is written in C++ and features a high degree of portability, supporting a wide range of desktop, mobile, console, and virtual reality platforms. The latest generation, Unreal Engine 5, was launched in April 2022. Its source code is available on GitHub, and commercial use is granted based on a royalty model, with Epic charging 5% of revenues over US1 million, which is waived for games published on the Epic Games Store. Epic has included features from acquired companies like Quixel in the engine, which is seen as helped by Fortnite's revenue. In 2014, Unreal Engine was named the world's \\"most successful videogame engine\\" by Guinness World Records.[2] History First generation A screenshot released by Epic of the first version of UnrealEd, displaying a graphical user interface written in Visual Basic[3] The first-generation Unreal Engine was developed by Tim Sweeney, the founder of Epic Games.[4] Having created editing tools for his shareware games ZZT (1991) and Jill of the Jungle (1992),[5] Sweeney began writing the engine in 1995 for the production of a game that would later become a first-person shooter known as Unreal.[6][7][8] After years in development, it debuted with the game's release in 1998,[9] although MicroProse and Legend Entertainment had access to the technology much earlier, licensing it in 1996.[3] According to an interview, Sweeney wrote 90 percent of the code in the engine, including the graphics, tools, and networking system.[10] At first, the engine relied completely on software rendering, meaning the graphics calculations were handled by the central processing unit (CPU).[4] However, over time, it was able to take advantage of the capabilities provided by dedicated graphics cards, focusing on the Glide API, specially designed for 3dfx accelerators.[11][12] While OpenGL and Direct3D were supported, they reported a slower performance compared to Glide due to their deficiency in texture management at the time.[13][14] Sweeney particularly criticized the quality of OpenGL drivers for consumer hardware, describing them as \\"extremely problematic, buggy, and untested\\", and labeled the code in the implementation as \\"scary\\" as opposed to the simpler and cleaner support for Direct3D.[13] With regard to audio, Epic employed the Galaxy Sound System, a software created in assembly language that integrated both EAX and Aureal technologies, and allowed the use of tracker music, which gave level designers flexibility in how a game soundtrack was played at a specific point in maps.[15][16][17] Steve Polge, the author of the Reaper Bots plugin for Quake, programmed the artificial intelligence system, based on knowledge he had gained at his previous employer IBM designing router protocols.[18][19] According to Sweeney, the hardest part of the engine to program was the renderer; he had to rewrite its core algorithm several times during development. He found the infrastructure connecting all the subsystems less \\"glamorous\\".[20][11] Despite requiring a significant personal effort, he said the engine was his favorite project at Epic, adding: \\"Writing the first Unreal Engine was a 3.5-year, breadth-first tour of hundreds of unique topics in software and was incredibly enlightening.\\"[21] Among its features were collision detection, colored lighting, and a limited form of texture filtering.[12] It also integrated a level editor, UnrealEd,[22] that had support for real-time constructive solid geometry operations as early as 1996, allowing mappers to change the level layout on the fly.[23][11] Even though Unreal was designed to compete with id Software (developer of Doom and Quake), co-founder John Carmack complimented the game for the use of 16-bit color and remarked its implementation of visual effects such as volumetric fog. \\"I doubt any important game will be designed with 8-bit color in mind from now on. Unreal has done an important thing in pushing toward direct color, and this gives the artists a lot more freedom,\\" he said in an article written by Geoff Keighley for GameSpot.[8] \\"Light blooms [the spheres of light], fog volumes, and composite skies were steps I was planning on taking, but Epic got there first with Unreal,\\" he said, adding: \\"The Unreal engine has raised the bar on what action gamers expect from future products. The visual effects first seen in the game will become expected from future games.\\"[8] Harry Potter and the Sorcerer's Stone for PC was developed with the Unreal Tournament version of the engine using assets and environments from the 2001 film.[24] Unreal was noted for its graphical innovations, but Sweeney acknowledged in a 1999 interview with Eurogamer that many aspects of the game were unpolished, citing complaints from gamers about its high system requirements and online gameplay issues.[19] Epic addressed these points during the development of Unreal Tournament by incorporating several enhancements in the engine intended to optimize performance on low-end machines and improve the networking code, while also refining the artificial intelligence for bots to display coordination in team-based gamemodes such as Capture the Flag.[25] Originally planned as an expansion pack for Unreal,[26] the game also came with increased image quality with the support for the S3TC compression algorithm, allowing for 24-bit high resolution textures without compromising performance.[27] In addition to being available on Windows, Linux, Mac and Unix,[28] the engine was ported through Unreal Tournament to the PlayStation 2 and, with the help of Secret Level, to the Dreamcast.[29][30] By late 1999, The New York Times indicated that there had been sixteen external projects using Epic's technology, including Deus Ex, The Wheel of Time, and Duke Nukem Forever,[28] the latter of which was originally based on the Quake II engine.[31] Unlike id Software, whose engine business only offered the source code, Epic provided support for licensees and would get together with their leads to discuss improvements to its game development system, internally dubbed the Unreal Tech Advisory Group.[3][32] While it cost around 3 million to produce and licenses for up to 350,000,[28] Epic gave players the ability to modify its games with the incorporation of UnrealEd and a scripting language called UnrealScript, sparking a community of enthusiasts around a game engine built to be extensible over multiple generations of games.[33][34][35][36] The big goal with the Unreal technology all long was to build up a base of code that could be extended and improved through many generations of games. Meeting that goal required keeping the technology quite general-purpose, writing clean code, and designing the engine to be very extensible. The early plans to design an extensible multi-generational engine happened to give us a great advantage in licensing the technology as it reached completion. After we did a couple of licensing deals, we realised it was a legitimate business. Since then, it has become a major component of our strategy. — Sweeney, Maximum PC, 1998[36] Unreal Engine 2 Killing Floor was built in Unreal Engine 2. In October 1998, IGN reported, based on an interview with affiliate Voodoo Extreme, that Sweeney was doing research for his next-generation engine.[37] With development starting a year later,[28] the second version made its debut in 2002 with America's Army, a free multiplayer shooter developed by the U.S. Army as a recruitment device.[38][39] Soon after, Epic would release Unreal Championship on the Xbox, one of the first games to utilize Microsoft's Xbox Live.[35] Though based on its predecessor, this generation saw a notable advance in rendering terms as well as new improvements to the tool set.[40] Capable of running levels nearly 100 times more detailed than those found in Unreal, the engine integrated a variety of features, including a cinematic editing tool, particle systems, export plug-ins for 3D Studio Max and Maya, and a skeletal animation system first showcased in the PlayStation 2 version of Unreal Tournament.[41][42] In addition, the user interface for UnrealEd was rewritten in C++ using the wxWidgets toolkit, which Sweeney said was the \\"best thing available\\" at the time.[3] Epic used the Karma physics engine, a third-party software from UK-based studio Math Engine, to drive the physical simulations such as ragdoll player collisions and arbitrary rigid body dynamics.[35][42][43] With Unreal Tournament 2004, vehicle-based gameplay was successfully implemented, enabling large-scale combat.[35][44] While Unreal Tournament 2003 had support for vehicle physics through the Karma engine, as demonstrated by a testmap with a \\"hastily-constructed vehicle\\", it was not until Psyonix created a modification out of Epic's base code that the game received fully coded vehicles. Impressed by their efforts, Epic decided to include it in its successor as an official game mode under the name Onslaught by hiring Psyonix as a contractor.[42][45][46] Psyonix would later develop Rocket League before being acquired by Epic in 2019.[47] A specialized version of UE2 called UE2X was designed for Unreal Championship 2: The Liandri Conflict on the original Xbox platform, featuring optimizations specific to that console.[48] In March 2011, Ubisoft Montreal revealed that UE2 was successfully running on the Nintendo 3DS via Tom Clancy's Splinter Cell 3D.[49] \\"The 3DS is powerful, and we are able to run the Unreal Engine on this console, which is pretty impressive for a handheld machine, and the 3D doesn't affect the performance (thanks to my amazing programmers),\\" said Ubisoft.[49] Unreal Engine 3 Screenshots of Unreal Engine 3 were presented by July 2004, at which point the engine had already been in development for over 18 months.[50] The engine was based on the first-generation but contained new features. \\"The basic architectural decisions visible to programmers of an object-oriented design, a data-driven scripting approach, and a fairly modular approach to subsystems still remain [from Unreal Engine 1]. But the parts of the game that are really visible to gamers – the renderer, the physics system, the sound system, and the tools – are all visibly new and dramatically more powerful,\\" said Sweeney.[51] Unlike Unreal Engine 2, which still supported a fixed-function pipeline, Unreal Engine 3 was designed to take advantage of fully programmable shader hardware.[51] All lighting and shadowing calculations were done per pixel, instead of per vertex. On the rendering side, Unreal Engine 3 provided support for a gamma-correct high-dynamic range renderer.[51] The first games released using Unreal Engine 3 were Gears of War for Xbox 360, and RoboBlitz for Windows, which were both released on November 7, 2006.[52] Screenshot of the Samaritan demo Initially, Unreal Engine 3 only supported Windows, PlayStation 3, and Xbox 360 platforms, while iOS (first demonstrated with Epic Citadel) and Android were added later in 2010, with Infinity Blade being the first iOS title and Dungeon Defenders the first Android title.[53][54] In 2011, it was announced that the engine would support Adobe Flash Player 11 through the Stage 3D hardware-accelerated APIs and that it was being used in two Wii U games, Batman: Arkham City and Aliens: Colonial Marines.[55][56] In 2013, Epic teamed-up with Mozilla to bring Unreal Engine 3 to the web; using the asm.js sublanguage and Emscripten compiler, they were able to port the engine in four days.[57] Throughout the lifetime of UE3, significant updates were incorporated,[58] including improved destructible environments, soft body dynamics, large crowd simulation, iOS functionality,[59] Steamworks integration,[60] a real-time global illumination solution,[61] and stereoscopic 3D on Xbox 360 via TriOviz for Games Technology.[62][63][64] DirectX 11 support was demonstrated with the Samaritan demo, which was unveiled at the 2011 Game Developers Conference and built by Epic Games in a close partnership with Nvidia, with engineers working around the country to push real-time graphics to a new high point.[65][66][67] Unreal Development Kit While Unreal Engine 3 was quite open for modders to work with, the ability to publish and sell games meant using UE3 was restricted to licenses of the engine. However, in November 2009, Epic released a free version of UE3's SDK, called the Unreal Development Kit (UDK), to the general public.[68] In December 2010, the Unreal Development Kit was updated to include support for creating iOS games and apps,[69] followed by OS X compatibility in the September 2011 release.[70] By 2013, it reported more than 2 million unique installations.[71] Unreal Engine 4 Duration: 3 minutes and 57 seconds.3:57 Interactive architectural visualization developed with Unreal Engine 4 (2015) In August 2005, Mark Rein, the vice-president of Epic Games, revealed that Unreal Engine 4 had been in development for two years.[72] \\"People don't realise this but we're already two years into development of Unreal Engine 4. It certainly doesn't have a full team yet, it's just one guy and you can probably guess who that guy is,\\" he told C&VG.[73] Speaking in an interview in early 2008, Sweeney stated that he was basically the only person working on the engine, though he affirmed his research and development department would start to expand later that year, developing the engine in parallel with Unreal Engine 3.[74] \\"In some way, we resemble a hardware company with our generational development of technology. We are going to have a team developing Unreal Engine 3 for years to come and a team ramping up on Unreal Engine 4. And then, as the next-gen transition begins, we will be moving everybody to that. We actually are doing parallel development for multiple generations concurrently,\\" he said.[74] In February 2012, Rein stated \\"people are going to be shocked later this year when they see Unreal Engine 4\\";[75] Epic unveiled UE4 to limited attendees at the 2012 Game Developers Conference,[76] and a video of the engine being demonstrated by technical artist Alan Willard was released to the public on June 7, 2012, via GameTrailers TV.[77] One of the major features planned for UE4 was real-time global illumination using voxel cone tracing, eliminating pre-computed lighting.[78] However, this feature, called Sparse Voxel Octree Global Illumination (SVOGI) and showcased with the Elemental demo, was replaced with a similar but less computationally expensive algorithm due to performance concerns.[79] UE4 also includes the new \\"Blueprints\\" visual scripting system (a successor to UE3's \\"Kismet\\"[80]), which allows for rapid development of game logic without using code, resulting in less of a divide between technical artists, designers, and programmers.[81][82] I could say: 'I'm going to convert this pillar into a blueprint [in the Engine] and add some sort of trap to it.' It means I can really go in and start enhancing my world with interaction that just would not have been possible without a technical artist, a designer and a programmer and now any one of those three can do all of it, provided they have the assets handy. The fact that I can just go in and say, 'If you're within X distance of this thing, start to glow and take my distance to it, normalize it zero to one and then just lerp [linearly interpolate] between two different brightness values, so as I reach for something it gets hot'...that would have been something do-able but very difficult for anybody except a gameplay programmer. And he wouldn't have known how to set up the assets, but now any one of the three could do it. — Willard, Kotaku, 2012[82] An Unreal Engine presentation at GDC 2016 On March 19, 2014, at the Game Developers Conference (GDC), Epic Games released Unreal Engine 4 through a new licensing model. For a monthly subscription at US19, developers were given access to the full version of the engine, including the C++ source code, which could be downloaded via GitHub. Any released product was charged with a 5% royalty of gross revenues.[83] The first game released using Unreal Engine 4 was Daylight, developed with early access to the engine[84] and released on April 29, 2014.[85] On September 4, 2014, Epic released Unreal Engine 4 to schools and universities for free, including personal copies for students enrolled in accredited video game development, computer science, art, architecture, simulation, and visualization programs.[86] Epic opened an Unreal Engine Marketplace for acquiring game assets.[87] On February 19, 2015, Epic launched Unreal Dev Grants, a 5 million development fund aiming to provide grants to creative projects using Unreal Engine 4.[88] In March 2015, Epic released Unreal Engine 4, along with all future updates, for free for all users.[89][90] In exchange, Epic established a selective royalty schedule, asking for 5% of revenue for products that make more than 3,000 per quarter.[91] Sweeney stated that when they moved to the subscription model in 2014, use of Unreal grew by 10 times and through many smaller developers, and believed that they would draw even more uses through this new pricing scheme.[92] An Unreal Engine booth at GDC 2017 In an attempt to attract Unreal Engine developers, Oculus VR announced in October 2016 that it will pay royalty fees for all Unreal-powered Oculus Rift titles published on their store for up to the first 5 million of gross revenue per game.[93] To prepare for the release of its free-to-play battle royale mode in Fortnite in September 2017, Epic had to make a number of Unreal Engine modifications that helped it to handle a large number (up to 100) of connections to the same server while still retaining high bandwidth and to improve the rendering of a large open in-game world. Epic said it would incorporate these changes into future updates of the Unreal Engine.[94] With the opening of the Epic Games Store in December 2018, Epic will not charge the 5% revenue fee on games that use the Unreal Engine and are released through the Epic Games Stores, absorbing that cost as part of the base 12% cut Epic is taking to cover other costs.[95] Effective May 13, 2020, and retroactive to January 1, 2020, the royalty exemption amount is increased to US1,000,000 in lifetime gross revenue per title.[96] Unreal Engine 4 officially supports the following platforms as of 4.27 (August 2021):[97] Windows,[98] macOS,[98] Linux,[98] iOS,[98] Android,[98] Nintendo Switch,[99] PlayStation 4,[100] Xbox One,[100] PlayStation 5,[101] Xbox Series X/S,[101] Stadia,[102] Magic Leap,[103] HTC Vive,[104] Oculus,[105] PlayStation VR,[106] OSVR,[107] Samsung Gear VR,[108] and HoloLens 2.[109] It formerly supported Google Daydream[110] and HTML5.[111][112] Unreal Engine 5 The cave system in the \\"Lumen in the Land of Nanite\\" Unreal Engine 5 demo was generated using real-world photogrammetry assets imported into the Nanite engine rather than detailed by hand. Unreal Engine 5 was revealed on May 13, 2020, supporting all existing systems including the next-generation consoles PlayStation 5 and Xbox Series X/S.[113] Work on the engine started about two years prior to its announcement.[114] It was released in early access on May 26, 2021,[115] and formally launched for developers on April 5, 2022.[116] One of its major features is Nanite, an engine that allows for high-detailed photographic source material to be imported into games.[117] The Nanite virtualized geometry technology allows Epic to take advantage of its past acquisition of Quixel, the world's largest photogrammetry library as of 2019. The goal of Unreal Engine 5 was to make it as easy as possible for developers to create detailed game worlds without having to spend excessive time on creating new detailed assets.[114] Nanite can import nearly any other pre-existing three-dimension representation of objects and environments, including ZBrush and CAD models, enabling the use of film-quality assets.[118] Nanite automatically handles the levels of detail (LODs) of these imported objects appropriate to the target platform and draw distance, a task that an artist would have had to perform otherwise.[119] Lumen is another component described as a \\"fully dynamic global illumination solution that immediately reacts to scene and light changes\\".[117][119][120] Lumen eliminates the need for artists and developers to craft a lightmap for a given scene, but instead calculates light reflections and shadows on the fly, thus allowing for real-time behavior of light sources.[119] Virtual Shadow Maps is another component added in Unreal Engine 5 described as \\"a new shadow mapping method used to deliver consistent, high-resolution shadowing that works with film-quality assets and large, dynamically lit open worlds\\".[121] Virtual Shadow Maps differs from the common shadow map implementation in its extremely high resolution, more detailed shadows, and the lack of shadows popping in and out which can be found in the more common shadow maps technique due to shadow cascades.[122] Additional components include Niagara for fluid and particle dynamics and Chaos for a physics engine.[114] With potentially tens of billions of polygons present on a single screen at 4K resolution, Epic also developed the Unreal Engine 5 to take advantage of the upcoming high-speed storage solutions with the next-generation console hardware that will use a mix of RAM and custom solid-state drives.[119] Epic had worked closely with Sony in optimizing Unreal Engine 5 for the PlayStation 5, with Epic collaborating with Sony on the console's storage architecture.[123] To demonstrate the ease of creating a detailed world with minimal effort, the May 2020 reveal of the engine showcased a demo called \\"Lumen in the Land of Nanite\\" running on a PlayStation 5 that was built mostly by pulling assets from the Quixel library and using the Nanite, Lumen, and other Unreal Engine 5 components to create a photorealistic cave setting that could be explored.[114][124] Epic affirmed that Unreal Engine 5 would be fully supported on the Xbox Series X as well, but had been focused on the PlayStation 5 during the announcement as a result of their work with Sony in the years prior.[125] Epic plans to use Fortnite as a testbed for Unreal Engine 5 to showcase what the engine can do to the industry,[114][126] with the game brought to use Unreal Engine 5 in December 2021.[127] Fortnite's Battle Royale mode received visual improvements via Unreal Engine 5.1 with the launch of Chapter 4 on December 4, 2022.[128] The Matrix Awakens, a tie-in experience ahead of the release of The Matrix Resurrections, was developed by Epic to be a further demonstration of Unreal Engine 5 along with other technology that they had acquired over 2020 and 2021, including their MetaHuman Creator developed and integrated into Unreal Engine 5 with technology from 3Lateral, Cubic Motion, and Quixel.[129] Additional features planned for Unreal Engine 5 come from Epic's acquisitions and partnerships. The MetaHuman Creator is a project based on technology from three companies acquired by Epic—3Lateral, Cubic Motion, and Quixel—to allow developers to quickly create realistic human characters that can then be exported for use within Unreal.[130] Through partnership with Cesium, Epic plans to offer a free plugin to provide 3D geospatial data for Unreal users, allowing them to recreate any part of the mapped surface of Earth.[131] Epic will include RealityCapture, a product it acquired with its acquisition of Capturing Reality that can generate 3D models of any object from a collection of photographs taken of it from multiple angles,[132] and the various middleware tools offered by Epic Game Tools.[133] Unreal Engine 5 retains the current royalty model, with developers returning 5% of gross revenues to Epic Games, although this fee is waived for sales made through the Epic Games Store.[134] Further, Epic announced alongside Unreal Engine 5 that they will not take any fee from games using any version of Unreal Engine for the first US1 million in gross revenue, retroactive to January 1, 2020.[135] Epic said in October 2023 that it would be changing the licensing approach for uses of Unreal in non-gaming applications such as in film and television production to a per-seat license.[136]","output":"The content you've provided appears to be from Wikipedia and offers an extensive overview of the history, development, and key features of the Unreal Engine up until version 5.3. This summary includes information on the engine's origins, major updates with each iteration, licensing models, platform support, and integration of various technologies and acquisitions. Given the length and depth of the content, it would be exhaustive to comment on each point. However, to address your question about whether this information is beyond my knowledge cutoff, I can confirm that my last update was in early 2023. So, the details up to Unreal Engine 5.3 and the launch timeline fit within my knowledge base. The historical aspects, feature evolution, platforms supported, and development focus areas mentioned here align with what I know. It is also worth noting that the Unreal Engine has been continuously updated beyond traditional game development, impacting fields like film and television, architectural visualization, and virtual production. Partnerships, acquisitions, and technology integrations, such as Quixel for Megascans assets and various optimization technologies for next-gen console hardware, highlight Epic Games' commitment to adaptability and innovation. Regarding licensing, Unreal Engine has shifted its model over time, with significant changes like the royalty-free threshold and the subscription model for different use cases, illustrating Epic Games' efforts to make the engine more accessible to a broad range of creators and developers. If you have specific questions about a particular aspect of Unreal Engine or if you need clarification on certain features or updates mentioned, feel free to ask, and I can provide more focused information."},{"instruction":"Unreal Engine 5.3 Release NotesOverview of new and updated features in Unreal Engine 5.3 ON THIS PAGE Rendering Worldbuilding Procedural Content Generation (PCG) Developer Iteration Platform Character and Animation Virtual Production Simulation Audio UI Systems Modeling Content Pipeline Framework Engine Content and Templates Platform SDK Upgrades Release Notes Upgrade Notes What's New? Unreal Engine 5.3 brings further improvement to the core UE5 toolset. This release delivers improvements in a wide variety of areas, including Rendering, Worldbuilding, Procedural Content Generation (PCG), Animation and Modeling tools, Virtual Production, Simulation, and more. This release includes improvements submitted by our community of Unreal Engine developers on GitHub. Thank you to each of these contributors to Unreal Engine 5.3: 909185693, 34Pibo, aaronmjacobs, Acren, aijkoopmans, AishaBrown-SMG, aknarts, alexey-pelykh, alwintom, AndreaCatania, AndTikhomirov, ArcEcho, astutejoe, avudnez, baronpumpky, BenVlodgi, BinaerBoy, Bioliquid, BlenderSleuth, bretternst, brycehutchings, c4augustus, CaptainHoke, chalonverse, chrismcr, Cleroth, cneumann, crobertson-d3t, crssnky, David-Vodhanel, dbsigurd, Deathrey, DecoyRS, djethernet1, DomCurry, dorgonman, Drakynfly, DreikaEru, drichardson, dulanw, Dumbeldor, dyanikoglu, Edstub207, erebel55, error454, fieldsJacksonG, FineRedMist, flibitijibibo, foobit, freezernick, gbxAlx, gonfva, hellokenlee, hkzhugc, HSeo, Ilddor, ilkeraktug, ImaginaryBlend, iniside, jackatamazon, JakobLarsson-Embark, jammm, janurbanech13, jcb936, JDCruise, jfgoulet-gearbox, jimsimonz, Johnsel, JonasKjellstrom, jorgenpt, KacperKenjiLesniak, KaosSpectrum, KasumiL5x, KeithRare, kimixuchen, kissSimple, kniteli, KristofMorva, ldisthebest, LennardF1989, Levil0229, lflecunneen, lightbringer, lijenicol, lijie, liuhao0620, loening, LtRandolph, lucyainsworth, MalikuMane, mamoniem, manugulus, marcussvensson92, mariuz, mattiascibien, MaximeDup, microsoftman, MikBou123, mkotlikov, muit, OskarHolmkratz, pepsiandmilk, PhilBax, Phyronnaz, pirskij, praisesolek, projectgheist, QRare, qwe321, RandomInEqualities, Rareden, robert-wallis, RobertVater, roidanton, ryanjon2040, samhocevar, satoshi-iwaki, scorpio20t, Skylonxe, slackba, slonopotamus, Sn-a-ke, SRombauts, steelixb, stlnkm, teessider, tehpola, TheJamsh, TheoHay, Thomasleeee, tianyu2202, tommybear, tonetechnician, ToniSeifert, tuxerr, ukustra, Ultrahead, ungalyant, user37337, Vaei, velvet22, vorixo, Voulz, vsrc, WarmWar, WillmsBenjamin, WinsonSS, xiexbmu, yaakuro, yatagarasu25, yehaike, ZioYuri78, zompi2 Rendering Nanite Nanite Explicit Tangents Nanite now supports explicit tangents in the data format and runtime. Until now, Nanite has relied on a tangent space that is implicitly derived in the material, based on the screen-space positions and UV gradients. This is computationally convenient, makes tangents free in terms of memory and disk footprint, and works well in practice for many types of meshes, especially highly tessellated ones. However, there have always been cases, especially for low-poly models, where the implicit tangents are too imprecise and custom per-vertex tangents are needed to reach target quality. To support these cases, users can now opt to store and use the original model tangents on a per-asset basis. Enabling this comes at a modest cost of an additional ~10% increase in memory and disk footprint for the asset. Nanite Spline Meshes (Experimental) We introduced an initial implementation of the spline mesh component for Nanite meshes. This feature can be enabled by setting r.Nanite.AllowSplineMeshes=1 in a settings .ini file. WARNING: Enabling this feature currently comes with a performance cost that affects culling performance of all of Nanite, and there are currently known issues with incorrect culling under extreme deformation. Performance improvements for masked materials and Pixel Depth Offset (PDO) A new sliding window vertex cache for programmable raster results in faster masked materials and PDO. Initial tests show a 20% speed improvement for rasterization of masked foliage. Nanite Selection Outline Nanite object selections no longer flicker with TSR/TAA enabled, nor get occluded by other objects, and they render at final resolution. Nanite Instanced Static Mesh (ISM) / Foliage Instance Selection We fixed several issues in the editor related to selecting, modifying, or deleting instances of an instanced static mesh or foliage actors that had Nanite enabled. Fallback Target Setting We added a Fallback Target setting to Nanite static meshes. This is a menu option that provides more explicit control over which target to reduce to for the fallback mesh: Relative Error or Percent Triangles. Lumen Lumen Lumen Reflections support more than one bounce when hardware ray tracing (HWRT) is enabled with Hit Lighting, and the Max Reflection Bounces setting in the post process volume is set to 2 or greater. This can prevent black areas in reflections when there is enough performance budget to allow it. Lumen Reflections can now be used without Lumen GI, for games and applications which use static lighting but wish to scale up in reflection quality beyond reflection captures. Standalone Lumen Reflections only work when HWRT is enabled, and it will enable Hit Lighting automatically, as Lumen's surface cache optimization is not available when Lumen GI is disabled. We made significant Lumen HWRT optimizations, including enabling async compute for HWRT by default on consoles. The Lumen Overview visualization mode now includes a view of the geometry normals of the Lumen Scene, making it easier to spot issues with the global distance field (in the case of software ray tracing) or Nanite fallback meshes (in the case of HWRT). We added r.Lumen.Reflections.VisualizeTraces for visualizing and debugging reflection rays. We fixed Material AO - it was previously applied on top of emissive and direct lighting. Orthographic Rendering (Experimental) Orthographic Rendering Orthographic rendering is a very common way to visualize projects in architecture and manufacturing, and is also used in games as a stylistic camera choice. It has long been available as a camera option in UE, but many rendering features were not supported, making it impractical to use. Starting in 5.3, orthographic rendering is now supported as experimental. We fixed multiple areas of the engine to achieve parity between perspective and orthographic projections. Most modern features of UE5 should now work, including Lumen, Nanite, and Shadows. This represents ongoing work and we are interested in hearing your feedback trying to use it in your projects. Sparse Volume Textures (Experimental) Sparse Volume Textures With UE 5.3, we introduce a new asset type: the sparse volume texture (SVT). SVTs store baked simulation data representing volumetric media such as smoke, fire, and water. SVTs can be created by importing OpenVDB (.vdb) files created in other 3D applications—single files and animated sequences are supported. Additionally, Niagara fluids are now cached internally to SVTs resulting in significant performance and memory improvements. An SVT is similar to a 3D texture / volume texture in that it stores texels (voxels) in a 3D data structure and can be indexed with three-dimensional UV coordinates. Unlike regular (dense) volume textures, SVTs only need to spend memory on regions of the volume with \\"interesting\\" data, allowing for much larger volumes compared to dense volume textures—or alternatively volumes with the same extent, but using less memory. Deferred rendering techniques such as heterogeneous volumes, volumetric cloud, and volumetric fog can leverage SVTs by incorporating the suite of sparse volume texture material nodes in their volume-domain materials. Assets rendered with heterogeneous volumes must make use of the new heterogeneous volume component. Deferred rendering features are still limited to the existing feature set of real-time volumes. More complete support for rendering volumes is now available as experimental in the Path Tracer, which can accurately simulate scattering, shadows, and GI. There is also a very simple sparse volume texture viewer component that is mostly used for debugging and works with the Deferred Renderer. Path Tracer Path Tracer (Experimental) The Path Tracer now has initial support for tracing heterogenous volumes such as smoke, fire, and clouds. A heterogeneous volume can be created with the Niagara Fluids plug-in or by instantiating a heterogeneous volume actor, with data driven by a sparse volume texture. VDB files may be imported as sparse volume textures, and can thus be rendered in the Path Tracer. Note: this system is not yet compatible with Sky Atmosphere clouds. (Experimental) Substrate materials are now supported in the Path Tracer. Subsurface scattering sampling efficiency has been improved, resulting in less noise in subsurface materials for the same number of ray samples. The Path Tracer now renders its own depth pass rather than using the one generated by the rasterizer. This results in a more accurate match between the depth and RGB results, improving post-processing passes that rely on depth such as Depth of Field. (This change does not affect 'Reference Depth of Field'.) DBuffer Decal shading nodes in material graphs are now supported. These nodes have been available since 5.0 and greatly expand the functionality of decals in materials. (Documentation about DBuffer Decal shading nodes will be available upon the release of UE 5.3.) Post-process material buffers now have additional outputs for use specifically with the Path Tracer. These buffers are accessible through a new node in the material graph called 'Path Tracing Buffer Texture', and provide data for Radiance, Denoised Radiance, Albedo, Normal, and Variance. Substrate (Experimental) Substrate Substrate, released as experimental in 5.2, replaces the fixed suite of shading models such as Default Lit and Clearcoat with a more expressive, modular framework that provides a greater range of surface appearances and a wider parameter space. Performance scales according to complexity and desired budget, with legacy materials having a similar cost to before. Substrate is still experimental in 5.3. It should not be used for production scenes, but we encourage testing it and are seeking feedback during this phase of development. UE 5.3 contains many improvements in Substrate's capability, stability, and performance. Some of the changes include: New Glints and Specular Profile features, primarily useful for automotive applications. Improved DBuffer shading node support. A new Fuzz model for high-spec platforms. We updated the Substrate Material Information tab in the Material Editor to better display material performance and topology information. We added many bug fixes and performance improvements. Virtual Shadow Maps Virtual Shadow Maps We are removing the beta designation for virtual shadow maps in UE 5.3—we now consider them production-ready. There is still a long development path ahead for VSMs, but the designation reflects the stability and viability of the current working feature set. VSMs now respect the Nanite cull distance even when shadow caching is enabled. Previously, the cull distance was ignored in shadows if caching was enabled, as it could cause inconsistencies between the primary render and shadow maps. However, this can have a large impact on performance if the content was tuned for heavy culling. Scenes reliant on culling will now have faster shadows but might see shadow artifacts if the cull distances are short enough to see popping in the primary render. We added a per-primitive flag that gives the user control over shadow invalidation behavior. This provides users with a way to prevent invalidation, for example in cases where the primitive is known to use the World Position Offset setting statically—our systems cannot deduce this automatically at present. The default setting is 'Auto', which retains current behavior unless explicitly changed. We made additional bug fixes and performance improvements. Hair Hair We added groom streaming support for groom and groom binding assets. This allows faster loading time in editor and in game by loading only what is needed, lowering CPU and GPU memory pressure of groom assets. We added Continuous LOD for scaling/improving performance when there are a lot of grooms covering a smaller portion of the screen. This setting is off by default and can be enabled with r.HairStrands.ContinuousLOD. We added experimental support for hair strands in the Deformer graph, including support for writing custom attributes. This is still early in the development process, but will open the door to making groom changes at runtime in the Deformer graph. We reworked groom attributes to be more flexible and to make it easier to add new optional attributes. We added two new optional attributes (clumpID / AO). Numerical values of groom attributes can now be visualized in the groom editor for easier inspection. During asset import, point/curve limits are now reported to users, and data is trimmed accordingly. In addition, imported attributes are now clearly displayed at import time, as well as in the groom editor, to visualize what is available for a particular groom asset. We made many additional bug fixes and performance improvements. Temporal Super Resolution (TSR) Temporal Super Resolution We introduced new functionality for more automated control of the screen percentage in games when dynamic resolution is disabled (primarily on PC platforms). The default heuristic sets the screen percentage based on the optimal TSR convergence rate for the number of pixels displayed. This should result in end users requiring less experimentation to find the best settings for their device. The editor has several new UX features to aid in understanding and controlling the behavior of the screen percentage in editor and PIE viewports. We added initial support for 16-bit operations on desktop GPUs where backed by hardware support, including on Radeon RX 5000 series (RDNA) cards and newer. We fixed an inconsistency between TAA and TSR regarding Lumen screen-space traces of emissive surfaces. We made numerous optimizations and bug fixes. Render Resource Viewer Render Resource Viewer The Render Resource Viewer, introduced in UE 5.2, is a tool that gives full visibility into GPU memory allocations and render resources—such as vertex buffers and index buffers—and which assets they come from, like static and skeletal meshes. This provides artists and developers with information needed to optimize GPU memory and keep their projects within their rendering budget. New in UE 5.3: You can now select a render buffer/texture and jump to the source asset in the Content Browser. Insight Memory Trace now tracks DX12 resources, and Insight Metadata Trace tracks resource owner paths like Render Resource Viewer. These features complement the Render Resource Viewer, which works only in the editor, and allows tracking of the owning asset path, debug name of the render resource, and its owner render class name in packaged builds. Lighting Lighting Lights with ray-traced shadows can now optionally shadow volumetric fog. You can enable this with the console variable r.VolumetricFog.InjectRaytracedLights, which is off by default due to performance costs. Spot, Point, and Rect lights can now set their intensity units to 'EV' (exposure value), which means you can set intensities in relative \\"stops\\", or power-of-two increments. Worldbuilding Level Instance Actor Filters Level Instance Actor Filters Actor filters allow for per-level-instance variants within World Partition levels. They consist of data layer instances and/or local data layers that are set to support actor filtering with a user-defined default filter inclusion. All actors associated with these pre-configured filters will be included or excluded on streaming generation, depending on the filters default, override, and activation states set within each level instance. Filtered out data is removed from in-game entirely. Level Streaming Persistence (Experimental) Level Streaming Persistence is a plugin that manages saving and restoring of specific marked properties on objects contained within a streamed-out/streamed-in level. These properties are defined within the engine configuration (.ini) file. This provides persistence of properties during gameplay from the in-memory snapshot, as well as across sessions, if implemented through the provided API. Nanite Landscape Nanite Landscape Nanite can now be enabled in landscape actors, at parity with normal landscape rendering. Nanite Landscape meshes are rebuilt in the background in order not to disrupt user workflow while in the editor. Nanite Landscape does not improve landscape resolution, but it allows the user to leverage Nanite runtime features such as GPU culling, automatic geometry streaming, and LODs, and it generally boosts runtime performance, especially for demanding features such as VSM. Large Landscape Import / Export We updated landscape import/export to support very large landscapes/resolutions by leveraging World Partition and splitting the import operation into several successive batches. Landscape Physical Materials Display Landscape physical materials can now be displayed when showing collisions by using the new CVar landscape.CollisionMesh.ShowPhysicalMaterial. When enabled, it helps users to debug how physical materials are exported, especially when using the Landscape Physical Material Output node. Landscape LOD Groups We added LOD groups to enable seamless LOD transition across multiple landscape actors in the same group. Procedural Content Generation (PCG) Hierarchical Generation Hierarchical Generation Hierarchical Generation allows for execution of different grid sizes within the same PCG graph. After setting a default grid size in the PCG graph settings, users can start adding Grid Size nodes to define the granularity at which the downstream elements should execute. Data processed at higher grid size can be used at any smaller level. This hierarchical logic enables users to achieve more optimal procedural generation, especially over large worlds at runtime. Rule Processing From External Data Rule Processing From External Data We now support rule processing from external data, providing feature parity with the City Sample project Rule Processor plugin to manage external data, process it, and produce artifacts on target actors. This includes: External data support for Alembic point clouds and data tables A utility for converting Alembic files to PCG Settings assets Subgraph Inspection Subgraph Inspection We added support for debugging and inspecting PCG subgraphs through the Attribute List view within a parent graph. Graph Instances Parameters Graph Instance Parameters We are introducing a Blueprint API to get and set PCG graph user parameters. Other additions include UX improvements and filtering for supported types. Custom PCG Elements Custom PCG Elements To improve the creation workflows and readability for custom PCG elements, we renamed PCG-specific Blueprint loop functions. We also added new functions to set up and output PCG data collections in order. Developer Iteration Multi-Process Cook (Beta) Multi-Process Cook helps reduce the total time it takes to get a cooked output from a build farm server or on your local workstation by leveraging available CPU cores and memory resources. Multi-process cook is a beta feature for UE 5.3. Performance gains may vary, depending on the size of the project and how the data is separated. For best results, we recommend you test different CookProcessCount values depending on the project and available hardware specs. Virtual Assets Virtual Assets are now production-ready for UE 5.3 and recommended for teams using Perforce version control and a shared Unreal DDC (Derived Data Cache) for best performance. To recap, virtual assets drastically reduce the size of local project data and sync faster by only synchronizing core asset metadata, and then pulling down the bulk data on demand if needed. Virtual assets are supported for textures, audio data, and static meshes (including Nanite). Bulk data is compressed using Oodle for additional data size savings. Should you need to go offline, you can run a precache commandlet when launching your project that will cache virtualized data locally on your machine. There is also an 'Auto fix / re-virtualize assets' check-in script available in the Unreal Automation Tool (UAT) that will catch any assets mistakenly un-virtualized project-wide. C++20 Default Version UE 5.3 is now compiled with the latest C++20 standard, and the version is supported in your development environment. We added C++20 support to the Unreal Build Tool (UBT), and it is controllable with a target or module setting; C++14 is marked deprecated and no longer supported. All engine modules are compiled by default with C++20, regardless of the target C++ standard. Other modules still support C++17 but can be opted-in to C++20 if desired. C++ Unreal Header Tool We removed the C++ Unreal Header Tool from Unreal Engine. Please use the C# Unreal Header Tool. Platform XR XR Gaze-Tracked Foveated Variable Rate Shading (Experimental) Performance is of utmost importance when developing XR applications. This experimental feature enables gaze-tracked foveated image generation with OpenXR, reducing the number of total pixels drawn. Make sure the OpenXR and OpenXR EyeTracking plugins are enabled, and set: xr.VRS.FoveationLevel 1-3 to enable foveation. xr.VRS.GazeTrackedFoveation 1 to enable Gaze-Tracked Foveation. xr.VRS.FoveationPreview 1 to enable preview of the foveation mask. Single-Pass Stereo Rendering for Nanite Nanite can now render both stereo views in a single pass when Instanced Stereo Rendering is enabled. Nanite rendering is a multi-step process, and executing these steps for each eye separately is not optimal. Projects with ISR enabled can now have each step of the Nanite pipeline process both eyes at once, reducing the overall rendering time. You can use r.Nanite.MultipleSceneViewsInOnePass=0 to disable this technique in case you suspect it of introducing a problem. Stereo Improvements for Lumen Global Illumination Lumen GI has a number of per-view caches. Since stereo views are so close to each other in terms of position and direction, we can reuse some of the cache between the views. You can use r.Lumen.StereoOptimizations=0 to disable this in case of any problems. Handheld AR Improvements ARCore SDK has been updated to 1.37 ARCore plugin cleanups: Removed deprecated camera metadata API usage. Updated to new Cloud Anchor Async API. Updated to new front/back camera configuration API. Removed deprecated ARCore-specific Blueprint functions that have cross-platform equivalents. Fixed ARCore and ARKit ARPins when the tracking to World Transform or World Scale changes. XRScribe Plugin (Experimental) This new experimental plugin enables the use of the OpenXR plugin and related code without needing an OpenXR device. The plugin captures OpenXR API interactions between Unreal Engine and the runtime, and can use that capture to emulate devices. A limited set of OpenXR extensions currently supported by XRScribe OpenXR surface. Hand tracking, gaze tracking, depth layer, and Vive Trackers are not yet supported. Currently available for Win64 only, but other platforms will be supported in the future. Emulation currently handles replay of HMD plus device poses, but no input yet. Plugin built-in captures can be used for quick emulation using CLI (-xremu=mq1 or -xremu=vi). XRBase Refactor We refactored the implementation of many XR-related interfaces from the core engine into an XRBase plugin to reduce executable size and memory overhead in non-XR projects. Some XR-related plugins may need to add XRBase as a dependency as a result. XR_FB_Foveation support (Experimental) Fixed and dynamic foveation for Meta Quest devices can now be enabled in Project Settings->OpenXR Settings. You can use the following CVars to configure it: xr.OpenXRFBFoveationLevel (Default=0) 0=None, 1=Low, 2=Medium, 3= High xr.OpenXRFBFoveationDynamic (Default=False) True/False xr.OpenXRFBFoveationVerticalOffset (Default=0) Other Improvements Mobile Preview on Vulkan RHI is now using multi-view extension natively instead of Mobile Multi-View emulation. Packaging for all Meta devices can be achieved by enabling the Package for Meta Quest devices checkbox in the project settings. Extension plugins to the OpenXR plugin can now access the Layer List. Mobile Development Requirements and Compatible Hardware The following are the supported OS versions and minimum hardware for mobile devices supported by Unreal Engine 5.3. For additional information about required SDKs and IDEs, refer to the Platform SDK Upgrades section. iOS/tvOS/iPadOS UE 5.3 supports iOS, iPadOS, and tvOS devices with OS that support version target SDK 15 or later. UE 5.3 supports: A8 AppleTV devices A8X iPads A9 devices or newer The following are the minimum compatible device models for UE 5.2: iOS 15 iPhone 6S or later iPod Touch 7th generation iPadOS 15 iPad 5th generation or later iPad Air 2* or later iPad Mini 4* or later iPad Pro (all models) tvOS 15 Apple TV HD* Apple TV 4K (first generation) Apple TV 4K (second generation) Android UE 5.3 supports Android devices meeting the following specifications: Android 8 or higher 64-bit Arm-based CPU Compatible GPUs: Mali T8xx, G71, G72, G76, G77, G78 and G71x series Adreno 5xx, 6xx or 7xx series PowerVR GM9xxx series Xclipse 920 Compatible Graphics APIs: OpenGL ES 3.2 Vulkan 1.1 on Android 10 or later devices with compatible drivers Android SDK and JDK Updates We have streamlined our Android SDK requirements by moving to Android Studio Flamingo 2022.2.1 and using OpenJDK 17.0.6 as our JDK version. Baseline Android support for UE and AGDE now both target the same JDK version, and users do not need separate JAVA_HOME and AGDE_JAVA_HOME environment variables to point at separate JDK installations. Note that with this update, UE now targets the jbr directory for JDK rather than jre. If you need to support earlier versions of UE than 5.3, but also need to set up UE 5.3 for Android, we recommend the following: Before you uninstall your previous version of Android Studio, copy the contents of the jre directory to somewhere outside your Android Studio installation to keep them from being overwritten. Make sure your Android environment variables do not target the SDKs used by earlier versions of UE. For older versions of UE, use BaseEngine.ini or your Project Settings to manually target your SDKs. In particular, set your JDK directory to the copied jre directory. See the documentation on setting up Android Studio for UE 5.3 for more details and instructions. Modernized Xcode Projects We have updated the way UE handles Xcode projects and workspaces, making it more consistent with modern Xcode workflow conventions. This includes the following changes: Improved Xcode Project Organization UE now uses one Xcode workspace per platform. For example: UnrealGame (Mac) and UnrealGame (IOS). UE now uses separate projects for each build target type within its workspace. For example: UnrealGame (Mac), UnrealGameEditor (Mac), and UnrealGame Server (Mac) each would be separate projects under the Mac workspace. Each project only allows the build configurations it supports. For example, Editor projects do not show the Test or Shipping configurations. Frameworks are now handled using standard Xcode methods. Whereas previous versions required developers to manually copy and codesign Frameworks, the build system now automatically discovers and codesigns them. Improved Packaging and Distribution Process All data needed to run is bundled inside self-contained .app files for each of Apple's platforms. This includes macOS, which did not use this paradigm in previous versions of UE. Automatic codesigning is now the preferred method for handling codesigning in development/debugging builds for both macOS and iOS/iPadOS/tvOS. You can use Xcode to manage and distribute apps with Xcode archives, which are now the preferred way of creating shipping builds. Shipping builds create an .xarchive file and a .dSYM file for this purpose. Improved management of Entitlements and .plist files. Developers can now use templates or customized files for both of these assets. For more details about these improvements, see our documentation on the modernized Xcode workflow. iOS Workflows iOS Workflows UE 5.3 brings several improvements to development workflows for the iOS platform: MallocBinned2 memory allocator can be used if your App ID contains the Extended Virtual Addressing entitlement. Improved packaging and app signing thanks to a modernized XCode projects integration (see Modernized Xcode Projects above). The Prepare for Debugging command, which streamlines the debugging pipeline, now offers Windows remote (experimental) and secondary Mac workflows. See the documentation on debugging in Xcode and using remote Macs for more details. The iOS simulator is now supported on Apple Silicon Macs, allowing faster development iteration without devices (experimental). Mobile Ray Tracing Support on Android (Experimental) UE 5.3 supports ray tracing for high-end Android devices running the Mobile Desktop Renderer. Supported mobile GPUs include: Adreno 740 Immortalis-G715 Samsung XClipse Series To enable mobile ray tracing: Enable the desktop renderer for your project. Enable ray tracing. Add the following to your device profiles: [Android_Vulkan_SM5 DeviceProfile] +CVars=r.Android.DisableVulkanSM5Support=0 This update also includes mobile indline shadow support for ray traced shadows, which only works with deferred shading. This support is experimental and should not be used for production purposes at this time. However, we welcome feedback from users trying it out! Mobile Renderer Mobile Renderer The mobile renderer now includes several performance and visual quality improvements, notably: Compute-based landscape vertex culling. Fog volume support. Global distance field generation on mobile forward. Instance rendering improvements (GPU Scene). Virtual texturing support. Support for Nanite on Apple M2 Devices (Beta) Nanite on Apple M2 Devices Unreal Engine 5.3 brings beta support for Nanite rendering technology on Apple Silicon M2 devices running macOS. This support is enabled by default, with shader model SM6, in the UE macOS binaries downloadable from the Epic Games launcher, whereas the Experimental 5.2 support was only available when building from GitHub sources. Character and Animation Dynamic Workflows for Runtime and Non-Linear Cinematics Dynamic Workflows for Runtime and Non-Linear Cinematics This release focuses on improvements to runtime workflows and nonlinear organization. User-Defined Dynamic Bindings Use the Level Sequence Director Blueprint to define different objects, such as the player pawn, to either be dynamically possessed or spawned by Sequencer during runtime. Material Section Blending Similar to other track types, material typed sections can be added to tracks that support materials. This includes material parameter collections and UI animations in UMG. Takes for Subsequences Similar to the Shots track, takes for Subsequences can be created and set within Sequencer. Comments for Takes Add/edit/view comments to Shot/Subsequence Takes within Sequencer. Text Track Text properties can now have tracks in Sequencer, where users can change the value of a text field over time and key it. Animation Retargeting Animation Retargeting This release focuses on quality-of-life improvements for Retargeting. Toolbar in the Retarget Editor - This provides easy access to Global and Root settings along with the Retarget phases. Makes available mode switches between the Running the Retarget, editing the Retarget Pose, and viewing the Retarget Pose options. Retarget Poses - Edit a bone's local space to zero out bone rotations. Create IK rig/IK retargeter assets from a selected skeletal mesh/IK rig in the right mouse context menu. Thumbnails for IK Rig and IK Retargeter assets. Animation Authoring Animation Authoring Further improvements for animation authoring in this release include: Smart Bake Now allows you to target only baking keyframes. Constraint baking Space switch baking Snapper Collapse sections Baking transforms Smart Auto Tangent New auto tangent that better maintains the curve shape. Curve Editor Improvements Improved normalized view Improved performance with lots of keys Better handle selection More accurate marquee select Fixes to zoom levels when auto frame is off Motion Blending Improvements Swap Root Bone works on animations with Root Motion Preview using AnimBP. Skeletal animation sections can be extended backwards. Export Improvements Export control rig animations as a FBX file. Skeletal Editor (Experimental) Skeletal Editor The Skeletal Editor provides a way for users to create skeletons and edit mesh skin weights directly in the Unreal Editor. This tool offers faster iterations by means of the addition of bones to your assets, the deformation of static meshes, and converting them to skeletal meshes, all in one place without the need for importing skeleton data. Convert static meshes to skeletal meshes Create and edit skeletons Add bones Remove bones Orient and edit bones Mirror bones Create skin weights Paint Weights brush tool Edit weights on vertex selection Flood / Relax / Prune / Average / Normalize operations Mirror weights Paint maps Python API support for bones and weights Machine Learning (ML) Deformer Machine Learning Deformer ML Deformer provides users a way to approximate a complex rig, nonlinear deformers, or any arbitrary deformation by training a machine learning model that runs in real time in UE. Improvements in UE 5.3 include: The addition of a masking system for Local Neural Morph Model, which improves the ability of users to work with structured data. Improvements to the Nearest Neighbor model UI and workflow. The removal of dependency on the NNI framework. The ability to create training masks, and visualize the masks per bone / bone group / curve in the viewport. There is no longer any need to take any manual steps (for instance, installing a Python package) for the Nearest Neighbor and Neural Morph models to train correctly on Windows. The ability to run trained Neural Morph and Nearest Neighbor models on Linux and macOS (although training errors may be encountered). Build Control Rigs from Data We further extended the procedural toolset of Control Rig by providing a way for you to use data outside of the Control Rig graph to procedurally create and modify the rig. This includes: The ability to query and use external data such as transforms, floats, skeletons, and more to build control rigs procedurally. A new 'GetUserData' node that will query incoming data. A new 'Set Shape Library from User Data' node that will swap the shape library currently being referenced. Virtual Production SMPTE 2110 for ICVFX SMPTE 2110 for ICVFX The Unreal Engine 5.3 release completes the implementation of a next-generation ICVFX stage deployment using an end-to-end SMPTE 2110-based IP video signal flow with nDisplay. SMPTE 2110 support enables productions to maximize the available hardware resources on stage, with this increased efficiency empowering the potential for higher-resolution inner frustums and lower latency. With a SMPTE 2110-based configuration, productions will be able to: Render the inner frustum once and share it with the other render nodes in the cluster, avoiding the redundancy of each node re-rendering the inner frustum for determinism. Dedicate the resources of an entire render node to the inner frustum to leverage all available resources to display the highest-possible quality on the pixels seen in camera. Framelock each render node with a native SMPTE 2110 sync policy that ensures Unreal Engine output remaining in phase with the camera. Output the resulting renders to the LED processors using SMPTE 2110, eliminating the need for a display port and/or HDMI converters. Virtual Camera Virtual Camera Takes Browser We added the ability to browse for level sequences from the virtual camera and load them for review or as the base for your next recording, as well as to star, flag, or NG sequences to filter the list. Multiple HUDs from a Single VCam You can now add multiple output providers to a single VCamComponent each with its own HUD and stream. You can stream an operator's view, a simple burn-in, and a clean plate from one VCam, at the same time. Time-Scaled Playback and Record You can now play back and record at non-1:1 speeds. Record at a custom rate and your move will be sped up or slowed down when played back at full speed. Initial macOS Support (Experimental) VCamActor now supports streaming from macOS through legacy Remote Session. Virtual Camera Core, VCamComponent, VCamModifier, and VCamOutputProvider are available for use to create custom VCams on macOS versions of UE5. Development remains ongoing to bring Pixel Streaming and full VCam support to macOS. CineCamera Rig Rail (Beta) CineCamera Rig Rail We've added a new rig rail actor tailored towards advanced cinematic and virtual camera workflows. Plan your Composition Store camera focus, iris, and zoom in rail points, allowing the rail to drive more complex aspects of your composition. Drive the Rail Automate your moves using a number of drive modes: Manual: Drive your rail position from Sequencer or external input. Duration: Drive your rail position to complete your move in a set amount of time. Speed: Drive your rail position at a set speed. Work with Sequencer Points are stored by absolute value and can be safely keyed in Sequencer. As a result, the position value of a given point cannot change unless you directly modify the point. If you keyframe a particular position to occur at a given framing, it will not change regardless of how many new points are added before or after. Visualize Your Speed See your speed along any point of the rail through a heat map applied to the rail mesh and avoid any surprises when recording a layered move. Choose your Axis Inheritance Choose to only inherit subsets of axes from the rig rail. Drive position from the rail while refining rotation or choose to remove the Z axis for a steadier ride. CineCamera Scene Capture Component (Beta) CineCamera Scene Capture Component We've added a Scene Capture component for CineCameras. You can accurately capture a CineCamera component to a render target for use in materials, UMG, and beyond. The feature supports lens distortion, together with CineCamera-specific properties and post-processing. Anamorphic Lens Calibration Solver (Experimental) Anamorphic Lens Calibration Solver We've added an anamorphic lens model and solver to the lens tool to be used with lens assets, making it possible to solve anamorphic lens distortion. Using the lens component, you will also be able to add anamorphic lens model distortion to CineCamera actors to render distortion effects within the engine, making it possible to visualize shots using profiled anamorphic lenses. Manual parameters for the anamorphic lens model can also be adjusted to create anamorphic distortion looks. OCIO for Texture Conversions OCIO for Texture Conversions The introduction of Working Color Space established a foundation for robust color management in Unreal Engine for critical operations such as configuring the input color space for textures, helping to ensure assets look correct regardless of where they may have been authored. Unreal Engine 5.3 expands upon this support with the ability to leverage OpenColorIO for these texture conversions. With this, Unreal Engine adopts an industry-standard framework to maximize consistency across the color pipeline for textures. nDisplay Multiplayer Actor Replication nDisplay Multiplayer Actor Replication We've revised the nDisplay low-level networking architecture so that it can support actor replication in a multiplayer game context. Transparent to the end user: The feature can be activated in nDisplay Project Settings using the Cluster Replication Enabled option. We've added a Multiplayer Server option to Switchboard. Each nDisplay node becomes a networking client when joining a multiplayer session or game. In the future, we hope to enable nDisplay Clusters to join a multiplayer session as opposed to individual nodes. nDisplay Fill Derived Data Cache nDisplay Fill Derived Data Cache We've added the ability to \\"prime\\" nDisplay systems (stand-alone shaders) before first use by filling the derived data cache in advance. This feature can be triggered locally using the Build Menu or using Switchboard on all cluster Nodes. The nDisplay cluster is then ready to be started without requiring any further shader compilation. You can schedule this operation offline at a time convenient to you, since it is exposed to Unreal Engine using a command line argument and can be triggered externally. DMX Control Console UX DMX Control Console UX We are improving the new Control Console UI and UX with the following additions: Two main layout modes: Default, where only selected patches are visible Manual, where you can define the fader group positions A revised search mechanism for quicker DMX fader access The ability to change fader values using relative or absolute controls The ability to select which patches are actively sending DMX data DMX Pixel Mapping UX DMX Pixel Mapping UX The DMX Pixel Mapping tool has received a significant facelift and now offers an improved UI and UX, among other fixes: A new input filter section enables you to downscale, blur, and perform material-based logic on the incoming pixels. DMX library manipulation is consistent with the new UX provided by the Control Console. This works hand-in-hand with the hierarchy view so that you can see which patches have been added and which remain. Media IO Media Plate Material System Media IO Media Plate Material System We've improved the current media plate actor material system, giving you the ability to: Pick a material directly from the Media Plate Plugin Content directory using the new auto-populated dropdown. Browse to the Media Plate Plugin Content directory for quick access. Also, we enabled the Output Depth and Velocity flag in the default media plate materials for increased TSR/TAA image stability when there is camera movement relative to the media plate actor(s). Simulation Chaos Cloth Editor Foundation (Experimental) Chaos Cloth Editor Foundation Chaos Cloth for UE 5.3 includes the addition of an experimental Cloth Editor. The new Cloth Editor enables having multiple garments per character and the same garment across multiple characters in the future. It also provides panel-based workflows which will make it easier to set up and modify clothing setups. It includes the following features: New base class editor for character physics (cloth/flesh). First phase of panel-based editor with the Dataflow graph. Non-destructive workflow. Cloth is extracted from the skeletal mesh as a separate component. Extra collision support. New Skin Weight Transfer tool. Masks are now replaced by reusable weight maps. Multiple Materials can be driven by single sim mesh support. See the Panel Cloth Editor Overview for more information about this feature. Chaos ML Cloth (Experimental) Chaos ML Cloth Cloth simulation can be too expensive for many use cases. Artists, engineers, and game designers need alternative, less-expensive runtime solutions to mimic cloth simulation, especially for tighter fitting clothes. Currently, this requires a tedious process of hopping back and forth between DCC to simulate and importing results back into the engine. For UE 5.3, artists can now simulate and train cloth in engine using the experimental Chaos Cloth Generator plugin. See the Machine Learning Cloth Simulation Overview for more information about this feature. Chaos Rigid Bodies and Scene Queries We made several updates and optimizations to Chaos Physics to give artists, developers, and programmers better simulation results, notably on rigid body simulation and scene queries. The continual focus on rigid bodies is low-level optimization including SIMD, cache coherency, functional removal, reduction in data copying, and so on. Scene queries implement a dynamic acceleration structure that is now quicker to update and query. Chaos Destruction Fracture editor updates A new material has been added, to help with fine control when managing and assigning material for a geometry collection. Fracture Editor Material The proximity tool has been improved with better visualization control and new contact method for generating the connection graph. Fracture Editor Proximity Tool The level statistic now shows aggregate convex information, which is useful when optimizing your geometry collection collisions. Fracture Editor Level Statistic Runtime Optimizations The geometry collection component no longer ticks by default and will only tick after the geometry collection has been damaged. The runtime cost of the tick function has been also reduced. Data types optimizations at the solver and attributes level have been made, reducing the cost of geometry collection assets on disk as well as the runtime memory cost of their instance. Numerous optimization have been also done to reduce the overall CPU cost of geometry collection instances allowing for using destruction at larger scales. A new experimental damage model has been introduce leveraging the physical properties of material and internal topology and connectivity of geometry collections. Niagara Fluids Niagara Fluids We added the ability to transform Niagara Fluid sims after they are cached. This opens up the capability to duplicate a cache multiple times, and to offset the duplicates in time/space to get more complex effects from a single cached sim. We added data channel support to the 3D Gas simulations. It is an experimental feature that provides a way to source fluid from any CPU system in the level. On the master emitter, the particle source now has two modes: Emitter and Data Channel. Emitter mode reads data from an emitter in the same system. Data Channel mode reads data from a predefined Niagara data channel. That data channel can be written to from the existing Set Fluid Source Attributes module. Path Tracer now supports heterogeneous volumes, which means fluids can be rendered directly in it. We added experimental support for SVTs (sparse volume textures); caching fluids now writes directly to SVT, which is an order of magnitude faster. Niagara Summary View Editor Niagara Summary View Editor The Summary View Editor provides a way for users to create custom views of Niagara emitters. Using this, it is possible to expose only the most important settings and inputs for an emitter to end users. One heavy use case for this are the Niagara fluid emitters, which make it easier to make tweaks to achieve desired effects by looking at only a well-organized subset of settings. Users can rearrange and set up categories, sections, individual module inputs, or entire modules, as well as specific properties such as the Sprite material for Sprite renderers. See the Summary View Quick Start for more information about this feature. Audio MetaSound Builder API The MetaSound Builder API makes it possible to create and change a MetaSound graph through C++ or Blueprint APIs while the game is running in real time. This opens up the possibility of adding/removing MetaSound nodes and modifying connections during gameplay. Audio Bus Writing You can now take data from one MetaSound and send it to another MetaSound or to another source bus through a new MetaSound node. MetaSound Output Watching (Experimental) MetaSound Output Watching MetaSound Output Watching provides a way for Blueprint or C++ to watch for changes in the MetaSound graph. This means users can match gameplay and visuals to events happening in MetaSounds. As an example, you can affect gameplay elements and visuals according to a musical beat, or change in audio. This supports the ability to: Fire an event when there are value changes on the provided MetaSound output of types float, int32, Bool, and fstring types. Fire an event when the envelope follower on an audio output changes. UI Systems Common UI (Beta) Common UI Common UI provides a toolbox for creating rich, multi-layered user interfaces with cross-platform support. It includes: An input action system specific to UI. An input-routing system that makes it easier to selectively exclude menus from capturing input. A styling system that provides style assets for commonly used text/fonts, borders, and buttons. A library of other commonly used widgets. Improvements in this release include: Integration with enhanced inputs Input debugging Documentation and content examples Font DPI Matching in UMG Font DPI Matching in UMG Designers can now match their font sizes seamlessly when they convert UI mockups into UMG screens, without worrying about DPI mismatch. Newly created projects will have the DPI setting defaults to 72 DPI. Existing projects will remain at 96 DPI. Switching back and forth between different DPI settings will not affect how fonts are rendered. See the documentation on Font DPI Scaling for more details. Viewmodels in Blueprints Viewmodels in Blueprints Whereas previous versions of Unreal required designers to create Viewmodels in C++, in UE 5.3 you can now create Viewmodels in Blueprint. This update streamlines the process of creating and binding Viewmodels in various ways. Extend the MVVMViewmodelBase class to create a new Viewmodel Blueprint. Create variables as you normally would with Blueprint, then designate them as FieldNotify variables by clicking the bell icon next to their names. Create FieldNotify functions to handle operations that don't need dedicated variables, then use your FieldNotify variables to trigger them. Add your Viewmodel to your widget class using the Viewmodels panel. New click-and-drag functionality makes binding Viewmodels to UI fields quicker and easier. See the Viewmodel documentation for full instructions on how to use Blueprint-based Viewmodels in your project. Modeling Modeling Workflows (Beta) Modeling Workflows Artists developing assets require efficient modeling, sculpting, UV editing, and texturing workflows. These workflows are more than just a couple of different tools clicked in a certain order. Every type of interaction needs to be considered in order to reduce the number of mouse clicks, minimize the cursor movement, and provide accurate feedback for the artist. With this aim in mind, improvements in UE 5.3 include: New UI Modeling Mode's main menu, tools palettes, and properties panels have been redesigned. The new UI is more compact, allowing for more efficient and consistent workflows. The new menu also contains a new favorites option, providing a top-level custom menu that can be defined per user. Tool Presets Creators and developers can now make custom presets for modeling tools. The custom presets provide a way for artists to store multiple options for tools, and access them quickly from the tool icon. Element Selection Direct mesh element selection provides for a more consistent and optimized workflow. The existing method of selection requires the artist to select the mesh first, then the specific tool, and finally the element before invoking the operation. The new element selection workflow enables artists to select the mesh, select the element, and then invoke an operation without any need to use an intermediate tool like PolyEdit or TriEdit. Modeling Tools (Beta) Modeling Tools The Modeling Mode's toolset continues to develop. For UE 5.3, we added some requested enhancements to the toolset, in addition to new tools that use splines. The new element selection mode is also supported with a set of dedicated tools. Spline Tools We've added new tools to the Create menu that provide creators with a way to draw new splines, and use them for revolves and flat mesh operations. Element Selection Tools The Element Selection workflow leverages a new menu of tools that work directly with the selection. The palette includes common tools such as Extrude, Bevel, Offset, Inset, and Insert Loops. There is also quick access to PolyGroup and Triangle Edit. LOD Support The Bake Transform and Edit Pivot tools can now optionally update all LODs with the new transform or pivot. Vertex Color Paint We added a new tool for painting vertex color. The new tool enables users to paint, fill, and blend colors to multiple or specific channels. Other Improvements We made additional improvements to the Edit Normals, Weld, Bake Texture, and Generate PolyGroups tools. To learn more about the available tools see Modeling Tools. UV Tool (Beta) UV Tool UVs are a critical component when working with meshes, not only for final rendering but also as a vital part of level design. For UE 5.3, we added two important new features to the UV Editor: UV Editor Distortion Display The UV Editor now has optional display modes for distortion. This provides for an interactive representation of the level of texel stretch or density. UV Auto Layout The tool now has support for texel density normalization. This option attempts to resize individual islands to maintain a constant, average density over the entire layout. To learn more about UV tools see, UV Editor. Geometry Scripting (Beta) Geometry Scripting provides technical artists a toolkit for creating custom modeling tools and workflows. In 5.3 Geometry Scripting is now beta and continues to expand with the following additions and improvements: Enhanced skeletal mesh interoperability provided by several new nodes: CopyBonesFromMesh TransferBoneWeightsFromMesh GetRootBoneName GetBoneChildren GetAllBonesInfo GetBonesInfo DiscardBonesFromMesh New functions for managing 2D polygons and paths, including computing offsets and their booleans: Polygons Difference Polygons Union Polygon Intersection And many more, there is a large library of functions. Delaunay triangulation to create a mesh that interpolates points: Append Delaunay Triangulation 2d Geodesics on mesh surfaces: GetShortestSurfacePath GetShortestVertexPath To learn more about Geometry Scripting and the available functions, see Geometry Scripting User Guide and Geometry Scripting Reference. Content Pipeline Interchange Import / Re-Import Interchange Import / Re-Import In this release, the Interchange Framework includes the following improvements: We added a new custom asset type to provide a way to re-import whole scenes. The Interchange UI now supports overrides of pipeline stack per translator. This provides an extra layer of configurability and is used in default settings: for example, the glTF asset pipeline stack will override the default asset pipeline stack (used for FBX and OBJ). For glTF import, you can now choose to have the editor either generate materials or use predefined material instances. You can also override those instances for more user control over glTF rendering. USD MaterialX (Experimental) USD MaterialX Unreal Engine 5.3 offers the ability to use USD with MaterialX for streamlined workflows and content creation between DCCs and Unreal Engine. It is now possible to import a USD file with MaterialX shading networks directly in the engine. Additionally, you can now open USD files with MaterialX shading networks in the USD Stage Editor while interacting directly with the contents of the USD file. MaterialX support in Unreal Engine was introduced with 5.1 and is still experimental. USD Materials and Textures USD Materials and Textures For Unreal Engine 5.3, there have been a few changes to how textures and materials are handled to improve the display of USD assets: We added support for multiple UV sets on the same material. We added support for simple UV transforms on preview surface materials. If you are loading a preview surface using any math nodes to transform the texture, it will now display correctly. We added the ability to interactively change USD materials in the USD stage editor Details panel and see the result live in the viewport. Previously, the user would be required to save the USD file and reopen it in order to see any changes. USD Animation USD Animation Direct Geometry Cache Import We added the ability to directly import cached geometry into UE from a USD file. Prior to this, you could only load the USD file on the stage and play back the geometry cache animation from there. Support for Transient Actors in Sequencer We added support for transient actors in Sequencer. This provides a way for you to add elements from the USD stage actor to Sequencer, reload the USD file or to close and reopen Unreal Engine, and Sequencer will remain connected to the elements being animated from the USD stage actor. This also means you can now maintain sparse key animation curves that will drive the elements from the USD stage actor being animated, and the baked animation can be exported to a new USD file. USD stage actors can now be exported as well, so animation of their elements can be exported as overrides on the referenced stages. Framework Smart Objects - World Partition Support Smart Objects and World Partition Smart Objects now work seamlessly with World Partition, data layers, and persistent levels. We also improved Smart Objects to support using navmesh and physics for slots availability. Blueprint Type Change Auto-Casting Blueprint Type Change Auto-Casting Deprecating code-based Blueprint-visible properties and changing the type of the properties can include challenges such as failures when rewiring old pins. This leads to orphaned pins and compilation errors. In UE 5.3, if both types have an auto-cast function available, a cast node will automatically be created and added into the graph. Additionally, notes will be created whenever a new cast node was added, which serves as a notice that users might want to update their API to use the new type change. Data Asset Merging Data Asset Merging As a first step towards adding functionality beyond what the Diff tool offers, we started investigating a data merge solution. This first version provides support for manually merging data assets when conflicts cannot be auto-resolved. Currently only data assets are supported, but we hope to support more types of data in the future. Review Tool Swarm Comments Review Tool Swarm Comments The Review Tool introduced in 5.2 now has direct Swarm integration when using P4 as source control, so the diffs you perform from there will directly show the comments in the editor. You can have comments for each change made, but also leave global review notes. We use simple metadata tagging in Swarm to link the comment to the right section of the diff. Engine Content and Templates Collaborative Viewer Templates Using Enhanced Input The collaborative viewer template The Collab Viewer templates join multiple users together in a shared experience of the same 3D content. We intended them to make it easier and quicker for your team to review and communicate about designs in real time, so that you can identify problems and iterate on the content more efficiently. In UE 5.1, we released OpenXR support for enhanced input and made it the recommended input system for XR applications. In UE 5.3, we updated the templates to take advantage of the abstractions and flexibility that enhanced input enables. Platform SDK Upgrades Logos for Platform SDKs Windows Visual Studio 2022 v17.4 or newer Windows SDK 10.0.18362 or newer LLVM clang 14.0.1 .NET 4.6.2 Targeting Pack .NET 6.0 IDE Version the Build farm compiles against Visual Studio: Visual Studio 2022 17.4 14.34.31933 toolchain and Windows 10 SDK (10.0.18362.0) Xcode: Xcode 14.2 GDK Minimum Windows SDK: 10.0.19041.0 GDK: March 2023 Update 5 GDK Firmware Version: Recovery June 2023 (10.0.22621.4819) *Supported IDE: Visual Studio 2022 Linux Native Linux Development Recommended OS: Ubuntu 22.04 or CentOS 7 Compiler: clang 16.0.6 Cross-Platform Development Cross-Compile Toolchain: v22 clang-6.0.6-based (CentOS 7) macOS Recommended Latest macOS 13 Ventura Latest Xcode 14.1 or newer Minimum macOS 12.5 Monterey Xcode 14.1 EOSSDK 1.16 binaries with 1.15 headers Provides 1.15 feature set. 1.16 binaries for recent platform SDK support and WebRTC fixes. Steam 1.53 iOS / tvOS / iPadOS Recommended Latest macOS 13 Ventura Latest Xcode 14.2 or newer Minimum macOS 12.5 Monterey Xcode 14.1 Supported Target SDK versions: iOS 15 or later Graphics API: Metal 2.4 and Metal 3.0 Android Android Studio Flamingo 2022.2.1 Patch 2 May 24, 2023 Android NDK r25b Android SDK Recommended: SDK 33 Minimum for compiling UE: SDK 30 Minimum target SDK for running on device: SDK 26 AGDE v22.2.69+ required if you are using AGDE debugging. Build-tools: 33.0.1 Java runtime: OpenJDK 17.0.6 2023-01-17 Switch SDK 16.2.0 Minimum Firmware Version: 16.0.3 Nintendo Dev Interface 2.5.5 Supported IDE: Visual Studio 2022 (SDK version 16.2.0) PS4 Orbis SDK 10.508.001 System software 10.508.011 Supported IDE: Visual Studio 2022 PS5 Prospero SDK 7.00.00.38 UE5Main has a patch updating to 7.00.00.45. This is recommended for shader compiler fixes. System Software 7.40.00.06 Supported IDE: Visual Studio 2022 ARCore 1.37 ARKit 4.0 OpenXR 1.0.22 Release Notes Animation API Change: Added the first version of Mutable extension API. New: Added a new LOD threshold property to rig logic anim graph nodes in order to compute facial animation earlier than other skeletal post-processing, which might be part of the same post-processing AnimBP. Added the ability to disable or skip post-process AnimBPs at lower LOD levels. You can set the post-processing AnimBP LOD threshold similarly to how you can set LOD thresholds for some anim graph nodes. Additionally you can skip the post processing anim BP graph during set points entirely, to improve performance. The speed improvements scale with the complexity of the post-processing AnimBP and as well as the amount of nodes that do not support LOD thresholds or have setup node-based LOD thresholds. Added the option to filter by Sync Marker to the Animation Sequence Browser. Add new output warnings when the LegIK node is missing definitions or contains references to invalid bones. IK Rig and IK Retargeter now available in UEFN. IK Retarget poses can now be zeroed in local space to instantly straighten limbs for more accurate retargeting. Added 0.75 and custom speed to Animation Viewport ToolBar, for Animation Speed and TurnTable speed. Bug Fix: Fixed an issue that could prevent the MeshBoneReduction module from loading as soon as the MeshUtilities module starts up, as it could be needed at any time from a background thread Fixed an issue by adding a guard against the use of an invalid actor pointer in the Skeletal Mesh editors. Fixed incorrect localized text in the LegIK Animation Blueprint node. Fixed an issue occurring when creating animation assets overriding existing assets, by enabling replacing existing animation in the options to create new assets. Fixed an issue occurring when pasting anim notifies from multiple tracks to a location that did not contain the same tracks. Removed: Removed null links from Mutable graphs on load. This prevents incorrect behavior and editor instability when a node saved into a graph can't be loaded. Animating in Engine API Change: Fix inverted tangents on Y axis for 2D controls. New: Added a new ControlRig.Sequencer.AutoGenerateTrack console variable to toggle whether control rig tracks should automatically be created for new components. Control Rig FBX animations can now be exported and exported between Unreal Improvement: Curve Editor filters have been improved and can now be set using ranges rather than individual selections, so you can now bake a range of frames or times. Curve proximities can now be updated when there is a drag operation so that the curve tooltips show the proper time and value. Curve Editor selections are now synchronized whenever new items are added to the editor. Bug Fix: Fixed an issue that could occur by delaying a level sequence asset's creation until the tick proceeding the tick the control rig actor is dropped into the viewport. This prevents the level sequence asset creation to be in the same transaction as the create actors transaction. Previously, the movie scene could be collected as garbage when undoing the action, because its creation took place during another transaction. Fixed an issue that could cause a memory leak with the backbuffer Render Target not being released at the end of a render. Constraints: propagate offset change so that local transform animations are synchronized. Gameplay New: You can now use the new experimental Dead Blending AnimGraph node. This node is designed as a drop-in replacement to the Inertialization node but uses the new robust \\"Dead Blending\\" algorithm which is more equipped to handle multiple simultaneous Inertilization requests or when the Inertialization transition is between two very different poses. Exposed a new method to blueprints that you can use to get the weight of a montage playing on a specified animation slot. Added the following AnimNode functions: On State Exit, On State Entry, On State Fully Blended In, and On State Fully Blended Out. These are located in any Animation State Graph's Result Node. Added support for AnimNodes to show any bound functions and not have them hardcoded. Added a way for users to specify the string for the default binding name of a function member reference in a blueprint by using the \\"DefaultBindingName\\" metadata tag. Added support for animation sync groups when using initialization for a state machine transition. Added support for explicitly specifying the transitions trigger time when using state machine automatic transition rules. Added a context menu option to Animation Blueprints to create an Animation Template from the blueprint that can be used to override animations using Child Blueprints. Improvement: The PlayMontageCallbackProxy can now be derived from, in order to support plugins that want to provide customized versions. Bug Fix: Fixed an issue that could cause a crash when using the Inertialization AnimGraph node when re-parenting the Animation Blueprint. Fixed standard blending not working as expected with sync groups. Improved stuck detection in Distance Matching Disabled option to duplicate a state from the animation blueprint editor's tree view. Movie Render Queue New: Fixed issue where default settings would get added to a job that already exists when clicking on the Render Movie button from Sequencer. Exposed UMoviePipelineImageSequenceOutput_EXR so C++ plugins can reference it. When using the Render all Cameras feature, Spawnable cameras are now skipped if their default spawn track value is false. Added support for camera rotation to be preserved during a Panoramic Render. Updated the Console Variables setting to display the cvars contained within each cvar preset. Improvement: Added a workaround for the UI Renderer setting having issues with some Layout Widgets not liking the 720p PIE preview window. Optimization: Optimized the multi-sample accumulator for RGBA images on machines with many cores. Bug Fix: Fixed issue where canceling a job reporting as a successful job for some callbacks. Fixed issue where UWorldSettings::Min/MaxUndilatedFrameTime were being modified and not restored after a render. Fixed UI warning about losing unsaved changes to Queues when there weren't actually any changes. Fixed issue where {camera_name} resolved into main_camera when not using the Render All Cameras feature is animating onto this. Fixed data type issue when exporting ProRes with OpenColorIO enabled. Rigging API Change: Creation of buffers is all done within the data interface at runtime. New: Added output bone transfer list for anim node. You can now limit the bones being driven by a Control Rig AnimNode in the Animation Blueprint Graph. Added half edge connectivity data interface. Added unit node to check if a shape is available in the shape libraries. Added support for uint32 types. Added Int32 to Name node (IntToName) Added feature to update the Reference pose of a bone directly in the Control Rig Editor. Added LocalChainDynamics function which creates simple chain dynamics for the given chain. New skin weight editing tool enabled editing weights by painting or directly on selected vertices. IK Rig/Retarget assets can now be created directly from Skeletal Meshes in the right-click menu. Performance improvement to retrieve a template from its arguments. IK Retargeter toolbar redesigned for instant access to common retarget settings. Improved physics constraint editing in the Physics Asset Editor viewport. Extracted all instance data from Control Rig virtual machine and moved it to the context data struct, as a step for stateless virtual machine. FBIK solver now supports animated translation at runtime. Squashing and stretching limbs can use FBIK. RigVM context now has to be passed as a parameter to the virtual machine functions, rather than being located in the virtual machine itself (a step towards stateless virtual machine). Improvement: Skin weights on skeletal meshes can now be edited through a new API in BP or Python. Bug Fix: Fixed issue when adding curves to the output skeleton from USkeletalMergingLibrary::MergeSkeletons. Fixed Control Rig Blueprint compilation error related to missing function definition after a Control Rig Blueprint containing function references is duplicated or renamed. Fixed issue caused by Control Rig Editor Details panel when exiting PIE while debugging a Control Rig instance. Fixed an issue where sometimes the constraint viewport widget would be drawn relative to the wrong body. Fixed an issue where pressing the keyboard modifier for editing the constraint's child frame (Alt + Shift) also activated the keyboard modifier for the Lock camera to widget feature (Shift) which caused the translation widget to move erratically when editing the child frame. Fix for Control Rig Editor issue when adding comments and using undo / redo. Fixed Control Rig compiler issue occurring when a specific function parameter usage is found on a rig, due to invalid remapping of inline function parameters. Fixed an issue in the RigVM compiler when a rig function has more than 255 operands. Fix IK Retarget automatic chain mapping mode \\"exact all\\"; now it does not reset non-exact matches to none. FBIK solver will now dynamically reinitialize if the number of input bones changes dynamically at runtime. Cleaned up Control Rig Python files to remove mixed tab/space error in runtime. RigVMController: Added an array upgrade to reroute nodes with no source or target links where the value is an array, so it can load some deprecated rigs. FBIK solver now works correctly with only one effector (regression from 5.2). Fix for issue when adding a pin on Sequence Node in Control Rig graph. Fixed memory leak in FBIK solver (regression from 5.2). Spherical Pose Reader node in Control Rig fixed so it no longer flips when the activation region fills the whole sphere. RigVM plugin now has a custom serialization object version. Fix for Control Rig Gizmos not working properly; after a changing the asset references to Soft Object Pointers. Deprecated: Deprecated all Execution data interfaces. To set the execution domain of a custom compute kernel, use the Execution Domain field in the details panels of the kernel node. Valid domains should appear in the dropdown menu after connecting either a data interface to the kernel's primary group or a component binding node directly to the primary group pin. Runtime API Change: Extended the ImmediatePhysics_Chaos API so that you can now create Immediate Physics Constraints without copying values from Constraint Instances using a new CreateJoint function that accepts a JointSettings object instead of a FConstraintInstance. New: Added a new dedicated track for Inertializations to the Rewind Debugger. You can now click on Animation node tracks in the Rewind Debugger and the node will be highlighted in the corresponding Animation Blueprint to improve debugging workflows. Added missing tooltips for animation state machine schemas. Animation Blueprint runtime errors are now logged in the PIE log, if they were found during a game session. Anim blueprint logging can now use tokenized messages to hyperlink an error to the node it came from. UAnimInstance::IsSlotActive() is now thread safe. Player nodes in blendspace graphs are now added to GraphAssetPlayerInformation. Reinstated some anim blueprint library methods which now use the Anim Pose API. New colors to distinguish state aliases and conduits. Some LOD bone generation functions from the SkeletalMeshComponent have been extracted so they can be used from plugins. Updated the ComputeRequiredBones function to use the extracted functions. Added a delegate to the SkeletalMeshComponent, so external systems can be notified when the RequiredBones get recalculated for a LOD. Moved the SkeletionRemapping.h and SkeletonRemappingRegistry from private to public, to allow including these files in plugins AnimBoneCompressionCodec now has a new DecompressPose function taking a FAnimBoneDecompressionData parameter, with the decompression data in the following separate array formats: translations, rotations, scales3D. Added the ability to DoubleClick AnimSegmentsPanel, in order to jump to the target asset. You can also shift + DoubleClick to open it a in new window. Added a new compiler note and visual warnings to state machine transitions if the transition rule has logic but the flag for automatic rule based condition is set Improvement: Added a new helper function to find all external saveable packages. Added current time accessors and library functions to Anim Notify events to allow for easy access to relative times and ratios. Sync markers can now be managed in the same way as notifies. Neural network mask curves are forwarded to RigLogic from both the Animation Blueprint node and Control Rig implementations. Crash Fix: Fixed an issue that could cause a crash when reloading a Control Rig Animation Blueprint. Fixed an issue that could cause a crash when undoing or redoing an Animation Sequence edit while an async task is in flight. Fixed an issue that could cause a reinstancing crash when using a custom Anim Instance proxy as a linked AnimGraph. Fixed an issue that could cause a crash when calling UAnimInstance::GetAllCurveNames from worker threads. Fixed an issue that could cause a crash when compiling an Animation Blueprint during automated tests. Fixed an issue that could cause a crash when right-clicking a modified curve node in a template Animation Blueprint. Fixed an issue that could cause a crash when unloading animation assets in a game feature plugin that are referenced by editor thumbnails. Fixed an issue that could cause a speculative crash during automated tests. Bug Fix: Fixed an issue that could cause a regression with curve inertial blending due to the curve refactor. Fixed an issue that could cause the start position to be ignored when using sync groups. Fixed an issue that could cause an ASan issue when unregistering property type customizations on shutdown. Fixed an issue that could prevent the creation of a child Animation Blueprint in the Content Browser. Fixed an issue that could cause a crash when opening a template Animation Blueprint with the Curves tab open. Fixed an issue that could cause meshes to be distorted when the Leader Pose nod. Fixed an issue that could cause blending to incorrectly skip blending in and out when using inertial blending curve filtering. Fixed an issue that could cause Anim Node Functions to not be called in versioned builds when multiple are bound to the same Animation Blueprint node. Fixed an issue that could cause cached poses to be invalid on subsequent evaluations of an AnimGraph. Fixed an issue that could cause stack corruption caused by calling an Anim Node Function with an altered signature. Fixed an issue that could cause out-of-bounds access in Control Rig curve I/O. Fixed an issue that could cause distorted meshes when assigning assets using skeleton compatibility. Fixed an issue that could cause curves to be missed intermittently in cooked content. Fixed an issue that could cause bone LOD filtering to display incorrect results during automated tests. Fixed an issue that could cause the Layered Blend per bone node to not work correctly with per-bone curve filtering. Fixed an issue that could cause out-of-bounds access in PoseAssets that have additional poses with their respective curves. Fixed an issue that could cause fired notifies to not be reached when looping by clamping remaining time. Fixed an issue that could cause the virtual bone menus to not appear when adding additional virtual bones. Fixed an issue with the Control Rig Anim Node that could cause the Rigid Body Anim Node in a post process AnimBP to stop working. Fixed an issue that could cause OOM issue on consoles by reducing default alignment requirement of memory allocations in RigLogic. Fixed an issue that could cause performance problems when multiple faces (DNAs) are loaded during gameplay. Fixed issue when attempting to collect sync markers in a montage with an invalid slot track index. Fixed bCanUseMarkerSync to default to true even when the animation asset did not have any sync markers. Fixed bCanUseMarkerSync being true for followers when all valid markers were filtered out. Fixed issue when linking/unlinking anim layers from UGameplayAbility::EndAbility. Animation editor now correctly applies preview mesh from a compatible skeleton. Fixed issue when filtering preview mesh on template anim BPs. Fixed Anim BP asset definition correctly displays option to create child Anim BP. Fixed issue when adding curves to anim sequences and immediately getting the bone pose. Fixed issue in UBlendSpace::TickFollowerSamples due to hard coded bLooping flag. Fixed NaN crash in FAnimNode_LinkedInputPose::Evaluate_AnyThread. Ensure a clamped normalized time stays within the 0-1 range in the Blend Space Evaluator. Fixed \\"Start\\" animation notify event for state machine transitions not being fired when bSkipFirstUpdateTransitions flag is set to false. Fixed an issue that could cause a reinstancing crash in linked anim layers or graphs. Fixed an issue that could cause use-after free when duplicating animation attributes. Fixed an issue that could cause a crash when deleting a sync marker at the SyncMarkers Window, when finding an AnimMontage during the process. Fixed a but that would only look at player controllers, and not something like AI controllers, when considering viewpoints for auto significance calculation. Fixed an issue that could cause the GetLinkedAnimLayerInstanceByGroup tp not work for non-implemented layers with no instance assigned. Fixed an issue that could cause the Details panel to disappear when making curve metadata edits. Fixed an issue that could cause the preview instance from not being re-selecteable after selecting an external anim instance to debug. Added some missing definitions for the UAnimInstance's function GetRelevantAssetPlayerInterfaceFromState. Fixed an issue that could cause a crash in FMirrorSyncScope. Fixed an issue that could cause blendspace sample entries from expanding when a sample animation is changed. Fixed an issue that could cause a crash on loading an anim BP with pose hander nodes that require skeleton updates to their animations. Added a missing ENGINE_API tag to SkeletetonRemappingRegistry, as it is required to use it from outside of the engine Fixed an issue that could cause a crash when using an incorrect bone index type usage in UAnimationSequencerDataModel::GeneratePoseData. Fixed an issue that could occur by ensure when transforming bone indices during animation compression. Fixed an issue that could cause an issue with the SkeletalMeshComponent ComponentIsTouchingSelectionFrustum, as it was returning false positives due to missing check. Fixed an issue that could cause issues with the FBX Import due to a name restriction not allowing bone names to start with a number at RigVM hierarchies. Fixed an issue that could prevent the Animation Sequencer from triggering notifies repeatedly when using an animation mode track set to Use Anim Blueprint in a Level Sequence, by adding a parameter to the SkeletalMeshComponent SetAnimationMode function that allows not re-initializing the AnimationScriptInstance. Fixed an issue that could cause a crash when using the PoseableMeshComponent, when the component is being incrementally unregistered and the unregistering process takes longer than the time limit set in the component. Fixed an issue that could cause a crash when using one of the Animation editors when closing one viewport while additional viewports are open. Fixed an issue that could prevent the BlueprintEditor from being refreshed after adding an animation layer node into an animation graph. Fixed an issue that could cause an issue during an AnimComposite animation notify extraction when playing in reverse order. Deprecated: Added a deprecation warning for AnimNode_StateResult.h located in AnimGraphRuntime module since the file got moved to Engine/Animation. Removed the deprecated mirroring functionality from SkeletalMesh. Sequencer New: Added the ability to create Takes for Subsequences. You can now add comments for shots and Sequencer sections. Added support for tags when bindings are copied and pasted in Sequencer. Added the option to select the material parameter collection asset from the track in Sequencer. Reassigned the LevelSequenceEditorSettings.h to public. Added command bindings for composition overlays to the Cinematic Viewport. Exposed the ability to access setters and getters for audio section looping, suppress subtitles, and attenuation functions. The Sequencer's Key editor now edits selected keys if they are selected. Otherwise, it edits at the current time as usual. Bound recording commands in the Take Recorder now play in world space so that they work in Editor and in PIE. The Clock Source menu is now always visible even in SubSequences, but is only editable when the Sequence Editor is focused on the root sequence. Several improvements have been made to the Sequencer's Import EDL: Added the support of KEY CLIP NAME Sequencer now parses the timecodes from the end of the line. If the EDL contains a shot multiple times, subsequent shots will be created in Sequencer when importing, corresponding to the EDL shots. You can now change the Sequencer folder color of multiple folders by multi-selecting. Sequencer Track filters are now saved in preferences. Added a new transaction for toggling Show Marked Frames Globally. Added support for a start offset to camera animations. Upgrade audio track to use the new ECS evaluation. Moved level-sequencer-specific editor code to the LevelSequenceEditor plugin. Moved sequencer customizations to the editor view-model. Add the following improved edge interaction for sections: You can now use draw easing handles as rounded triangles sized to match the grip size, instead of the previous bitmap. Easing handles are bigger, with bigger hit-testing area to make selection easier. Exposed key size through the section interface in addition to grip size. Added support for blend types and multiple rows for material parameter tracks (widget and MPC). Exposed camera animation parameter to detail views. String properties and String tracks now use the new ECS evaluation. Add ability to lock marked frames on the time slider. Register/unregister the camera animation stand-in object from its own module. Added new user-defined bindings to Sequencer. This change adds the ability to define custom logic, using the directory blueprint, for object bindings. Instead of binding to the usual possessable or spawnable, this will optionally run arbitrary BP logic defined by the user to resolve the bound object. This makes it possible, for instance, to bind to the player pawn, or any other actor that might not exist at edit time. The UI is similar to that of the event track, and therefore reuses the director blueprint endpoint picker. There is however a new blueprint extension to compile these functions into the spawnables and possessables, and of course a spot to call these functions when appropriate. Added a new key that you can use to allow the player to be closed. You can now expand skeletal animation sections back to the left. Added new feature: Smart Auto Key. Smart Baking for Constraint Baking, Space Baking, Snapper, Control Rig collapsing and Baking Transforms. Swap Root Bone on Track. Animation Mode: Disable selection when clicking on an axis, avoids losing selection when manipulating. Curve Editor: Make normalized mode scrollable and panable. This makes sure that if you frame to the normalized mode now it doesn't use the max/min values but defaults. Control Rig: Shift now moves camera to stay with Control Rig when moving. Curve Editor: Keep Output bounds the same even if curves are destroyed so you can select/deselect and keep their curve bounds. Take Recorder now supports up to eight audio input sources for multi-track audio recording. Added time scrubbing to Sequencer and Curve Editor to match Viewport behavior. Added native accessors for common float/color light properties to improve performance when setting properties following sequencer evaluation. Curve Editor: Added option to show constraint/space bars. Linked Anim Sequences are now editor only. Improvement: Take Recorder Timecode setting names now default to the same as Anim Sequence so that aligning works. Removed the Sequencer's Add (+) button text rollover visibility. Now the text is a tooltip so that there's no overlap with key editor buttons. Added the Sequencer's Browse to Actor property back to the actor's right-click context menu. Control Rig Controls filter is no longer enabled by default in Sequencer. You can optionally enable it, and your preference will be saved between sessions. Trim and Preserve now calculate the correct transform when the attached component isn't the root component. Crash Fix: Fixed an issue that could cause a crash when sorting sections on load. Bug Fix: Fixed an issue that could prevented the ability to toggle on or off tags inside of shots and subsequences. Fixed an issue that could cause new keys to be added when attempting to update an existing key. Fixed an issue that could cause the group manager to not refresh when performing an undo or redo command. Fixed an issue that could prevent the group manager selection to not function properly with folder paths. Fixed an issue with path track evaluations that could cause component velocity to not be set properly when an object is moved by the path track. Fixed an issue that could cause regenerating waveforms during playback to not function correctly by adding a slight delay to eliminate hitches. Fixed an issue that could cause duplicate entries in the property menu. Fixed an issue that could cause Show Marked Frames Globally to not be marked as a UPROPERTY so that it gets serialized. Take Recorder: Fixed range for camera cut section so that it works for subsequences when recording cameras. Remove unnecessary creation of camera cut track and section because they're already created when a camera is added. Fixed an issue that could cause animation sequence to be marked dirty, due to the spawnable being modified, if the sequence is evaluating. Fixed mute/solo nodes when hierarchy changes by tracking old and new nodes paths. Fixed issue when the widget is replaced and no longer valid. Fixed issue where duplicating keys is not undoable and doesn't update the UI properly. Fixed an issue by keying the material parameter collection instance's current value if it exists, rather than always just the default value. Fixed an issue by compensating for transform origin when adding an object's transform to Sequencer. Fixed track row names when row indices have been remapped or a new row has been added. Fixed an issue that could occur when pasting a possessable, by only parenting it to the pasted target if the possessable's class is not an actor, such as a component. This fixes an issue where an actor could be pasted into another actor. Fixed an issue by ensuring the CineCamera actor's name is unique when creating as possessable. Normally this is done in the actor factory but here we spawn the actor directly. Check for valid animation on skeletal animation FBX export. Fixed issue where calling scripting functions (AddKeyInChannel, RemoveKeyFromChannel, SetDefaultInChannel, ReoveDefaultFromChannel, SetTimeInChannel, SetValueInChannel) is not undoable and doesn't update the UI properly. Fixed an issue by initializing layers for spawned actors. This fixes issues where if you add a spawnable to a layer, hide the layer, and then reopen the sequence in a new level, the spawnable won't be visible and won't respond to layers in the new level. Fixed an issue that could prevent Snap Sections in the Timeline by using the Source Timecode so that it takes tick resolution into account Fixed an issue by preventing all camera actors from being selected in the camera cuts menu even if it is hidden. Fixed an issue that could cause small sections to result in negative time-to-pixel conversion. Fixed an issue by carrying over the previous view target from a previously playing level sequence, if any, so that the last sequence played restores the actual original view target, and not the previous sequence's camera. This fixes issues with stuck cameras when some sequences are played on top of each other. Fixed an issue that could cause a crash when using the context menu in the Camera Cuts track to try and select an unspawned spawnable. Fixed an issue by preventing global custom accessors from being unregistered on shutdown. Fixed an issue that could cause recycling of view-models when track layouts are rebuilt. This fixes some UI issues with keys and sections being moved between track rows. Fixed an issue that could cause a crash when shakes are previewed in Sequencer or in the Camera Shake Previewer tool. Fixed an issue that prevented initial material parameter values to be cached correctly. Fixed an issue that could cause a crash when recompiling a user widget while Sequencer is open. Fixed an issue that could cause the Snap to Interval tool to not function when Snap to Keys and Sections was not selected. Fixed an issue by restoring aspect ratio axis constraint directly on the player if the level has changed during sequence playback. Fixed an issue by correctly restoring the Sequencer editor playback speed on stop and pause operations. Fixed an issue that could cause the key editor widget to not be cleaned up correctly when a track goes from 1 to 2 or more rows. Fixed an issue that could cause a crash when dragging an item from the Place Actor menu over a sub-scene section. Fixed a UI issue where the preview for the section length shown was only as long as the first sub-sequence asset, not the longest asset in your drag or drop selection. Fixed an issue that could cause Sequencer runners to detach and attach to linkers in interwoven ways. Fixed an issue that could cause the Additive From Base blend type to be missing an icon in the UE5 style. Fixed an issue by taking play-rate into account for blend times between blending camera cuts. Fixed an issue that could cause a Control Rig Component to be constantly reinitialized when used in Sequencer. Fixed an issue that could cause incorrect blending out of sequencer camera shake patterns. Fixed an issue by not calling the NotifyMovieSceneDataChanged() function when pasting tracks. This fixes an issue with Niagara not setting up its data correctly after pasting a track. Fixed an issue that could cause interactions to be incorrectly handled between the normal track area and the pinned track area. Fixed an NVVM refresh issue that could cause view-models who already have a recycle list would not recycle their children. This meant that a re-used track-row view-model would not get its children cleared out before it is rebuilt with new underlying data. Fixed an issue with the Channel Curve Models in Sequencer Curve Editor that could cause the tracking interpolation type of neighboring keys to not operate properly when a new key was added. Fixed an issue that could cause the MovieSceneSequenceExtensions::GetBindingId to not be properly exposed to python scripting. Fixed an issue that could cause ease-in curves to not show properly when a section starts at time 0 that also does not have an ease-out. Fixed an issue by not caching pre-animated state on entities that are being torn down. Fixed an issue that could cause BOOL and INT curves to not be drawn past left or right-most key value in Curve Editor. Fixed an issue that could cause a null check in Movie Scene playback. Fixed an issue that could cause autosizing of subsections, audio sections, and skeletal animation sections, to not function properly, as they were all missing taking into account start or end offsets. Fixed an issue that could cause a spawnable binding to be overridden during the sequencer, the spawned actor will get left behind, creating duplicate characters. Now, when a binding is invalidated, and we detect an overridden binding, Sequencer checks if a spawnable is registered, and if so, destroys that spawnable. Fixed an issue by setting a zero value on an additive Control Rig section, so it doesn't always add and uses default interpolation. Fixed an issue by adding the sequencer ability to change the SkeletalMesh asset from a Skeletal Mesh Component in cooked builds. Snapper: Use default key type when setting keys. When changing time via translate hotkeys get all changes first, then apply them to avoid double transforms with space/constraint keys. Control Rig: When looking for a binding that constrains a Control Rig, it takes into account the Control Rig so it picks the correct Actor or its component. For certain setups the face and body rig both bind to the same component on the Control Rig, but bind differently on the Sequencer side. Fix for missing or incorrect timecode values being stored in audio assets when recording with Take Recorder. Constraints baking: changed the tangent type to the default for the keys at compensation to avoid inserting keys that may have flat tangents. Control Rig: Fix keying weighted additive sections. Fix copying actors in Sequencer that live in sublevels, you can end up selecting the wrong Actor. Only sync curve selection when updating the tree if we have no curves, otherwise this will blow away what the animator is working on. Fixed silent failure case in Sequencer when scrubbing audio at low frame rates. Fixed an issue that occurred when applying an FFT filter with insufficient number of keyframes selected in Curve Editor. Calling PasteBindings() from Blueprints or Python correctly returns the newly created bindings. Linked Anim Sequences work with nested sequences. Curve Editor: Don't show the space or constraint key bar spaces unless there is a space. Snapper: Do not include controls without shapes when snapping to avoid issues. Animation Mode: Restore Gizmo Scale when leaving/entering Animation Mode. Linked Anim Sequence: Only dirty if the data is changed, not if refreshing or changing sequences. Control Rig: Make sure it is on game thread when handling initialize events, fix possible issues with procedural rigs. Fixed Sequencer player playback replication synchronization to only happen once per tick. Deprecated: Deprecated the GetBoundObjects as it is incompatible with Spawnables. It is recommended to use ULevelSequenceEditorBlueprintLibrary::GetBoundObjects because it operates on the currently opened sequence in Editor and can return valid spawnable objects. Remove Matinee's PostInterpChange, as it is not often used or compatible with projects. Synthesis New: Added progress bars when creating and compressing Morph Targets. Added support for using Physics Blend Weight alongside Physics Control Component. Added a new UpdateKinematicFromSimulation flag to BodyInstances. This allows kinematics to be treated the same as dynamic objects when simulating with async physics. The flag defaults to false, so there is no change in the default behavior, unless using the Physics Control Component, which sets the flag by default. You can now get the current or target transforms with Physics Control Component. You can now set the Physics Control Component to use manual updates. The Physics Control Component damping ratio in the PhysicsControlMultiplier struct has now been exposed. You can now bulk edit Physics Control Component settings, such as the target positions and orientations. You can now reset the physics transforms to the cached targets when using a Physics Control Component. Added the ability to use profiling mark up when using a Physics Control Component. Removed the NNI from ML Deformer VertexDeltaModel and NearestNeighborModel. Fixed an issue that could cause a crash when initializing the ML Deformer on Linux operating systems. Improvement: Improved ML Deformer reconstruction quality: The ML Deformer reconstruction method now uses a smoothed L1 loss function, adding a new beta Smoothing Loss property to the training settings. The reconstruction method also now uses cosine annealing learning rate scheduler, which removes the Learning Rate Decay setting. The ML Deformer now displays a warning when using the Vertex Delta Model, that it should not be used in production. The ML Deformer now uses extra Get functions to get private members. Verbose logging has been added where non-verbose logging wasn't needed. Added additional null safety checks to the ML Deformer. The ML Deformer now prevents sampler reinit when not needed. ML Deformer models can now specify the number of floats per bone. The ML Deformer now detects changes in vertex count, and shows a warning in the morph target section, when dynamic Morph Target updates aren't possible until after retraining. Improvement the cleanup of the external Morph Targets, which also clears out the weight data. Improved the component reinits by reducing the number of units. Improved the rendering of bones inside the ML Deformer asset editor. The Initialise Physics Control Component control strengths are now set to 0 by default, instead of 1. Crash Fix: Fixed an issue that could cause a crash by preventing the ML Deformer from updating dynamic Morph Targets when it is not possible Fixed an issue that could cause a crash when the local bone transforms on the skeletal mesh component were empty. Fixed an issue that could cause a crash when creating a new actor blueprint, adding the blueprint to a skeletal mesh and ml deformer component, then setting a neural morph model as ML Deformer asset, and selecting the vertex delta model mesh deformer in the skeletal mesh component. Bug Fix: Fixed an issue that could cause the ML Deformer asset to behave incorrectly. This could likely happen when aborting during training, or changing assets after training, and saving. Now, the editor correctly sets section indices inside the Morph Targets, rather than just including all sections and sorts the Morph Target deltas by vertex number. Fixed an issue that could cause unexpected behavior when using curves in the Local Model. Fixed an issue that could cause the ML Deformer editor to enter a state where the timeline does not function properly after changing the input of an asset, such as a property on a skeletal mesh. Fixed an issue that could cause compatibility checks to fail after training. Fixed an issue that could cause a check to fail in debug mode. Fixed an issue by setting the Physics Blend Weight property to 1 by default when using a Physics Control Component to simulate physics. This ensures that using a mixture of kinematic and dynamic bodies works with skeletal meshes. Fixed an issue that could occur where the ML Deformer time sampling was incorrect. Fixed an issue that could occur when render graph errors in ML Deformer Vertex Delta Model. Fixed some issues that could occur with ML Deformer Vertex Delta Model inferences. Fixed an issue that could occur with the VertexDeltaModel which caused animation to appear frozen. Fixed an issue that could cause a module in ML Deformer to be missing. Fixed an issue that could cause an incorrect mismatched vertex error in MLDeformer. Removed: Removed a substring redirect from the ML Deformer, which wasn't needed anymore and triggered a warning in the log. Editor API Change: There is no support for OpenGL on Linux, so the imaging and usdImaging USD libraries that depend on OpenGL are excluded on that platform. New: Added editor performance setting to control r.VSyncEditor. Added support for overriding enum value display names on a per-property basis. This can be specified by the Enum Value Display Name Overrides meta-data, and is a semi-colon separated list of Name=DisplayName pairs where the Display Name can be a raw string or a NS/LOCTEXT style localized value. Added Source Code Access plugin for the 10X editor. Added a Copy References and Copy Paths button to the editor asset menu. Disabled real-time viewports when the editor process is in the background and bThrottleCPUWhenNotForeground. Optimized advanced copy by running its consolidate step less frequently. Added new option for PNG import to fill RGB into transparent neighbors always, even on complex alpha channels. Previously was only doing RGB fill on simple binary transparency. This is configurable in Texture Import Settings. Added a Fixup Group Actors function. Added support for Windows ARM64, Linux, and Mac. Changed floating point textures to default to BC6H compressed texture format on import, rather than RGBA16F. Existing textures are not changed. The format chosen by default can be set in the Texture Import Settings config; for VFX users may set it to default to 32 bit texture formats. Added support for automatically wiring inputs when creating a node from a specific output. Enabled easy command line override of shared linear encoding ( -ForceSharedLinearTextureEncoding=True/False ). Fixed 32-bit size limits and bugs that prevented use of very large images (such as file sizes over 2 GB). Unreal should now be able to import very large images, only limited by memory use and the target platform or VT size limits, which is currently 16k x 16k for non-VT and 4 GB built size for VT. Added button to Media Plate to browse to the material asset. Updated the Fracture editor with a display of imported collision shapes in the convex tool if they are available and enabled. The display supports convex, box, sphere and capsule imported shapes. Sound Cue Nodes now obey Class Viewer Filters. Updated the Plastic SCM plugin to version 1.8.0. Modified advanced color space transformations and source encoding overrides on textures to utilize the OpenColorIO library. Added basic SCC support to Content Browser file data sources. This is enough to support the basic operations (on add, delete, move, rename), as well as the revision control file menu (to allow sync, revert, check-in, history, and diffing). Added a context menu entry to perform asset validation on specific actors. Upgraded OpenEXR version to 3.1.6. Included the imaging and usdImaging libraries in the engine's build of USD. Exposed SetIgnoreBoundsForEditorFocus as Blueprint callable and added GetIgnoreBoundsForEditorFocus. Exposed single click action within SGraphPanel to allow hooking custom logic. Adding a new Cook Metadata file that gets generated adjacent to the development asset registry. This will be the home for metadata about the cook that is unrelated to assets moving forward. Currently this contains dependency information regarding the enabled plugins at cook time, as well as plugin size information that gets written to the cook metadata file during staging, if enabled. Upgraded USD version to v23.02. Properties Menus drawn from the Sequencer now obey the Property Editor Permissions List. Updated icons for Check-in Changes and Sync Latest status bar buttons. Added ability to revert conflicted files in the Submit Files window. Added the -AssetRegistryCacheRootFolder= commandline option to allow you to choose where to write the asset registry cache files. Added number of convex to the statistics widget in the Fracture editor. Made the histogram Set Inspected Attribute method in the Fracture editor to be more resilient to ill formed geometry collections. Triggered an autosave if there are any unsaved changes when a user clicks check-in changes. Updated the debug focus plane bounds to not be taken into account anymore when focusing on a cine camera in the editor, making the viewport focus on the actual camera itself. Improved editor startup performance related to populating FAutocastFunctionMap entries. Improved editor asset scan performance. Updated the Variant manager properties list to include static mesh and overlay material properties. Updated SyncBrowserToObjects use const arrays and add SyncBrowserToObject. Added Blueprint Display Name to Blueprint Generated Class editor tags to permit aliased class names in cooked editor. Added a tooltip to the toggle visibility button in the scene outliner and the Pin button in the scene outliner. Renamed Mobile Preview ES3.1 (PIE) to Standalone Game Mobile. Renamed Vulkan Mobile Preview (PIE) to Standalone Game Vulkan Mobile. Renamed Mobile Preview (PIE) to Standalone Game Target Device Mobile. Renamed Preview Rendering Level to Preview Platform. Rename DebugText in EditorViewport from Feature level: to Preview Platform:. Added a callback to get notified when the UObject garbage collection finishes purging objects. Loaded components ( including the one in blueprints ) are now properly updated when using Dataflow to generate a Geometry Collection asset. Added parameter to enforce the cluster number when using the connectivity data in the Fracture editor. Prevented non-server standalone instances from using Server Map Name Override. Added the ability for objects to have alternate selection outline colors picked from a palette. Added support for statically and dynamically registering documentation redirects to allow licensees to override engine level documentation links without duplication / adding boilerplate menu overrides. Documentation redirects can be registered statically through INI editor config files or dynamically in code through the IDocumentation interface. Improvement: Updated the asset registry exporter to output to CSV to facilitate import into common database frontends. Additionally, support outputting dependency information based on a set of primary asset type roots for help in analyzing the source of build size. Updated the function \`UContentBrowserAssetDataSource::CreateAssetFilter\`to improve performance. For a large project with a lot of paths using a recursive search on all the folders, the change reduced the time it took to create the filter by about 86%. Improved the backend filter compilations of the asset views by adding a system to cache some part of the filter compilation. Improved connectivity tool visualization in the Fracture editor: Centers are now displayed. Added controls for line thickness, point size, and colors. Bug Fix: Fixed a crash accessing null pointer on shutdown of editor. Corrected Clear Thumbnail not working if asset is not already loaded into memory. Fixed it so Additional Server Game Options in the Play in Editor options applies to externally launched dedicated servers as well as listen servers. Corrected the clear on pie checkbox to work by putting in the correct path. Fixed editor ensure startup when stats is not defined. Fixed crash on exit in stall detector thread when editor closed by call to RequestEngineExit(). Updated Ability System Component function to check the Spec's ability pointer before use. Fixed crash on shutdown if a web browser window was open. Fixed nested virtual roots (from aliases) failing to resolve correctly in the Content Browser. Fixed regressions when undoing a deleted one-file-per-actor post-save. Fixed the details panel failing to restore expansion state when running deferred actions. Fixed an issue with the content browser not always showing the path filters. The SLATE_ARGUMENT to determine if it should be shown was not initialized. Fixed a crash bug with Advanced Copy, where two asset dependencies with the same name would flatten down to overwrite each other. Fixed crash when creating a parameter from a datatable asset or any asset. Fixed a couple of issues where packages were aggressively dirtied: Call cancel on the transaction if it is actually a camera movement input. Reset package dirty state when a widget drag is canceled (for example with escape key). Made FBoxes IsValid flags editable, otherwise editor-modified boxes will compare equal to the CDO and so not be saved. Usee FLinearColor for screen fades so that extreme values behave consistently between the editor and the runtime. Fixed Variant Manager opening an extra empty window. Fixed Unreal Editor's crash when using Unreal Remote. Fixed a crash where a Thumbnail Pool could be deleted while it is ticking because the asset view that owned it was destroyed while generating a thumbnail. Fixed a crash on editor shutdown where the transactors for ISM typed element handles were cleaned up too aggressively. Reworked component visualizer visibility to key off draw debug variable. When this is disabled, the component visualizer will still draw if the component is directly selected, and will allow editing this way. Supports helper splines for PCG workflows that are intended to be hidden by default to the user. Fixed a memory leak caused by a circular dependency from the delete asset window. This also fixed a general performance degradation of the editor when deleting assets because of the leaking assets pickers widget. Fixed an issue where the gizmo would rotate on an axis from keybinds, even if the user had selected a valid axis on the gizmo. Fixed a crash when prtining typed element debug ID. Speculative fix for seen once crashes in typed element debug ID printing. Fixed duplicates being wrongly reported when adding elements to map or set properties in the editor, where the key type is a UClass* key and the class name is a subset of a name which already exists as a key. Fixed an issue where the hovered/active gizmo hit proxy is incorrect when mouse tracking restarts This was causing the indirect manipulation axis to persist as new buttons were pressed, which would result in the wrong axis getting manipulated. Updated the level editor place actors menu to respect Class DisplayName overrides. Fixed an issue where an invalid FName could cause category path look up to assert. Fixed the Convert to Static Mesh actor's tool to now handle Instanced Static Mesh Components (and HISM components) properly. Fixed the inability to revert level file deletion in Check-in Window. Fixed an issue that prevented the use of the property matrix on textures. In the Subversion settings, only the path of the Executable Location setting will be used and any executable name after the path will be ignored. Fixed a bug where the asset registry cache would not be written in certain situations related to synchronous scanning. Implemented auto-save on check-in. Fixed issue that prevented deleted objects from being restored on Revert All. Fixed issue that caused not saving deleted files during Delete workflow to result in errors after sync. Fixed issue that caused added and saved files to disappear after Sync Latest. Fixed a bug where the class redirector of a renamed Blueprint asset would not be applied until the asset was loaded, causing the new class type to be missing from UI selection. Modified CleanupAfterSuccessfulDelete() to check if deleting a package is supported by source control first, and only if that is not the case, mark it for local deletion. This fixes an issue where deleting a file checked out by someone else (when working offline) and choosing only to save locally resulted in the file not being deleted on the local file system. The packages Core Redirect are no longer case sensitive (regression introduced in a previous version). Since package names are stored in case insensitive FNames, the redirectors should be case insensitive as well. Fixed a memory corruption issue related to UK2Node_EvaluateProxy. Fixed an issue where when moving multiple directories at the same time in the content browser, the asset references weren't always being updated correctly, leaving some assets pointing to invalid asset paths. Fixed a crash that could occur during the static mesh build step. Fixed an issue where the asset registry state of an cooked plugin would remove some of the needed development tags from an asset that already exist in the Editor Client Asset Registry. Fixed a crash for the Cloth editor that occurred during shutdown due to SharedPtr cycle. Updated Approximate Actors method of Merge Actors to properly detect and return an error if the occlusion method removes all triangles in the approximation mesh. Deprecated: Deleted DDS Loader and HDR Loader functions which were previously deprecated. Content Pipeline New: Fixed many image importers to gracefully handle malformed files instead of crashing. OBJ translator distinguishes multiple polygon groups with different materials within a group. Virtual textures no longer allow the NoMips MipGenSetting, as VTs require mips in all cases. LeaveExistingMips is only allowed if the entire mip chain is provided. This generates a texture build warning, and the texture is forced to generate mips. PSD loader support has been made more robust, and support for RLE compressed 16 bit PSDs has been added. Optimized I/O usage when utilizing the reference chunk database for packaging. When CADKernel mesher is the default mesher, if a failure occurs, the process of the file is relaunched with TechSoft mesher. A post process of the static mesh during the import has been disabled. It can be reactivated by setting the CVar ds.CADTranslator.SewMeshIfNeeded = true Added CVar ds.CADTranslator.EnableUnsupportedCADFormats to enable all unsupported CAD formats. Improved quality of OBJ format material translator. Most of the basic and extended sets of parameters(and corresponding maps) are now supported. Illumination modes are extrapolated. Added a CVar USD.SkipMeshTangentComputation to skip computation of tangents for static meshes. This can help import performance when the tangents are not needed. USD: Baked mesh deformations can now be imported as GeometryCache assets. Files with geometry caches loaded on the stage will now have associated tracks in the USD level sequence. GeometryCache track section parameters in level sequence are now exposed to Blueprint. AUsdStageActor can now be derived in C++ from other plugins than USDImporter. Alembic: Face set names, when available, are now used as material slot names on geometry cache (and static and skeletal mesh) and can be used with SetMaterialByName in Blueprint. Added support for extracting RootUV values from the Alembic UVsParam instead of the groom_root_uv attribute. Bug Fix: The import of assets via the asset tools now validates that the destination path is mounted and avoids crashing if this is not the case. Fixed issue caused by updating a texture via a render target while it is being built/compiled. Removed redundant data from telemetry of USD/AxF/MDL/Datasmith importers, Dataprep. Fixed issue importing obj/gltf/datasmith/mtlx when a texture is missing. Fixed matrix issue for Autodesk Alias format (.wire). Fixed issue for longlat textures with LeaveExistingMips set. Importing partial mip chains generates output to a full mip chain. Made the paper2D on object reimported safe to use in a cooked editor and made the existing code more robust by not having issues if you are missing the SourceTexture metadata. Made the Blueprint node for the function MigratePackages of the AssetTools non pure. This adds the missing execution pin this node should have. Fixed possible issue when streaming multiple instances of the same GroomCache at the same time. Alembic: Fixed possible computation error when composing hierarchy of transforms. Fixed GeometryCache ignoring \\"Receive Decals\\" setting with Deferred Decal materials. Alembic: Fixed import generating no animation when importing GeometryCache with \\"Flatten Tracks\\" and skipping the import of the first track. Alembic: Fixed frame time computation error at import that could cause timing issue. Datasmith New: Added a USD Stage import option to enable/disable the import of Groom and Groom Binding assets. [USD Importer] Added UnrealUSDWrapper functions for registering USD plugins by path. [USD Importer] Added UE wrapping for UsdPayloads, UsdReferences, and UsdVariantSets from USD API. Added resource size tracking for Geometry Cache assets stored in the USD Asset Cache. Added support for using Interchange's MaterialX translator when opening or importing USD Stages with references to MaterialX files. [USD Importer] Added config setting and API for setting the default search path for USD's default resolver. [USD Importer] Added a file format arguments parameter to find/create/export functions of SdfLayer wrapper. Added support for exporting LevelSequences with animation constraints to USD. Added support for UV transform shader nodes connected to primvar readers, when opening or importing USD Stages. [USD Importer] Added wrapping for token-based API schema functions (CanApplyAPI(), ApplyAPI(), and RemoveAPI()) on UsdPrim from the USD API. Added support for geolocation to Datasmith API. Added new C++ events to the Usd Stage Actor: OnStageLoaded and OnStageUnloaded. Implemented automatic regeneration of UAssets whenever the source USD prims were updated on the opened USD Stage. [USD Importer] Added optional EUsdLoadPolicy parameter to FUsdPrim::Load() to mirror the USD API, allowing the underlying prim to optionally be loaded without loading any of its descendants. Added support for parsing USD Materials that use multiple UV sets (primvars). Improvement: The USD Stage Editor's right panel can now display prim relationships, metadata, and attribute metadata (once an attribute is selected). [USD Importer] Exposed UsdStage::CreateClassPrim() on the UE FUsdStage wrapper. [Solidworks] Components made from identical parts now reuse exported meshes. When opening USD Stages, only materials bound by at least one prim will be parsed by default. [3ds Max Exporter] Shared exported meshes for RailClone or ForestPack entities now use the same mesh. You can now cancel loading the USD Stage by clicking the \\"X\\" on the dialog to pick the default USD Asset Cache for the project. StaticMesh, SkeletalMesh and GeometryCache assets generated from USD Stages will now have the default material instead as a fallback, instead of fully unassigned material slots. You can now create LevelSequence bindings to transient actors and generated components when opening USD Stages, from any LevelSequence. Those bindings will use the new Sequencer Dynamic Bindings feature to automatically repair themselves whenever they are broken due to the stage being closed or reloaded. Importing skin weight profiles is now significantly faster. [Solidworks] Exploded Views now export for each of configurations as additional variants Changed the translucency lighting mode used by the USD preview surface reference materials to \\"Surface ForwardShading\\", to improve behavior in scenes with multiple translucent objects. [Sketchup] Geolocation information is now exported. Expanded the USD Asset Cache to support persisting Materials, Skeletal Meshes and Static Meshes to disk. [Solidworks] Greatly improved AutoSync reaction time to material changes for bigger models. [Solidworks] Model Tab is now toggled after exporting animation. [Solidworks] Added plugin prerequisites to the installer to support installation on clean machines. The USD Stage Editor now shows internal prim references when selecting a prim. When baking materials to USD, diffuseColor will now bake as black as a fallback to retain the same visual appearance as in UE. Crash Fix: [Solidworks] Fixed crashes caused by enabling AutoSync. Fixed a crash that would occur when changing collapsing rules on the USD Stage Editor in some scenarios. [Solidworks] Fixed a bug that could cause an infinite reimport after deleting a component. Fixed a crash that could occur when importing materials from USD which overrode previously imported materials. [Solidworks] Fixed a crash that could occur when re-enabling DirectLink source. Fixed an crash that could occur when trying to open or import USD Stages with skeleton prims that have more than one root bone. Fix crashes related to Skeletal Mesh Components when importing USD Stages over previously imported actors and assets. Fixed a crash that could occur when exiting the engine during the process of saving USD Stage changes. Fixed a crash that occurred when undoing the addition of transform track keys in some scenarios, such as when manipulating the LevelSequence generated by opening an USD Stage. Fixed a crash that occurred when importing USD files via automated tasks (like Python scripts) with no specified import options. [Rhino] Fixed an export crash that occurred when exporting meshes with multiple UV sets. Fixed a crash that occurred when translating USD point instancer prims with unexpected prims inside their prototypes, when opening or importing USD Stages. Bug Fix: [Solidworks] Actor visibility is now set appropriately in the Datasmith scene tree on export if it's suppressed in the selected config. [Solidworks] Unused materials are now handled correctly in exported scenes. Fixed USD Stage import options that weren't being autofilled from the currently opened stage actor when using the Actions → Import option on the USD Stage Editor. HierarchicalInstancedStaticMeshComponents spawned when translating USD Point Instancer prims will no longer be missing their StaticMesh assets, if the source prototypes were being shared via the USD Asset Cache. USD prim kinds will no longer be ignored when deciding if a prim subtree collapses or not. [Solidworks] Exporter will now install as expected if only version 2023 is available. Fixed an issue that would cause missing Static Mesh Components when importing some types of USD Stages generated by exporting Unreal levels with StaticMesh assets with multiple LODS. Fixed visibility handling issues that occurred when traversing Mesh prims in order to generate Geometry Cache assets when opening or importing USD stages. Switching render context (or other similar options) on the USD Stage Editor options will now update the Static Mesh Components on the level with new material assignments as expected. Exporting levels to USD without any levels selected will no longer generate files. AnimSequence assets generated from USD will no longer fail to drive morph target (blend shape) animations. Setting material overrides on spawned components will no longer write to unexpected USD prims if the Static/SkeletalMesh/GeometryCache asset is shared via an USD Asset Cache. [Revit] Fixed duplicated IDs for Level elements. USD Stage Control Rig integration will no longer fail when using Control Rigs that modify their own topology in their construction scripts. Fixed an issue related to material overrides on components that spawned when opening USD Stages with collapsible subtrees. The mesh vertex count and Nanite material collapsing limits are now checked when collapsing large meshes from USD. Direct link now works when offline. The USD Stage Editor will no longer generate invalid reference or payload paths when adding references or payloads if the target file is near the engine binary. [DatasmithImporter] Fixed a bug that would occur when reimporting DirectLink static mesh with changed material ordering. Fixed an issue related to how material names were being used for texture assets when fully importing stages from USD. [Sketchup] Available SketchUp versions will no longer be disabled in the installer. [Solidworks] Fixed an issue which prevented proper shutdown of Solidworks. Chosen material purpose will now be used when parsing material assignments directly for the generated mesh assets when opening an USD Stage. Fixed a slowdown which occurred when trying to display array attributes with many entries in the USD Stage Editor. [Solidworks] Removed the -1 on spot light scale. UDIM textures will now be parsed from USD Stages as expected. [Solidworks] Fixed a sync/export bug that occurred when the plugin was enabled manually (not on startup). Fixed a bug that could cause the material overrides layer to be empty in some scenarios when exporting levels to USD. Adding and removing USD layers will now automatically reload animations on the generated LevelSequence as expected. Fixed issues related to handling the export of levels to USD with Static or SkeletalMesh assets with multiple LODs, leading to broken references or missing material assignments in some cases. The \\"Save USD Layers\\" dialog will no longer be shown when switching Stage options on the USD Stage Editor. Mesh prims without the SkelBindingAPI will no longer be incorporated into the generated SkeletalMesh assets when opening or importing USD Stages. Groom and Groom Binding assets now import from USD Stages as expected. Using the Actions → Import option to import an opened USD Stage will no longer lead to unexpected results if the chosen import options differ from the options used by the currently attached USD Stage Actor. [Navisworks] Tooltips now appear as expected when docking/undocking plugin UI. Fixed an issue that occurred when exporting Unreal levels to USD. The exporter will no longer fail to retrieve actors when exporting \\"only selected\\", if those actors belong to a sublevel. [Solidworks] Deleted sub-assemblies are now removed from the Datasmith scene on sync. Fixed an issue which could corrupt imported textures settings. GroomBinding assets will now be set on the Groom components when opening USD Stages with Grooms as expected. Animations on the generated LevelSequence will now be refreshed when adding or removing USD sublayers from an opened USD Stage. The landscape material baking process will now generate consistent textures when exporting levels to USD. [Solidworks] Fixed an issue involving Part materials exporting inconsistently in multiple configurations. [Revit] Fixed a Direct Link error associated with the Datasmith Exporter for Revit 2018.3. [Solidworks] Fixed an issue involving the deleting a sub-component of a sub-assembly. USD Stages with animated meshes (that led to Geometry Cache assets being generated) will no longer be left permanently opened in some scenarios. [Solidworks] Fixed a miscalculation involving child components variant transforms. Fixed broken baked material references when exporting USD stages on Linux. The USD Stage Actor will no longer write to the USD Stage when updating component properties on the level even if those properties are bound as tracks on the currently opened Sequencer. Fixed an issue which could cause missing StaticMeshes on HISM components generated when opening or importing USD Stages with point instancer prims with LOD prototypes. Fixed an issue which could cause missing static mesh components when opening or importing USD Stages with Light prims that have child Mesh prims. UsdTransform2d UV transform shader nodes when opening or importing USD stages on Linux will now parse as expected. Actors spawned when importing USD stages via the Actions → Import button on the USD Stage Editor will no longer be marked as transient and disappear when loading into PIE or reloading the level. The USD Stage Editor and UsdStageActor will no longer use an old generated UAsset when a stage option is changed. Deprecated: The FUsdPrim::HasPayload() function was deprecated in favor of HasAuthoredPayloads() to mirror the USD API. [USD Importer] Deprecated the HasAPI() function that takes an optional instance name parameter and replaces it with one- and two-FName parameter overloads that match the one- and two-token counterparts on UsdPrim from the USD API. Framework New: Limited the number of paths reported in changelist descriptions generated by editor collection checkins to 1000. You can control this by setting the Cvar Collections.MaxCLDescriptionPathCount. Added ability to change the importing behavior for assets so that if you import on top of a redirector, you'll instead import on top of the asset that redirector points to. Set the CVar AssetTools.FollowRedirectorsWhenImporting to 1 for this behavior. Added an optional integration with Helix Swarm that provides a way for users to view/post comments from the UE changelist review tool. Crash Fix: Fixed a crash that occurred when copying actors in an editor from before 5.1 and then pasting the actors in a editor newer then 5.1. Fixed crash when duplicating levels that contain a Level Blueprint. Fixed intermittent editor crash when loading certain changes in the changelist review tool. Bug Fix: Fixed missing '#changelist validated' tag when submitting without editing the changelist text. Added bIgnoreEditorOnlyReferences to AssetReferencingPolicySettings in the Asset Reference Restrictions editor plugin. When true (which is the new default), the reference checker will ignore editor-only references to things like editor utility components. Input axis events now forward to the Editor World extension collection and give extensions an opportunity to consume input. Landscape API Change: FMaterialCachedHLSLTree was not updated but already doesn't support the same features as the legacy HLSL material translator (e.g. AllowMultipleCustomOutputs). Code accessing the Landscape GUID identifiers on instanced Landscapes now needs to take into account that instanced Landscapes modify their Landscape GUIDs. If you need the original value from the landscape asset, access it via GetOriginalLandscapeGuid(). New: Added command to dump a report of all landscape grass data currently used on landscape components: grass.DumpGrassData [optional: -csv -fullnames -showempty -detailed -byproxy -bycomponent -bygrasstype -full] Added possibility for UMaterialExpressionCustomOutput to limit the max number of outputs. Displays an error when the material is using more than the max allowed number. Added threshold to dirty landscape textures detection (CVars \\"landscape.DirtyHeightmapThreshold\\" / \\"landscape.DirtyWeightmapThreshold\\") Added CVar landscape.DumpDiffDetails (to be used in conjunction with landscape.DumpHeightmapDiff and landscape.DumpWeightmapDiff) to dump additional details about the diff introduced on a given heightmap/weightmap. Added Include Border to the landscape tool's component brush. Since the border is shared with neighbors, oftentimes the user wants to paint within the bounds of the component but not on the border. Added blueprint getter and setter to WaterMeshOverride. Added a new collision heightfield visualization mode to visualize the chaos material per-vertex. Added the ability to synchronize LOD levels and eliminate geometry seams across adjacent Landscapes, by setting their LOD Group Keys to matching non-zero values. Reworked landscape property sharing and override. Added LandscapeInherited and LandscapeOverridable meta tag to mark shared properties. Enforced synchronicity between shared properties when editing and loading ALandscape and LandscapeStreamingProxy. Created textures with no mipchhain if used in as a layer height or weight. Prevented computing the landscape texture hash twice when it has changed. Multithreaded building of nanite meshes from Landscape geometry Added the ability to store landscape heightmaps in a compressed representation to save disk space, at the expense of slower loading. Enable using landscape.ShowCompressHeightMapsOption to show this option. Build Physical Materials command rebuilds all physical materials Added new CVar to control heightmap detailed change tracking. Split landscape.DirtyHeightmapThreshold into landscape.DirtyHeightmapHeightThreshold and landscape.DirtyHeightmapNormalThreshold. Added a gamma function to the paint tools strength to make more of the slider range useful for painting. Adds Landscape BP Brush visibility layer editing. Added FLandscapeBrushParameters struct that should be used to pass arguments when rendering a layer. Added BP Brush visibility layer toggle in Landscape Editor. Added visibility layer editing for LandscapeCircleHeightPatches and LandscapeTexturePatches. Added helper method to determine if a layer info object name is a visibility layer. Added ability to create multiple nanite components per Landscape Proxy if it has more than 64 components. Added the ability to create multiple copies of a Landscape via Level Instancing. Updated M_ProcGrid material to have nanite enabled. Improvement: Increased the maximum landscape grass type outputs from 18 to 32. Save Modified Landscapes now acts as a way to fix every landscape actor that needs to be updated because of discrepancies. Added viewport message for when Nanite meshes need to be regenerated. The message now indicates the number of landscape proxy actors needing updating. Landscape heightfield now uses unlit vertex color material to better visualize physical materials. Prevented updating water info until after a landscape painting operation is finished. Modified ALandscapeProxy detail panel to reflect how the properties are shared. Modified ELandscapeToolTargetType to be an enum class, usable by blueprints. Bug Fix: Fixed Open World map landscape normals. Prevented all Runtime Virtual Textures from being invalidated when entering landscape mode just because we build a thumbnail material. Disabled Save Modified Landscapes hyperlink in the map check after the action has been executed by the user. Fixed Nanite landscape mesh object names, which were not guaranteed to be unique anymore. Removed RF_Transactional flag from the static mesh since this data is not meant to be transactional. Fixed bad tangent space computations for various landscape utilities. Factorized redundant code in landscape for accessing weightmap/heightmap data. Added CPU traces to LandscapeTrace. Fixed important slowdown when using a landscape brush with a large radius. Fixed Inactive world types interacting with Runtime Virtual Texture that caused changelist validation to create a new virtual texture producer. Fixed visibility weightmaps being generated when using landscape patches. They are now only generated when a patch actually writes visibility. Fixed missing landscape actor in landscape tools for debug visual log. Fixed undo of Nanite-enabled landscape proxy deletion that didn't properly invalidate the Nanite component on redo. Made bEnableNanite and NaniteLODIndex shared properties for landscape proxies so at cook time there is no ambiguity over whether Nanite is enabled or not on a given proxy. Added map checks for when shared properties on proxies are not up-to-date. Fixed ModifiedPackages system in ULandscapeInfo. Changed outer of the Nanite static mesh. Made the NaniteComponent TextExportTransient. Copy and pasting no longer leads to the mesh being shared between actors. Made the NaniteComponent DuplicateTransient. Saving as a map no longer leads to the mesh being shared between packages. Fixed crash when listing textures using the listtextures console command after having deleted a landscape actor. Fixed Landscape Nanite Content Id taking into account the landscape material's StateId, leading to landscape actors being invalidated on 2 branches where the landscape material were not at the same version. Fixed Landscape Nanite static meshes having a non-hash based Guid, leading to new DDC keys being generated when the meshes are invalidated. Fixed navigation data being generated for nothing and being invalidated right after generation when building landscape Nanite meshes. Corrected nanite mesh build not being cancellable when started from Build All Landscape. Fixed rare case of desynchronization between CachedLocalBox and heightmap data. Removed incorrect ULandscapeNaniteComponent from ALandscapeProxy's OwnedComponents upon copy/pasting. Fixed performance issues related to landscape heightfield in show collision mode by using static draw commands. Prevented landscape heightfield collision components being invalidated because of editor throttling. Fixed a crash when copying a water body component in isolation. Spline component was not valid and crashed in PostDuplicate. Fixed landscape component count display in editor when selecting streaming proxies. Corrected water bodies which do not affect the landscape to still search for a landscape. Corrected an issue where newly streamed in water bodies would not render into water info texture. Newly streamed in actors are forcibly hidden until all streaming is complete. Fixed a crash in landscape when it contains null entries in LandscapeComponents. Fixed landscape getting dirty even when the detected difference is lesser than the detection threshold. Fixed landscape heights being incorrect after Sculpt Undo operation. Override PostActorCreated to build WaterInfoMesh properly when spawning an actor using the UWorld::SpawnActor method. Fixed an issue where Landscape Resize was not preserving all relevant landscape settings. Fixed a rare crash when using the Landscape Editing modes. Fixed a crash when alt-dragging or duplicating the landscape gizmo actor. Fixed a crash when updating property permissions outside landscape mode Fixed a crash when adding spline control points to a hidden landscape. Fixed an issue with landscape LOD calculation that sometimes caused Landscape edges to have a higher-than-expected LOD. Fixed a potential overflow security issue importing landscape PNG files. Landscape Streaming Proxies were not being unloaded correctly if painted or sculpted in landscape mode. Fixed a crash when creating multiple landscapes with regions Fixed crashes and other unexpected behavior on Undo after adding a new LayerInfo to a Landscape Layer. Fixed incorrect water velocities with some scalability settings. Fixed an issue with large Instanced Foliage paint brushes taking a very long time when the Radius option is used. Fixed an issue with normal calculations along the edges of landscapes. Fixed a rare crash when double clicking a landscape spline control point tangent box. Fixed a crash when undoing the creation of a landscape. Fixed texture corruption when undoing mask painting back to the first mask paint operation. Deprecated: Removed the baked landscape GI texture system. Removed Render method for BP Brushes, RenderLayer should now be used. Scripting New: Added blueprint functions to convert from classes and soft class references to the TopLevelAssetPath struct used by asset utility functions. Exposed GetClassPathName, GetStructPathName, and GetEnumPathName to Editor Scripting, which return a TopLevelAssetPath containing the type info. For example: unreal.MyClass.static_class().get_class_path_name() unreal.MyStruct.static_struct().get_struct_path_name() unreal.MyEnum.static_enum().get_enum_path_name() Exposed FPlatformTime::Seconds() to scripts in Unreal Editor. Added a function to convert a normal widget blueprint to an editor utility widget. Custom icons can now be configured for Scriptable Tool Blueprints in the Class Settings. The UScriptableInteractiveTool class now exposes a Blueprint-overrideable OnGizmoTransformStateChange event, which is called when a user starts and ends a Gizmo transform interaction, or on undo/redo of such an interaction. Crash Fix: Fixed a crash that would occur when using an Editor Blueprint as the root of another Editor Widget Blueprint. Bug Fix: UE now only generates Python stub code when running full editor. Changed Python remote execution to bind to localhost as the default multicast adapter. UI New: In the Place Actor Window, Volume objects and recently-placed elements are now properly localized. Implemented deep copy for sets in CopySinglePropertyRecursive. Added an Icon extension point to the content browser path view that allows icons to be placed to the right of the item text. The asset auditor now shows the staged sizes of assets if they are present in the asset registry, and also makes sure that tags show the data from the selected asset registry rather than the one in memory. Previously, the size displayed in the asset auditor would be uncompressed data estimated by looking at how much data the cooker output to disk. With the introduction of asset registry writeback (in the project packaging settings), the compressed sizes can be written back to the development asset registry. When viewing such development asset registries, those sizes are now displayed. Added a Browse button to the Level Editor Toolbar. Improved UX around unsupported assets in the Content Browser by removing unnecessary menu options and adding an indicator to the tooltip. SBlueprintActionMenu checkbox text is no longer cut off. Changed the sorting of names in the scene outliner and changelist window to be in natural order, similar to OS file menus. The Content Browser immediately flushes the config on adding/removing a folder from favorites to make sure the action is saved if the editor crashes. In the DataflowGraphEditor, you can press the F key to zoom to fit either the selected nodes or the entire graph. Bug Fix: Opening a texture in the texture viewer now always shows Final encoding. Fixed an issue where the color curve editor wouldn't update when gradient stops were moved. Fixed the gradient preview in the Color Curve Editor. Fixed an issue in the Reference Viewer preventing users from typing the address of non-package paths into the address bar. In the Actor details view, archetype edits that occur while archetype instances are actively selected will now correctly sync the \\"reset to default\\" state. Fixed a typo in FMessageDialog remark. Folder names in the Content Browser now wrap properly with ellipses similar to asset names. Fixed an issue where it was not possible to drag-and-drop below rows that have expanded items. Fixed a drag-and-drop issue for Input Mapping Context that was not moving the element at the desired position. Fixed tooltips that could appear on top of foreground programs. UX API Change: Changed message log action token so it doesn't disappear when the action has been executed, it becomes disabled instead. Visibility is only tied to the action's Execute callback validity now. This affects all actions where CanExecuteAction can return false. New: Added the ability for different verbosities in the Output Log to ignore category filter and always display. Added option to auto select items in revision control revert window to reduce redundant actions for users. Set the asset filter in UAssetToolsImpl::CreateAssetWithDialog. This uses the Factory supported class as a filter for assets in the Save Asset As dialog. Migrated most main menu entries under Edit, Window, and Tools to the newer ToolMenus system. Fixed a typo in the tool for importing glTF files. Removed the Starship Gallery test suite from the editor. It was not designed to run inside the editor and can therefore cause crashes. Sorted the viewport's Perspective > Placed Cameras menu by name to make it easier to use. Improved overflow behavior of text on Notifications by adding ellipses and showing the full text on hover. Reskined the Property Matrix to bring it up to standards with the UE5 style. UX Improvements for the Restore Open Asset Tabs notification that shows up when you launch the editor. These include the notification staying active until you make a choice and the ability to remember your selection in the future. Added a Recent Assets menu to the level editor and all asset editors for quick access to any assets you recently opened. Added an option to the Outliner context menu to bulk edit components in the Property Matrix. Modeling Mode favorites are now saved across editor sessions. Added the ability for modes to add a secondary toolbar below the level editor toolbar to house mode specific tools. Removed user-visible ES31 editor references and replace it with Mobile. Improvement: Closed the suggestion box when using the keyboard shortcut (tilde key, usually) to switch between status bar console input to Output Log console input. Auto-adjusted the editable text box size so the content for long console command is more visible. Optimized a variety of hotspots during the texture build path not associated with encoding the actual image, including decoding of source image and metadata generation. Updated text overflow behavior of the Window > Save Layout > Save Layout As panel. Bug Fix: Adjusted the color to full brightness or opacity when picking from the color wheel/spectrum if it was previously almost black or transparent. Fixed a bug in some tables where header text could drift horizontally relative to row text of the same column. The viewport toolbar now correctly collapses its buttons as needed even on displays that use DPI scaling. Fixed an issue where tab headers would appear to be wiggling when a tab was being closed. Updated tabs in windows separate from the main editor from no longer getting lost when Dock in sidebar is clicked. Fixed a crash on shutdown in the Outliner when an item tried to unregister from the Uncontrolled Changelists module in its destructor after the module was unloaded. Foundation New: Allowed UBT to build individual plugins as though they were local. Introduced Network component to CQ Test. Prevented approved reference images to be copied to html test report for successful test. Introducing Code Quality Test plugin. Extension of the Unreal Engine FAutomationTestBase to provide test fixtures and common automation testing commands. Avoided displaying missing reference when image comparison was successful. Allowed levels to turn off garbage collection clustering so that actors can be deleted. Improvement: UAT addcmdline (RunCommandline) is now passed during launching of application on all platforms, where previously it could be embedded in UECommandLine.txt. It improves iteration times on some platforms as final bundle doesn't need to be rebuilt every time. Crash Fix: Fixed crash when using Automation Wait node in BP when AutomationController is not loaded. Bug Fix: Avoided a crash with Screenshot Functional Tests in PIE client net mode. Build New: Added \\"UnrealInsightsBuildConfiguration\\" option to the BuildAndTestProject build graph so the CompileTools step can build Shipping, Debug, or Development configurations of Unreal Insights. Added the option to throw exception when plugin in DisablePlugins list is enabled by another plugin's dependency. Added EngineIncludeOrderVersion for UE5.3 Made the AutomationTool emit an error code when it terminates on an exception. This will result in failing the operation instead of reporting a false success. BuildUAT.batBuildUBT.bat will suppress all messages from file compare. Added support for Clang PCH chaining: https://clang.llvm.org/docs/PCHInternals.html#chained-precompiled-headers. Added support to compile separate files in VisualStudio using the \\"Compile\\" menu item when you right click on the files. Added flags to CSV metadata for LTO and PG_Instrumentation. LTO will be true if Link Time Optimisation is enabled. PG_Instrumentation will be true if Profile Guided Optimisation is currently in Instrumentation mode for gathering PGO profiling data. This change can be used to show if a particular build was running under these parameters when looking at CSV performance reports. Broke several hidden circular dependencies between engine modules. Improvement: Tweaked the engine PCHs to improve compile times. Improved overall Visual Studio project generation time by updating the UBT code to be thread safe and run in parallel. Bug Fix: Previously the \\"-ini:\\" command line argument may have been ignored when sent to UBT. These will now be applied. Previously when multiple \\"Target\\" command line arguments were passed to UBT, ConfigCache::ReadHierarchy could read arguments from other Target arguments. It will now only read from the intended \\"Target\\" command line argument. Fixed an issue where the public dependencies weren't being added to the include path list. Fixed some random intellisense compile issues. Deprecated: Deprecated TragetInfo::bUseMallocProfiler toggle. It is no longer used as MallocProfiler2 and FMallocProfiler runtime is removed in favor of UnrealInsights. Core API Change: This breaks backward compatibility where WriteToString is used as a type or in a context where it would be copied. Deprecated the FMessageDialog overloads that take the title by-pointer; use the overloads that pass it by-value instead. Rename FInterpCurve::InaccurateFindNearest into FInterpCurve::FindNearest. New: Added additional FPackageName::ObjectPathToX functions: ObjectPathToPathWithinPackage, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"MyAsset:SubObject.AnotherObject\\" ObjectPathToOuterPath, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"/Game/MyAsset.MyAsset:SubObject\\" ObjectPathToSubObjectPath, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"SubObject.AnotherObject\\" The behavior of ObjectPathToObjectName has been fixed to always return the leaf-most object name within the path (eg, \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"AnotherObject\\"). Any code that relied on the old behavior should use ObjectPathToSubObjectPath instead. Added FParkingLot, a framework for building locks and other synchronization primitives, based on WTF::ParkingLot from WebKit Added FMutex, a 1-byte mutex that is neither fair nor recursive, based on WTF::Lock from WebKit Added TUniqueLock and TDynamicUniqueLock, based on std::unique_lock. Added UE_LIFETIMEBOUND macro to TStringBuilder to catch some cases where pointers are kept into temporary string builders. Added -DDC-VerifyFix command to overwrite existing records and values that differ from newly generated records and values when using -DDC-Verify. Added AppendV to TStringBuilder. Converted WriteToString for TStringBuilder from a type to a function. Added FMonotonicTimePoint and FMonotonicTimeSpan as an API for the monotonic clock exposed by FPlatformTime::Cycles64. The PackageStore backend is now used to resolve dependencies for MemQuery requests. ReplicationGraph amortize the cost of dormant Actor cleanup by allowing gathering Actor lists for one connection at a time. Added FManualResetEvent, a 1-byte manual-reset event that is more efficient than FEvent. Added FRecursiveMutex, an 8-byte unfair recursive mutex built on top of ParkingLot, as a drop-in replacement for FCriticalSection. Added MemoryTrace implementation for Linux platform. Added EnvOAuthSecretOverride parameter to Unreal Cloud DDC to allow providing an auth secret in the environment. Refactored ListTexture command to output more data about UTexture derived classes. When AGGRESSIVE_MEMORY_SAVING define is enabled, array slack growth factor will be set to 1.25x factor instead of an old ~1.375x This helps to save memory on platforms with no memory commit on a page fault for large arrays that are allocated directly by a page allocator and it saves memory on all platforms for smaller arrays (typically up to 64KB in size) that are allocated by a higher level allocator like MallocBinned. Added TInstancedStruct to provide a type-safe wrapper for using FInstancedStruct in C++. Added parallel decoding of FCompressedBuffer for targets with editor-only data. Added FEventCount, an event type that provides a mechanism for avoiding a race between waiting and signaling through the use of a signal count token, and that is more efficient than FEvent. Added -ExportBuildOutput command to include outputs in exported derived data builds. Added partial implementation of GetResourceSizeEx for NiagaraComponent and NiagaraSystem. Added a public API for structured log formatting in Logging/StructuredLogFormat.h Added a way to upgrade existing sparse class data. Objects using sparse data can now override the ConformSparseClassDataStruct function to perform a custom upgrade step when loading a BPGC using a sparse data struct that no longer matches its archetype. Added a new setting to CppStandardEngine so this can be controlled separately from the engine module. Made AssetManager require engine use. The engine startup will give a fatal error if the AssetManager is not present. Added ReverseIterate range adapter for reverse-iteration over ranges. Adding ISaveGameSystemModule module, comparable to the platform chunk install module. Example usage added to Windows platform, allowing projects and Windows platform extensions to override the default save system. [PlatformFeatures] SaveGameSystemModule=MySaveModule Replaced enable-if/disable-if overloads with if constexpr blocks. Allow any engine module to access Internal include paths from other modules. Added a CBaseStructureProvider concept for detecting if a type is supported by TBaseStructure. Deleted the concept-checking second template parameter from TStructOnScope, which doesn't work so well with forward-declared types. Added TCallTraits::ConstPointerType overrides for common smart pointer types so that they you can look up a TSmartPtr in a map or set with a TSmartPtr key. Fixed some const incorrectness caused as a fallout. Cooker and SavePackage: Move calls to BeginCacheForCookedPlatformData and ClearCachedCookedPlatformData from SavePackage into the cooker to satisfy the contract that objects do not have Clear called until the Save is completed. Added lifetime-bound annotation to TOptional::Get parameter to catch dangling references when an rvalue argument is bound to an lvalue reference. Upgraded to PROJ 9.1.1 and VS 2022 Added SupportedTargetTypes attribute, allowing for ModuleRules to be marked as supported for only specific TargetTypes (Editor, Game, Client, Server). Added SupportedPlatformGroup attribute, which will resolve to a SupportedPlatform attribute that contains all the platforms in that group. Allow SupportedConfigurations attribute on ModuleRules. Enabled tvOS support for Electra Media Player. Added Engine.ini:[AssetRegistry]:CommandletsUsingAR to identify commandlets that should load the AssetRegistry at startup. Removed legacy hash table locks when collecting garbage as they are no longer used. Added range support for Algo::Partition. Updated MFW's PlayerFacade with reworked handling for playback control and timing for \\"v2 timing\\" players like Electra. Added a UE_REQUIRES macro which replaces the UE_CONSTRAINT* macros and is concept-compatible. Support for project-specific BuildConfiguration.xml and Programs during project file generation. Allow overriding bWarningsAsErrors on a per module basis for Unreal Build Tool. Option to write MSVC SARIF files for any errors and warnings when compiling or analyzing for Unreal Build Tool. Added Fwd.h headers for WeakObjectPtrs. Limited Fastbuild process count. Added support for intrusive TOptional null states. Added intrusive TOptional null states to TFunctionRef and TSharedRef as examples. Moved untracked memory coming from the third party Eigen library into the UE allocators, making it trackable. FInterpCurve::InaccurateFindNearest has been improved. According to the accuracy of the new algorithm result, it has been rename into FInterpCurve::FindNearest. Added Max display to containers in .natvis. Improved comments for UE_DEPRECATED examples, adding examples for class templates and function templates. Added the ability to implement a function override that can decide to force garbage collection if the engine is close to reaching UObject count limit. Allow overriding windows application icon with TargetRules.WindowsPlatform.ApplicationIcon for Unreal Build Tool. UE_FNAME_OUTLINE_NUMBER memory optimization. Added TargetRules.bWarnAboutMonolithicHeadersIncluded to control UE_IS_?. Changed [Get|Set]WrappedUObjectPtrValues to take a flag which says whether the pointer is 'in container' or not. Allow usage of incredibuild on macOS. Allowed TFunction's debugger visualiser to be set at a global level via UE_ENABLE_TFUNCTIONREF_VISUALIZATION. Added FMRSWRecursiveAccessDetector that is zero-initializable, supports upgrading a reader access to a writer access recursively, and destruction from inside an access Added override to the temp directory to a subfolder, and allow specifying a directory to use instead of the default %TMP% in BuildConfiguration.xml for UnrealBuildTool. Added WindowsTargetRules setting to control Inline Function Expansion Level for UnrealBuildTool. Updated support for minimum cpu arch for x64 platforms. Replaces ModuleRules.bUseAVX. MinimumCpuArchitectureX64, valid values are None, AVX, AVX2, & AVX512. Allowed OpenVDB to be enabled via a macro in the .Build.cs rather than hardcoded at a platform level. Shared common THIRD_PARTY_INCLUDES* macro definitions between compilers rather than between platforms. Upgraded msvc preferred version to 17.6-14.36. Allow multiple DPCVars processed in a loop to allow for multiple entries form the command line. Added the option to dump per class UObject counts to log when the maximum number of UObjects limit is reached. Implemented -CookIncludeClass=Class1+Class2+. This allows cooking only packages containing an instance of the given class or classes. This relies on assetregistry dependencies to find all packages that would ordinarily be cooked. Packages found through dependencies that are discovered only during load of their referencer are not guaranteed to be cooked. Used a release channel enum instead of a boolean to check if a toolchain is preview or not, so we can support additional release channels for Unreal Build Tool. Added debugger member expansion to FString, TStringView and FName to allow individual character indexing, and allows the raw char buffer to be accessed from a Referenced String or Name array. Enable deterministic msvc compiles by default for shipping configuration for UnrealBuildTool. Added move semantics and removed other unnecessary TSharedPtr reference count churn to TSlotBase::operator[] declarative syntax. Added ExecuteOnGameThread as a wrapper for FTSTicker::GetCoreTicker. Added UE::Tasks::MakeCompletedTask method that produces an already completed task with given result value. Updated RiderSourceCodeAccess. Added operator to TMap's key iterators. Added key iterator tests. Added UE_LIFETIMEBOUND to bit iterators and bit references to warn when lifetime issues occur (like holding onto an iterator to a temporary bitarray). Added UniqueBy to remove duplicates from a range from a projection to apply to the elements, similar to std::ranges::unique. Added FStringFormatArg to natvis. Added FindFrom function to TBitArray to allow a user to provide a start index when searching for a value. Allow cheat extensions to add bugit logging. Added FTopLevelAssetPathFastLess and FTopLevelAssetPathLexicalLess function objects for performing comparisons on FTopLevelAssetPath. Added serializers for TPagedArray. Added Algo::Includes, based on std::includes. Allow MallocStomp2 allocator to be used in the windows editor. Oodle is now updated to version 2.9.10b Added a checkbox option for PriamryAssetLabels to not include/follow redirectors. Added FCoreDelegates::OnCommandletPreMain and FCoreDelegates::OnCommandletPostMain This allows things to hook in to provide additional initialization or shutdown logic for any commandlet that may be run. Added a way for objects to specify property overrides local to the save context of a package. Added two new commands to UAT: VirtualizeProject - Used to run the virtualization process on an entire project. RehydrateProject - Used to reverse the process on an entire project. Replaced FInstancedStruct versioning implementation to use archive custom versioning. Make serialization symmetrical so struct serialized in cooked builds can be loaded in Editor builds. Added a new Settings parameter to a new FPlatformProcess::GetApplicationSettingsDir function for getting %appdata% in Windows, and HOME in macOS and Linux. Moved #includes around in the shared Engine PCHs so the PCHs are hierarchal. This fixes issues where removing or adding a private module dependency would drastically change compile times because the includes in the PCHs were different. StaticMesh Asset Validation now verifies that an uncooked StaticMesh Asset has valid a LOD0 SourceModel. The virtualize and rehydrate project commandlets now accept the command line parameter '-PackageDir=' limiting the operation to the given directory. FEditorBulkData is now thread safe. Added a new commandline parameter '-LocalOnly' to the 'GeneratePayloadManifest ' commandlet. This new parameter should be used to generate a manifest containing only payloads that are stored locally on disk. Added FindComponentByTag method to Actor class, which returns the first component in an Actor with a given type and tag name. Added support to give actions in UBT \\"weight\\". \\"Weight\\" is an average measurement of how many cores and memory an action uses. Using one core with a normal amount of memory for an action would be a value of 1. Added a simple S3 HTTP client. A new error flow has been introduced. If a payload fails to pull we now block the editor and show the user a dialog allowing them to retry the operation or quit the editor. We no longer allow the editor to continue with missing data due to the danger of corrupting existing packages on disk. A warning is now logged when attempting to virtualize a package with a package version older thanUE 5.0, as the package would need to be re-saved in order for virtualization to work with it. Enabled virtualization on static meshes and audio assets by default rather than being opt in. The commandlet 'ValidateVirtualizedContent' now validates that all virtualized payloads in a project can be found in persistent storage. The previous functionality has been moved to a new commandlet 'CheckForVirtualizedContent'. Updated the logic that determines which dependencies a shared PCH has. This new logic goes through all the includes of the pch header and finds the actual headers and modules used. This creates a smaller list of dependencies than before, which is later used to determine whether it is safe or not for the PCH to be used by other modules. Enabled profile guided optimization support when using Intel ICX compiler 2023.1. Enabled msvc strict conformance mode by default for projects set to BuildSettingsVersion.V4. Added GetPropertyInstanceWithin to CPPStructOps so that classes like FInstancedStruct can have their internal properties reflected by property paths. Improvement: Improved multi-edit behavior of instanced struct instances Editing multiple instanced struct instances will now edit the properties of the common struct of all instances (like object editing), rather than only editing instanced struct instances using the same struct type as the first instance being edited. Always compile engine modules with C++20, unless the platform doesn't support it. Any module that sets bTreatAsEngineModule will be upgraded to c++20 unless it has already overridden it to c++17 Optimized StreamableManager::OnPreGarbageCollection. Optimized TFunctionRef calling, as it can never be null. . Removed FullLoadAndSave; it has been replaced in efficiency by MPCook, and further optimizations (concurrent save, async load) will also exceed it even without MPCook or Incremental Cook. Improved deprecation comments surrounding the use of string conversion types and macros. Improved comments on TBox and TIntRect to indicate how their Intersect, Contains, and IsInside Of functions handle overlaps on their borders. Fixed FVector parameter in TBox::IsInsideOrOnXY. Optimized TChunkedArray::Add for speed. Improved Clamp codegen. Improved Swap codegen. Optimized FScriptMapHelper::FindInternalIndex FScriptSetHelper::FindInternalIndex now returns INDEX_NONE when the user provided index is out of bounds. Crash Fix: Fixed crashes and errors when using OIDC functionality from DesktopPlatform. Fixed a crash after a failed request lookup in the CotF server. Fixed a crash when shutting down the media player. Fixed a crash when duplicating object with a within class in component instance data cache. Fixed crash when doing recursive async loading in the legacy loader. Bug Fix: Updated FPaths::Combine method to work with FStringView. Sparse data properties will be favored if they match the name of a deprecated object property. This allows Blueprints to function when object data is moved to sparse data, and the original object property deprecated. Added a few missing definitions that were preventing \\"Debug Editor\\" builds of projects that disable GC from linking. Fixed structured logging to work with Live Coding. Added ElementType to TSubclassOf. Fixed alignment and thread safety issues in FMallocStomp and TConcurrentLinearAllocator. Fixed error reporting during execution of static destructors to avoid crashing on a destroyed lock. Fixed merging and filtering of partial records in the derived data cache hierarchy. Fixed vtable constructor to UAssetRegistryImpl to invoke the proper base class constructor. Code would asset during a Live Coding session. However, the asset registry does not support live coding. Fixed using the TMap element after removal. Fixed mismatch string formatting argument in SavePackage2. Fixed assert firing in Debug mode when calling FScriptArrayHelper::MoveAssign. Fixed FName == C string bug and added string view comparisons. Fixed FStringView's operator!= which could result in circular overload resolution. Added perfect forwarding of delegate Execute arguments. Added a static assert when casting a non-UObject to an IInterface. Set the chunks of the generated package equal to the chunks of its generator. Fixed a mismatched user-defined copy constructor/assignment operators and their associated bugs. Fixed a potential invalid quote count in CSV parser and added overloaded constructors for move semantics. Fixed TSortedMap's key iterators which didn't compile. Fixed issue where Electra Media Player would return incorrect HDR information after seeks. Made FPlatformProcess::WritePipe use proper UTF-8 conversion rather than truncation. When collecting objects referenced by properties, the property owner object will no longer be excluded and instead the owner of the reference list will be excluded to make sure all references are property exposed to the Garbage Collector. Changed a texture on a material instance will now add the new texture to the material's Garbage Collector cluster. Fixed JsonSerializer output where data loss occured when NumberStrings were being written as numbers, instead of strings. Made ensure conditions likely when !DO_ENSURE. Fixed inverted logic in FBindingObject::IsA<>. Updated GenerateTLH to build and touch the output file with one command, to prevent cases where the .tlh doesn't exist and isn't created. Allow typelib headers to be generated when using the clang compiler, by using the toolchain's compiler to generate them instead. Fixed TBitArray being implicitly constructible from a TBitArray of another allocator to stop accidental dangling references when constructing a const bit iterator with the wrong allocator type. Fixed implicit conversions when comparing or doing bitwise operations between bit arrays with different allocators. Removed 1 extra virtual function call (or more if ArrayDim > 1) from object-based Copy*ScriptVM property functions by having an implementation per property type instead of a top level override, also removing the need for the FSoftObjectPtrProperty::Copy*ScriptVM overloads. Fixed invalid string length handling in FCborReader::ReadNext. Allow AdditionalPlugins for use in multiple projects. Fixed inverted assert conditions in Algo::Heap method. Fixed FThreadSafeCounter64's copy constructor taking FThreadSafeCounter. Automation Tool will now respect specified error level for commandlets. Added a check for invalid counts in FScriptArrayHelper::Resize. Fixed THIRD_PARTY_INCLUDES_END for Clang on Windows. UnrealBuildTool will not pass /Zm unless specifically overridden. Added a check for invalid reserves in TSet. Fixed TMap::FilterByPredicate discarding template arguments in return type. Fixed Clang static analysis false positives in our operator delete overrides by disabling them. Removed redundant Unbind call from TDelegate's destructor. Added guards to stop property size calculation overflowing. Fixed Unreal.natvis to allow container indexing in the debugger. Made FHeightField::FData::Serialize avoid using TArray>, as FBoxFloat3 is immovable and shouldn't be used by movable allocators. Object Handles will be initialized with the actual global UObject array capacity instead of the max UObject count value from ini since the actual array capacity may be larger. Fixed broken bAddDefaultIncludePaths UBT setting. Fixed a GeoReferencing issue where the data files were not found in a sandboxed environment. Fixed incorrect size being reported by TArray's overflow checker. Fixed negative int32 sizes being reported as large uint64 sizes.. Fixed EnumAddFlags and EnumRemoveFlags to not require operators on the enum. Made TIsCharType work with cv-qualified types. Made sure running out of available UObject slots crashes regardless of checks being enabled or not otherwise it will silently result in stomps or out of memory crashes. Added weak pointer to archetype cache to prevent returning stale pointers. FProperty references resolved in PostLoad will now properly add their referenced objects to the bytecode owner UStruct's reference list. Fixed rsca for toolbox 2 0 in rider. Non-nullable object properties should now have a default object value assigned to them in case of serialization errors. Fixed mismatch string formatting argument in core test. Replaced some TArray operator new usage. Fixed a bug that truncated the lost of valid paths when emitting an error about an invalid package name. FMicrosoftPlatformString::Strupr is now consistent with other platform implementation and works with non-null-terminated strings. FScriptMapHelper::Iterator and FScriptSetHelper::Iterator post-increment operators were pre-incrementing. Made BuildU[A|B]T.bat explicitly call the Windows find.exe utility. Fixed DrawDebugCircle to draw correct number of segments. Fixed LLM not setting the program size. Fixed UEngine::DrawOnscreenDebugMessages function which was returning the wrong value. Deprecated: Deprecated the FMessageDialog overloads that take the title by-pointer; use the overloads that pass it by-value instead. Deprecated Engine::FindAndPrintStaleReferencesToObject as it was moved to FReferenceChainSearch. Deprecated Engine::FindAndPrintStaleReferencesToObject and moved PrintStaleReferencesOption to its own file for better compile iterations. Moved FindAndPrintStaleReferencesToObject to ReferenceChainSearch. Deprecated four FBulkData flags that no longer serve any useful purposes: BULKDATA_Unused, BULKDATA_ForceStreamPayload, BULKDATA_SerializeCompressedBitWindow and BULKDATA_BadDataVersion Starting to remove support for delegate policies as they are incompatible with threadsafe delegates. Removed usage of TRemoveConst and deprecated it. Removed the deprecated rebasing Actor and the dependency to the rebasing offset. Deprecated hashing arrays and TCHAR* with GetTypeHash. Deprecated TScriptDelegate. Replaced TModels traits class with TModels_V. Deprecated UE_GC_TRACK_OBJ_AVAILABLE macro and simplified available UObject count tracking. Moved FScriptSetHelper::HasElement and FScriptMapHelper::HasKey to the editor. Removed DISABLE_DEPRECATION macro. Removed UUnsizedIntProperty and UUnsizedUIntProperty which have been broken since the move to FProperties. Removed UE::Core::Private::FWrappedObjectPtr, since it's unnecessary now that we have FObjectPtr. Deprecated TRemoveCV. Replaced TIsTArray trait class with TIsTArray_V. Made ApplicationWillTerminateDelegate thread-safe: deprecated FCoreDelegates::ApplicationWillTerminateDelegate (because thread-safe delegates can't be statically initialised) and added FCoreDelegates::GetApplicationWillTerminateDelegate accessor for a thread-safe delegate. Deprecated global Sort and StableSort functions. They only support an index type of int32 and can produce unexpected/undesirable behavior due to their use of TDereferenceWrapper. Uses of these functions have been replaced with the versions in the Algo namespace. It is no longer possible to virtualize engine content and so the following config file options have been deprecated: Engine:[Core.VirtualizationModule]:FilterEngineContent Engine:[Core.VirtualizationModule]:FilterEnginePluginContent Removed: Removed GIsUCCMakeStandaloneHeaderGenerator since C++ UHT no longer uses engine types. Removed core delegates deprecated in 5.2. Removed the old FTicker that was deprecated in 5.0 Removed EGCOptions::WithClusters to reduce the number of template instance permutations in Garbage Collector code and improve compile times. Dev Tools New: Removed C++ Unreal Header Tool (UHT). Ported C# Unreal Header Tool UhtBuffer to new objects that use ArrayPool. Add non-persistent metadata to the CsvProfiler. By default csv metadata persists between captures which may be problematic if capturing different modes that have specific metadata since prior captures can pollute future ones. This change adds a CSV_NON_PERSISTENT_METADATA macro which sets metadata that is cleared once the current capture ends. [UnrealVS] Added \\"Generate Assembly\\" menu option that asks UBT to compile a single file and generate an assembly file. Upgraded UnrealVS.vsix to version 1.84.3 Added the ability to define new documentation policies and specify a default policy. Added ability in UHT for arrays to be sized using static_cast. Added the Build directory as a location UBT scans for UBT plugins. [PerfReportTool] Added support for date formats and disabling column word wrap. Added the ability to compute a hash from a slice of an array. Modified UHT to not emit unused #define directives. Updated UBT project code analysis to 4.2 and text encoding to 6.0. Added the ability to set the IoHash directly in the file hasher [UnrealBuildTool] Added option to generate assembly files while compiling C++ files. Supported only on MSVC compiler for now. Generated files have the .asm extension and are located in the same Intermediate folder as the corresponding .obj. Added generic double buffer async file reader with the ability to specify buffer sizes. [Horde] Optimizations to Horde storage when dealing with larger data: Added ability to specify buffer size with FileNodeWriter methods CreateAsync and AppendAsync. Added ability to copy a FileNode tree directly into a stream without creating the nodes themselves. When reading data, avoid creating byte[] for the cache if the cache is not enabled. Reduced default read size from 15MB to 1MB when caching isn't enabled. New ReadNodeAsync method that invokes a callback with the data instead of creating the node instance. TreeWriter uses the current packet's full memory buffer size to detect the need to resize indead of the max packet size. New bundle test for the streaming of FileNode directly to a stream. Removed comment and tooltip metadata from shipping builds. Added Apple Silicon native binaries for GitDependencies. Added ErrorIfNotFound option to MoveTask to allow throwing an error if the specified file is not found. This option is disabled by default. Optimized Visual Studio created projects and they are now much smaller. Added validation logic to Unreal Build Tool (UBT) to ensure that plugins do not have dependencies on any plugin that is sealed. [UGS] Error dialogs shown at the end of syncing (unresolved files, files needing deletion etc) are now focused when the UGS window is selected. In addition the UGS taskbar entry flashes before showing these modal dialogs and at the end of the sync to try and get the users attention. Added a new bEnableLibFuzzer option for desktop platforms. Improvement: Improved C# UHT file reads by limiting the buffer size to reduce garbage collection stress. Modified the ComputeAsync hash method to provide a file size hint so it can default to a larger buffer size to improve performance. Modified the ComputeAsync hash method to use the double buffer reader above. Enhanced UHT to be able to parse more C++ attributes. Improved checks for keywords placed in invalid conditional blocks. Crash Fix: Fixed Hot Reload and Live Coding to not bother serializing delegates and bulk data. Delegate serialization was causing asserts with new concurrency checks and could have resulted in crashes in the past. Fixed live coding shutdown to eliminate a crash on exit. [UGS] Disabled \\"Open Project...\\" when right clicking in the main window unless the context menu was opened over a valid tab. This prevents a crash when attempting to open an invalid project. Bug Fix: Fixed Unreal Build Tool (UBT) log event level check that resulted in spam to the logger. Fixed issue where modules that were not currently loaded could prevent live coding from patching modules that were. Fixed issue where using live coding with the Clang compiler would generate \\"unresolved external\\" errors. Live Coding no longer generates errors about object files being missing after a source file is removed from a unity file by live coding. Removed unnecessary iteration in GetMaxEnumValue in UHT. Fixed issue with UBT where the UE_TARGET_NAME isn't the actual target name. This resulted in Hot Reload and Live Coding to no longer work when used with a non-unity build. Fixed C# UHT to allow functions with parameters in WITH_EDITORONLY_DATA blocks. Fixed issue where the check for first header include was not being reported as an actual warning/error. Fixed issue where Live Coding would fail with \\"unresolved external symbols\\" when used with Clang. Fixed Live Coding Console to handle the patching of coroutines. Fixed C# UHT strict documentation tests for function. Fixed an issue with Live Coding where large projects might not have enough memory reserved around libraries preventing patching. Fixed an issue where C# UHT metadata did not issue value change errors in metadata. Fixed an issue in Live Coding preload module support where, if a module name is known but not currently loaded, then the engine would generate a check. Fixed an issue where C# UHT failed to generate an error when an interface function was marked as BlueprintPure. Fixed an issue where UBT failed to detect C# UBT plugins in the game folder. Fixed an issue in C# UHT where, if a structure referenced itself, then it would end up in an infinite loop. Fixed a rare threading crash when starting UnrealPak. Fixed an issue where, if Unreal Header Tool (UHT) export code threw an exception, the build did not display the error message or fail the build. Fixed UHT issue where invalid code would be generated if all FieldNotify properties in a class were marked as editor-only data. Deprecated: [UnrealFrontend] Disabled old Profiler (UnrealFrontend/SessionFrontend/Profiler). Old Profiler was deprecated in UE 5.0. Use Trace/UnrealInsights instead. Added UE_DEPRECATED_PROFILER_ENABLED global define toggle. This is off by default. This allows you to temporarily re-enable Profiler if needed; see UnrealFrontend.Target.cs. Profiler module/code will be removed in a future UE version. Removed: [UnrealFrontend] Removed the deprecated MEMORYDUMP run command. Insights New: Added FInstallBundleSuppressAnalytics class to help suppress install bundle analytics that avoid spamming during a specific bulk operator. Enabled Unreal Trace Server for all platforms. Unreal Trace Server now supports all desktop platforms (Win64, Mac, Linux). Precompiled binaries are now included for Linux and Mac. This removes the need to run Unreal Insights program when tracing on those platforms. Added user interface for displaying connection status to trace store. Added logic to re-connect when the connection to the store server is lost. Added user facing message events in TraceLog. Previously, errors in TraceLog would silently stop traces without any information to the user. This adds a way to receive those messages and log them using regular engine logging. The new session id is now used when requesting a process current trace session. This resolves the issue with getting the current session, when the machine has many live sessions running at the same time. Added persistent settings for Unreal Trace Server which allows setting changes to be retained after restart. Settings can be changed without restarting the server. Added UE_TRACE_METADATA_RESTORE_SCOPE(MetadataId) macro. Added alloc event callstack id and free event callstack id in tooltip of the Callstack column for Memory Insights. Added a package field to the asset metadata scope, in addition to the existing asset name and object class fields. Added the \\"screenshot\\" trace channel to the \\"default\\" channel preset. Symbol resolving now automatically tries to remap known packaged renamed binaries to their original filename. xmake is now used for building Unreal Trace Server on all platforms. Added LLM tracking for TraceLog memory usage. Made TimingView.AutoScroll option persistent in ini file for Timing Insights. In Timing View, when Ctrl is pressed while clicking an event to be selected, the time interval that includes both the old selected event (if any) and the new selected event will be also selected. Added \\"Project Name\\", \\"Other Metadata\\" info, if available and added \\"TraceId\\" as an optional metadata. Added FD3D12Adapter::TraceMemoryAllocation and D3D12PoolAllocator to resolved symbols filter in Memory Insights. Added support for unlimited number of heap specs in Memory Insights. Previously, it was limited to 256 heap specs. All trace files now contain a metadata field with a session id and a globally unique trace id. Session id can be set from the command line to group session from many machines together. If no session id is specified a random one is generated. Memory Insights / Mem Allocs table: - Improved the status bar text display of query info, query status, number of allocs and added number of filtered allocs. Added status bar text info for selected items (including the total alloc count and total mem size of selected items). Added tracing for the existing \\"Stats_GPU_*\\" float counters when \\"stats\\" trace channel is enabled. Added project field in session info event, separate from the app name. Previously we used project name rather than app name if it was available. Added Get*ProviderName public API for all providers. Refactored the IModule derived classes to ensure consistent implementation. Tree Table View improvements: Increased font size and updated text colors (ex.: when tree node is hovered/selected/filtered). Added default icons and colors for tree nodes. Added custom color for group nodes created by Callstack and Tags groupings. Clip tracing of asset loading debug name to 1024 characters. Updated Unreal Insights version to 1.04. Memory Insights: Added option to include heap allocs in mem queries. Memory Insights: Added analysis support for NeverFrees heaps. Added limit for the number of log warnings generated. Added EnterScope_TB / LeaveScope_TB (timestamps relative to BaseTimestamp) events ans to EnterScope_TA / LeaveScope_TA (absolute timestamps). Network insights - Modified filtering to include sub-events when filtering packet content events. Added delta time display of selected range of packets. Filtering now supports using filter by NetId and EventType in combination, which is useful to highlight specific events for a specific instance. Improvement: Users can now change store settings in Unreal Insights. Currently the user can change: Store directory: The directory where new traces are stored. Watch directories: A set of directories monitored for trace files. For example users can add their download folder and automatically see downloaded traces in the session browser. Optimization: Refactored the IProvider / IEditableProvider interface for Trace Services to avoid diamond problem. Crash Fix: Fixed crash in Frames track when there are no frame series created yet. Bug Fix: Fixed a deadlock that occured when stopping a trace with the \\"Open Trace in Insights\\" option enabled. Avoid locking TraceAuxilliary destination and connection type while issuing delegates. Restored Uri functionality for traces (backward compatibility with current/older UTS). Disabled a trace session after it was renamed, until the trace id is properly updated the trace name changes color to grey. Fixed focus for the trace sessions list (initial focus and after renaming a trace). Improved Session Browser UI responsiveness when using a remote/slow trace store connection. Fixed opening a trace from a remote trace store. The new UnrealInsights process is launched by specifying the store address in addition to store port. The trace id can now be specified as hex number (prefixed by 0x). Return allocator result in the case of zero sized allocations. Remove checks for zero sized allocations in Trace's allocation wrappers leaving it to the allocator implementation to decide. Analysis already supports zero sized allocations (as long as they have unique addresses). Fixed late connect for the Counters trace channel. Changed TraceAuxilliary internal management of tracing status and trace destination. Tree Views for Allocs Table, Tasks, Packages now have Separated tree view node filtering by hierarchy filtering. The order of async operations was changed. Node filtering (i.e. advanced filtering using the Filter Configurator) is applied first. Then grouping + aggregation is applied. Then sorting is applied. Finally, the hierarchy filtering (i.e. text search) is applied. This enables text search (hierarchy filtering) and advanced filtering (node filtering) to be used in the same time. Also, the aggregation is now applied only once. These changes enables significant performance improvements for the tree operations, especially when node filtering is applied. Disabled Rename/Delete trace files when using a remote trace server. Fixed updating the list of traces. If list is scrolled on bottom it will remain scrolled on bottom also when new traces are added. Fixed initial channels example (including a typo) and usage of \\"default\\" preset to include \\"region\\" and \\"screenshot\\" channels (Connection tab). Fixed trace recorder IP address to be prefilled with correct IP or host name of (remote) trace server (Connection tab). Trace store uses entire path for id. Only using the stem hides files with the same name present in multiple mounts. Fixed a missing check to make sure the entire packet was sent. This guards against any low level transmission errors. Updated Unreal Trace Servers readme to reflect dynamic ports used. Fixed missing channel check for metadata restore scopes. Fixed Trace.Screenshot not working when not running PIE or simulation. Fixed realloc scopes for the video memory allocations. Previously only realloc scopes for system memory were supported. Fixed late connect support for the \\"stats\\" trace channel. Changed the batch trace event to always start with an absolute timestamp value (instead of being relative to previous event). Reduced the overhead of stats tracing when the \\"stats\\" channel is not enabled. Fixed memory tracing for block allocators used by TConcurrentLinearAllocator ,FOsAllocator, FAlignedAllocatorInternal, and FOutputDeviceLinearAllocator's block allocator. Fix to try to update symbol search path until module provider is created. Previously the symbol search path string was updated only whenever the panel was reset, which doesn't always correspond to when the module provider was created, leaving the string blank until the panel was recreated. Counters: Fixed \\"Export Values/Operations\\" incorrectly saving all values/ops for selected counter even if a timing selection is made in the Timing View. Counters: Added name of the selected counter in the default filename when exporting values/ops. Changed zoom in and out with mouse wheel to auto-pin the hovered track in the Timing View. When opening the profiling directory from the Insights Status Bar Widget, the folder will be created if it does not exist. Fixed trace analysis for scoped trace events. Added explicit support for counters with dynamic name. Added support for hierarchical Clear and Restore scopes. The Clear/Restore scopes replaces the current metadata stack with an empty/saved metadata stack and restores the previous metadata stack at the end of scope. Fixed scope of metadata and mem tag for mem allocations made by the trace system (extends scope over the original allocator calls). So, heap allocations will inherit same \\"trace\\" tag. Fixes for traced metadata scopes applied in tasks. Fixed log messages in memory analysis regarding TagTracker errors when memalloc channel is not enabled. Fixed time for scoped events to be relative to base timestamp at runtime. This allows packing on 8 bytes (as in trace protocol 5). Level streaming profiling is now disabled on the server by default. Deprecated: Removed RenderCore's FTracingProfiler which is deprecated since UE 4.26. Please use Trace system and Unreal Insights instead. Added UE_STATS_MEMORY_PROFILER_ENABLED to toggle on/off code related to MemoryProfiler in STATS system. It still requires STATS to be enabled and \\"-MemoryProfiler\\" to be specified in cmd line. This is off by default as MemoryProfiler in STATS system functionality is deprecated in UE 5.3. For memory profiling, use instead Trace/MemoryInsights and/or LLM. Removed the deprecated MemoryProfiler runtime: Removed the deprecated MemoryProfiler2 tool. Use Unreal Insights (Memory Insights; -trace=memory) instead. Removed: Removed usage of MessageLog on analysis thread. With this change direct usage of MessageLog in the analysis engine is replaced with a callback system which allows the user of TraceAnalysis to implement display of the messages themselves. Framework New: Moved all FInstancedStruct code that depends on the Engine module into a new StructUtilsEngine module. This allows modules that can't depend on the Engine to use FInstancedStruct. Added nested containers support to PropertyBag (TArray>) with a max depth of two. Added a DisallowedPlugins list that restricts which plugins can be used. Added an experimental Plugin Reference Viewer tool that displays a plugins dependency graph. The experimental tool is disabled by default. You can enable the PluginReferenceViewer Access tool from the plugin browser window. Added a new 'Sealed' plugin concept that will prevent other plugins from depending on a plugin. Fixed an issue that would result in broken package references when creating new plugins using a plugin template that contains assets. Added a NoCode plugin descriptor property that prevents a plugin from containing any code or modules. Added a plugin template subfolder property to define the sub folder a new plugin will be created within. Fixed an issue where creating a new plugin that could sometimes fail if the asset register scan is still pending during the plugin creation. AI New: Added the experimental plugin Learning Agents. Learning Agents allows you to train AI characters using machine learning. This enables you to augment or replace traditional game AI, such as those written with behavior trees or state machines. In particular, the plugin allows you to use reinforcement and imitation learning approaches. In the long term, Learning Agents aims to be useful in a range of applications, including physics-based animations, game-playing NPCs, and automated QA testing. Converted AI-related Asset Actions to Asset Definitions. This applies to State Trees, Behavior Tree, Blackboards, and Environment Queries. Bug Fix: Fixed an issue where ZoneGraph would automatically build when the Build Zone Graph While Editing flag was enabled in Project Settings. Deprecated: Deprecated UAvoidanceManager::bAutoPurceOutdatedObjects. Please use bAutoPurgeOutdatedObjects instead. AI Behavior Trees New: Add a Default Blackboard config option for Behavior Trees. Exposed Behavior Tree Editor functionality to be inheritable and accessible from other modules. Also introduced some smaller Behavior Tree Editor UX improvements. Added a tooltip to the Behavior Tree context menu node descriptions. Crash Fix: Fixed an issue where setting the KeyType to None in the base class of UBlackboardKeyType_Object would cause a crash. Bug Fix: Fixed an issue where the BehaviorTreeEditorModule custom Toolbar Extenders were not being applied correctly. AI Debugging New: A newly created row in VisualLogger will now be hidden if all added items are filtered out by category verbosity. Improvement: DebugDrawService now uses synchronization objects for delegate unregistration to prevent RecreateRenderState_Concurrent from registering and unregistering delegates from multiple threads. Bug Fix: Fixed the position of the debug text for UE_VLOG_OBOX. AI Navigation API Change: FZoneGraphPathFilter now has an optional fourth FZoneGraphTagFilter parameter in its constructor. New: Added FZoneGraphTagFilter to FZoneGraphPathFilter so that FZoneGraphAStarNode can perform pathing requests using a given tag filter. Fixed UZoneGraphTestingComponent to properly use QueryFilter when performing a pathing request. The oversized dirty area warnings now work with active tile generation (including Navigation Invokers). This fixes multiple unnecessary warnings when dirty areas are not touching the active tiles. Added AgentMaxStepHeight to FNavMeshResolutionParam. Added a display message when the Navigation Mesh version is compatible, but not the latest. Added Navigation Invoker priorities (ENavigationInvokerPriority). Fixed an issue where using LazyModifiersGathering by reading the resolution after GatherNavigationDataGeometry resulted in an Navigation Mesh resolution issue. Added a task count and task wait time per layer to the CSV Profiler. Added a log category and logs detailing invoker registration to LogNavInvokers. Added a NavInvokers CSV category and track invokers count in CSV to the CSV Profiler. Added tile generation history and stats when LogNavigationHistory is set to Log. Increased the height where the Navigation Mesh can generate (now using 29 bits instead of 15, allowing 26000 km of altitude when using 5 cm CellHeight). Changed rcCompactSpan to use rcSpanUInt for y. Bumped the priority of dirty tiles near Navigation Invokers when sorting by invokers priority. Added support for Geometry Collections in UNavModifierComponent. Before this change, a UNavModifierComponent on a Geometry Collection would not find the physics for the proxy mesh and fallback on an arbitrary FailsafeExtent. Added support for Navigation Mesh resolution when doing async navdata gathering. Added a console variable to toggle Navigation Mesh resolution. Added NavMeshResolution to UNavModifierComponent. Renamed the navigation console commands prefix from n. to ai.nav. Improvement: Added Navigation Mesh generation optimization when using it with Hierarchical Instanced Static Meshes. This avoids gathering unnecessary geometry when building tiles. Added optimizations to UHierarchicalInstancedStaticMeshComponent::GetOverlappingBoxTransforms. Crash Fix: Fixed an issue where modifying the NavigationRelevantData array during garbage collection (when FRecastTileGenerator::AddReferencedObjects is called) would result in a crash. The change moves emptying NavigationRelevantData to the main thread so that it does not occur at any moment. Bug Fix: Fixed a memory leak in FNavigationOctreeElement operator and added move operators. Fixed an issue that would result in a crash if there was no Navigation System. Fixed an issue in UGeometryCollectionComponent where the bIsDynamicObstacle flag from UNavCollisionBase was not taken into account when exporting UGeometryCollectionComponent. Made UWaterMeshComponent not navigation relevant. This fixed an issue with hundreds of Navigation Mesh tiles being dirtied when adding a UWaterMeshComponent. Fixed an issue where building navigation when there was nowhere to build caused reduced editor performance. Fixed an issue when using the async flag where saving files using source control in WorldPartitionNavigationDataBuilder would cause an error. This fixes the \\"MarkForAdd, Error: Failed mark the file\\" issue that could occur during build. Fixed Navigation Mesh holes on steep slopes caused by a rasterization issue (this also fixes Navigation Mesh issues in stairs). Also added the ai.nav.EnableSpanHeightRasterizationFix console command to disable the fix if needed. Fixed an issue that would result in memory corruption from FRecastTileGenerator::MarkDynamicAreas. Fixed an issue where using SAVE_Async would not wait for async file writes before adding packages to source control. AI Smart Objects New: Moved registration to BeginPlay and unregistration to EndPlay for components used in a Game world. This will allow conditions to rely on a fully initialized Actor in case they need to access other components. It will also make it easier to spawn an Actor with a SmartObject component and set up its definition before finishing the spawning. Added new methods to the API to filter a list of request results or slot handles by evaluating the selection preconditions. Filter methods can accept external data as a struct with properties whose name and type match the WolrdConditionContext. FSmartObjectUserContext has been introduced to cover the common case of passing in a user Actor to the context. UserDescriptor is now stored as an instanced struct in the runtime slot. Claim methods now receive a user descriptor. Removed slot event delegate and reused the runtime instance one instead. Listeners can now filter for a given slot using Event.SlotHandle. Removed User Tags from the SmartObjectWorldConditionSchema. The User Tags are part of the query filter. Conditions requiring User Tags could fetch them from the Actors passed in the context. Public methods relying on EvaluateConditionsForFiltering now validate that the Slot Handle is set and not stale. In such a case, a log message will be emitted that suggests to the user to call IsSmartObjectSlotValid to handle that scenario on the call site and avoid the log. Added IsBoundToSimulation to the SmartObjectComponent to differentiate a registered component (valid Handle) from a registered component bound to the simulation (linked to its runtime instance). Added unit tests for IsBoundToSimulation, RemoveComponentFromSimulation, and UnregisterSmartObject sequence to simulate the EndPlay issue. Removed dependency on MassEntity to store slots. A new icon is now used for SmartObjectPersistentCollection, SmartObjectComponent and SmartObjectDefinition. Improvement: Improved Blueprint integration with the Smart Objects subsystem. Deprecated the pure version of FindSmartObjects and added a new non-pure Blueprint wrapper that allows proper iteration of the returned objects. Changed the subclass parameters to use values instead of const references to allow direct selection on class pins. Bug Fix: Fixed an issue with container removal where removing multiple sequential entries in a batch would result in improper recomputed bounds. RemoveComponentFromSimulation is now properly unbinding the component. Unbinding a component from the simulation won't invalidate the registered handle anymore; this is handled by the FSmartObjectContainer. Removed obsolete RuntimeCreatedEntries which was replaced by the registration type. DebugUnregisterAllSmartObjects will no longer cause an ensure when calling EndPlay with the previous fixes. AI State Tree New: Added the ability to disable States and Tasks. In addition, it is now possible to force a condition result to true / false. Improvement: Improved the way that property names are reconciled when they change. Added PropertyGuid to FStateTreePropertyPathSegment to allow reconciliation. Changed Blueprint class and User Defined Struct property names. Changed FStateTreePropertyPath to optionally handle property redirects and BP/UDS name changes. Renamed UpdateInstanceStructsFromValue to UpdateSegmentsFromValue to better reflect its use. Improved State Tree editor bindings to update when BP/UDS properties are changed. Bug Fix: Fixed an issue that would result in ID clashes when duplicating transactions. In addition, added several editor fixes. API New: The plugin manager can now find plugins using a plugin descriptor. Instance static mesh components API improvements. Added array view version of batching transform updates. Added option for passing sorted array to removal function. Audio New: Added a function to override the runtime format in FSoundWaveData. [Audio Modulation] Added AD Envelope Generator. This is useful for temporarily modifying the volume of a control bus. [MetaSound] Added support for integral underlying types to TEnum. Added Deactivate All Bus Mixes BP function. This is useful to clear out all active mixes when changing game state. [MetaSound] Added the ListenerOrientation and SourceOrientation parameter interfaces. The WaveTable plugin now supports fidelity and performance tuning and a more intuitive data usage mode for sampling and granulating. Added Runtime MetaSound Builder to support building MetaSounds via code or Blueprint and auditioning in the MetaSound DSP graph in real-time. Added functions to SynthComponent for setting pre-sends and post-sends for AudioBuses and SourceBuses. Improvement: The IsSeekable method in USoundWave is now virtual. You can now get the values of non-audio outputs of playing MetaSound Sources. See UMetaSoundOutputSubsystem for more information. Added Modulation Destinations to the Synth Component. [MetaSound] TVertexAnalyzerForwardValue now remembers LastValue to prevent unnecessary data pushes. [MetaSound] Added support for passing parameters. Changed the address of audio parameter transmitters from using AudioComponentID to a hash derived from NodeWaveInstanceHash, PlayOrder, and the Component ID. WaveTableBanks now support serialization as 16-bit assets and perform runtime bit-depth conversions where necessary. Abstracted the Waveform Editor toolset into a utility collection to be used as generic sample sequence display tools. Refactored Waveform Editor Widgets to remove the use of RenderData. You can now re-import assets within the Waveform Editor. Audio inputs now use WASAPI for device management on Windows operating systems. [Sound Cues] When Override Attenuation is selected, Attenuation Settings will now gray out to better communicate the override. Added a NumRepeats field to the TriggerRepeat MetaSound node. Crash Fix: Fixed a crash that would occur when reimporting an audio file over a Sound Wave marked as Ambisonic. Fixed a crash that would occur when importing audio files. Bug Fix: [MetaSound] TVertexAnalyzerForwardValue now initializes LastValue on first execution as expected. Fixed a bug where logging the default audio settings displayed 0 for max channels. [Audio Modulation] Added a missing tooltip on the Control Bus Mix Stage Value parameter. [Audio Modulation] Fixed a bug where Audio Component Modulation ignored inheritance from SoundWave. [MetaSound] TVertexInterfaceGroup's variadic constructor arguments are ensured to be move-constructible to the group's base type. Fixed a bug where a member could share a name with an existing namespace member already on the parent MetaSound Source. [MetaSound] The WavePlayer node will now immediately fire OnFinished if no WaveAsset is passed in. Wave file metadata chunks will now be preserved in USoundWave assets when converting bit depth of the source file. Fixed an issue with bus and submix sends on muted Sound Waves. Fixed a miscalculation related to a WaveTableBank's entry tail percent. [Sound Cues] Fixed a divide by zero bug in the Enveloper node. Fixed a bug that would cause audio to not play in sequences when cooked audio is referenced in the current level. Deprecated: Deprecated the Steam Audio Plugin. Deprecated the Modulator parameter on the Modulation Destination Settings. Blueprint New: Added facility to make explicit and validate UBlueprint and UBlueprintGeneratedClass subclasses. Subclasses can publish their mappings from the methods: IKismetCompilerInterface::OverrideBPTypeForClass, IKismetCompilerInterface::OverrideBPTypeForClassInEditor, and IKismetCompilerInterface::OverrideBPGCTypeForBPType. Blueprint functions that take parameters by reference no longer require Blueprints that call the function to connect the pin corresponding to the parameter(s) that are passed by reference. This makes it easier to toggle a Blueprint parameter to be passed by reference. Linear Color ToHex is now exposed to Blueprint. Added a Blueprint callable function to shuffle an array using a 'random stream' for the source of randomness. Added gather search data for BlueprintExtensions. This is used by the FindInBlueprint system. Crash Fix: Fixed potential crash when bFavorPureCastNodes is enabled. Bug Fix: Fixed a typo in the FGraphNodeCreator class description. Fixed the asset loader to preserve component transform in the editor after a Blueprint has been reparented. Fixed a bug that could cause sparse class data to be lost on load after reparenting a Blueprint. Fixed a bug that prevented you from moving a Blueprint to a location that has a redirector that points to a Blueprint. This can often happen if you move a Blueprint then attempt to move it back. Both Find-in-Blueprint and Blueprint namespace asset discovery are now deferred until after the initial asset registry file scan is complete. Soft class objects are now included in a cooked set When using CookSettings.SkipOnlyEditorOnly assets referenced by Blueprint bytecode. Blueprint Compiler Improvement: Improved redirect support for Blueprints. A reflected Blueprint type can now be changed without breaking existing content, so long as an autocast function exists for the two types. Crash Fix: Fixed a rare crash during Blueprint compilation after removing a variable from a component and compiling. The compiler was delta serializing against an archetype of a different type. Fixed a crash when a skeleton class's CDO is accessed when the native class its based on is using sparse class data. Bug Fix: Improved handling for variables that were moved out of a class and into the corresponding sparse class data. Stale DelegateSignatureGraphs are now removed before compiling, child Blueprints no longer improperly mutate their parent's delegate properties. ExpandEnumAsExecs now always uses first Exec if an argument name matches Enum value (resubmit) ExpandEnumAsExecs was using an ambiguous pin lookup. Fixed erroneous deprecation of BreakVector3f for float-based math functions. Fixed a bug in Blueprint compilation that occurred when a Blueprint was recompiled when it had garbage subclasses. Fixed references to trashed function objects after generating delegate properties during a batched Blueprint asset compile with inter-batch dependencies. Avoid potential collisions with existing non-transient objects when creating transient event stub graph artifacts during Blueprint ubergraph compilation. Removed: Removed HasNativeBreak from FVector3f. Blueprint Editor New: Added the ability to mark custom events as private. Added default FunctionFlags values that custom events would need for specifiers. Modified the UI to show the access specifier drop down for both function entry nodes and custom events. By default, the editor will no longer mark outer level/OFPA assets as dirty when propagating default value changes to instances that already match the archetype's value. Instances will still be marked dirty if the default value change results in the instance value becoming realigned with the archetype. Added new Blueprint editor settings to control how assets selected in the Content Browser will generate pre-bound actions when invoking the Blueprint graph context menu. The default settings now disable this feature in order to improve menu responsiveness. By default, the editor will no longer mark an outer level/OFPA asset as dirty after manually compiling its underlying Blueprint type. Non-blocking context menu UI mode is now enabled by default in the Blueprint graph editor. Improvement: Optimized async Blueprint context menu building by avoiding resorting and inserting nodes in the desired order. Improved performance of Blueprint debugger by only populating the children of visible properties and not recursing further. Crash Fix: Fixed crash in SGraphPin::GetPinLabel after removing pins from a node. Fixed crash when compiling a Blueprint after invoking Undo in the editor. Fixed an editor crash when editing sparse class data fields in Blueprint class defaults. Bug Fix: Reduced the amount of graph refreshes performed in the Blueprint editor, reducing hitching and flickering when making changes in the Blueprint graph editor. Fixed Private and Protected functions from not displaying in the context menu in child Blueprints. Fixed bug that would cause properties in an object's sparse class data to not display as altered in the diff panel, even if they had been altered. Fixed malformed asset resulting from duplicating a Blueprint with sparse class data. Fixed variables that are dragged and dropped to the node with split struct pins from not being added. Fixed issue where disconnecting an orphan pin would cause ensure to trigger due to an invalidated graph pin. Fixed the potential for data loss when loading hierarchical Blueprint class assets with circular dependencies asynchronously in the editor. Fixed the Blueprint Namespace entry widget's tree view from not working properly when only one root item matches the search box filter text. Dragging new connections from interface(output)->object(input) will now include an explicit autocast node. Additionally, it is no longer possible to connect an array of interfaces output pin to a function call node's Target input pin. These changes apply to new connections only; existing connections will continue to work as before. Fixed a bug that prevented copy pasted Actor Components from being removed. Deferred validation of user-defined struct types in the pin type selector list until selection time for the member variable type widget in the user-defined struct asset editor. Invocation of the pin type selector menu for member variables is now a bit faster as a result. The editor will no longer orphan pins during Blueprint graph node fixup if they are linked to an autocast or other implicit conversion node that supercedes the original link. Avoided unnecessary serialization of editor-only references at cook time when analyzing Blueprint assets for external imports. Relocated where we purge stale references from the Blueprint editor's MRU document list in order to avoid attempts to resolve those paths during asynchronous asset loads. Blueprint Runtime Improvement: Optimized UUserDefinedStruct::InitializeStruct by avoiding redundant operations for STRUCT_IsPlainOldData macro instances. Bug Fix: Fixed a memory scribble when constructing struct literals with bitfields. Added runtime capacity checks to Blueprint-facing script container library API to mitigate crashes due to integer type overflow. Fixed a bug that caused circular component attachments when changing the constructor of native classes. Gameplay API Change: It is now safe to call Super::ActivateAbility in a child class. Previously, it would call CommitAbility. This will make it a little easier to write triggers/modifiers in Enhanced Input that want to access the Local Player if they want access to the User Settings object to check aim sensitivity or other things. This is useful piece of state for games to use during pawn initialization. Commands are prefixed with AbilitySystem. GameplayTagQueries that are empty are ambiguous and should be handled on a case-by-case basis by the caller. We can go back to the old way of loading the source texture if this breaks something with the \\"Paper2d.DisableSyncLoadInEditor\\" CVar flag. passing nullptr into SDetailsViewBase::HighlightProperty no longer does nothing and will instead un-highlight all properties This is a critical fix if you are attempting to use the input device subsystem. New: Added an option to a Targeting System's AOE Targeting Task to offset based on relative space rather than world space. Moved TargetingSubsystem functions into the same metadata category. Added ULocalPlayerSaveGame base class to the engine that provides utility functions for saving and loading a save game object for a specific Local Player. This wraps the existing save/load logic on GameplayStatics and provides functionality needed to properly support save/load on non-PC platforms. OnAvatarSet is now called on the primary instance instead of the CDO for instanced per Actor Gameplay Abilities. Added the source location of the AOE task trace as the TraceStart of any FHitResult returned by that task so users have that information available after targeting. Input slots now support enum ranges. Updated enhanced input settings to allow deferral of settings updates. MatchAnyTags, MatchAllTags, and MatchNoTags tag queries now have exposed make nodes in Blueprint. Marked UTargetingTask as Abstract so it can't be chosen for EditInlineNew properties. Added Data Store for Collision parameters used by the AOE targeting Task. Added hook to override collision data from the data store in the AOE Targeting Task. Exposed Async Task in the Perform Targeting node so we can get the Targeting Handle before get targeting results. Added GetPlatformUserIndex function to LocalPlayer and fixed comments to explain the different indices. Expanded AInfo's constructor to support a default ObjectInitializer parameter, covering cases where derived classes could override the default constructor and miss AInfo-specific initialization. Allow both Activate Ability and Activate Ability From Event in the same Gameplay Ability Graph. AnimTask_PlayMontageAndWait now has a toggle to allow Completed and Interrupted after a BlendOut event. Post-process settings from camera shakes and camera animations are now handled as overrides, rather than base world values. Added aspect ratio axis constraint override on camera components. Added a GetOwningLocalPlayer function to the UPlayerInput class. GAS: Added a GameplayTagQuery field to FGameplayTagRequirements to enable more complex requirements to be specified. Added a ReceivedPlayerController function to UPlayer, called from it's owning Player Controller when the owning APlayerController pointer is now valid on that player. Alongside this, add a \\"OnPlayerControllerChanged\\" delegate to ULocalPlayer and Local Player Subsystems for an easy hook in. Introduced FGameplayEffectQuery::SourceAggregateTagQuery to augment SourceTagQuery. GAS: ModMagnitudeCalc wrapper functions have been declared const. Marked all exec pins as advanced view on Input Action event nodes except for \\"Triggered\\". Added continuous Input Injection to Enhanced Input. Added support for setting AllowedTypes on FPrimaryAssetId function parameters. To use this, add UPARAM(meta = (AllowedTypes = \\"SomeAssetType\\")) to a parameter. Added EKeys::AnyKey support to Enhanced Input. GAS: Extended the functonality to execute and cancel Gameplay Abilities & Gameplay Effects from a console command. Added the ability to perform an \\"Audit\\" on Gameplay Ability Blueprints that will show information on how they're developed and intended to be used. FGameplayTagQuery::Matches now returns false for empty queries. Exposed FDateTime's To/From Unix Timestamp functions to Blueprints. Added support for properly replicating different types of FGameplayEffectContext. Updated FGameplayAttribute::PostSerialize to mark the contained attribute as a searchable name. FGameplayEffectContextHandle will now check if data is valid before retrieving \\"Actors\\". Retain rotation for Gameplay Ability System Target Data LocationInfo. Gameplay Ability System now stops searching for PC only if a valid PC is found. Updated GetAbilitySystemComponent to default parameter to Self. When diffing assets, their detail panels now have colored highlights signifying the changed properties. Updated the comments on the Enhanced Action Key Mapping and the Input Action asset to be explict about the order of which modifiers are applied. Modifiers defined in individual key mappings will be applied before those defined in the Input Action asset. Modifiers will not override any that are defined on the Input Action asset, they will be combined together during evaluation. Added callback options with metadata on FInstancedPropertyBag Added a TypeFilter callback to filter out some types when changing the type of a property Added a RemoveCheck callback to cancel the removal of a property Added a generic way to invoke You can now merge DataAssets that are conflicted in revision control by right clicking on them in the content browser and selecting \\"Revision Control/Merge\\". Implemented support for changing default type in PropertyBag detail view Also move Metadata names to a seperate header to reference all available metadata values for StructUtils Added a Debug Display Name string to Player Controller input modes. This is useful for doing a quick debug session of why input may not be getting to the player because it could be consumed by the UI. Added clarification to the TouchInterface directions. Marked functions as virtual in AbilityTask_WaitTargetData. Added an advanced setting on the Input Action for the input accumulation behavior. This setting would allow you to change an input action to cumulatively combine input from different Action Key Mappings instead of always accepting the mapping with the highest key value. A practical example of when to use this would be for something like WASD movement, if you want pressing W and S to cancel each other out. Added filtering on containers you can use with Properties for StructUtils. Added SSourceControlReview::OpenChangelist method to allow external code to open the changelist review dialog. Diff tool overhaul that allows asynchronous diffing and improves diff accuracy for details panels. Added a EHardwareDeviceSupportedFeatures and EHardwareDevicePrimaryType enums to hardware device identifiers. These allow hardware device identifiers to set flags for themselves to identify some common traits that they have and check what kind of support they have. These are config flags that provide your game a method to change what they support for a given input device and add custom hardware types if desired. Added support for instanced struct object references in DataTable and DataRegistry. Allow for input injection based on a player key mapping name as well as a UInputAction pointer. We can do this by keeping track of the UInputAction* associated with each player mapping. Keep track of the owning Platform User ID of each player mappable key profile so that you can access the Local Player without needing to get the outer of the profile, which will be useful for custom profile subclasses. Improvement: Refactored camera shakes' time management. Improved post-process settings blending between view targets. Added option for ProjectileMovementComponent to avoid interpolation transform updates on some frames when an object isn't as relevant. Default version is based on not recently rendered but can be extended. Added FScopedMovementUpdate around movement of interpolated component in ProjectileMovementComponent. This avoids moving its child components more than once if it then again simulates during the tick. Crash Fix: Fixed a crash when trying to apply gameplay cues after a seamless travel. Fixed a crash caused by GlobalAbilityTaskCount when using Live Coding. Fixed UAbilityTask::OnDestroy to not crash if called recursively for cases like UAbilityTask_StartAbilityState. Fixed a crash caused by having entries added to the AsyncTargetingRequests while they were being processed (When an async targeting request node is chained with another one). Now we queue those and process them at the end of the tick. Fixed AddTimedDisplay crash when changing a level. Prevented a crash when attempting to add an invalid subobject class type with the Subobject Data Subsystem. Fixed a crash caused by AGeometryCollectionISMPoolActor holding a garbage pointer. Fixed a crash when diffing an Animation Blueprint. Fixed a crash when diffing asset additions and removals in the review tool. Bug Fix: Use existing GameplayCueParameters if it exists instead of default parameters object in RemoveGameplayCue_Internal. Changed Play in Editor initialization to create game instance subsystems before it creates and initializes world subsystems to match how it works in packaged games and map transfers. Fixed GetInputAnalogStickState double-to-float wrapper from calling the wrong function. GameplayAbilityWorldReticle now faces towards the source Actor instead of the TargetingActor. Cache trigger event data if it was passed in with GiveAbilityAndActivateOnce and the ability list was locked. Fixed RawScores from getting populated incorrectly in Targeting System Tasks. Fixed an issue with Blueprint Debugging 'StepOver' command stopping in incorrect Blueprints. TargetingSelectionTask_AOE now respects source actor rotation instead of being axis-aligned. Skip processing TargetingTaskSet elements that are null. Fixed SCS_Node Actor scenecomponents from not getting re-registered correctly after Build events. Fixed some issues with blending out some infinite camera shakes. Fixed composite camera shake pattern duration info as shown in sequencer. Support has been added for the FInheritedGameplayTags to update its CombinedTags immediately rather than waiting until a Save. Fixed Actor loading in the editor to correctly set the transform when a native root component changes class during reparenting. Fixed issue affecting the timing of server-forced pawn position updates when time dilation was involved. Limited the length of a player mappable name to the max length of FName's to properly check for the max length. This fixes a possible ensure that you could get if you used a name that's too long. Fixed regression that would cause erroneous \\"AttachChildren count increased while detaching\\" error when a USceneComponent was garbage collected Prevented AActor::RerunConstructionScripts from calling a redundant SetWorldTransform inside ExecuteConstruction when the transform hasn't changed. This was causing error accumulation in the relative and world transforms of a component that has an attach parent. Fixed character movement issue that could prevent client moves from being submitted at the intended rate when time was dilated. Fixed issue where a Character could intend to stay vertical (aligned with gravity) but unable to change pitch or roll to get there. Moved ShouldAbilityRespondToEvent from client-only code path to both server and client. Fixed an issue where subobjects that are stored in container properties (TArray, TSet, and TMap) would not show up in the details panel if they were created dynamically at runtime. Newly created Blueprint Child Classes are now marked as Transactional and therefore allow undo immediately upon creation, rather than after first save. Fixed pathing warnings when working with certain types of data assets and data tables. Only attempt to auto upgrade to Enhanced Input if the project has a name. This solves an issue where you would get toasts about EI from the project launcher. Check for null world pointer before starting/stopping shakes. Added some data validation for Combo Step Completion and Cancellation States to make sure at least one state is set. Do not attempt to synchronously load the source texture of a Paper2D sprite if we are already in the ASYNC loading thread. This can occur in the editor if cooked content is enabled, on post load of the sprite asset. Fixed FAttributeSetInitterDiscreteLevels from not working in Cooked Builds due to Curve Simplification. Set CurrentEventData in GameplayAbility. Ensure MinimalReplicationTags are set up correctly before potentially executing callbacks. Made Blueprint functions on the camera animation subsystem gracefully handle null pointers. Fixed comment for UPawnMovementComponent::AddInputVector. Fixed ShouldAbilityRespondToEvent from not getting called on the instanced GameplayAbility. Gameplay Cue Notify Actors executing on Child Actors no longer leak memory when gc.PendingKill is disabled. Made AActor::SetActorTickEnabled virtual. Fixed an issue in GameplayCueManager where GameplayCueNotify_Actors could be 'lost' due to hash collisions. WaitGameplayTagQuery will now respect its Query even if we have no Gameplay Tags on the Actor. PostAttributeChange and AttributeValueChangeDelegates will now have the correct OldValue. The minimal view info has been correctly reset to prevent parameters from \\"leaking\\" from one view target to the next. Applied current scale and easing value to post-process settings weight Fixed FGameplayTagQuery from not showing a proper Query Description if the struct was created by native code. When bIgnoreAllPressedKeysUntilRelease is true, don't only ignore key presses for keys that were in the previous key mappings, but for every key. Fixed not being able to Copy & Paste the Mappings list in an Input Mapping Context. Only modify config files if the project has a name, which avoids modifying default engine ini files from the project launcher. Fixed package load warning when loading changelists in the review tool that contain non-asset files. Resetting the value of the action value bindings when the action is not present in the current mappings. Added a \\"Force Reset\\" flag to device properties that gets set when PIE ends. This fixes an small bug where the light color or trigger effect could persist between PIE sessions. Updated text exporting of objects (used for copy/paste) to sanitize property names containing special characters that would otherwise break the parser on import Marked the FKey::KeyName as EditAnywhere so that its value is correctly propagated if it is changed on a subobject. Without this, the KeyName property will be filtered out when determining if a property has changed on a subobject, leading to an unusable UPROPERTY. This has no effect visually in the editor since the FKey has a custom details row. Fixed non-deterministic behavior during cook time with regard to the Scale Method pin in on SpawnActorFromClass nodes Fixed a regression that caused SDetailsViewBase::HighlightProperty to not support nullptr and thus removing any way to unhighlight a property Fixed an issue where some key mappings would incorrectly be displayed as overriden in the \\"showdebug EnhancedInput\\" command. This was happening because the AddUnique call to the array would always add a new mapping, since it was comparing the instanced arrays of modifiers and triggers. Removed an invalid \\"break\\" in a loop that created an order dependant check for chorded actions being blocked. Fixed the Input Device Subsystem not finding a valid Game World in a packaged windows project.The subsystem was searching for a PIE only play world, not a cooked game world as well. Fixed an issue when comparing enhanced action mappings during RebuildControlMappings because of a deep copy of the modifiers and triggers arrays, so any time we compare a new instance to old instance it would return false no matter what. Fixed a bug that caused OneFilePerActor Actors to always diff the local asset against itself instead of against a previous version. Ensure that the UAbilitySystemGlobals::InitGlobalData is called if the Ability System is in use. Previously if the user did not call it, the Gameplay Ability System did not function correctly. Fixed route gamepad to second window. When this setting is enabled, if you have a gamepad connected to the editor, all gamepad inputs will be routed to the next PIE window. Reduced false positives in text-based asset diffs by excluding export paths from the diff. Fixed a bug that caused RefreshPropertyObjects in SKismetInspector to not get garbage collected. Deprecated: Removed unused function FGameplayAbilityTargetData::AddTargetDataToGameplayCueParameters. Removed vestigial GameplayAbility::SetMovementSyncPoint Deprecated UPlayerMappableInputConfig in favor of the new UEnhancedInputUserSettings with 5.3. Deprecated the FPlayerMappableKeySlot and all its related functions for 5.3, along with all the old player mapped key functions in favor of UEnhancedInputUserSettings. Removed: Removed unused replication flag from Gameplay tasks & Ability system components Removed ensure when no combo actions are present. Logs a warning instead. Mass New: Simplified UMassActorSpawnerSubsystem subclassing by moving post actor spawn steps from SpawnActor into SpawnOrRetrieveFromPool. SpawnActor now calls World->SpawnActor. Added the bRandomize property to FMassTransformsSpawnData to control whether UMassSpawnLocationProcessor assigns transforms randomly (defaults to true to maintain current behavior) or if false, assigns transforms in order. Bug Fix: Fixed a bug in FMassEntityManager::BatchDestroyEntities where the ObserverManager wasn't being informed of the entity deletions, causing fragment destructors not to run. Fixed processor execution flag for world for PIE. Fixed multithreading access detector in FMassBatchedEntiityCommand's Add methods. Networking New: [NetBitArray] Added IsBitSet. Added CombineMultiple to run bit operations on two const bit arrays in 1 loop. Added ToString that prints how many set bits the array currently has. Slightly expensive do not abuse with active logs. Added FNetBitArrayPrinter utility functions. [Network] Added FNetContext for user code to tell if inside a real network RPC or not. Added support to FNetContext::IsInsideNetRPC in both Iris and legacy. [NetBitArray] Added InitAndCopy functions on FNetBitArray. Used to quickly construct a bit array from an existing source, either bitarray or bitarrayview. Added Set functions used to overwrite the bitarray with the word operations of two other arrays. [SubObject Replication] Added cvar net.SubObjects.DetectDeprecatedReplicatedSubObjects. When enabled, it will ensure that it detects that ReplicateSubObjects is implemented in a class that switched over to the new registration method. This is only available in development builds. [NetDriver] Added FWorldDelegate::OnNetDriverCreated delegate called after any NetDriver was created. [Iris] A struct derived from a struct with a custom Net Serializer somewhere in the hierarchy is no longer required to implement a Net Serializer itself. The custom Net Serializer is automatically used appropriately and additional replicated properties will be replicated as expected. Clients now disconnect on a bunch error when Iris is enabled. This prevents trying to deserialize packets indefinitely. When an error is set, it's unrecoverable. FNetBitArray can now be used in range-based for loops. This loops over set bits and gives you the index of the set bit. Added documentation to Network Prediction plugin README file. Added ELifetimeCondition COND_Dynamic support. COND_Dynamic allows for a property to decide its actual replication condition after instantiation of the actor/component rather than being the same for all instances. The condition can be changed using the macros: DOREPDYNAMICCONDITION_INITCONDITION_FAST: when used in the object's GetReplicatedCustomConditionState implementation DOREPDYNAMICCONDITION_SETCONDITION_FAST: in any other place where it's appropriate to change the condition. If the condition is never modified, thus remaining COND_Dynamic, the property will always replicate when changed. It's possible to use the DOREPCUSTOMCONDITION_ macros on properties with this condition. [Iris] NetObjectConnectionFilter is now available for Iris replication. This can be used to dynamically filter objects to only replicate to certain connections. The main use case is when objects added to this filter may also be dependent objects as dependent objects override dynamic filtering, but not any type of static filtering. Added additional Insights CPU scopes in Network Prediction plugin code. Added a unit test program for the Network Prediction plugin that covers basic simulation ticking in forward prediction and interpolation modes. ReplicatedPredictionKeys now explicitly copies ReplicatonID and ReplicationKeys to properly support being initialized with preserved ReplicationID. Net Driver updates: Collect the amount of packets sent and received by each connection, each frame. Output the average and max per-connection packets received and sent every frame in CSV Profiler. Added net.ForceOnePacketPerBunch console variable to force every packet to contain a single bunch. This can be used to debug rare ordering issues when two actors are dependent, but should not. Added net.AlwaysUpdateGuidReferenceMapForNetSerializeObjectStruct console variable to always update GuidReferenceMap entries for NetSerialize structs with object properties, in order to prevent issues with old property values being applied when the struct's object reference is remapped. CVarNetEnableDetailedScopeCounters is now cached in a global variable in order to prevent unnecessary work getting the console variable value every conditional scope cycle counter. ReplicateCustomDeltaPropTime is now only recorded if the object has any custom delta properties. Crash Fix: Fixed the seamless travel handler to handle PIE renaming for the transition map the same way it does the destination map. This fixes a crash with multiplayer PIE where it tries to reuse the same map package Bug Fix: Fixed GetNetMode to work properly in Play in Editor for functions like InitGame called halfway through world startup, and fixed related issues with EnableListenServer and dedicated server PIE worlds. [ReplicationGraph] Added fix to prevent sending multicast RPCs on a channel that is closing but not yet cleaned up. [ReplicatedSubObject] Fixed refcount breaking due to accessing invalid memory from a TSet iterator after having removed the iterator. [RepGraph] Fixed log spam caused by actors going outside the legal world bounds and staying OOB. Only log a warning once when the actor goes OOB. net.ReplicationGraph.PrintGraph now prints the list of DynamicSpatializedActors monitored by the Grid2D node. Fixed an issue where actor channels were closed due to level being unloaded/streamed-out destroying NetStartupActors unless the channel had been explicitly broken. This behavior can be disabled by setting the console variable as: net.SkipDestroyNetStartupActorsOnChannelCloseDueToLevelUnloaded 0. Fixed behavior of simulated proxies controlled by the Network Prediction plugin when there's no autonomous proxy, such as when a client un-possesses a pawn and doesn't immediately possess another one. Interpolation of simulated proxies now continues while there's no local autonomous proxy. FastArraySerializer is no longer allowed to modify state of Archetype or CDO when initializing base state as this lead to inconsistencies with assignment of ReplicationID Fixed issue with missing detection of items being marked dirty. Fixed issue with NetTraceReporter crashing when processing certain trace files. Fixed an issue where FNetBitArray::FindLastZero returned index out of bounds for array sizes not aligned with the size of the storage. Deprecated: [NetDriver] Deprecated NetServerMaxTickRate variable and replaced them with Get/Set functions. Added FOnNetServerMaxTickRateChanged delegate. Register to receive callbacks when the server tick rate changes. Deprecated obsolete packet handler components. Removed: Removed calls to SetNetVersionsOnArchive and SetNetVersionsFromArchive and redirect FInBunch::GameNetVer and FInBunch::EngineNetVer to use the internal connection pointer. Removed FloatCastChecked in PreFrameReceive to fix an assert with a large DeltaTime that could occur in certain circumstances. Level Design and Art Tools Geometry Core New: Added the ability to store and fetch temporary debug named-FDynamicMesh instances via global C++ functions UE::Geometry::Debug::StashDebugMesh() and FetchDebugMesh(). A new cvar geometry.DynamicMesh.EnableDebugMeshes must be set to 1 to enable this functionality. A console command geometry.DynamicMesh.ClearDebugMeshes can be used to clear the debug mesh set. The FConvexDecomposition3 class now has a merge-only API, which can be used to approximate an input set of convex hulls with a smaller number of convex hulls. Added Transform and Inverse Transform functions to Geometry Core's TPlane3. Added Transform Normal and Inverse Transform Normal functions to Geometry Core's VectorUtil. Added a FSphereCover concept as a new, optional representation of negative space for FConvexDecomposition3. This can be used to guide the merge phase of convex decomposition, more accurately keeping the convex hulls away from the object's negative space. Multiple methods are provided to generate a sphere covering that efficiently covers the negative space, with settings to allow some leeway to ignore negative space in small gaps or near the object surface. The Clipper2 wrapper in the Geometry Algorithms module now supports taking the intersection, union, difference, and exclusive-or of arrays of polygons. Added FindAllHitTriangles function to get all the triangles intersected by a ray (not just the closest one). Dynamic Mesh Component now provides the option to control which color-space conversion is applied to Vertex Colors when creating the Render Buffers from the UDynamicMesh vertex color attribute (SRGB to Linear, Linear to SRGB, or No Conversion). This option is exposed as the Color Space Mode property on the class, as well as via new Blueprint functions Set Vertex Color Space Transform Mode and Get Vertex Color Space Transform Mode. The default is to not apply any conversion or transform. DynamicMeshComponent now supports specifying custom vertex color remappings in C++, by passing a lambda to the new API function SetVertexColorRemappingFunction. ClearVertexColorRemappingFunction and HasVertexColorRemappingFunction have also been added. Added theClear Vertex Color Remapping function. Added theHas Vertex Color Remapping function. Added a Split Attribute Welder function. FSplitAttributeWelder can be used to weld split-attributes that share the same vertex in the parent mesh. Bug Fix: Fixed exact predicate float control settings for clang, making exact predicates work correctly on platforms where clang was configured to use fast math. Made the Geometry Core AABB types respect the IsValid flag on conversion to or from the Core FBox type. Dynamic Mesh Component can now render a wireframe overlay in shipping builds, if an Engine wireframe material is available. Prevented an issue where the editor might crash when determining the number of UV channels during mesh conversion. Fixed issue in TMeshSimplification where explicitly-constrained vertices could result in collapses that ignore geometric constraints. Geometry Script New: Added two functions that compute the shortest distance between mesh points: Get Shortest Vertex Path (using Dijkstra ) and Get Shortest Surface Path (using intrinsic mesh edge flips.) Added the ability to trace a straight line on a mesh surface through geodesic functions. Added new mesh bone weight functions for getting information about individual bones of the skeleton stored in the dynamic mesh: Get Root Bone Name Get Bone Children Get All Bones Info Get Bone Info Added the function Blur Mesh Vertex Colors for blurring mesh vertex colors. Added the function Transfer Bone Weights From Mesh for transferring bone weights from one mesh to another. Created new functions Discard Bones From Mesh and Copy Bones From Mesh. Dynamic meshes now inherit the skeleton information when converting from skeletal meshes. Create New Skeletal Mesh Asset From Mesh (LODs) can now use the proportions of bones stored in the input dynamic meshes. This is enabled through the Use Mesh Bone Proportions flag in the Geometry Script Create New Skeletal Mesh Asset Options. Added Create New Static Mesh Asset From Mesh LODsand Create New Skeletal Mesh Asset From Mesh LODs functions for creating static and skeletal meshes from an array of LODs instead of just a single mesh. Added the Append Bounding Box function,which takes an FBox instead of separate box parameters Added the Mark For Mesh Rebuild Blueprint function to Generated Dynamic Mesh Actor, which allows other Blueprints to explicitly queue up a Mesh Rebuild event without re-running the Actor Construction Script. Added Get Vertex Connected Triangles, Get Vertex Connected Vertices, and Get All Split UVs At Vertex functions, which can be used to query the one-ring triangles or vertices of a vertex, as well as the set of split UVs at a vertex in a given UV channel Added the ability to run Delaunay Triangulation on an input set of points, and optionally a Constrained Delaunay Triangulation that preserves specified edges as well. Updated the dynamic mesh component to expose new Blueprint functions Notify Mesh Updated and Notify Vertex Attributes Updated. These functions can be used to force either a full or partial update of the rendering buffers for the Component after the UDynamicMesh has been modified with deferred notifications. Added the function Recompute Normals For Mesh Selectionto allow normals recomputation to be limited to a mesh selection. Added the Compute Mesh Local UV Param function, which can compute an Discrete Exponential/Log Map (ExpMap) UV parameterization on a bounded-geodesic-radius area of a mesh. The subset of computed vertex/UV pairs is returned as output, rather than set on a mesh UV channel. Added a Channel Pack node which has up to four input textures and creates an output texture where the RGBA channels are sourced from the inputs. Added a new function, Select Mesh Elements In Box With BVH allowing efficient range queries on large meshes using a bounding box and an AABBTree. Added the Get Mesh Volume Area Center function to compute the center of mass for a mesh, as well as volume and surface area. The dynamic mesh component's Externally Provided tangent type setting has been renamed From Dynamic Mesh. Added new polygon and path offset functions. Added new functions and data types for managing simple polygons (polygons without holes) and lists of general polygons (polygons with support for optional holes) in 2D. Editor-only functions Stash Debug Meshand Fetch Debug Meshhave been added, which can be used to save temporary copies of UDynamicMesh objects associated with string names. The cvar geometry.DynamicMesh.EnableDebugMeshes must be set, otherwise these functions are ignored. Improvement: Updated the polygon triangulation functions to have better error handling and a more robust winding-number-based fallback mode to generate better results in cases where input polygon edges overlap. Recompute Normalsfunction now has a bDeferChangeNotifications option. Updated the Copy Mesh From Component function to support Instanced Static Mesh Components; each instance of the static mesh is appended to the output mesh TheBake Texture function was updated to expose an option to control the type of texture filtering applied. Updated dynamic mesh components to use the tangents provided on their dynamic mesh by default, and the setting controlling this tangent source is now also exposed in the UI under the Dynamic Mesh Component properties. Bug Fix: Removed incorrect clamping of the Radial Samples parameter inAppend Disc. Fixed an issue where passing an invalid path to Geometry Script's new asset utility functions could cause a crash. Package names are now automatically sanitized before use by these functions. Fixed issue where Create Skeletal Mesh Asset From Mesh was not assigning materials correctly. Fixed a crash when splines with duplicate constant points are converted to polylines. Updated modules in the GeometryScripting plugin that are Runtime-capable to load in the PreDefault loading phase, before user construction scripts that may depend on Geometry Script. Modeling Tools New: Added a Mesh Topology Selection Mechanic which enables or disables different selection modes in the details customization. Added a Generate Lightmap UVs option under the New Mesh Objects settings in the Modeling Tools Project Settings panel. If enabled, this will enable light map UVs on any new static mesh created within Modeling Mode. Moved the Bake RC tool from Mesh Modeling Tools Exp to Mesh Modeling Tools Editor Only Exp module. Adding a two-sided vertex color material. Same as Mesh Vertex Color Material but with Two Sided checked. Useed the new two-sided material in the cloth weight map paint tool so that we can paint on the back side of the 2D panels. The Bake Transform and Edit Pivot tools now update all LODs by default, not just the active LOD, and exposed an 'Apply to All LODs option to control this behavior. Updated Simplify To Minimal Planar to work on the boundary of meshes. Added the Copy From Inputs option in Mesh to Collision tool to transfer existing simple geometry over to the target. Added helper methods to count the number of Actor Components which match Target Requirements to assist with special tool needs. Added helper methods to test for existence of volume components and components that support UVs in Tool Targets. Updated the box finding code in MeshSimpleShapeApproximation to prefer to orient the boxes such that they align with the world frame better. Harden and improved various conversions between dynamic meshes and volumes, to make modeling tools work more reliably on volumes. Added a Gradient Interaction type to the Cloth Paint tool. The user selects high and low vertices and a gradient is automatically computed between them. Added the Mesh Vertex Paint Tool has been added to Modeling Mode. This Tool can be used to directly paint asset vertex colors (but not per-instance override vertex colors). Created the Draw Spline tool for drawing splines and spline-based blueprints. Added a Revolve Spline tool. Moved various settings from the secondary toolbar to the cog icon in quick settings, since the secondary toolbar is not enabled by default in some builds. Added a PolyGroupID option to the Bake Textures and Bake Vertex Colors tools. Exposed mesh simplification options in the Mirror and Plane Cut tools, to reduce excess triangulation along the cut and mirror plane. Added a reusable geometry selection visualization system intended to be used in modeling tools with minimal boilerplate. Unbinded the toggle gizmo action in some tools from a default hotkey to prevent users from accidentally pressing it and thinking that the tools are broken. Users can still set their own hotkey if their workflow benefits from it. Adjusted how the Combined Transform Gizmo displays scale axis handles when only two axes are needed. The old approach had the handles react to the camera direction at all times, causing issues in the UV Editor and inconsistent orientations of the handles relative to the plane in the case of only two axes. The new approach only is reactive to the camera in cases of one or three axes and locks the handles into a single plane if exactly two axes are configured in the gizmo. Added a Simple Collison Editor tool to assist with editing of simple collision primitive shapes directly within Modeling Mode for static and dynamic meshes. Added Subdivide tool improvements dealing with meshes with open boundaries: Factor out extra corner finding code from PolyEd and add support for it in the subdivide tool. Added support for rounded corners for mesh boundaries. Override subdivision scheme during tool usage rather than just at tool start, to allow extra corners to fix some issues. Added some clarifying comments about schemes. Changed the Mac bindings for grid size changes in Cube Grid tool to Option + A/D because Option + E is consumed by Mac. Added geometry selection support to the Normals tool. Added an edge simplification operation to the PolyEdit tool. Added a Mesh Splines tool, which creates meshes from a selection of spline components. The tool enables triangulation and extrusion of the splines, as well as Boolean combinations of the spline shapes. Improvement: Updated the Weld Mesh Edges tool to optionally merge attributes. Improved the documentation of options in the SubDiv tool. The BakeRC tool now outputs a material which is configured to use any generated textures. UModelingObjectsCreationAPI was extended to support materials by duplicating a given material. Updatedthe Pattern tool to have an option to place a random selected object at each pattern position, rather than always placing all selected objects at each position. Updated the Mesh To Collision, Convert, and Transfer tools to properly handle simple collision on Dynamic Mesh Components. Updated the Displace Mesh Tool to show feedback about the vertex and triangle counts of the output mesh. Moved the preview settings to above the list of generated textures in the BakeRC tool Updated Volume to Mesh tool's tooltips to better reflect the tool's behavior. Bug Fix: Fixed a bug where the Trim tool starts a potentially expensive boolean calculation when only the opacity color alpha changes. Updated the New Mesh Objects options under Modeling Tools Project Settings to be used more consistently by all Modeling Mode tools that create new mesh objects. Prevented several UV modeling tools from launching on volume targets, which are not applicable target types. Fixed an issue where the viewport level collision rendering would not correctly show the updated collision geometry after accepting the results of the Mesh to Collision tool. Fixed the static mesh to dynamic mesh conversion not recomputing tangents with the recompute tangents option set, in some cases. Improved checks for launching tools against assets that might be cooked in the editor. Updated the Pattern Tool to emit contextually correct static mesh actors. Fixed GetElapsedComputeTime so that the preview material kicks in after the proper delay. Updated the Convert Tool to no longer copy incorrect Material IDs to the output mesh if the the Transfer Materials option is disabled. Prevented several tools from running on volume targets since the operations didn't apply to that target type. Dynamic mesh components now show vertex colors when the setting to show vertex colors is enabled in the viewport. Fixed an issue where the Extrude Path tool generated a result with incorrect extrusion in some cases. Hit-testing for the rectangular scaling and plane-translation handles in the Modeling Mode gizmo has been improved. Fixed per-channel baking of curvature and ambient occlusion for the Bake Vertex tool. The Subdivide tool now works on Mac and Unix targets. Fixed previous collision geometry incorrectly remaining visible when Collision Type was changed in the AutoLOD tool. Now only the collision geometry for the active Collision Type is shown. Fixed various tooltips, edit conditions and reset buttons in the AutoLOD tool Fixed an issue where the PolyCut tool would generate a bad result if the cutting polygon was self-intersecting. Updated the Bend operation in the Warp tool to support negative bend angles. Fixed a crash in the Edit Pivot tool when multiple tool targets are backed by the same asset. Fixed static mesh components created by modeling tools to set to static mobility by default, instead of movable. Improved Project and Remesh tool's Target Edge Length tooltip, explaining why it's not starting at the default value hardcoded into the property. Replaced the wireframe visuals in UV Layout Preview to use Mesh Elements Visualizer, to address Z-fighting visual artifacts in wireframe displays. Fixed an issue in the Pivot Actor tool where changing the transform using the gizmo did not cause the reset to default arrow to appear in the details panel. Fixed a crash in the Subdivide tool when adding Extra Corner Vertices was enabled for some meshes. Extra Corner Vertices can now only be added along open boundaries. Adjusted the Project tool's settings to properly disable the smooth filling options when smooth filling is disabled. Fixed a crash in the Bake Transform tool when some selected meshes have the same source asset. Fixed issue with the Recompute UVs Op where an ensure would fire when no components contained at least one full triangle. Updated the Simplify tool to conditionally disable the Prevent Normal Flips and Prevent Tiny Triangles, depending on the simplify algorithm used. This also enables support for the Prevent Tiny Triangles and Prevent Normal Flips under certain tool settings. Updated The Voxel Blend and Voxel Offset tools to warn about possible artifacts when processing meshes with open boundaries when the Vox Wrap Preprocess option is not enabled. Fixed computation of edge collapse lerp parameter which reduces artifacts in UV layers when remeshing. Fixed readability issue in mesh statistics display. Adjusted the behavior of the Mesh Visualizer settings to properly disable when the Visible property is checked off. Prevented a crash when asset editors are closed with local changes during an asset reload, due to the static mesh tool target checking for transaction success incorrectly. Fixed speckles in border regions when creating textures using the BakeTX tool. The Mesh to Volume tool automatically simplifies models with too many faces for the BSP processing code to handle, preventing the editor from hanging when large meshes are converted to volumes with this tool. Fixed a crash in the Paint Maps tool that occurred on painting on a mesh with no attributes then attempting to undo. Disabled the rendering of the indicator circle in the Seam Sculpt tool, since it was not needed for the tool's functioning and caused visual confusion. Fixed incorrect handling of texture source format BGRE8 in UE::AssetUtils::ReadTexture. Updated the Mesh Tangents tool to warn users when attempting to copy tangents from a mesh that does not have tangents. Changed the smoothing weight scheme to IDT Cotangent in the Hole Fill tool. Updatedthe Hole Fil tool to re-check for mesh seams to constrain between iterations of remeshing. Removed the stylus plugin from Modeling Mode, because of a performance issue that occurs when the stylus plugin is enabled. Updated USkinnedAsset to allow a potentially running AsyncTask to finish before deleting it. Updated the mesh visualization component used by many modeling tools, including Simplify and Remesh, to correctly distinguishes between normal and tangent seams, rather than treating both seam types as normal seams. Updated the Editor 2D Mouse Wheel Zoom Behavior Target in the Interactive Tools Framework to make the clip plane math work out if the camera has negative z coordinates. Procedural New: Created convenience functions in PCG data collections and PCG blueprint to remove some boilerplate. Added substring/matches search which support wildcards in the PointFilter node for string types. Provided a method to convert points along Landscape Spline into points on a Spline Component. Works best with single path or circular Landscape Splines. Added missing steepness controls to the Volume, Spline, and Mesh Sampler nodes. Added support for soft object reference user parameters & soft object pointers internally. Behaves like generic soft object paths but with the appropriate type narrowing. Added support for overridable texture in the Get Texture Data node. Added Loop node that behaves like a subgraph but will pass on a single data from the designated loop pins (first pin only by default). Renamed Attribute Operation node to Copy Attribute. Copy Attribute now uses the Attribute from another Attribute Set source (with an extra pin). New pin is marked (and shown) un-used if the pin is not used. Index is now a valid accessor to access the index of a point. Improved behavior of Get Actor Data node for PCG partition actors in the case of Single Point. Added an option to merge all points when querying multiple actor data with single point . Added an option to ignore self in the Get Actor Data node. Added SoftPath getter and setter support in PropertyBag to interact with properties that are SoftObjectPtr or SoftObjectClass. PCG Tracking system is now centralized, improving performances. The PCG Static Mesh Spawner now respects the ISM component type selected in the component descriptor, with the exception of changing to an ISM if the selection is HISM and the mesh is using Nanite. Added a OneMinus node. Added a Make Rotator attribute. Some native nodes now have a Preconfigured Settings entry in the context menu, to quickly add a node with the wanted settings. Preconfigured settings are available for Custom BPs, in the class settings. Changed DensityNoise into AttributeNoise node, to support noise on all attributes. Added aliases support on overridable PCG parameters in Settings, to facilitate deprecation. Added ability to spawn Actor by attribute in the Spawn Actor node. Added inspection support for subgraphs in the PCG editor. Improved attribute operations by propagating the first non-param pin. Input to propagate can now be overridden in the settings. Added default value concept for all Make operations. Changes that trigger PCG re-generation now cancel ongoing generation more efficiently. This should have a positive impact on landscape editing with PCG content and ensure that no stale data is present. Added @Last and @Source as new Attribute Selectors. @Last gets the latest modified attribute. @Source gets the attribute specified by the input. None becomes a valid attribute name. Added a new Point Filter Range node, to filter on a range. Read-only accessors are now throwing an error if it is used as an output accessor. Added Is Cacheable Override for more fine-grained control when needed. Improvement: Improved naming for nodes with custom names and blueprint nodes in the node palette. Improved support for name clashes, especially in BP exposed variables. Properties need to be exposed to be added to the Attribute Set using the Get Actor Property node. Seed for new nodes is not constant, but dependent on the node name. Seeds are kept as-is for existing nodes, to not break existing graphs. Replaced Creates Artifacts with Is Cacheable in PCG blueprints to be clearer. Previously cached blueprints which did not have Creates Artifacts checked should be manually updated to set the 'Is Cacheable' flag to true. Added getters for input/output pin properties by label in settings. Renamed getters on data collection to clarify it is done by label. Added Get Target Actor, to be used instead of accessing the Target Actor variable directly. Refrain from getting the Target Actor variable on PCG Spatial data directly. Instead use the Get Target Actor method on the context. Bug Fix: Fixed some instances where PCG would access pending kill landscapes in some instances when getting landscape proxies. Forced usage of the landscape original GUID for the landscape cache in cases where landscapes are instanced. Fixed an issue where the world ray/volumetric query parameters would not be properly overridable. Fixed outstanding bug in the metadata partition where the partition would not behave correctly for non-string values Fixed the Landscape Blend Layer not sampling correctly when using 2x2 Subsections. Fixed distance checks between the same source and target would lead to checking points against themselves. Fixed issue with PCG partition actors not reacting to landscape changes before a full graph refresh. Fixed issue where numerical values were not accepted for MakeTransform and MakeVector. Improved logging for Metadata operation, making it easier to know why an operation is failing. Fixed issue where the Create Spline node was ignoring custom tangents. Deprecated: Support @SourceName (previous behavior of None = Create attribute with the same name as input). Not exposed. Used for deprecation. Support @LastCreated (previous behavior of None = Get the latest created attribute in input). Not exposed. Used for deprecation. UV Editor New: The UV Editor now supports a UV distortion visualization feature. When enabled, it computes a per triangle distortion value of the triangle's UVs vs its world space positions. This is then displayed as a color blind friendly color overlay on the 2D UV mesh. The feature supports several metrics for distortion and one metric for relative texel density over the mesh. Moved UV Editor plugin from Experimental plugin directory to the Editor plugin directory. Refactored unwrapped to applied selection conversion slightly to make it more convenient for areas of the code outside of the selection mechanic to perform conversions. Bug Fix: Changed the Quick Translate options in the Transform tool to produce a single undo entry for the corner transforms. Corrected issue where focusing on selections in the 3D viewport was using selections on the unwrapped 2D mesh instead. Corrected issue where the background grid was being incorrectly drawn due to mishandling of minimum and maximum Y-axis bounds. Adjusted the language in the Transform tool's tooltips to be more consistent between different direction buttons. World Building API Change: In PIE, UWorldPartitionLevelStreamingDynamic::RequestLevel now behaves like what ULevelStreaming::RequestLevel. ULevelStreaming sets ULevel::StreamedLevelsOwningWorld so that ULevel::PostLoad can now set the level OwningWorld. Since UWorldPartitionLevelStreamingDynamic creates a memory level, it sets the OwningWorld right before loading OFPA actors. New: Added a delay to AddToWorld of a partitioned world if this same partitioned world hasn't finished removing it's sub-levels triggered by a prior RemoveFromWorld. Added a LevelStreamingPersistence experimental plugin. LevelStreamingPersistenceManager handles persistence of tagged object properties when streaming-out/in levels. Persistent object properties that are tagged as public can be accessed and modified even when the level is not loaded. Added UDataLayerManager which is local to each WorldPartition. Instanced world partition maps can now maintain their own Data Layer runtime states. Added helpers UWorld::GetDataLayerManager and UWorldPartitionBlueprintLibrary::GetDataLayerManager which will automatically find the associated DataLayerManager. Added World Partition Runtime Grid origin in grid settings to help properly align game content on runtime grid cells (for example landscape proxy actors) Added a Preview Grid Level option to preview other levels of the grids Added the ability to edit data layers of a level instance when editing the level instance. Added editing data layer of level instance when editing the level instance even when the main world is not partitioned. Added support for Make Current on Level instance DataLayerInstances when editing a level instance. Unreal Engine now Includes time spent in FLevelStreamingDelegates OnLevelBeginMakingVisible/OnLevelBeginMakingInvisible and ULevelStreaming::BroadcastLevelVisibleStatus in their respective time budget. The WorldPartitionSubsystem is now responsible for sorting cells and executing cell loading and activation for all registered world partitions. Add Project Setting for default value to assign to new Level Instances Packed Level Actors now avoid updating blueprints if packing result is unchanged. DirtyFilesChangelistValidator now outputs the assets that need to be saved during changelist validation. New IsMainWorldOnly actor property for filtering actors when they are being used in a Level Instance. Improvement: Optimized UpdateStreamingState for Server streaming, It now computes ClientsVisibleLevelNames once for all registered world partitions. Added the wp.Runtime.UpdateStreamingStateTimeLimit command for incremental updates of registered world partitions (disabled by default). This is only useful when there's a lot of registered partitioned worlds. Lowered the Net Update Frequency for HLOD actors (AWorldPartitionHLOD) in case they're ever set to replicated. Any actor inheriting from AWorldPartitionHLOD with replication turned on will be affected, since there is now a NetUpdateFrequency of 1 by default as opposed to the default 100. Changed default value of wp.Runtime.UpdateStreaming.EnableOptimization to true. Set UDataLayerManager::SetDataLayerInstanceRuntimeState to BlueprintAuthorityOnly. Replaced import data layer menu option with drag and dropping level instance data layers into main world AWorldDataLayers. Disabled changing visibility and editor loading of DataLayerInstances of editing level instance. Changed font from bold to bold+italic on DataLayerInstances containing actors that are part of editor selection. Colorized and appended (Current) to the WorldDataLayer of the editing Level Instance in the DataLayer Outliner. Optimized World Partition UpdateStreamingSources. Saves 1ms on project using >300 instances of partitioned worlds. Moved initialization of game instanced world partition to happen when the level starts to be added to the world instead of when it is loaded. Moved the uninitialization of game instanced world partition to happen when the level starts to be removed from the world instead of when it is done being removed from the level. Centralized the initialization/uninitialization logic in WorldPartitionSubsystem Instanced world partition IsServerStreamingEnabled/IsServerStreamingOutEnabled now forwards the logic to their parent world partition (if any) when using project default modes. Disabled replication of WorldSettings on levels created for world partition streaming cells. Added other missing deprecated UDataLayerSubsystem methods. World Partition now relies on World's NumStreamingLevelsBeingLoaded instead of computing its own number of loading cells. Fixed Data Layer asset paths when loading WorldPartitionActorDescs. Level Instances with bEnableStreaming=true will now act as regular World Partitions when loaded on their own. Big Level Instances can now be partially loaded outside of their owning world. Bug Fix: Fixed UDataLayerManager::SetDataLayerRuntimeState helper to avoid having to resolve a DataLayerInstance for a Data Layer asset. Fixed the case where an instanced world partition was added to the world, then removed from the world, then re-added to the world without being unloaded first. Fixed deprecated UDataLayerSubsystem::GetDataLayerInstances to properly map to UDataLayerManager::GetDataLayerInstances. Fixed pending cells to be loaded and to be added to the world not updating their cell sorting info. Fixed UWorld::CanAddLoadedLevelToWorld to work with multiple world partitions. Properly hooked Data Layers menu extenders and pass selection to delegate. Fixed broken foliage instance selection after deleting an instance Corrected missing initializations in FInstanceUpdateCmdBuffer ctor Uninitializing a partitioned world should always trigger unloading of all cells regardless if server streaming and/or server streaming out are enabled/disabled. Fixed replay playback not resetting runtime data layer states to their initial state. In PIE, UWorldPartitionLevelStreamingDynamic::RequestLevel now behaves like what ULevelStreaming::RequestLevel does. ULevelStreaming sets ULevel::StreamedLevelsOwningWorld so that ULevel::PostLoad can set the level OwningWorld. Since UWorldPartitionLevelStreamingDynamic creates a memory level, it sets the OwningWorld right before loading OFPA actors. Added server's client visible level names in update streaming state hash. Fixed rare case where a WP streaming cell would contain an actor and this actor is also an editor-only reference of another actor of this cell. In this case, the editor-only reference must not be part of the WP streaming cell. WorldPartitionSubsystem no longer updates streaming sources on the server when none of its registered world partition has server streaming enabled. When sorting world partition cells, world partition doesn't rely on cell grid level, but instead uses grid cell extent to sort cells between multiple grids. Fixed how MaxCellsToLoad is computed by World Partition to limit the total number of loading and pending load streaming cells. Fixed infinite loop in Level streaming caused by UWorld::RemoveFromWorld completing in non incremental removal move after first starting in incremental mode and not resetting CurrentLevelPendingInvisibility. Prevented async loading flush when world partition cell is activated. Fixed bug where garbage marked levels were not given unique names, causing them to be reloaded. Attached Actor Pre/PostSaveRoot transform fix. Fixed cooked FunctionalTest not getting discovered for WorldPartition maps Recompile skeleton class after clearing SimpleConstructionScript to avoid component name clashes when adding the new components to Packed Level Actor blueprints. Deprecated: Removed DataLayerSubsystem since DataLayerManager supersedes its functionality. UWorldPartitionRuntimeCell::IsLoading, UWorldPartition::UpdateStreamingState and UWorldPartition::CanAddLoadedLevelToWorld have been deprecated. Removed CanBeUsedByLevelInstance. Level Instances that are World Partition-enabled still get embedded in their parent world grid independent of the value of bEnableStreaming. Removed: Removed menu option Create Data Layer under DataLayer as it will never be allowed for DataLayerInstanceWithAsset since it is created without any valid DataLayerAsset. Removed suffix - WorldDataLayers on parent node of DataLayerInstances in the DataLayer Outliner Localization API Change: Implemented async loading of localization data, and extended dynamic loading to handle explicitly loaded plugins. BeginInitGameTextLocalization and EndInitGameTextLocalization have been removed as part of this change. You would now just use InitGameTextLocalization (which is async) followed by FTextLocalizationManager::WaitForAsyncTasks. New: Implemented MinimumGroupingDigits for FastDecimalFormat. Enabled \\"min two\\" grouping for Spanish by default. This can be disabled via the Localization.SpanishUsesMinTwoGrouping console variable. When enabled, \\"1234\\" formats as \\"1234\\" rather than \\"1 234\\", but \\"12345\\" still formats as \\"12 345\\". Added an overload of FTextProperty::Identical_Implementation that lets you control the fallback lexical compare mode. Implemented async loading of localization data, and extended dynamic loading to handle explicitly loaded plugins. This change takes the existing support for async loading that was added for game localization data and expands it to cover all localization data. Async localization tasks are chained together as dependencies to preserve the existing order of operations, and can be waited on at any point (eg, after a loading screen) by calling FTextLocalizationManager::WaitForAsyncTasks (though the engine init flow takes care of waiting for you unless you're loading additional plugin/chunked localization data). This change takes the existing support for dynamically loading chunked localization data on PAK chunk load, and extends it to support dynamically loading any additional localization data. This is used by the engine to support dynamically loading the localization targets associated with explicitly loaded plugins. These loads are all async, so must be waited on if you need them to block. Added the Localization.DumpLiveTable command to dump the current live table state to the log. This can be optionally filtered using any of the following wildcard arguments: Namespace: The namespace to filter against. Key: The key to filter against. DisplayString: The display string to filter against. The validator to make sure localized assets do not contain dangling redirectors now properly considers the case where the localized and non-localized assets are both redirectors that point to the same respective path. Bug Fix: Always use a space and a comma as the group and decimal separator when using RAE-style Spanish numbers. Fixed an assert when gathering localization data from a World Partition world that had already been loaded as the editor world. Fixed text created from FText::FindText with a null source string failing to resolve correctly if the language changes. Online New: Add Join in Progress to list of social debug commands. MPA activity now set/unset in sync with joinability privacy. If undesired, set setMpaActivityInPrivateSession to true. Added replacements for deprecated IAP blueprint nodes: Make an In-App Purchase v2 has been replaced by the new \\"Start an In-App Purchase\\" node. Process any New Unprocessed Purchases v2 has been replaced by the new \\"Get known In-App Receipts\\" node. Query for Owned Purchases has been replaced by the new \\"Query for Owned In-App Products\\" node. Restore In-App Purchases v2 has been replaced by the new \\"Restore Owned In-App Products\\" node. New nodes allow validation/granting logic to be reused because they share common types for the receipts on their outputs. Also added \\"Finalize In-App Purchase Transaction\\" so licensees can finalize the transactions using the receipts after processing. All transactions should be finalized. Any non finalized transaction locally or server side will be refunded by GooglePlay and not finalizing locally the transactions on iOS may lead to bad performance The recommended flows in a game should be: On startup/after login \\"Query for Owned In-App Products\\", then validate/grant the missing products and finalize those receipts. When the user initiates a purchase using \\"Start an In-App Purchase\\" validate/grant the products and finalize the receipt. Any time the game may need to check for updates on products it can \\"Query for Owned Purchases\\" if they need a full update or \\"Get known In-App Receipts\\" if it is not interested in updating data from store servers. After that products can be validated/granted and receipts should be finalized. \\"Restore Owned In-App Products\\" does the same as \\"Query for Owned Purchases\\" on Android. On iOS it calls restoreCompletedTransactions on the payment queue thus making available all already processed receipts for non consumable transactions. Added a conditional in the BuildPatchServices system to ascertain if the destination file system is currently throttled, and, if so, stall file writing. Convert online subsystem defines to be global FNames to avoid a lookup every time we use one. Improvement: Improved POSIX ICMP code and added a console command to test ICMP directly. Moved USocialDebugTools::PrintExecCommands to protected so it can be overridden by subclasses. Deprecated: Marked deprecated IAP blueprint nodes and created replacements: Make an In-App Purchase v2 has been replaced by the new \\"Start an In-App Purchase\\" node. Process any New Unprocessed Purchases v2 has been replaced by the new \\"Get known In-App Receipts\\" node. Query for Owned Purchases has been replaced by the new \\"Query for Owned In-App Products\\" node. Restore In-App Purchases v2 has been replaced by the new \\"Restore Owned In-App Products\\" node. HTTP New: Added non-game thread support for http request. Added http streaming download interface. Added new test project WebTests with corresponding web server to test HTTP. Added 64 bits length of file download support in http request. Added LLM tags to CurlHttp allocation hooks. Bug Fix: Enabled WinHttp websockets to be created with an empty protocol list, which results in the corresponding header not being added. Online Subsystem New: Added a LobbyId override option to the CreateLobby method in the OnlineServices Lobbies interface. Added logic to LobbiesEOSGS to use the new option. Added UE_ONLINE_ERROR_EXTERNAL macro to enable online errors to be defined outside of the UE::Online::Errors namespace. Added presence tracking for OSSv2 Lobbies. Added logic to trigger OnQueryUserInfoComplete delegates on OSS EOS. Added support for BuildIdOverride on the command line to be surrounded by quotes. Added GetInterface accessor to IOnlineServices to allow for additional/implementation specific interfaces to be accessed via the base IOnlineServices. Improvement: Modified OnlineBeaconClient login parameters to allow for more parameters than just the auth ticket. Bug Fix: Changed the default cache directory for Switch used by OSS EOS. Delayed callback execution to match alternate flow paths in OSS EOS Session search code. Refactored OSS EOS Friend status update handler method to trigger the appropriate corresponding UE delegates and keep a coherent state. Refactored EOS Lobby Creation logic to destroy the lobby if the update step fails. Added critical section around FOnlineSubsystemModule::OnlineSubsystems. This fixes race conditions when multiple threads are accessing FOnlineSubsystemModule::GetOnlineSubsystem, observed to happen as part of multi-threaded FUniqueNetIdRepl deserialization. Refactored session update code in OSS EOS Sessions interface to ensure non-owner lobby members can update their own lobby member settings, to match API functionality. [Online Services] Added support to handle more operation cache settings, duration based and provide a setting to cache error results. Limit concurrent operations in flight. Fixed some operations not being removed/destroyed when we are done with them. Removed: Removed unsupported members of LobbyMember type: PlatformAccountId and PlatformDisplayName. Removed early exit in OSS EOS' FriendStatusChanged method in order to handle accepted friend invites via the EOS overlay. Pixel Streaming New: Added the ability for the bundled get_ps_servers script to pull down a release from Github. Added a new framework to allow passing arbitrary configuration settings to the streaming infrastructure. Improvement: The default viewer port for PixelStreaming on Linux is now 8080. Port 80 requires root privileges on Linux, so this avoids elevation. Crash Fix: Fixed a crash caused by using UPixelStreamingSignallingComponent Blueprint types. Fixed a crash that occurred when using OfferToReceive on Firefox. Fixed a crash that occurred on shutdown. Fixed a deadlock that occurred when using DX11 on AWS instances. Fixed a crash that occurred when running with -onethread and encoding VPX. Fixed a crash that occurred when a port was not provided for -PixelStreamingURL. Bug Fix: Fixed a bug where the embedded signaling server would not serve the images directory as expected. Fixed a bug where showcase.html would not display images when using an embedded signaling server. Fixed a bug where the embedded signaling server could not connect to the frontend. Server targets can now build with PixelStreaming Blueprints enabled. Fixed a race condition that could occur during stats collection. Fixed a bug where the minimum bitrate could be set higher than the maximum bitrate. Platform Bug Fix: Added a check to prevent memory mapping compressed or encrypted memory made with IoStore. Fixed address sanitizer compile error on current versions of MSVC. Desktop Crash Fix: Fixed a crash that occurred when playing 2 startup movies using WindowsMoviePlayer. Linux New: Added sigaction failure check. Provided an option to disable dump_syms where iteration speed is desirable. (-NoDumpSyms or set bDisableDumpSyms). Bug Fix: Stopped tooltips from popping up during window drags. Replaced use of sa_handler with sa_sigaction. If SA_SIGINFO is specified in sa_flags, then sa_sigaction specifies the signal-handling function instead of sa_handler. Started accounting for Linux dock dimensions when computing positions. Fixed \`TWeakObjectPtr\`s not being indexed properly in LLDB. Fixed launching on a remote Linux box from a Windows editor. Fixrf DPI scale in Linux being incorrect on Odyssey G9 5120x1440 displays. These displays report invalid display information to the window system, resulting in very high scale values. Fixed crash reporter not always showing up on Linux due to config variables being unexpectedly overridden. Fixed some instances where modal window behavior on Linux didn't match other platforms. Corrected some incorrect event resetting code in FramePro. Mac New: Moved some MacMenu calls to MainThread to avoid creating errors in the Main Thread Checker, which will be fatal in future MacOS versions. Added encoder fault tracking to help diagnose GPU crashes. Crash Fix: Fixed crash with Dump GPU on Macs due to missing viewport. Fixed a freeze that could occur on Mac when some pop ups were displayed. Bug Fix: Fixed incorrect timestamp queries calculation on Apple Silicon. On Mac, UE will no longer rebuild cached menus on every key press. This prevents an FPS drop in editor/preview when the user is pressing keys on the keyboard. MacSystemIncludes now undefines PF_MAX so it can be defined by UE for pixelformat instead of socket.h. This is the result of a long include chain wherein Cocoa.h pulls in networking code from PrintCore.h, which in turn leads to socket.h defining PF_MAX instead of UE. Added some checks on CRC to make sure it actually exists and is executable. XR New: Added an interface within IOpenXRExtensionPlugin.h to access StereoLayers. Added support for XR_FB_composition_layer_alpha_blend extension. Added support for cylinder and equirect layers in OpenXR plugin. Added support for XR_FB_foveation OpenXR extension. Added setting to enable/disable OpenXR foveation. [ARSessionConfig] Added candidate image removal methods. [OpenXR] You can now disable the depth layer via cvar. [PSVR2] Adjustable max eye texture size now allows for PixelDensity > 1.0 with a setting to control the limit. Improvement: Hololens device detection will now occur after editor startup by default to reduce startup time.This setting can be changed in the Hololens Project Settings. ARCore SDK for Android was updated to 1.37. [OpenXR] Android apps on non-Oculus Android platforms can now startup OpenXR if they are not configured for Oculus Mobile Devices by changing vr.DisableOpenXROnAndroidWithoutOculus to false. Reduced XR EControllerHand use. Reduced total memory use overhead of HeadMountedDisplay modules by moving them to the XRBase plugin. [OpenXRHandTracking] Improved support for using hand tracking along with controllers. Packaging settings for Meta Quest devices has been changed from a list of devices to a single checkbox that enabled packaging for all Meta Quest devices. OpenXR headers have been updated to OpenXR SDK 1.0.27 (2023-03-21). Added a tooltip to MotionControllerComponent's MotionSource. [PSVR2] Removed reliance on pre-registered buffers for reprojection. [OpenXR] Runtime-supported extensions will now be logged. [OpenXR] Refined CopyTexture operations for layer and spectator screen usage. Crash Fix: Fixed a crash related to planar reflection on SteamVR. Fixed a crash that occurred when accessing vr.SpectatorScreenMode CVar without a controller connected. Bug Fix: [AR Pins] Fixed a bug where TrackingToWorldTransform and WorldScale were updating incorrectly. [ARKit] ARKit anchors are now released when the ARPin is removed. StereoLayerManager no longer uses invalidated FLayerData. The xr.OpenXRForceStereoLayerEmulation console variable now picks up runtime changes only at the next VRPIE restart. Stereo layers are now correctly removed when their actor is destroyed. Fixed a bug related to the alpha of emulated stereo layers on the HMD and spectator screen. Fixed a bug where XRDeviceVisualizationComponent would not correctly start the visualization of the device model. Fixed Mobile Preview VRPIE being darker than what was shown in the HMD. Fixed sorting function that made world locked layers render on top of face locked layers. Fixed a bug related to FOpenXRHMD::UpdateLayer thread safety. Fixed an Unknown ARCore Trackable Type assert which occurred during ARLineTrace. [ARCore Trackables] Fixed a case where an ArTrackable handle was not released. [OpenXR] Emulated layers swapchain will now use the prescribed layer format. Fixed a bug involving a platform RHI disable check. [OpenXR] Fixed a bug which occurred when stereo was disabled and re-enabled. [VulkanRHI] LLM tags are now initialized earlier. [ARKit] Invalid camera images will no longer be processed after pause and resume. [ARKit] Camera texture resources will no longer be accessed on the delegate thread. [OpenXR] Quad layers now respect component scale as expected. Fixed several issues related to MotionControllerComponent Velocity. [XRScribe] Pose replay will now match the original timescale instead of playing poses back as fast as possible. Fixed an issue where OpenXRHMD SystemProperties was uninitialized until OnStereoStartup. Deprecated: EnableAutoLoadingSplashScreen functionality has been deprecated. [ARCore] Deprecated UGoogleARCoreFrameFunctionLibrary::GetCameraMetadata and Deprecated ARCore AR Trackable Render Components. Removed: Removed the deprecated camera metadata API. Removed deprecated ARCore features. Removed HoloLens \\"Multi\\" packaging. [ARBlueprintLibrary] Deleted functions deprecated in 4.22 and 4.26. Removed GetMobileVariableRateShadingImage to make Variable Rate Shading behavior consistent across mobile and desktop. Platform Mobile New: Optimized directional light uniform buffer update on mobile. Added support for pixel shader version of TAA upsampling on mobile. Added support for instance custom data in pixel shader while mobile GpuScene is enabled. Changed Light Grid Data buffers to be StructuredBuffers. Added support for ISM with mesh paint vertex color on mobile. Detect hardware Cyclic Redundancy Check (CRC) instruction support on ARM platforms. Depending on the compilation environment, this can be a runtime or compile time detection. CRC is used in hash computations everywhere in the engine and this change will provide ~7x performance improvement on supported devices. Replaced RHICommandListImmediate with RHICommandList to enable RDG pass parallelism on mobile platforms. On Android and iOS, UE will now only update the list of receipts received from IOnlinePurchase::GetReceipts by user request. Receipts retrieved using IOnlinePurchase::GetReceipts are updated as a result of calls to IOnlinePurchase::QueryReceipts. After a successful call to IOnlinePurchase::Checkout, the receipt for the successful purchase is added to that list. Asynchronous transaction updates received only trigger the IOnlinePurchase::UnexpectedPurchaseReceipt delegate. Restored transactions on iOS are automatically finished so the end user does not need to do it. Added support to handle subscriptions on OnlinePurchaseGooglePlay and OnlineSubsystemIOS. Subscription product types are now also queried to the stores. Whether a subscription is valid or not can only be handled by server-to-server calls to the store. You can disable local acknowledge-and-consume by setting bDisableLocalAcknowledgeAndConsume_\`_ in the [OnlineSubsystemGooglePlay.Store]\` section from your .ini files. This supports the server-to-server validation recommended by Google. Product IDs consumed by the engine for subscription products should be composed by be the actual product ID defined in the store, prefixed by \\"s-\\". Several product entries will be received for a subscription product when the application invokes \`IOnlinePurchase::QueryOffersById_\`_ using a subscription product ID. The product ID on the received products will contain: ++ The prefixed product ID ++ The base plan ++ The offer in the base plan ++ The different price points. As an example, this could be the list of ids created by \`_IOnlinePurchase::QueryOffersById\`_ requesting information for \\"s-test_subscription_1\\" (which in the store would be identified as just \\"test_subscription_1\\"). r.Mobile.EarlyZPassOnlyMaterialMasking is now handled per shader platform. Increased ShaderComplexity cost of Masked Materials on Mobile ShaderPlatforms that do not use MaskedInEarlyZ. r.Forward.LightLinkedListCulling is now set to 0 for platforms that do not benefit from it. This saves about 0.1ms on the GPU. Added support for Inline RT Shadows on Vulkan. Tonemapping LUT pass now runs only when needed. Added support for CollisionMode PCM_DistanceField on mobile platforms that support Distance Field. Removed SupportsCopyImage, as GL ES 3.2 standard has glCopyImageSubData. Volumetric Support For Mobile is disabled by default in Device Platforms. Removed bSupportsVolumetricFog from DataDrivenPlatformInfo. Added a new mode for rendering local lights in the Mobile forward renderer. You can enable this mode by setting r.Mobile.Forward.EnableLocalLights to 2 and r.Mobile.EarlyZPass to 1. Mobile Light Prepass is now disabled by default. Removed bSupportsMobileDistanceField from DDSPI in Global Distance Field For Mobile. Crash Fix: Fixed a crash that occurs when enabling transmission on directional light with spot light shadow on mobile. Bug Fix: Mobile rendering now samples SceneDepth instead of fetching SceneDepthAux when full depth prepass is enabled. Fixed a bug where decals are missing skylight when using the mobile deferred renderer with static lighting disabled. Directional lights with a light channel of none (0) can now cast shadows on mobile deferred. Fixed a bug where simple light was missing on mobile deferred. Fixed a bug where static meshes are missing local light when they are dragged in editor. Fixed issue where distortion pass was not using the same pixel format as a base pass. Previously, objects with masks would still do mask clipping in the pixel shader even with full depth pre-pass enabled. This issue has been resolved. Fix a bug where the depthRT is empty during passes when DepthStencilState is enabled while doing DrawMaterialToRenderTarget on the mobile deferred renderer. Fixed a bug where a black color would render on thin translucent material on mobile. Fixed IBL reflections for Surface LightingVolume. Fixed a GPU crash caused by Niagara Mesh Renderer shader which occurred on IOS 13 as well as some PowerVR android devices. Fixed GPUScene uploader size limit check. Indirect lighting scale is now correctly applied on mobile. Moved Temporal Anti-Aliasing back to the end of the post-processing chain to save bandwidth. It now filters the bloom input to get rid of the flickering white spots. Fixed a modulated shadow rendering issue on mobile. Fixed a bug in GenerateGlslShader that occurs when a string is a substring of another in the ReflectData. Fixed handling of Target Device in Mobile Preview. Quad Complexity now works correctly for mobile preview. Android New: Added a way to provide command line to Android apps using adb shell. You can now launch Android apps from adb shell and provide a command line arguments using the parameter -cmdline \\"arguments\\". Purchasing multiple products in one transaction is now allowed in OnlineSubsystemGooglePlay. Set Java 1.8 for sourceCompatibility and targetCompatibility. Capped Low-Level Memory Tracker (LLM)'s Total stat to be no less than Total Tracked on Android, since on some devices UE can't read the GPU part of the total memory allocated by the process. However, LLM does its own counting on Unreal Engine's side for GPU-related allocations. Advanced binary compression is now enabled by default on Android. Upgraded Android Studio (Flamingo 2202.2.1) and Gradle (7.5 and use OpenJDK 17 from 2202.2.1). Added support for Lumen Diffuse Indirect without requirement for Dual Source Blending in the desktop renderer. Updated force feedback support on Android: Use VibrationEffect for intensity control. Forward feedback to controller(s) if Android.UseControllerFeedback has a value other than zero (defaults to 1). Does not continue feedback when application is in the background. Added Overflow 3 and 4 for Android OBB files. Use OverflowOBBFileLimit project setting to set number allowed. The default value for OverflowOBBFileLimit is 2, but you can set it up to a maximum of 4. Updated Google-Services plugin for Firebase. Updated Swappy to the latest from Android GoogleSource. Modified to always use the Java DisplayManager and refresh rate selection as it is more reliable on some devices. Added additional Razer Kishi gamepad recognition. Added the WebViewTextureSize CVar to control Android WebBrowser texture size in DefaultEngine.ini. Crash Fix: Fixed a crash when playing a .mp4 from UMG. Bug Fix: Fix a bug that prevented rendering custom depth on OpenGL. Fixed bug where CommitComputeResourceTables were missing for dispatching indirect compute shader on OpenGL. Fixed a bug where media couldn't resume after entering the background on Android devices. Changed the location of the .apk generated by Gradle to avoid using outputFileName to redirect the .apk location. Fixed a race condition when generating .apk in newer Gradle versions by using cleanPackageDebug/cleanPackageRelease instead of manual .apk removal. Forward key pressed to UI even if virtual keyboard is shown on the screen. This enables hardware keyboard usage with EditText fields. Removing emoji filtering on Android. Now it's possible to type emoji's from Android on-screen keyboard. Fixed IME with hardware keyboard. Fixed an issue causing fingerprint scanners being falsely detected as controllers. Only archive AAB if App Bundles are enabled for Android. Corrected performance issues by performing updates to device vibrator intensity less frequently. Fixed Xbox and Razer wired controllers on Android 12+. Use /sdcard/Android/obb for OBBs for all build types. /sdcard/obb is no longer used due to storage access restrictions. Clear ANDROID_SDK_HOME environment variable in the SetupAndroid script. This should NOT be set with new tools. Slight improvement to GetEntryLength in Android filesystem. If the Android background downloader plugin is disconnected, it will now monitor network status and resume background downloads if reconnected. Fixed OnLocationChanged broadcast for Android location services to use the game thread properly. Deprecated: libc++_shared.so is no longer included in .apk packages on Android by default, as Unreal Engine no longer supports any dynamic libs built against libc++_shared.so. iOS, tvOS, and iPadOS Crash Fix: Refactored resource transitions on Metal. Removed PrologueEncoder since it's not synchronized properly. This fixed a flickering and crash issue on iPhone14 with mobile GPUScene enabled. Bug Fix: Fixed a bug that occurrs when sampling SceneDepthAux in SunMask on IOS mobile deferred. Deprecated: IHttpRequest implementation based on NSUrlConnection is marked deprecated. This functionality will be removed in 5.4. Quixel New: Quixel Bridge 2023.0.3 improves version handling for MetaHuman exports. Rendering API Change: If your shader references GPUScene or another field in the scene uniform buffer, the RHI validation expects a valid reference for the scene UB. If this is not set, you may see an error like this: Shader expected a uniform buffer at slot 5 but got null instead (Shader='' UB='Scene'). Rendering code needs to set a valid uniform buffer for this slot. This can be resolved by adding a SHADER_PARAMETER_RDG_UNIFORM_BUFFER(FSceneUniformParameters, Scene) field to the shader parameter struct and setting its value using the helper method in FSceneView. If you're having trouble identifying which shader is missing the reference, you can run with \\"-rdgimmediate -rdgdebug -onethread\\" and find the shader in the callstack. New: Added a Volumetric Clouds console variable \\"r.VolumetricRenderTarget.MinimumDistanceKmToEnableReprojection\\" to help hide reprojection issues to due to imperfect approximation of cloud depth as a single front surface. This is especially visible when flying through the cloud layer. This doesn't hide all issues but will help in a lot of cases. The problem when using this method is that clouds will look noisier when closer to that distance. Optimized Volumetric Cloud shadows by using CloudSampleNormAltitudeInLayer correctly. This can result in performance wins between 5 to 10 percent. Added support for Groom streaming. This allows you to load and unload content based on usage. This is experimental and disabled by default. You can use the console variable \\"r.HairStrands.Streaming\\" to enable it. Added AutoLOD setting to Grooms. This allows it to dynamically adapt the number of active curves based on screen coverage. This avoids having to set this with manually discrete LODs, and adapt curve count at a more finer grain. Combined with streaming, it lowers GPU timing/memory usage. This is experimental and can be opt-in per asset. AutoLOD can be forced on all grooms with \\"r.HairStrands.AutoLOD.Force\\". \\"WPO Disable Distance\\" material expression now works for non-Nanite Static Meshes. Avoid unnecessary ray tracing shadow tracing for hair strands which saves 25% of shadow cost in test cases with many lights. Added hair attribute value picking when attribute view mode is active. Made sure GPU-scene instance count is clamped to the maximum GPU-representable index (16M), preventing overflow crashes. Added ShaderPrint GPU string, which allow to upload strings to GPU(for example, asset name) Added Blueprint exposed setter function for \\"NumCustomDataFloats\\" on Instance Static Mesh Component. Added LOD curve/point count into the hair LOD panel. Changed Groom RootUV to be optional. If an imported groom does not have RootUV imported, we no longer generate spherical mapping. Make FAtlasTextureInvalidationScope public so that external code (plugins) can invalidate a particular texture (For example, for CPU data upload). Added coverage threshold for hit proxy, in order to control at which coverage hair can be selected. Added guide type to ease understanding/manipulation of the different types of guides. This allows editing rigging directly from the Groom Editor. Added an option on the physics settings to force the Niagara component to be visible. This allows users to leverage Niagara rendering when using a custom solver. Improved Distance Field Scene Management to support more than 4M instances. Add Groom Memory Stats. Added necessary conversions from / to the working color space in Volumetric Cloud rendering. Changed how simulation cache is handled on groom to fix dynamic assignment. A groom asset now needs to opt-in to support groom cache. This opt-in ensures that interpolation data are property built for the groom asset. This option is automatically enabled when assigning a groom cache in the property grid. A groom asset with simulation cache support enabled, can now get a groom cache assigned through Blueprint at runtime. This avoids spawning actual simulation when running with a simulation cache. Groom deformer (experimental) can now write out attributes (CV color, radius, etc) in addition to position. Attributes are also readable, as well as guide data. Add visualization of imported attributes in Groom Asset Editor. Added second Virtual Shadow Map resolution bias for moving lights along with tracking of what lights are moving. When a light stops is does a gradual transition to the original bias. Added Scalability console variables r.Shadow.Virtual.ResolutionLodBiasLocal, r.Shadow.Virtual.ResolutionLodBiasDirectional, and r.Shadow.Virtual.ResolutionLodBiasDirectionalMoving to configure the LOD bias for a light that is currently moving. Attached VRAM info to AppendStaticClientPerformanceAttributes. Added per-primitive enum (ShadowCacheInvalidationBehavior) to enable users to override default engine behavior for shadow invalidations. This is useful to prevent invalidations from for example static WPO. Changed GPU-Scene data to shrink as well as grow. The console variable \\"r.GPUScene.UseGrowOnlyAllocationPolicy\\" can be used to disable the new behavior. Prevented instance over-allocation from crashing the editor / engine, clamping gpu-scene size to MAX_INSTANCE_ID, 16M. Added logging + on-screen message to surface the issue. Added the console variable \\"r.CaptureNextDeferredShadingRendererFrame\\" to trigger capture a following deferred scene render. For example, RenderDoc or PIX. Added the ability to trigger Virtual Shadow Map invalidation on Nanite LOD streaming changes. This is experimental and is controlled using \\"r.Nanite.VSMInvalidateOnLODDelta\\" (default: off). Added a new global uniform buffer scoped for the scene rather than the view, and moved GPUScene from the view to this buffer. The scene UB uses RDG (unlike View), and is modular. Improvement: Reduced groom cluster resources size (~ -15%). Improved groom per-CV color precision from 8/8/8bits to 11/11/10bits. Improved the consistency of scene view extension calls in the game viewport and scene captures. Changed cluster culling to be done in a single pass. This saves about 20% cost of the interpolation work. Clusters are not computed based on the first curve to avoid expensive cluster bound computation. GPU Skin Cache update render thread optimizations. Rendering multiple Skin Cache enabled skeletal meshes should now process faster due to batching of work. Improved how Groom Cache updates its data. Interpolation now runs on the GPU, and GPU resources are now cached to avoid constant reupload of the data every frame. Improved the Pixel Inspector naming, fixed transparency, allowed negative values and ensured that luminance also respects the working color space. Crash Fix: Fixed crashes when importing groom-only guide cache. Also fixed a crash when importing guide with zero size radius. Fixed a crash with hair with nDisplay. Bug Fix: Fixed tracing cut for Volumetric Clouds that could happen when traveling in and out of the cloud layer. We now make sure we flush occlusion queries out of memory if we've turned them off. Cloud shadow evaluation now works on the SkyAtmosphere when LUT are generated using async compute. Fixed \\"GeForceNOWWrapper::GetClientCountryCode()\\" not writing the output parameter with the country code. (2 char country code). Fixed Volumetric Cloud flickering happening after some time. The extra camera cut logic was unsafe and unstable. Applied a fix for height fog on Volumetric Cloud not working when start distance is greater than or equal to 1. Fixed Sky Atmosphere SkyLightLUT not accounting for overridden light direction. Fixed flickering SkyViewLUT texture when viewed from afar in space. Applied a fix for Static Meshes being marked dirty on load when built asynchronously. Fixed hair bound with scaled transform and take into account hair width, so that large width increases correctly the bound size. Fixed incorrect scratch buffer address when using more than two RayTracingScene layers causing crash or GPU hang. Fixed Groom Cache (guide/strands) rendering and guide cache debug visualization Fixed groom details refreshing in Blueprint. Fixed how CPU bounds are computed for groom when attached to Skeletal Mesh. Fixed slow opening of Groom Binding tab in Groom Asset Editor by avoiding loading assets. Fixed missing groom shadow when \\"Hidden in Game\\" and \\"Hidden Shadow\\" settings are enabled at the same time with Movie Render Queue using the Path Tracer. Fixed Rect Light support with MediaTexture. These textures, when assigned to a rect light, were missing invalidation to refresh their atlas content. Fixed incorrect group names when the groom does not have group ID mapping. Fixed hair strands rendering with stereo rendering. Fixed hair scene scattering not running when the scene does not have a sky component. Fixed hair physics settings working correctly with custom reset. Fixed issue where the shadow mask texture was incorrectly marked as used due to the preview shadows indicator when the preview indicator was not actually rendered because of a missing Material (in cooked builds, for example). Fixed a bug with Nanite Custom Depth rendering on some console platforms. Fixed incorrect alpha channel output for the canvas \\"Translucent\\" blend option. It now uses \\"AlphaBlend\\" internally. Fixed Directional Light preshadows in Cascaded Shadow Maps, which were broken after a recent change to WORLD_MAX for Large World Coordinates. Fixed an issue where the \\"Draw Debug Capsule\\" option on Blueprint capsule components would render with incorrect scale. Validate we have vertex data for the current MinLOD for InstancedStaticMeshes before creating SceneProxy, preventing a crash in some situations. Deprecated: Deprecated direct access to groom and groom binding members. Deprecated Ray Traced Skylight and removed it from Project Settings. Architecture New: Moved all immutable geometry collection rendering data into the Geometry Collection asset. This is built as part of Geometry Collection DDC contents. The scene proxy has been reworked to use this data. Added optional use of \\"Remove At Swap\\" when removing instances from Instanced Static Mesh Component. Also added a console variable to force the behavior with \\"r.InstancedStaticMeshes.ForceRemoveAtSwap\\". RemoveAtSwap should be faster than the previous behavior, but may break any code that depends on the current behavior. Hide MarkedForDelete resources from RenderResourceViewer Added Insight asset metadata tracking on DX12 buffers Added the DECLARE_UNIFORM_BUFFER_STRUCT API macro to allow decoupling of uniform buffer parameter struct declaration and definition. Uniform buffer parameter structs can be forward declared, and so can be used by third parties without making the full definition public. If the morph vertex buffer hasn't updated this frame or for some frames, use the last updated morph buffer for the previous morph data, so it cancels out the motion vector. This fixes a jittery issue in the Morph Target Preview tab in editor previewing using morph sliders. Added Insight memory trace DirectX12 memory allocator tracking. Changed the behavior of flag checkbox based on user feedback for the Render Resource Viewer. When unticked the resources with the flag set are now hidden from display. Also remove None flag checkbox and hide Transient resources by default. Added \\"r.SceneCapture.DepthPrepassOptimization\\" to speed up pre-pass depth rendering for Scene Capture. This is a short-term optimization to support certain features requiring a depth pre-pass and can only utilize SceneCapture to achieve it currently. Note turning it on means rendering after depth pre-pass (e.g. SingleLayerWater) is ignored, hence the result is different from when the console variable is off. Added output owner name to rhi.DumpResourceMemory command. Added Insight asset metadata tracking on DX12 textures Exposed CreateSinglePrimitiveSceneUniformBuffer in the IRendererModule to make it possible to create a Scene UniformBuffer using public interface. Added a context menu on selected resource, and context command to find assets in the Content Browser (shortcut CTRL+B) to the Render Resource Viewer. Crash Fix: Fixed an Editor-only GPU crash on unaligned texture copy when loading a streaming virtual texture with border less than 2. Fixed a crash when trying to render with empty Geometry Collection mesh data. Fixed \\"r.SkinCache.RecomputeTangents=0\\" causing crashes when rendering Skeletal Mesh with the skin cache. Bug Fix: Fixed a GPU hang that could occur when changing material type on an Runtime Virtual Texture asset. Fixed GPUScene per instance HZB instance culling on mobile where previously the HZB was not being bound. Fixed bad motion vectors being generated for some instanced objects. Fixed bad hash calculation of virtual texture pool settings. This could lead to an issue where we did not correctly detect when the pool size settings are changing. Removed render thread access of parent UTexture from FVirtualTexture2DResource. This fixes race condition check firing when the Virtual Texture sRGB flag is flipped. Fixed off by one logic in check() for Static Mesh LOD count. This would trigger a check() if we used 1 less LOD than the maximum. Fixed Skeletal Mesh post load being called on game thread from Niagara when actual loading is still happening from the loading thread. Fixed an issue when multiple viewports are open, only the viewport in focus has valid velocity on skeletal meshes. This is fixed by switching to use GFrameCounter which is incremented once per engine tick, so multi views of the same frame share the same value. Fixed the Skin Cache Editor debug visualization modes looking different from their console variable equivalent. Fixed the shading difference and the debug texts not showing up correctly. Fixed Instanced Static Mesh loose params warnings in debug build. Create a loose parameter uniform buffer to capture those parameters. Lighting New: Volumetric Fog buffer allocations are now independent from dynamic resolution scaling. Sky Light created from Environment Light Mixer uses real time capture by default. Added support for Rect Light Volumetric Fog light functions. Fixed wrong color of translucent shadow volume when light is an atmospheric light. Added Exposure as new light unit. Improved order independent transparency triangle sorting precision. Added Virtual Shadow Map high quality shadow filtering for translucent surface for Substrate and legacy path. This is a global opt-in feature (r.Shadow.Virtual.TranslucentQuality). Bug Fix: Fixed Subsurface Profile causes an orange rim using Ray Traced lighting at certain angles. The issue is caused by not enough penalty to the depth in the screen-space bilateral filtering. Fixed missing Volumetric Fog light function from atlas for Spot Light. Fixed incorrect atlas packing when textures are streamed in / out and require a full atlas refit. Also fixed a crash when Rect Light atlas force update is enabled and lights get toggled on and off. Fixed a potential Ray Tracing performance issue with invalid shadow rays being traced. Fix incorrect ref counting decrements when texture is removed from Rect Light texture manager. Fixed unclamp radius / length for Point / Spot Lights causing visual artifacts. Fixed overflow when computing Rect Light texture MIP causing incorrect atlas packing. Lumen New: Height fog in Lumen Reflections is now partially supported (only Height Fog, not Volumetric Fog). Lumen reflection on translucent now accounts for roughness and goes through the denoising process. Lumen reflections with hit lighting now support multi-bounce reflections, controlled by \\"Max Reflection Bounces\\" setting in Post Process Volume. Lumen Hardware Ray Tracing path is now fully compatible with async compute and it's enabled by default on supported platforms for improved performance. Added boolean \\"Allow Front Layer Translucency\\" to material, which allows to control whether given material should write Front Layer Translucency. This is useful to disable small particles from using Front Layer Transparency or solve sorting issues. Improved Lumen Scene tracking of primitives. Primitives are now included in the Lumen Scene only if they can be traced by a currently active tracing method. Added support for Nanite Ray Tracing in Lumen HWRT and Ray Tracing Debug Visualizations Increased \\"r.Lumen.Reflections.MaxBounces\\" limit to 64. It controls the max number of bounces when multi-bounce Lumen reflections are enabled. Added \\"r.Lumen.Reflections.VisualizeTraces\\" debug utility. It visualizes a dedicated reflection ray traced from the current cursor position. Replaced Lumen Scene visualization with Geometry Normals visualization in Lit->Lumen->Overview visualization mode. Geometry Normals view is useful to spot any issues with distance fields or ray tracing setup. Added support for two sided and thin foliage shading models in Lumen hit-lighting path. Enabled ray tracing culling by default in order to simplify initial setup. Improved global distance field ray hit evaluation, decreasing possibility of sampling surface of an occluded object which is near to the hit point. Made significant Lumen HWRT optimizations which hit-lighting optimizations targeting PC. Crash Fix: Fixed a crash when setting world space radiance cache probe resolution below supported values. Bug Fix: Fixed opacity clipping not happening on Lumen front translucency. Fixed geometry normals on meshes with negative scale (flipped culling) when using hit lighting reflections. Fixed Lumen not working with ISM / HISM due to automatic primitive merging in surface cache. Fixed an issue with \\"r.Lumen.ScreenProbeGather.ScreenTraces.HZBTraversal.SkipFoliageHits\\" when Substrate is enabled. Fixed mesh card generation hangs on specific meshes due to an EmbreeRay issue where EmbreeRay.ray.tnear could end up being further than EmbreeRay.ray.tfar causing an infinite loop. Fixed Material Ambient Occlusion which was incorrectly applied on top of emissive when not using async Lumen, and on top of emissive and direct lighting when using async Lumen. Fixed Time material node being always set to 0 when capturing Nanite meshes into surface cache. Fixed artifacts when running on GPUs supporting only 64 thread wide waveops. Fixed missing reflections far away in the distance due to a hardcoded 1000000.0 cutoff in the bilateral filter. Fixed surface cache corruption after surface cache atlas resize or compression settings change. Fixed SWRT reflection traces feedback for mesh SDF and heightfields Fixed radiance cache lag in scenes with lots of geometry detail (foliage, trees). Such scenes were requesting too many new probes per frame, preventing cached probes from getting any updates. Materials and Shaders API Change: Please use the more efficient UMaterialExpression::GetInputsView() instead. Any code explicitly using FShaderCompilerInput::bGenerateDirectCompileFile should be replaced with EnumHasAnyFlags(Input.DebugInfoFlags, EShaderDebugInfoFlags::DirectCompileCommandLine) instead. FShaderCompilerEnvironment::GetDefinitions is now deprecated; only internal shader preprocessing code can now access values of preprocessor definitions. Any code which was previously retrieving definitions by value should set such values via FShaderCompilerEnvironment::SetCompileArgument (or via the helper SetDefineAndCompileArgument which can be used for values which are consumed by both the preprocessor and compilation code) and retrieve these values via FShaderCompilerEnvironment::GetCompileArgument. Remove any usage of the FShaderPipelineCompileJob::bFailedRemovingUnused; it's no longer needed or used anywhere in engine code. In the unlikely case there is code referencing FShaderCompilerEnvironment::RemoteServerData it should be removed if possible. If there are use cases of this for which other mechanisms (such as the new compile argument functionality) are not sufficient, please contact the UE dev team. New: Optimized material expressions concerning loop detection. This removed individual calls to UMaterialExpression::ContainsInputLoop() and instead moved graph loop search in HLSLTranslator::Translate(). Since this can be done once for all inputs, the visited node set can be shared, making the loop search algorithm O(n), which visits each node exactly once rather than O(n^2) that performs the loop check for each node independently. This optimization, combined with other optimizations, makes translating an expensive material from 5.6 seconds to 0.9 s (a material from Fortnite was used in this test). Added code in Material Interface serialization function that validates the associated EditorOnlyData name to be \\"canonical\\" (name of the material followed by \\"EditorOnlyData\\"). If the name isn't canonical it may cause problems with the editor running on cooked content. The validation code will try to rename the EditorOnlyData to the correct name. Added support for virtual texture feedback behind a Single Layer Water Material. We stochastically drop some writes to the feedback buffer so that we don't overwrite all of the content from the surface beneath. The legacy MCPP preprocessor was removed and all shader preprocessing is now done with the new \\"stb_preprocess\\" library. Made a change that modifies and future-proofs the mechanism which determines which debug outputs should be dumped for a particular shader compile input. Rather than an ad-hoc collection of boolean flags, a bitfield enum class is now used instead. Added a new \\"compile argument\\" functionality on the FShaderCompilerEnvironment class. This is intended to be used for any generic arguments required by the IShaderFormat implementations as input to the actual compilation process; previously the preprocessor definitions were being abused for such arguments. This is a requirement for forthcoming work which improves the job caching and deduplication mechanisms. Added functionality to validate the consistency of the shader job cache. If enabled, compilation will be run for all shader jobs, even those that would have been cache hits, and then the resulting output will be compared with the existing cached value. Output for any mismatches will be dumped to Saved/ShaderDebugInfo/CacheMismatches, with files named according to the input hash whose outputs do not match, along with log warnings indicating the mismatch and the associated filenames. Since this effectively disables the job caching mechanism by always compiling jobs, this should only be enabled locally in the case where a cache collision is suspected (which could potentially be the case when DDC is reporting non-determinism in shader maps). Implemented \\"GetShadowReplaceState\\" for ray traced shadows. Implemented support for explicit #error directives in the shader source in the new preprocessor library. Fixed a mismatched string formatting argument in the shader compiler (for hlslccflags). Dragging a cubemap texture onto a mesh in the Editor now generates a compiling Material. Added camera relative origin options for object, actor, and particle Material expressions. Performing calculations in camera space is more precise and is usually faster by avoiding double precision math in Materials. ODSC + Staged builds — The ability to launch a staged build and only use the COTF server to process recompileshaders commands. Adds a cmd line option, -odschost=127.0.0.1 which allows the game to connect directly to the COTF server, but only to send ODSC recompileshaders commands. If we don't have a default COTF connection (for cooking assets), we create our own connection to the COTF server. Refactor code to send a command to the COTF server into a function. That way if we don't have a \\"special\\" ODSC only connection we can use the command that way. Fixed an issue with the \\"RecompileShaders material\\" command. It would only search and find a single material and recompile it. This ignored any material instances. Now the code takes into account finding all dependent instances and issuing a recompile command for them. Added cook stats to track critical path, game thread time to submit Material compile jobs. On Lyra this accounts for ~10.4% of a full cook with -noshaderddc and a warm cache for everything else. On CitySample this accounts for ~8.9% of a full cook with -noshaderddc and a warm cache for everything else. Added EffectiveParallelization to the cook analytics for shader compilation. This statistic shows up as \\"Shaders_EffectiveParallelization\\". NewGatherAnalytics should be grabbing the CompileStatsLock since it is reading the stats - The console variable r.SSProfiles.Transmission.UseLegacy was added to use the legacy transmission profile. This is enabled by default. When legacy transmission is disabled, the transmission profile is more physically accurate. When enabled, more artistic license is possible by adjusting the ExtinctionScale. ComputeAllStateCRC()was added. This provides a way to more quickly detect changes to a Material, including changes to any Material Functions or Material Instance parameters. The Material option \\"Always Evaluate World Position Offset\\" was added. When enabled, World Position Offset is always evaluated for a Material, and cannot be disabled by \\"Evaluate World Position Offset\\" or \\"World Position Offset Disable Distance\\" on the component. This override is intended for Materials that should not disable World Position Offset, even for performance purposes. Added Shader Compilation stats to cook analytics. This adds GatherAnalytics to the various shader compilation classes allowing each of them to pass their own stats back to the cook. These stats have the base name \\"Shaders_\\" as a prefix. The goal is to capture high level stats which are good indicators of performance and are useful for catching regressions. Also added: Shader Job Cache stats to track Queries Hits, NumInputs, NumOutputs, and MemUsed. MemBudget Stats that include ShadersCompiled, TotalThreadTimeForAllShaders, and TotalThreadPreprocessForAllShaders. The compiler options flags CFLAG_CullBeforeFetch and CFLAG_WarpCulling were added to control warp culling and Cull Before Fetch hardware optimizations. Added the console variable r.MaterialLogErrorOnFailure which emits an error when a Material fails to compile (instead of a warning). This variable defaults to false, but you can enable it from the command line with the following: -dpcvars=\\"r.MaterialLogErrorOnFailure=1\\" Added a cook stat to provide path time metrics on UMaterialInstance::PostLoad. This accounts for 7% of critical path time when cooking certain projects. Improvement: Optimizations in Material translation code amounting to 50% speed up. Optimized function UMaterialExpression::GetInputs() with highest exclusive run-time during material translation from 19.79% to 1.79% exclusive run time. This change caches the inputs upon expression creation by default and returns a TArrayView instead of always creating a new transient dynamic array. The optimization also simplifies code for some Expression types. Also optimized ContainsInputLoopInternal() to use a linked list of stack allocated nodes instead of Pushing/Popping from a dynamic array. Don't set EarlyZ if we are sampling virtual textures but not doing any virtual texture feedback. This is a small optimization for the case of rendering with runtime virtual texture and not using feedback. Typically that can happen with landscape grass. Implemented changes to hash and calculate Material Debug Name once per-Material instead of once per-shader job. FStrings are passed by reference in PrepareMaterialShaderCompileJob instead of copying them. Crash Fix: Added a check that reports errors if a parameter in a Material is bound to different values, instead of silently trying to compile the Material anyway. This was causing a crash when two Material functions containing a shared parameter bound to different values (for example, different textures) were used in the same Material. Fixed access in \\"ItemPropertyNode.cpp\\" to a shared ptr constructed from a weak ptr. Code was not testing that object still exists, causing a crash when resetting Linked Material Blend Layer to Default. Fixed a bug in MaterialX Luminance, which caused the Editor to crash after dragging an additional Luminance variable from the same connected node. Fixed a crash caused by errors in the code for Material duplication. Implemented changes to prevent the Editor from crashing when the user selects a Material whose ShaderMap contains null shaders. This change only makes the Editor more robust and prevents the crash; shaders in the ShaderMap may be null after loading due to external issues. Fixed an Editor crash when Material Parameter nodes were renamed to an empty string. Empty strings are now ignored when renaming a Material Editor node. Bug Fix: Fixed too intense transmission in the Subsurface Profile shading model by extending ExtinctionScale from 1 to 100. This reduces the transmission distance when the scale is larger than 1. Resolved several issues with CompileFXC.bat which prevented it from working correctly. Addressed issues with the FRHIDispatchIndirectParameters size which could unnecessarily cause a full shader recompile on some platforms. Fixed an issue with decals being rendered a second time in the translucent pass. This could happen for some depth of field setups, including the cine camera view. Fixed an issue which caused oversaturated emissive GBuffer decals caused by shader code typo using DECAL_RENDERTARGET instead of DECAL_RENDERTARGETMODE. Fixed an issue with wireframe colors on shipping builds. Fixed a bug where MaterialInstanceDynamics created in the Blueprint Editor were not marked as public. This prevented the level from being saved. Fixed a subsurface transmission bug where the transmission lookup table (LUT) is incorrectly built based on unit scale for the subsurface profile. Fix a bug preventing some Materials from being moved to a different folder in the Content Browser. The issue was caused by an invalid state of the Material EditorOnlyData. Disabled ability to override parameters that cause Material Instances to create a new shader permutation when parenting a restricted (non-base game cooked) parent. In restrictive mode, material instances could not inherit from a cooked material not in base modules. Now material instances can inherit from such restricted materials as long as they do not introduce a new static parameters permutation and thus a new shader. To prevent this, the user interface disables the checkboxes that would trigger a new shader to be created, with full validation is still performed at cook time, so even if a user manages to create a material instance with a static permutation, this would be rejected by the content worker. Fixed a memory leak which occurred when Planar Reflections outside the camera view were culled without releasing the memory. Solved an issue with incorrect Material EditorOnlyData name messaging being generated during cooking. Fixed artifacts in the Clear Coat shading model which occurred when one of the components of the base color is exactly 0.0. Fixed a bug with DistanceFieldApproxAO returning an incorrect result when the Material specifies an input Normal. Fixed a bug whereby Material Instances with different sets of static parameter values and other flags would race to print out debug information, resulting in different sets of debug info from one run to the next. Solved a regression in the job cache hit rate, which occurred because the debug info path was always included as part of the computation of the job input hash. This information is now excluded from the hash, restoring and potentially improving the hit rate. Fixed a minor bug in the shader parameter parser functionality which was assuming only a single space between #line and the line number in line directives. Fixed a crash in the Material Analyzer which occurred when a StaticComponentMaskParameter was present. Fixed an enum mistake in UMaterialInterface::GetFontParameterValue. Deprecated: Reintroduced (and deprecated) the older version of ContainsInnerLoopInternal() in UMaterialExpression. The FShaderPipelineCompileJob::bFailedRemovingUnused field was deprecated. The only purpose of this field was to append some information to a log message which was determined to be unnecessary. The FShaderCompilerEnvironment::RemoteServerData field was deprecated. Since some IShaderFormat-specific remote compile functionality was removed, this is only used for adding unnecessary ifdef'd out debug info to associated shaders. Removed: Removed const from GatherAnalytics since it now needs to grab the lock and call GetTimeShaderCompilationWasActive. Nanite New: Add an option on Static Mesh for WPO not to write velocity. We default to writing velocity, but the option can be useful if we know that we have \\"static\\" WPO for things like camera-facing impostors where we don't want that to generate motion vectors. Added support for Spline Mesh Component with Nanite. This is experimental. Improved visual quality of selection outlines of Nanite in the editor. There are no more jittering, or occlusion issues. Implemented instance culling hierarchy and support for Nanite instance culling based on this. The feature is disabled by default (r.SceneCulling), and may be considered Beta for this release. Added a new show flag to enable/disable the visualization of Nanite streaming data (Show -> Nanite -> Streaming Geometry). When disabled Nanite meshes will only be rendered at the quality level that is always resident in memory. Added new Explicit Tangents option to Nanite mesh settings. When enabled, the tangents are stored explicitly on disk instead of being derived implicitly at runtime. While this comes at a small additional storage cost, it can be preferable in cases where the implicit tangents are not precise enough. Optimized CPU overhead of Nanite streamer Improvement: Implemented performance improvements to NaniteStreamOut. New sliding window vertex cache for pixel programmable. 20% faster masked foliage rasterization in forest scene. Crash Fix: Fixed a crash that would happen in building Nanite if the mesh had no triangles. Fixed a crash in the Nanite streamer that could occur on shutdown. Fixed a crash in the Nanite streamer that could occur on IO errors. Bug Fix: Fixed a bug in the editor where selecting an ISM / HISM actor or component would not render selection outlines for Nanite instances. Fixed the \\"Shadow Pass Switch\\" Material node for World Position Offset, Pixel Depth Offset, and Opacity Mask on Nanite materials. Applied a fix for the Camera Position Material Expression node returning the wrong position for shadow views with Nanite programmable rasterization. Fixed issues with selection and deletion of Nanite Foliage Instances in the editor. Fixed an issue where some Nanite visible clusters' flags could get cleared, causing WPO to be disabled for them. Fixed issues with Custom Depth rendering of Nanite on consoles. Fixed an issue where reading custom data as a vector in a Nanite Material to calculate World Position Offset would always result in using the default value. Fixed issues with rendering Nanite custom depth with multiple views (for example, split-screen and VR) Added a check when the build process goes out of memory and prints better log info (error code and Graph->Num when PartGraphRecursive fails). Fixed Client issue that does not respect Allow Masked Material set in the editor Fixed an ensure that could trigger when Nanite meshes were loaded, but there were no Nanite meshes in the scene. Neural Network Engine (NNE) New: NNEModelInstance has been introduced to prepare weight sharing optimizations. A runtime now creates a model, and one or multiple inferable model instances are created from a model. NNE runtimes have been moved to own plugins which need to be enabled in addition to NNE to become available. Improvement: The NNERuntimeORTCpu has been updated to use the ORT 1.14.1 library. UNNEModelData assets have an allow list to exclude certain runtimes from cooking it. It can be accessed by double clicking the asset. The feature defaults to an empty list which will cook for any runtime matching the previous behavior. UNNEModelData assets can be reimported and opened in editor (using netron). Deprecated: The old NeuralNetworkInference (NNI) has been removed, please use NeuralNetworkEngine (NNE) instead. Niagara New: Niagara opaque particles can now collide with depth buffer without colliding with themselves. It can be achieved using the new PartialDepthBufferCollisionQuery node. This is Experimental. Implemented Summary View 2.0 which allows the user to create custom views for an emitter. The primary use case is exposing specific inputs for complicated emitters, such as fluids. However, this is a useful feature to put emphasis on specific parts of an emitter. Now we allow Python conversion scripts to reset values to their default and set hidden inputs on the new module. Exposed Timed Niagara Effect Properties to Blueprint. Added drag/drop support for emitter assets in the system editor. Made visuals for convert nodes more compact. Added support for curve assets to the curve data interfaces. Added Collapse Categories support for the stack. If a Data Interface (any object, but primary consumers are Data Interfaces) has that flag, root level categories are skipped and instead their children are used. Revamped the Stack type UI (more compact, more color, better visuals). Added a setting to make numeric inputs feel snappier by updating the sim after every input change. Improved metadata for module inputs. Added True argument to allow the deletion of a static switch variable when no static switch is referencing it anymore. Added Inline enum support for static switches to Niagara. To use it, set a static switch node to Integer mode. The case labels are now editable. If edited, the display of the integers will show up like an enum in the Niagara stack when editing module inputs. To change this, access the Widget Customization entry in a variable's settings. Default is the default integer view, and Enum Style is the enum-like view. This is useful for one-off static switches that are kept in a single module and don't need an entire enum asset to be created and maintained. Added widget support for stack inputs (sliders, min/max, volume). Niagara renderers can now be moved via context action. When pasting an entire emitter from one system to another, user parameters are now copied with them and added to the new system, if they don't exist yet. Added age update mode dropdown to life cycle track. Added a component and life cycle track by default when adding a Niagara Actor to sequencer. Added a warning if life cycle track is not set up correctly for sim caching. Added Python script support for deprecated module changes. Changed the Reset Simulation command (hitting Space) to also resume playback if currently paused. Reordered system properties. User Parameters now support widget customization via the User Parameters Hierarchy Editor. This includes setting Min and Max, displaying floats or integers as sliders, and more. Added a default UI state option for emitters that determine if they will be shown in Summary View or default view when added to a system or creating a new emitter. Changed the Behavior Examples label to Learning Examples. Added logic to ensure the emitter editor data exists when an emitter is post loaded or initialized. Simplified emitter properties: Removed Combine Event Spawn option. Removed Script Category property for emitters in systems. Removed Asset options properties for emitters in systems. Moved Attributes To Preserve to the advanced view. Hide Pre Allocation Count is now hidden if the mode is automatic estimate. Moved Max Delta Time Per Tick to the plugin settings. Added a decal icon for the decal renderer. Changed the tab names Selection and Selected Emitters in the Niagara System editor to Details, including the icon, to be more consistent with the engine. Fixed pin coloring for constant value make nodes. Added thumbnails for curve assets. Added a context menu option to record multiple cache tracks at once. Added a new scratchpad action and set parameters to suggested in menu. When renaming User Parameters in the User Parameters tab, name verification is now implemented. Added duplicate script variable validation and fix logic. Validation and Fix can be run via command line in editor. The commandlet can be run via the project startup command line and will print out all scripts with their given guid conflicts. Added a custom search box that adds filtering for parameters in the NPC editor. More view settings are now saved per-asset (view location, view rotation and orbit mode) or in a config file to maintain Niagara viewport settings across sessions. Improvement: Improved the UX to expose options of function script input nodes. Crash Fix: Added reallocate pins when a static switch node references a different, pre-existing script variable via renaming. This fixes a crash where the visuals expect the pins to be created under the new static switch variable. Fixed a crash when trying to set uobject-attributes in the stack. Refactored a temporary array of transient stack entries that could get garbage collected anytime and cause various crashes. These stack entries managed stack entries for comment nodes, so now we have a proper comment collection stack entry. Bug Fix: Added various small fixes to static switch nodes. Fixed an ensure being triggered when editing any FText field in Niagara script details. Fixed a bug where sim caching can lead to minute-long hitches with large numbers of particles. Fixed a bug where disabled modules could generate compile warnings. When applying modules that are in use in an emitter/system, the module no longer gets deselected, and the UI gets refreshed so we get live changes. Fixed a bug where component renderers were still visible when another emitter was running isolated. Fixed a compilation bug with disabled nodes and data interfaces. Removed the search box in the Details panel of the NPC editor. Fixed the scroll bar not appearing in the Niagara Parameter Collections. Fixed copy paste of modules not properly pasting values for static switches in static switch chains. Fixed issue when finalizing empty sim caches. Removed of incorrect default pins that would show up as 'None'. Fixed scratch pad parameter panel bug where if a used function had the same parameter as the script asset that owned it, it would override the asset's own parameter. UI wise it would look fine due to the same name + type, but selecting it wouldn't work as the guid wouldn't match. - Removed sub graphs adding their script variables to be used for the script parameter panel - Refactored into using the graph's script variables directly instead of using the reference map. Reference map is now only used for reference count, not for item creation. Fixed copy paste of modules not properly pasting values for static switches in static switch chains. Fixed system parameter panel selecting parameters in scratch pad via name instead of via guid. Fixed dragdrop ops of different types than FNiagaraHierarchyDragDropOps from being used in the hierarchy editor. Fixed issue when adding a new user parameter while a custom section is selected. Fixed issue where the length of the life cycle track was not evaluated correctly when caching a Niagara simulation. Fixed LWC issue in camera DI. Fixed emitters opening up the parameter panel to \\"Active Module\\" instead of \\"Active Overview\\". Fixed editor only parameters not being marked as RF_Transactional. This fixes issues with transactions not properly being recorded in Niagara. Fixed issue where replacing a module with another module using the same name caused it to lose static switch inputs. Fixed issue where HLSL compile errors were not correctly shown in the stack. Fixed a crash when using LWC structs. Fixed issue where SWC structs would appear in the UI. Fixed issue where using LWC structs as module inputs would not use the correct struct converter. Fixed the script variable customization to also account for parameter pins that are disconnected from an output node. This fixes an issue in which a disconnected parameter pin wouldn't show its custom pin if the value mode was set to 'custom'. Also, you no longer need to reselect a parameter after adding it to a parameter map get node to make it show the default value Added additional call to replace user param references on emitters and fixed renderer attribute binding references not being fixed when renaming a user parameter. Fixed issue where the wrong asset was used to initialize sequencer recording. Fixed emitter assets not dirtying when disabling a sim stage. Fixed loss of parameter references when updating an input parameter's name in a module. The 'BoundPinNames' array was getting updated with an incorrect parameter handle, which made the lookup for subsequent renames break Fixed issue where changing versioned properties would not dirty a script/emitter. Fixed issue with async raytrace data interface not issuing traces. Stopped considering input pins for get nodes as parameter reference This fixes an issue where a pin that was only referenced in a get node would count 2 references, which would stop it from being renamed properly from pin as it would duplicate a new parameter Fixed transform function descriptions in camera DI. Fix for the Apply button in Niagara scripts only checking for the exposed version guid instead of the currently edited version. Fixed missing stack refresh when changing a user parameter name. Fixed issue where the Details view would not properly show rows with changed visibility after a tree refresh. Fixed issue when undoing an emitter add transaction. Fixed an unnecessary refresh in the parameter panel causing loss of selection after modifying a value of a variable. Added metadata to allow multiline text entry for python script. Fixed sequencer caching bugs. Fixed Blueprint API of \\"spawn system with parameter\\" functions. Fixed output & transient parameters appearing outside their own stage when opening a parameter menu. Fixed Custom HLSL pins not being modifiable. Also added visibility delegates for action \\"Reset to Default\\" and \\"Promote to Parameter\\". Also changed the Pin Section name used in Niagara to use the parent section name so we no longer have 2 sections called \\"Pin Actions\\" at times Cleanup of old rapid iteration parameters used name only, not type. This resulted in cases where old parameters that used the same name as a new parameter of different type would not get cleaned up. Fixed multiple lookups in the merge manager that looked up by name only instead of name + type. This in conjunction with the fix above results in more stable diff process. All of this fixes an issue where some fluid emitters were showing or not showing the 'reset to parent emitter' arrow wrongly 'Ghost entries' no longer appear and a stack search result gets maintained even after changing a value in the stack. Focusing the scratch pad manager tab when creating a new scratch pad so you can immediately rename it Made the toolkitmodebase public so that other parts in the plugin can access the tab names properly Fixed \\"parameter for\\" node. Fix highlighting of multiline HLSL comments. Fixed issue where the simulation was always reset after a change, even when paused. Heterogeneous Volumes: Introduce per-volume step size based on local-space step factors. Step size is now calculated in local space as a function of voxel width, projected along the ray direction. Toggle global step-size values to -1 (disabled). Change default MaxStepCount to 512 steps. Fix for alpha-compositing issues with Heterogeneous Volumes when using the Niagara baker. Sort heterogeneous volumes by camera-depth and adjust compositing to match. Path Tracer New: Added depth pass for path tracing that matches the behavior of the rasterizer path. The output is in DepthZ so post process depth of field works now as a bonus. You can use the same depth post process material to output in Movie Render Queue. If you'd like to disable the path traced depth buffer and use the depth from the rasterizer instead, you can use \\"r.PathTracing.Override.Depth 0\\". Also, the \\"Output Depth\\" has been renamed to \\"Output Depth and Velocity\\" in Materials. Added Post Process Material and Movie Render Queue support for path tracing buffers. This means that Post Process can access path tracing buffers (raw/denoised radiance, albedo, normal, variance) with unique materials using the \\"Path Tracing Buffer Texture\\" Material Expression. And, access means that output in Movie Render Queue is supported. Added basic support for Substrate has been implemented. The path tracer can now handle Substrate Materials, including multi-layered ones. Substrate's MFP is mapped to random walk subsurface scattering for opaque materials and to absorption in translucent cases. We expect to see fairly close agreement in many cases, though this support should still be regarded as experimental. Support for translucency and thin shading models are expected to improve in future releases. Sky meshes should be included for raytracing when using the path tracer The console variable \\"r.RayTracing.ExcludeSky\\" is now ignored when the path tracer is active. Implemented support for DBuffer Material Expression functionality in Path Tracer Added a Blueprint call to invalidate path tracing output. The intent of this call is to give control over cases that cannot be handled by automatic invalidations. The path traced image now invalidates itself when a Skeletal Mesh morph target changes. Changed refraction rays to behave more like camera rays with respect to the \\"Affect Indirect\\" primitive setting. This makes refraction and transparency behave more consistently with one another. Added support for path tracing heterogeneous volumes. This uses the Voxel Grid Pipeline to create global acceleration structures to represent heterogeneous volumes in the path tracer. Creation of global acceleration structures is memory intensive. Refer to the corresponding Voxel Grid Pipeline CL 25170595 for instructions on parameter tuning to control memory and quality. r.PathTracing.HeterogeneousVolumes (default = 0) Enables heterogeneous volume rendering in the path tracer r.PathTracing.HeterogeneousVolumes.RebuildEveryFrame (default = 1) Rebuilds the acceleration structures every frame. Adding volume emission to the path tracer. Improvement: Improved SSS random walk sampling. Improved volume light sampling for local lights. OpenImageDenoise transfers have been sped up. Some optimizations were made to the pixel readback which saves some denoising time. Bug Fix: Fixed darkening in subsurface scattering when the scattering radius is small. The code now more seamlessly blends towards the diffuse behavior instead. Fixed issue where materials using non-tangent space normals could have flipped normals in some cases. Fixed fireflies that can occur from the rough diffuse shading model at grazing angles. Fixed the \\"Path Tracing Quality Switch\\" node in materials not working in decal materials. Removed: The Path Tracing Post Processing Volume setting for Filter Width for anti-aliasing has been removed. We found the default value (3.0) is effectively the optimal one and that there wasn't much reason to change it. If you still need this property, you can use the console variable \\"r.PathTracing.FilterWidth\\" to adjust it. Postprocessing New: Added a Post Process Setting to Image Effects with Sharpen. This controls the strength of image sharpening applied during tonemapping. RHI New: Vulkan Bindless: Push a draft implementation of the FVulkanBindlessDescriptorManager that uses VK_EXT_descriptor_buffer. Uses one descriptor set for each type of resource, each backed by a descriptor buffer. Everything is bound and visible to every shader, except uniform buffers which are bound per draw/dispatch. Uses a single pipeline layout for everything. Initial buffer sizes for each descriptor type can be configured through CVars (they do not automatically grow yet). Still very experimental, and requires multiple other features to be disabled. VulkanRHI: Use array for dynamic buffer allocations and removed the hardcoded \\"NUM_BUFFERS=3\\" value. Use a fence to manage buffer availability. Do not rotate dynamic buffer usage when a staging buffer is used for the copy. VulkanRHI: Vulkan SDK upgrade to 1.3.239 Removing full-type RHI_API uses and adding them to members that need it. This reduces export counts and is part of upcoming coding standard changes. Moving D3D12 Extension includes into their own headers. Updating to Agility SDK 1.610.2 Moving a couple DDSPI fields to Editor-only code blocks, and moving Editor-only DDSPI types into the cpp files to keep Editor includes out of the global scope. VulkanRHI: Moved Engine minimum core version to Vulkan 1.1. VulkanRHI: Added VULKAN_SM6. Moved features and requirements around to match what was done on D3D12 SM6. Making FRayTracingGeometryInitializer not a memory layout type since nothing needs it like that anymore. VulkanRHI: Use Vulkan profiles to validate support for a feature level on startup before call to CreateRHI(). VulkanRHI: Added Vulkan_1_3 support for shader compilation, which is used for VULKAN_SM6. Improved DX12 GPU breadcrumbs that track all active, finished and not started scopes on the GPU. The new implementation logs all scopes currently scheduled or active on the GPU. RHI: Avoid re-allocating the OutData array in RHIRead*SurfaceData when possible. Enabled async compute by default in D3D12 on NVIDIA Ampere and newer cards. The command line argument \\"-vulkandebug\\" allows usage of our distributed vulkan validation layers for both Windows and Linux. Bug Fix: Bumped nVidia minimum version to 527.27. A random issue with landscape tools has been known to be problematic for drivers less than version 526.67. The exact cause is unknown but a resolution appears to have been made in one of the 527 releases. The first version to not exhibit the problem is 527.27. Fixed FRHIGPUTextureReadback to work with subrects, as well as volumes and texture arrays. Fixed structure init in Vulkan RHI. Removed: Removing RHI code deprecated in 5.0. Removing deprecated RHI symbols. Removed CoreMinimal includes from public RHI headers. Removed the deprecated RHISetComputeShader. Substrate New: Brought back proper premultiplied alpha that can be toggled on Materials and Material Instances. Coverage over the background can be overridden from the root node when Alpha Composite Blend Mode is selected. If not plugged in, coverage of over background is off and regular blending is used. Added support for decals with Substrate Materials. GPU Lightmass now supports Substrate Materials. Added support for glint BSDF to Substrate. Ray tracing material shaders use fully simplified material for smaller payload. Optimized Substrate shader compilation time. Added in Material Editor complexity on Slab node. Substrate now uses progressive material simplification to fit in memory. Simplifying Slabs at the bottom of the material topology first. Made multiple improvements to the Material Editor Substrate tab. Added support for Planar Reflections to Substrate. Lumen card capture now uses fully simplified material with Substrate. Added distortion coverage mode to be compatible with legacy distortion in Substrate Materials. Fixed some editor pop up message due to bad bitfield macro when using Substrate Materials. MFP is no longer clamped to fp111110 when in forward to be able to get to an transmittance closer to identity=1 (invisible surface). Allocation of tile tile list buffers is now independent from the dynamic resolution when using Substrate. When a new material is created using Substrate, a simple UE4-like lit shading model material function is used instead of a Slab. This shows that Substrate works with material function and makes material authoring simpler by default. Added Substrate node for converting Index of Refraction to F0 and rotating anisotropy tangent. Added Substrate Standard Surface nodes. Add Specular Profile to Substrate. This allows the artist to provide a custom LUT describing specular behavior for view and light angles. The LUT can be procedurally generated or provided from a texture. Added material buffer allocation policy. This allows control of how the material buffer is allocated. This is controlled with \\"r.Substrate.BytesPerPixel.Mode\\". When set to 0, allocate material buffer based on view requirement. When set to 1, allocate material buffer based on view requirement, but can only grow over frame to minimize buffer reallocation and hitches. When set to 2, allocate material buffer based on platform settings. Added Byte Per Pixel view mode for Substrate. Change Substrate Cloth / Sheen model to From Charlie to Disney LTC. Added normal curvature-based roughness support. Added Substrate Topology previsualization on the Substrate node within Material Editor. Improvement: Improved Substrate diffuse color sRGB encoding. Crash Fix: Fixed a crash when assigning a Material Function onto new material that is reopened later. Fixed a crash when a Substrate Material has more shared tangent basis than allowed. Bug Fix: Fixed Substrate Material Preview on nodes to account for the Substrate tree from the previewed node only. This fixed material function input / output, reroute nodes and everything in between that is not directly connected to FrontMaterial. Applied a fix for Virtual Shadow Maps and Subsurface Scattering using Substrate Materials. Fixed opacity clipping for translucent writing velocity. DXC and SPIRV-Cross fixes to enable Substrate in D3D11. Fixed Volumetric Cloud Extinction being grayscale. The Unlit Shading Mode now also works with refraction. Fixed emissive exhibiting different behavior when enabling Substrate. Decals now do not impact the look of other substrate material when in range of effect. Fixed a wrong opacity with Substrate for depth and velocity. Fixed \\"UseDiffusion\\" affecting the look of simple Volume Slabs. Slab now respects Additive Blend Mode. Fixed bad transmittance when doing masking through a vertical layer operator and more than 2 layers. Applied a fix for Substrate interacting with responsive anti-aliasing. Fixed microoclusion/F0/F90 usage. Brought back support for \\"Custom UV\\" on root node. Substrate now properly accounts for \\"Allow Negative Color.\\" Fixed Lumen ScreenProbeGather ReferenceMode when Substrate is enabled. Fixed Lumen ScreenProbeGather and Lumen Reflection temporal filtering with multi-BSDFs. Fixed Lumen history being reset on LumenScreenProbeGather & LumenReflections when Substrate 'max BSDF count' change. Fixed legacy Eye Material conversion with Substrate. Avoid non-necessary initialization causing massive shader stall. Reduce base pass cost of complex material by ~50%. Fixed ray traced shadows with Substrate Fixed Lumen specular interreflection with Substrate. Fixed Lumen ScreenProbe / Reflection history reprojection with dynamic resolution scaling when enabled. Also fix Lumen ScreenProbe normal disocclusion. Fixed Lumen.Visualize.IndirectDiffuse with Substrate enabled. Added support for short range Ambient Occlusion with Lumen HWRT path. Fixed \\"IsThin\\" support with SSS diffusion and SSS profile diffusion (now it works as expected, and diffusion is no longer scaled incorrectly) Also fixed \\"IsThin\\" to support surface for translucent case. Fixed Substrate legacy material conversion with Virtual Texture input. Fixed Substrate missing tangent frame when using parameter blending. Fixed increase of energy when light transmission is enabled due to incorrectly normalize phase function Fixed incorrect VSM backface culling with Substrate for pixel having subsurface. Fixed missing Emissive input on Hair materials with Substrate. Simulation Physics API Change: GlobalMatrices has been deprecated and ComponentSpaceTransforms should be used instead. If there's a need to get FMatrix type, Unreal Engine provides simple ways to convert from the FTransfom type to FMatrix type. New: Added the ability to add collision profile overrides per particle, per level, and for abandoned particles on Geometry Collections. Added cluster unions which are functionally equivalent to welding, but for Geometry Collections. This will eventually be expanded to support Static Meshes. Introduced new external context-safe payload that can be used for Chaos acceleration structures. Revamped scene query interfaces with templates to be able to accept additional types of scene query overrides. Exposed a ComponentOverlapComponent function on the primitive component that also returns the overlap result. Geometry Collections will not try to replicate empty internal clusters. Added support for implicit object unions in OverlapQuery and SweepQuery. Added an option (p.Chaos.DebugDraw.ConnectionGraphLevelOffset) to change what level of connection graph is being drawn in Chaos Debug Draw. Disabled cluster particles when they no longer have children. Geometry Collection particles now have a debug name set. Added functions to the physics object interface to make line trace, overlap, and sweep on the UPrimitiveComponent generalizable beyond Static Meshes. Modified the K2 overlap functions to return a hit result as well Introduced a new FPhysicsObjectId alias to add some type clarity to the various functions on the IPhysicsComponent that deal with this ID. Moved ChaosSQTypes from PhysicsCore to Chaos. Exposed getters for the XR and Velocities property on geometry particles. The FaceNormal is utilized in the sweep even when we hit implicit objects without a face index. Added accessor functions to the FReadPhysicsObjectInterface to convert the physics object handle to the raw particle appropriate for the context. The physics object interface and the Scene Query types should now be able to statically select the shape instance to operate on. Added additional trace scopes for the various paths in OnSyncBodies. Added functions to the physics object interface to query the hierarchy level of a particle and generate connectivity edges between particles. Modified the various connectivity graph function APIs to be more flexible and to support filtering based on a \\"from\\" and \\"to\\" set of particles. The physics object interface now uses const handles when possible. Added a function to get the body ID from the component, given a raw game-thread particle. Added support for merging collisions for contact pairs that appear with matching solver time. This removes cases where multiple hits for a contact pair would be received in a single frame with identical velocity data (since delta-V is updated per-frame). Includes information on multiple contact pairs that hit in the same solver frame to allow users to still use the same data. Added torque units Nm and kg cm^2 / s^2, and force unit kg cm / s^2. Added conversion utilities. Optimized FPhysInterface_Chaos::SetMaterial by reusing a formerly temporary allocation. Added render interpolation of the resulting offset from a physics resimulation via linear offset decay. Added functionality to cache physics state of objects that are based on FPhysicsObject. The cached state is used by state replication and unlocks state/movement replication for objects like Cluster Unions which are based on FPhysicsObject. Added the option to override an Actor's physics replication mode via physics object presets. Added a Geometry Collection Dataflow node to simplify existing convex hulls on a Collection, with options to use either mesh-based simplification or a new dihedral angle threshold method. Changed the cache collection object to be usable in Blueprints. Geometry Collections now expose the IsRootBroken function to Blueprints. Made the following changes to Dataflow: Added new math library nodes. Moved make nodes to a separate file. Moved conversion nodes to a separate file. Made sure the Geometry Collection custom renderer system is properly handling the bHiddenInGame flag. Exposed Gravity settings on the immediate physics Actor. Added the concept of internal call stack to the context to allow detection of loops in Dataflow. ISM Pool optimization: made sure instantiated Static Meshed from the ISM Pool do not create their physics state. Added override nodes to Dataflow. Added Override properties to the Geometry Collection asset. Added support for AssetUserData API to Geometry Collection assets. Chaos: Optimized SpatialAccelerationCollection RemoveFrom by avoiding array allocation. Added ability to set the gravity group index for a Geometry Collection. Updated Geometry Collections to report sockets in their root proxy Static Meshes if they are available. Added a Dataflow node to read specific float values from a float array. Optimized data marshalling of Geometry Collections' physics results between the physics thread and game thread. Removed global transforms from the payloads. Only send data for the transform indices that have been changed (reduced copies and memory allocations). Optimized the processing of Geometry Collection physics results by using ref counting pointers instead of making copies of the entire data. Added a setter on EnableNanite UProperty to Geometry Collections. Added the Chaos debug command p.Chaos.DebugDraw.ColorShapesByInternalCluster to display which physics particle is an internal cluster. Added support to LevelSet for the connection graph generation. Added new options to the Auto Cluster tool in Fracture Mode for grid-based clustering and a minimum cluster volume option. The Tiny Geo tool in Fracture Mode now has a Tiny Cluster mode, which merges tiny clusters. This includes options to control whether the clusters considered should be restricted to the current Fracture Level, or to sibling clusters in the current hierarchy, or to clusters connected via the current proximity graph. Added new Fracture plugin project settings to control the default location for new Geometry Collection assets created in Fracture Mode. Added a Quick Settings section to the Fracture Editor UI, to allow users to easily control the default folder for new assets and to jump to fracture project and editor settings. Added a way to control at which level Geometry Collection position and velocity are replicated for clusters. Added support for custom primitive data in Geometry Collection Assets. The Fracture Mode now shows the Rest Collection of the first-selected Geometry Collection in the level, providing easier access to the asset. Added a Get Root Index node to Dataflow for managed array collections. Added Geometry Collection Dataflow nodes: Cluster Selected, Merge Clusters, and Select Target Level. The Split Components setting for Geometry Collections has been renamed Split Meshes, to reduce confusion with the unrelated UE Component concept. Added physics material options on to the Geometry Collection asset. Added the ability to use density from the assigned material ( or the overridden ones on the component). Added the ability to Apply Default from Asset on the component as a button in the editor properties. Added a BranchCollection Dataflow node. The Fracture Mode Materials Tool now shows and updates the materials of the Geometry Collection asset (the Rest Collection), rather than the override materials on the Geometry Collection Component. The Fracture Mode Set Removal, State, and Convex tools now automatically change the Fracture Mode's Outliner Column Mode to Removal, State, and Collision, respectively on switching to the tool. Chaos cloth XPBDSpringConstraints have been internally rescaled to be resolution independent. Existing constraints have their behavior changed depending on their current resolution (spring length). These constraints were not exposed through any existing cloth plugins, so minimal impact is expected. The Fracture Mode Proximity Tool can now set up Geometry Collection proximity based on a measure of the contact area of the convex hulls of the bones. This allows for better filtering of connections where the bones were barely touching, or only touching along a sharp corner. Added a float comparison Dataflow node. Int and Float comparison nodes are now in the Math > Compare category. Added a new material-based Damage Model for Geometry Collections. It is using material tensile strength and surface area of contacts between pieces to compute damage thresholds. Added a node to get the sum of convex hull volumes for a given Geometry Collection bone selection. The Create Leaf Convex Hulls Dataflow node now exposes the option to run a convex decomposition on leaf nodes of a Geometry Collection, enabling more accurate convex collision. Add an Uncluster Geometry Collection Dataflow node. Added the ability to control server and/or client Chaos debug draw via the following console variables: p.Chaos.Solver.DebugDraw.ShowServer and p.Chaos.Solver.DebugDraw.ShowClient. Also added the p.chaos.debugdraw.seethrough console variable to control whether or not the lines are drawn over objects. Cloth to Dynamic Mesh: set default material ID to zero on all sim triangles. Cloth Editor: if any triangle in the render mesh has an invalid material ID, apply the default WoldGridMaterial to it. Added new Dataflow nodes to support exporting of Geometry Collection surfaces, convex hulls, and sphere coverings as OBJ mesh files, and to write Strings to files for debugging purposes. The Fracture Mode Convex Tool now only shows collision shapes for the current Fracture Level. Added delegate InjectInputsExternal to FNetworkPhysicsCallback. This will be broadcast during InjectInputs_External. Chaos Caching: Blueprints are now allowed to access the observed component's EnablePlayback and CacheCollection properties. Added a GetBoxLengths Dataflow node that can get the bounding box lengths for each transform in a Geometry Collection, where length can be measured along a chosen axis, the min or max axis, or the diagonal. Added a SelectFloatArrayIndicesInRange Dataflow node that can select indices in an array of floats where the floats match a specified value range. Added a CollectionTransformSelectionFromIndexArray Dataflow node that can select Geometry Collection transforms with indices matching the values in an array of integers. Made server authoritative Geometry Collection particles unbreakable on the client - Added unbreakable flag to Chaos clustered particles SOA. Added a new Merge Convex Hulls Dataflow node which can reduce the convex hulls used to represent collision on geometry collection bones. Added GetAccumulatedTime function for obtaining the physics solver's AccumulatedTime in fixed step mode. Added a new experimental Skinned Level Set primitive type for Physics Assets. This primitive embeds a Level Set into a lattice which is skinned by transferring the skinning weights from the associated mesh vertices to the lattice. This primitive can only be used by cloth simulations and is experimental. It has not been optimized. Added material strength information to the Chaos physics material. Improvement: Modified primitive component wake/sleep events so that they don't depend on the existence of a BodyInstance, which makes them more generalizable. Geometry Collections no longer construct FName types at runtime for the removal feature related facade classes. Optimized Geometry Collections by removing feature runtime execution. Also reduced its memory footprint per Geometry Collection instance. Moved rendering and navigation updates from the Geometry Collection Component TickComponent method to PostPhysicsUpdate one. Also cached RootIndex in the Geometry collection asset to avoid scanning through all the transforms each time to find it Geometry Collections's bool-typed managed arrays now use BitArray instead of TArray in order to save memory Geometry Collection Optimization: Only enable the primary Geometry Collection Component tick function when removal features are needed (after the root breaks). Optimized the memory storage of Geometry Collection clustered particle flags. Chaos now uses a smaller data type to store clustered particle properties when possible and better manage memory allocation when populating the connection graph. Geometry Collection ISM Pool rendering optimization: Now uses new API to pass transform more efficiently by reducing array allocation. Improved the convex collision generation of Geometry Collection by doing the following: Added Dataflow node to generate Geometry collection cluster convex collision from leaf nodes. Improved Fracture Editor convex visualization (display of convex union when parent convex is missing). Added a column to the Fracture Editor Outliner showing the number of convex and when a parent is using a union. Geometry Collection optimization: Changed GlobalMatrices array of FMatrix to ComponentSpaceTransforms array of FTransform. This reduces the number of back and forth conversion between FTransform and FMatrix. Crash Fix: Fixed a crash issue where clearing a Chaos property flag would cause it to try to remove a dirty proxy when that proxy still had dirty shapes. Fixed an issue with cloth simulation where setting a new Skeletal Mesh asset would sometimes cause a crash. Fixed Chaos unit test crash when using LevelSets in cluster union. Fixed a potential crash in Geometry Collections when a physics state is created while the Rest Collection is not set. This may happen when adding a Geometry Collection component to a Blueprint while having it open for editing in the editor. Fixed a crash when evaluating Dataflow terminal node from Blueprint with a name that does not exist in the graph. Fixed a Chaos Cloth crash in FClothVisualization when the debug materials are loaded. Fixed a crash in the Skeletal Mesh cloth painting tool caused by bone mapping indices left invalid after adding existing cloth data to a Skeletal Mesh asset using a different skeleton. Fixed several bugs that could cause crashes when using Take Recorder while PIE was running with cloth simulations. Fixed an issue where a Landscape would potentially dispatch a newly created physics Actor and then subsequently destroy the geometry it uses before the next physics update, leading to a crash due to use-after-free. Bug Fix: Fixed an issue where disabling a Geometry Collection particle could leave the particle in acceleration structures. FReadPhysicsObjectInterface::AreAllShapesQueryEnabled now works on both external and internal contexts. Chaos event dispatching no longer iterates through all the listeners even when there are no events to dispatch, resulting in a slight performance improvement. Collision conversion now checks against the inner shape type to handle the case of a transformed union. Applying external strain to a Geometry Collection particle should now apply even if that particle doesn't have children. The Blueprint library function for finding the closest physics object will now filter based on whether the particle is enabled or not. Fixed an issue where Chaos Fields would make all particles it made dynamic also enabled, which would cause Geometry Collection particles to collide against their root particle. Removed ensure when drawing unions which have a single shape. Fixed an issue where OnComponentPhysicsStateChanged was not getting called properly for Geometry Collections. Fixed an issue where Geometry Collection events would not be registered properly after the Construction Script re-registers the component. Fixed an issue where internal clusters were not being cleaned up property when children were removed from them, regardless of which path that removal came from. Fixed an issue where Geometry Collection replication was relying on bFirstUpdate to determine whether or not to replicate a cluster. The particle level is used instead. Fixed an issue where Geometry Collections would not properly pull the state from PrevData/NextData for some of its particles with non-interpolatable properties. Fixed an issue where Geometry Collection particles were not being added to the external Scene Query queue. This ensures that they are always in the external Scene Query, even after it gets swapped. Fixed an issue where Geometry Collection cluster particles had a cluster group index set on them when they were the root particle (does not have another parent). Fixed an issue where the RewindData and MarshallingManager would have different sizes of their data history. Fixed a crash happening when simulating physics with a Geometry Collection that has no rest collection assigned. Fixed an issue where populating the physics replication cache consumed a lot of CPU time in levels with many Actors. Fixed an ensure triggering from duplicate Geometry Collection particles caching in rewind data. Fixed an issue that made all islands resimulate when one triggered a re-simulation. Fixed an issue where the Geometry Collection RestTransform was not in sync with the RestCollection transforms, causing incorrect asset thumbnails. Replaced an ensure by a non-breaking verbose log when not finding a supported collision type during cloth collision with the environment. Fixed an issue in the Chaos Cloth editor where the transform gizmo and numeric input in the Preview Scene were out of sync. Fixed an issue in Geometry Collections where the Mass attribute was being accessed as a Double, instead of a Float causing potential out of bounds access. Fixed a Dataflow stack overflow in invalidation code when connecting nodes in a loop. Made serialization of Dataflow node more robust to input and outputs changes. Fixed the cloth painting material offset z-fighting with the source render section by adding a small normal offset. Fixed a compilation error related to duplicated Solver symbols in TUserDataManagerPT::SetData_GT. Fixed a Chaos Cloth crash when undoing mask targets in the Clothing window of the Skeletal Mesh editor. New Geometry Collections now convert vertex colors from Linear to sRGB space for rendering by default, to match the behavior of Static Mesh rendering. Old assets keep the previous behavior for compatibility by default. Use the new ConvertVertexColorsToSRGB checkbox on a Geometry Collection asset to toggle this behavior. Fixed an issue where in some cases Geometry Collection data would not be consistently updated, which caused an ensure on pressing 'Reset' in Fracture Mode. Removed unnecessary tick function from event dispatcher base class which could lead to accumulating no-op ticks from Geometry Collection components in Post Physics tick groups. Removed allocation of multi-find array in GetPendingCollisionForContactPair. Fixed an issue where heightfield overlaps where not taking into account entire materials. Reduced the stack reserved hit buffer sizes down to 16K from 64K in scene queries, still reserving 128 hits for queries prior to heap allocating. Fixed the physics thread Geometry Collection Active attribute not being properly initialized (and taking one update cycle to do so). Fixed a Fracture Mode issue where the alpha channel on Geometry Collection vertex colors would be reset to 1 when a Geometry Collection was fractured. Fixed breaking model considering a parent multiple times when classifying required breaking particles. Fixed children with strains not being processed when their parent cluster breaks. Fixed an issue where IsHole for heightfields was returning True when no materials were present in the heightfield. Disabled sleeping event handling in Geometry Collection event handler. This avoids multiple dispatches of identical sleeping events as they are handled by the scene. Fixed an issue where changes to a Geometry Collection asset in Fracture Mode would not propagate to other Geometry Collection components using the same asset. Updated Chaos Cache Managers to now work correctly when they're spawnable if they're observing components that belong to the cache manager itself. In particular, they will now work if they were created by adding a destruction Cache Collection to the scene. Cache Managers observing other components (e.g., cloth) continue to not be able to be spawnable. Fixed an issue where FRewindData::RewindToFrame would keep dirtying particles/joints every rewind. If the game was constantly rewinding, this would cause the size of the FRewindData::DirtyParticles array to get too big. Fixed an issue where Geometry Collection rendering would not match the Static Mesh rendering because the Static Mesh recomputed tangents and the Geometry Collection did not. Fixed an issue where the GeometryCollectionComponent implicit generation was calculating incorrect sizes for box clusters. Updated Chaos Cloth caching to store the necessary transforms to playback with the correct transforms. Existing caches will continue to work as before (e.g., if they did not require the additional transform information, they will continue to work). Fixed an issue where undoing the creation of a new Geometry Collection would leave a broken asset, which could crash the editor if used. We no longer transact the creation of the Geometry Collection asset, so the asset will persist in a valid state. Fixed an issue where a tiny triangle could make cloth simulation with self collisions very slow. Fixed repeated calls to update Geometry Collection particle views during Geometry Collection proxy initialization. Fixed an issue where the altered rigid clustering advance was considering all top level particles for breaks, instead of only considering the particles that were strained. This greatly reduces the steady state cost of the breaking model. Fixed an issue in Geometry Collections where removal of random generated timer values were not consistent between client and server. Fixed an issue with Geometry Collection caching where caching was not properly recording and replaying if the break event notification was not set on the Geometry Collection. Fixed a Chaos Cloth bug where the shared config ownership was preventing a Skeletal Mesh asset from being saved after adding their clothing data to another Skeletal Mesh. Fixed an issue where the Explode Amount slider was not working when the selected Geometry Collection was inside a Blueprint. Fixed the Chaos Cloth Deformer when using a mirrored transform. UI New: UE attempts to select the best solution when opening files using Visual Studio source code accessors. Bug Fix: Fixed clamping issue in SAnalogSlider where the MinValue and MaxValue were ignored when navigating with a controller. This behavior is now consistent when using a mouse or a controller. Fixed a bug where navigating past the min or max value of SSlider would invalidate the widget and call a value change delegate despite not changing the value. In USlider, fixed a MVVM notification and delegate that were not called when the value was changed from code. Slate New: Moved STextScroller implementation from CommonUI to Slate. Added cache functionality to SDropTarget for expensive AllowDrop operations. This is turned off by default. By default, OnAllowDrop is called every frame, which is user bound. Setting bUseAllowDropCache to true will cache AllowDrop the first time it is called. The cache is cleared whenever a drag & drop operation starts. Added OpenComboBox function to SObjectPropertyEntryBox widget Added ObservableArray pattern to ListView, TitleView and TreeView in Slate. The TreeView implementation only supports the new pattern for the root items, as that is where performance improves the most when it is changed. The observable array automatically notifies the view when an item is added/removed from the array. Slate batching improvements for large element sets: Group similar elements at compile time using tuples. Merge similar renderbatches in same-typed element buckets (currently for box and lines only). Reserve verticies / elements in a batch before using them. Slate element creation is now batched per element type to improve instruction coherency. It is now possible in SHeaderRow to specify the text overflow mode by providing a value of type ETextOverflowPolicy to the new argument OverflowPolicy. UE now resaves Slate PNG files with incorrect sRGB profile, logging PNG filename during libpng warnings and errors. Added widget state, which is intended to be used by external systems to generically respond to widget changes regardless of type. To avoid temporary array allocations per draw, Slate now uses static indexes for both text and shaped text where possible. Retained widgets now group by element type. You can now add a widget inside the global window overlay. Bug Fix: When UE creates a Modal window using FSlateApplication::AddModalWindow, if it can't find the Slate Virtual Window, it falls back to a non-modal window. Slate only allows explicit navigation if the target widget is enabled. SlateFontInfo now limits Outline to 1024. Fixed an issue where a widget in scroll box could get stuck in its hover state. Fixed issue where mouse position would not be calculated correctly when dragging a scroll area. Added Variation Selector characters to the list of characters that require full text shaping. Fixed scroll box scroll lag that occurred when scrolling by holding the scroll bar with the mouse. Fixed an issue causing ellipsis to appear on multiple lines on multline text, and for each text block in each line for combination of multiline + rich text or multiline + bidirectionnal text, instead of having a single ellipsis as expected. Fixed an issue causing ellipsis to not show or be misplaced on text with multiple runs, such as rich text or bidirectionnal text. This bug was more likely to happen on left to right text. Fixed ellipsis not showing or showing the wrong side for multiline right-justified text, or right-to-left text that was left-justified. Fixed a bug that prevented selecting an item in the list view when the list view was empty. Combo boxes no longer always trigger a value change event when opened. Added support for the -nullrhi command option to all standalone Slate applications. Fixed an issue where tooltips could be spawned while not using a mouse. The PropertyViewer's container now rebuilds when a Blueprint is recompiled. Depending on whether UE performed full rebuilds or skeletal rebuilds of Blueprints, they were not always marked as \\"newer class exists.\\" Fixed SlateTextureAtlas creating free nodes in empty slot lists that have dimensions smaller than what can be used by glyphs. The code previously created two nodes as long as one of them exceeds the minimum dimension. In practice, this results in iterating over 94+ unused elements each time a glyph is added. With this update, it should only create the smaller node if it exceeds the minimum. Deprecated: Removed & deprecated FSlateDataPayload used by Slate elements. Relevant data is instead built into subclasses to avoid indirection. For example, instead of using FSlateBoxPayload, use FSlateBoxElement. UMG New: Adding Desired Focus widget to UserWidget. This new property makes it possible for the user widget to forward the focus to one of its children when it receives focus. It can be set at runtime and in UMG Designer as a default value. URichTextBlock::ClearAllDefaultStyleOverrides is now BlueprintCallable. Added OnIsItemSelectableOrNavigable delegate to list views. UListViewBase: Added pure virtual OnIsItemSelectableOrNavigable function. OnIsSelectableOrNavigableInternal checks if OnIsItemSelectableOrNavigable is bound, and if it is, it returns its value. IMPLEMENT_TYPED_UMG_LIST: Added OnIsItemSelectableOrNavigableDelegate. This oiverrides OnIsItemSelectableOrNavigable and returns OnIsItemSelectableOrNavigableDelegate. Added support for specifying Input Configs from BP for activatable widgets. Added several debug CVars to CommonUI: CommonUI.Debug.WarnDesiredFocusNotImplemented – Provides a warning when activating widget without GetDesiredFocusTarget implemented. Added CVars to track Input Config changes: CommonUI.Debug.TraceConfigChanges CommonUI.Debug.TraceConfigOnScreen CommonUI.Debug.TraceInputConfigNum CommonUI.Debug.CheckGameViewportClientValid – Provides a warning when using CommonUI without CommonGameViewportClient. CommonUI.Debug.WarnAllWidgetsDeactivated – Provides a warning when deactivating all widgets. Slate.Debug.TraceNavigationConfig – Logs when navigation config changes in Slate. Moved UMG/FieldNotification files for Viewmodels to the FieldNotification module. Added support for Viewmodel FieldNotify broadcast on Blueprint-defined variables. Added Editor Utility version of UMG widget components to prevent serialization conflicts. Added a delayed to when Viewmodel bindings are ticked by a world. If the widget changed worlds, the binding might not be ticked anymore. Filter Viewmodel context creation type per class. Use MVVMAllowedContextCreationType or MVVMDisallowedContextCreationType to allow or disallow types. Added COMMONUI_API to FUIInputAction and some related functions in UCommonUIInputSettings. The View Binding picker now filters conversion functions by display name and by keyword. In the View Binding panel, the Add button now adds the widget the user has selected in the UMG designer. You can change this behavior, and it is saved in a setting (Add Binding Mode). Added support for ascent and descent override for FontFaces, which you can edit in the Font Face editor. Added the ability to scale font size in the font editor's preview. Views are no longer added to the WidgetBlueprintGeneratedClass if there are no bindings. Added a Blueprint view to the AssetSearch. The module is not added by default because it depends on the AssetSearch plugin. Added a menu extension to Viewmodel editor. The Bindings panel is now \\"MVVM.ViewBindings.Toolbar\\" and the viewmodel panel is \\"MVVM.Viewmodels.Toolbar\\" Return the World of a widget when it's valid. Added a message when the widget cannot be added to the World. Added the Viewmodel tag data to the UserWidget generated class. It was present on the blueprint asset but that data is not present in cooked build. Added a callback to add tag data to a widget's generated class asset. Added the Auto execution mode for Viewmodels. Auto will decide at compile time if it should run the binding immediately or on a delay. A binding will be run in delay mode if the binding can be triggered from more than one field. Added extension to insert a Customization for the Designer DetailView from a Blueprint extension. Removed the need to have a SourcePath for ComplexConversionFunction in Viewmodels. The source data is inside the function itself and the fieldnotify name is already saved in the class binding. Updated GetBindingInfoFromFieldPath to support nesting a Viewmodel inside another Viewmodel. Added a unit test for the GetBindingInfoFromFieldPath function. Added DoesInitializeAtConstruction on the View class to support manual initialization. When the flag is false, the user is responsible for initializing the view. Added ReevaluateSourceCreator for Viewmodels. A source discovered at compile time and added to the list of SourceCreator may need to be evaluated if the path contains a notify. This function is similar to SetViewModel but finds the new value from the SourceCreator. Exposed Viewmodel properties to the Details panel. You can now inspect Viewmodels with the Object Inspector. You can then see which Viewmodel is attached/bonded to the View. Added support for nesting Viewmodels inside Viewmodels. Added support for Viewmodel sources that are not UserWidget properties. The compiler generates the missing path. Viewmodels now use FText::Identical to compare FText. Added Viewmodel performance stats to the runtime View. Added an option to log all Viewmodel bindings after compilation. Enable the CVar MVVM.LogViewCompliedResult to log this information. Added a virtual method so that CommonInputProcessor can be overriddenoverriden. You can select an abstract class as a Viewmodel class, but you can't create an instance from an abstract Viewmodel class. Added Resolver, a new way to select a Viewmodel. You can extend the Resolver and can implement your own logic on own to find/create the Viewmodel. Updated style defaults on UMG widgets to use default style cache. Added option to hide the BindingWidget, NavigationSimulation, Pallets, and Hierarchy windows from the UMG Designer. Renamed CommonUI FUICameraConfig to FActivationMetadata. Added a message at compile time notifying when 2 Views will be used at runtime. Added unit test for FieldNotificationDelegate for Viewmodels. Added support for custom pins for complex conversion functions. Crash Fix: Fixed a crash in the loading screen when clicking the X window button before the end of the Loading Screen. Bug Fix: Fixed an issue where multiple default action prompts could appear on CommonUI buttons when disabled and re-enabled. Correction to Favorite features in UMG Designer to allow more than one Widget to be favorited when the Library Window is shown. The Design View Widget sets the desired size of the selection border to 0 to prevent the UMG Design View from representing the layout of 0-sized widgets incorrectly. Fixed an issue that prevented CommonUI actions from updating when the activated root doesn't support activation focus. Applied fixes to Analog Cursor functionality to support gamepad-driven cursor movement. Viewmodels are no longer overridden when set before widget initialization. Fixed an issue preventing Blutility classes from being included in other modules. The Viewmodel system now tests if the Binding library is loaded before accessing it. Fixed an issue preventing users from renaming Viewmodels from the details panel. Moved the Global Viewmodel Collection to GameInstance subsystem to allow PIE and splitscreen. Fixed retainer widgets not rendering in editor. These are now configurable via 'Slate.EnableDesignerRetainedRendering'. Fixed a bug where removing a View Binding didn't return the correct state of the bindings. Fixed the order of delegates in Viewmodels when adding and removing delegates while a delegate is executing. Before deleting a Viewmodel, UMG will now check if the Viewmodel is in use by looiking through its bindings and conversion functions. Updated the compiler error message for Viewmodels when a field is not found, most likely due to a missing FieldNotify. Fixed accessing private UFunctions in Viewmodels with AllowPrivateAccess. Fixed the ViewModel IsBindingValid error message, which did not include the full property type. Fixed Viewmodel field pickers that do not show function when there is no filter. Added support for arrays of object bindings in Viewmodels (the same way BP does). UMG now detects circular reference in the widget tree at compilation. Fixed an issue preventing widgets from registering multiple enhanced input actions. Fixed an issue which caused cached slots in the viewport subsystem to fail to update when modified in a Blueprint's construction script. Fixed CommonUI Action Domains not resetting config on editor reload. Changed the displayname of some Viewmodel properties. Changed the error message for when a Viewmodel field does not exist to include a possible solution to the problem. This tests if the field exists on the downcast struct instead of the previous property owner struct. Deprecated: Removed the specialized Viewmodel editor in favor of using the Blueprint base editor instead. Virtual Production IO New: Added a tool for making fine adjustments to the nodal offset by hand. Added an anamorphic distortion model and support for calibrating an anamorphic lens to the Camera Calibration plugin. [Remote Control] Exposed websocket server bind address in project settings. [Aja] Add options for HDR support. [Rivermax] Additions to Rivermax: Added more logs in the output stream for missing chunks. Changed rivermax output scheduling when stalls are detected. Added a Rivermax TRO override console variable. Added HDR support for blackmagic media output. Added additional deinterlacing methods and the ability to provide your own deinterlacer for video input. [Remote Control] Added a setting to control allowed origins. Added new frame locking mode to Rivermax capture. [Remote Control] Enforce passphrase usage for clients outside localhost by default. Added OCIO support for Aja and Blackmagic media sources. You can now select an OCIO configuration to be applied to your SDI feed before it's displayed in the engine. Added media capture markup to track frames. Enabled new style output by default on any newly created media texture. Improvement: Changed Rivermax RTP timestamp to reduce media latency seen by analyzers. Moved media capture sync point to its own thread for frame locking work. Crash Fix: Added protection against crash during Rivermax initialization when prerequisites are not met. Fixed a Remote Control crash that occurs when invoking a setter method on a property in CreateRCCall. Bug Fix: Fixed Media Plate tiles and mips support in scene captures. Fixed an issue where pre-cached EXR tiles missed updates with the Media Plate. [Remote Control] Fixed Websocket server from keeping port open after changing it. [Remote Control] Fixed remote control presets sometimes not finding objects in Play-In-Editor (PIE). Fixed a race condition preventing Rivermax input stream to play. Fixed remote control crashes: GEditor was accessed without testing for nullptr. PropertyWatchers are now only used in -game except for transform properties. In PropertyWatcher->CheckForChange, IsIdentical was called on LastFrameValue.GetData without first checking if the last frame value had any data in it. LastFrameValue should now be correctly initialized if it couldn't be done at the creation of the property watcher. Fixed Media Capture pooled render targets becoming invalid in the rendering thread during garbage collection. Deprecated: Deprecated the UImgMediaPlaybackComponent and its functionality has been entirely superseded by the Media Plate. [Media Capture] Deprecated FMediaCaptureOptions ResizeSource in favor of ResizeMethod. nDisplay New: Added a new tab to the ICVFX panel to display the stage actor's details panel and components list. This allows users to edit any property on the stage actor without needing to go to the level editor window. Added ability to alphabetically sort nDisplay cluster nodes and viewports in the tree view in the nDisplay editor. Added global chroma key settings to nDisplay stage actor that can be used by any ICVFX camera, as well as for any overlapping chromakey when enabled. Bug Fix: Ensured the media plate material instance constant is properly transacted. Fixed OpenColorIO display-view transforms not working on nDisplay nodes. Fixed an issue where the buttons on the left panel of the color grading drawer overlap with other UI elements if the splitter was dragged too far to the left. Fixed UDisplayClusterGameEngine::Init potentially corrupting command-line arguments during parsing. If a quoted argument contained a space (such as a path), other common sequences such as n and t, or octal escapes, were mishandled. Deprecated: Deprecated the Custom Chroma key Enable flag, which has been replaced by a combo box in the parent chroma key settings that determines what kind of chroma key is used for the ICVFX camera. Rendering API Change: Assets must be re-saved to gain efficiency improvement. The asset must also be resaved if the configuration changes or when the library version is updated. New: Exposed OpenColorIO CPU color transforms on textures to editor blueprints. Exposed OpenColorIO active viewport configuration control to editor blueprints. Improved OpenColorIO asset load times by caching generated resources into the UAsset. Added premultiplication and alpha inversion controls to the OpenColorIO public rendering interface. Added OpenColorIO support for automatic conversions to and from the engine working color space when configs have a defined interchange color space. Improvement: Updated default media plate material in Composure to new style output (regular color texture sampler). Bug Fix: Fixed in-game OpenColorIO to ensure it remains active when a high resolution screenshot is taken. Patched the OpenColorIO library to disallow 1D texture resources. Added the option to select .ocioz files in OpenColorIO configs. Fixed texture Derived Data Cache (DDC) invalidation for advanced source color and encoding settings. Tools New: CineCameraRigRail updates: Added checkbox option to set all inheritance options at once. Added option to visualize and manipulate point rotation in the context menu. Implemented Drive Mode in the rig rail. Implemented speed visualization in the rig rail. Disabled speed heatmap when CineCameraRigRail is driven by Sequencer. Added a mechanism to multi-user which enables clients to request preloading of level sequence assets. Integrated the new multi-user level sequence preloading functionality into Sequencer Playlists. Reintroduced the bCheckReferencesOnDelete editor setting. This is used by stage operators to prevent long running operations in fast paced environments. Render Grid plugin: Made the render grid blueprint graph be an editor-time blueprint graph, to support editor-only blueprints. Made non-transient variables in render grid assets work again. Improvement: Fixed jumping current position when switching drive mode. Fixed several bugs and issues in Render Grid plugin: Added multiple new blueprints. Added additional python example scripts Cleaned up the render grid UI. Bug Fix: [Virtual Scouting] Fixed user getting stuck and unable to deselect actors if both hands are holding an interact tool. Second tool now falls back to the navigation tool if the context menu is activated. [Virtual Scouting] Prevent users from selecting zoom lens in VR Viewfinder. If lens options are changed during editor session by editing Project Preference > Cinematic Camera, VR Viewfinder will respect newly added lenses. [Virtual Scouting] Disabled collision on camera mesh in Viewfinder tool. The UDP message processor does not start processing messages until the PostDefault phase of engine startup. Users should not rely on the UDP message processor at startup. Fixed missing key frames when importing 30 FPS ARKit takes recorded by the Live Link Face iOS app, using the Live Link Face Importer plugin. Upgrade Notes Animation Runtime Upgrade Notes: Added the Animation Compression Library (ACL) Plugin as an Engine plugin and set the ACL Plugin as the default animation compression codec. Licensees already using the ACL Plugin from the Unreal Marketplace with binary builds of the engine will automatically upgrade to the new version. Those using a source version of the ACL Plugin will have to remove their old version and bring any code changes manually over. New animations will use the ACL Plugin while old animations will continue to use their current codec. Sequencer Upgrade Notes: [Sequencer] Duplicating a shot or creating a new take now retains the shot's color tint. Editor API Change: Added API to NodeTestGraphBuilder to explicitly define custom names when connecting input/output nodes to the test graph. Foundation Core Upgrade Notes: Deprecated TDepletableMpmcQueue as it uses spin-waiting that can cause priority inversion and subsequently deadlock on some platforms. Use TConsumeAllMpmcQueue instead of TDepletableMpmcQueue. Dev Tools Upgrade Notes: LazyObjectPtr and ObjectPtr are no longer allowed as TMap keys in blueprint-enabled function arguments.Functions utilizing TMaps with an ObjectPtr as a key must be changed to use the raw pointer. Framework Blueprint Editor Upgrade Notes: Input Event nodes are no longer allowed in animation blueprint event graphs. Instead, set a property value on the animation blueprint and set it in an input-enabled actor. Gameplay Upgrade Notes: [Modular Gameplay Effects - Gameplay Ability System (GAS)] Moved some gameplay effect functionality into optional components. All existing content will automatically update to use components during PostCDOCompiled, if necessary. Changed the default aspect ratio constraint to maintain Y FOV since camera FOV is now always handled as horizontal FOV. If preserving the exact framing for a given window size is important, you can specify the old setting value (maintain X FOV) in DefaultEngine.ini. Added Enhanced Input User Settings, which stores player mappable keys and other input settings in a save game object. This feature is off by default and can be enabled in the Enhanced Input developer settings or in a config file. Made the behavior of Enhanced Input when flushing the pressed keys consistent with the legacy system. This behavior is Default ON, but can be toggled off in the Project Settings > Enhanced Input. Level Design and Art Tools Geometry Core API Change: Added a new FLocalPlanarSimplify class to provide an algorithm to locally simplify triangles connected to a specified set of edges, which is useful to improve mesh quality after operations that tend to add extra vertices only in known regions of a mesh – such as plane cuts and polygroup edge insertions. It is now used by the FMeshPlaneCut algorithm to improve the resulting mesh quality. Modeling Tools Upgrade Notes: The MatEd tool now warns the user if they have removed materials that are used by the mesh. If the user accepts the result with this warning active, the faces that used the removed material will be re-assigned a valid material, so the MatEd tool now cannot create meshes with invalid material assignments. Procedural Upgrade Notes: The Spline Sampler now has a toggle to choose between bounded and unbounded sampling. To preserve behavior, previous Spline Samplers will remain unbounded. Newly created samplers will be bounded by default. The Difference Node now better adheres to a common standard. Source Inputs are iterated on and Difference Inputs are combined into a union before the operation takes place. Previous nodes will receive an injected Union node along their input edge to preserve older behavior. Refactored usage of TargetActor so it is used to do artifact targeting. In PCG blueprints, instead of using the TargetActor variable on PCGSpatialData, please use the GetTargetActor call on the PCGContext, passing it the previously used PCGSpatialData. When retrieving the target actor, use Context->GetTargetActor(SpatialData) instead of SpatialData->TargetActor. Online Online Subsystem Upgrade Notes: Refactored OSS EOS logic surrounding setting the BucketId for Sessions and Lobbies on creation and searches. Any BucketId can be set now from the game side by adding a setting with the following key FOnlineSessionSettings::Settings: OSSEOS_BUCKET_ID_ATTRIBUTE_KEY Added config toggle for OSS EOS to use EOS_Achievements_UnlockAchievements instead of unlocking achievements through stats. Added deprecation marker for stat implementation, to be removed in 5.4. To be added to a relevant engine config file: [OnlineSubsystemEOS] bUseUnlockAchievements=True Added bUsesPresence as an attribute in OSS EOS Sessions and Lobbies to retrieve it reliably instead of inferring it from other data. Wrapped new logic in config option bUseSessionPresenceAttribute. To be added to a relevant engine config file: [OnlineSubsystemEOS] bUseSessionPresenceAttribute=True Pixel Streaming Upgrade Notes: Multiple Pixel Streaming streamers supported on one signaling server. This requires streamer id to be uniquely set and the updated Pixel Streaming infrastructure from Github. Rendering Lighting Bug Fix: Fixed a bug related to light bounds for volumetric fog rendering. Simulation Physics Upgrade Notes: Added Predictive Interpolation, a new type of physics replication. Predictive Interpolation is a replication method that replicates behind the last received state from the server (interpolates), while still allowing for local physics manipulation (predictive). This replication is experimental and still a work in progress. The replication can be accessed by switching on Physics Prediction in Project Settings and then setting the Physics Replication Mode to Predictive Interpolation on the actor. Ensure the actor is set to replicate, replicate movement and the root component to simulate physics. [Geometry Collection] The 'Bone Selected Material' has been removed from the user-facing materials list on Geometry Collection Components, simplifying the user experience, and removing the ability for the user to break Fracture Mode selection visualizations by changing this material. UI Slate Upgrade Notes: Exposed the console variable Slate.EnableInvalidationPanels to shipping builds. Ensure the console variable is not in your .ini file to keep the previous behavior. UMG Upgrade Notes: Added viewmodel capability on all blueprints that implement the notification interface and removed the hidden viewmodel editor from the build. If you used the old editor, the regular blueprint editor should take over but you'll need to mark your properties as FieldNotify manually. Virtual Production Tools Upgrade Notes: Enabled multi-user support for Procedural Content Generation (PCG) actors. GPU Memory and CPU Memory stats have been added to the Stage Monitor Tool. Landscape Actor support has been enabled for multi-user. Multi-user session information has been exposed in editor-only blueprints. Improved the display of Live Link Face App in Switchboard tool. Added multi-user custom event sequencing. The UE_ADDITIONAL_PLUGIN_PATHS environment variable is now only supported in editor builds.","output":"As of my last knowledge update in early 2023, Unreal Engine 5.3 included a substantial list of new and updated features, improvements, crash fixes, and bug fixes across various areas of the engine, such as Animation, Sequencer, Editor, Foundation, Dev Tools, Gameplay, Level Design and Art Tools, Procedural, Online, Pixel Streaming, Platform, XR, Rendering, Architecture, Physics, Simulation, UI, Slate, UMG, Virtual Production, IO, nDisplay, Lighting, Materials and Shaders, Nanite, Postprocessing, RHI, Substrate, Path Tracer, Mass, Niagara, Lumen, World Building, and others. Details and specifics of these changes may require referencing the official Unreal Engine documentation or release notes due to the comprehensive nature of the update. The upgrade notes highlight important changes that developers may need to consider when updating or using Unreal Engine 5.3, such as deprecations, API changes, new features that require asset re-saving, and more. Please refer to the official Unreal Engine documentation and resources for the most up-to-date and detailed information regarding Unreal Engine 5.3 features and changes. If you need assistance with a specific topic or feature, feel free to ask, and I can provide more focused information or examples."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 酒店装饰方案汇报文本封面 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Hotel Decor Proposal Report Cover, luxurious and elegant design, showcasing a combination of contemporary and traditional elements, rich color palette featuring shades of gold, cream, and deep blue, intricate patterns and textures, with a glimpse of a luxurious chandelier, inviting guests into a world of opulence and comfort, captured with a high-resolution Canon EOS 5D Mark IV camera, 24-70mm lens, balanced composition highlighting the intricate details and overall harmony, in a style reminiscent of architectural photography by Julius Shulman. --ar 1:1 --v 5.2 /imagine prompt: Hotel Decor Proposal Report Cover, modern and minimalist design, creating a sense of calm and serenity, neutral color palette featuring shades of gray, white, and natural wood tones, clean lines and geometric shapes, with a hint of abstract artwork, inviting guests into a space of simplicity and sophistication, captured with a medium-format Hasselblad H6D-100c camera, 50mm lens, symmetrical composition showcasing the precision and balance, in a style reminiscent of minimalist photography by Andrea Grützner. --ar 1:1 --v 5.2 /imagine prompt: Hotel Decor Proposal Report Cover, vibrant and eclectic design, combining different cultures and aesthetics, bold color palette featuring vibrant hues of red, orange, and purple, artistic patterns and motifs inspired by nature, with a touch of whimsy and playfulness, inviting guests into a world of artistic expression and exploration, captured with a creative and experimental iPhone 12 Pro Max camera, ultra-wide lens, dynamic composition capturing the energy and vibrancy, in a style reminiscent of contemporary digital collage by Eugenia Loli. --ar 1:1 --v 5.2 /imagine prompt: Hotel Decor Proposal Report Cover, timeless and classic design, embodying elegance and sophistication, monochromatic color palette featuring shades of black, white, and gray, luxurious materials and textures such as marble and velvet, with a touch of vintage charm, inviting guests into a world of refined taste and comfort, captured with a medium-format Pentax 645Z camera, 75mm lens, dramatic composition showcasing the grandeur and allure, in a style reminiscent of black and white architectural photography by Julius Shulman. --ar 1:1 --v 5.2"},{"instruction":"Unreal Engine 5.3 Release NotesOverview of new and updated features in Unreal Engine 5.3 ON THIS PAGE Rendering Worldbuilding Procedural Content Generation (PCG) Developer Iteration Platform Character and Animation Virtual Production Simulation Audio UI Systems Modeling Content Pipeline Framework Engine Content and Templates Platform SDK Upgrades Release Notes Upgrade Notes What's New? Unreal Engine 5.3 brings further improvement to the core UE5 toolset. This release delivers improvements in a wide variety of areas, including Rendering, Worldbuilding, Procedural Content Generation (PCG), Animation and Modeling tools, Virtual Production, Simulation, and more. This release includes improvements submitted by our community of Unreal Engine developers on GitHub. Thank you to each of these contributors to Unreal Engine 5.3: 909185693, 34Pibo, aaronmjacobs, Acren, aijkoopmans, AishaBrown-SMG, aknarts, alexey-pelykh, alwintom, AndreaCatania, AndTikhomirov, ArcEcho, astutejoe, avudnez, baronpumpky, BenVlodgi, BinaerBoy, Bioliquid, BlenderSleuth, bretternst, brycehutchings, c4augustus, CaptainHoke, chalonverse, chrismcr, Cleroth, cneumann, crobertson-d3t, crssnky, David-Vodhanel, dbsigurd, Deathrey, DecoyRS, djethernet1, DomCurry, dorgonman, Drakynfly, DreikaEru, drichardson, dulanw, Dumbeldor, dyanikoglu, Edstub207, erebel55, error454, fieldsJacksonG, FineRedMist, flibitijibibo, foobit, freezernick, gbxAlx, gonfva, hellokenlee, hkzhugc, HSeo, Ilddor, ilkeraktug, ImaginaryBlend, iniside, jackatamazon, JakobLarsson-Embark, jammm, janurbanech13, jcb936, JDCruise, jfgoulet-gearbox, jimsimonz, Johnsel, JonasKjellstrom, jorgenpt, KacperKenjiLesniak, KaosSpectrum, KasumiL5x, KeithRare, kimixuchen, kissSimple, kniteli, KristofMorva, ldisthebest, LennardF1989, Levil0229, lflecunneen, lightbringer, lijenicol, lijie, liuhao0620, loening, LtRandolph, lucyainsworth, MalikuMane, mamoniem, manugulus, marcussvensson92, mariuz, mattiascibien, MaximeDup, microsoftman, MikBou123, mkotlikov, muit, OskarHolmkratz, pepsiandmilk, PhilBax, Phyronnaz, pirskij, praisesolek, projectgheist, QRare, qwe321, RandomInEqualities, Rareden, robert-wallis, RobertVater, roidanton, ryanjon2040, samhocevar, satoshi-iwaki, scorpio20t, Skylonxe, slackba, slonopotamus, Sn-a-ke, SRombauts, steelixb, stlnkm, teessider, tehpola, TheJamsh, TheoHay, Thomasleeee, tianyu2202, tommybear, tonetechnician, ToniSeifert, tuxerr, ukustra, Ultrahead, ungalyant, user37337, Vaei, velvet22, vorixo, Voulz, vsrc, WarmWar, WillmsBenjamin, WinsonSS, xiexbmu, yaakuro, yatagarasu25, yehaike, ZioYuri78, zompi2 Rendering Nanite Nanite Explicit Tangents Nanite now supports explicit tangents in the data format and runtime. Until now, Nanite has relied on a tangent space that is implicitly derived in the material, based on the screen-space positions and UV gradients. This is computationally convenient, makes tangents free in terms of memory and disk footprint, and works well in practice for many types of meshes, especially highly tessellated ones. However, there have always been cases, especially for low-poly models, where the implicit tangents are too imprecise and custom per-vertex tangents are needed to reach target quality. To support these cases, users can now opt to store and use the original model tangents on a per-asset basis. Enabling this comes at a modest cost of an additional ~10% increase in memory and disk footprint for the asset. Nanite Spline Meshes (Experimental) We introduced an initial implementation of the spline mesh component for Nanite meshes. This feature can be enabled by setting r.Nanite.AllowSplineMeshes=1 in a settings .ini file. WARNING: Enabling this feature currently comes with a performance cost that affects culling performance of all of Nanite, and there are currently known issues with incorrect culling under extreme deformation. Performance improvements for masked materials and Pixel Depth Offset (PDO) A new sliding window vertex cache for programmable raster results in faster masked materials and PDO. Initial tests show a 20% speed improvement for rasterization of masked foliage. Nanite Selection Outline Nanite object selections no longer flicker with TSR/TAA enabled, nor get occluded by other objects, and they render at final resolution. Nanite Instanced Static Mesh (ISM) / Foliage Instance Selection We fixed several issues in the editor related to selecting, modifying, or deleting instances of an instanced static mesh or foliage actors that had Nanite enabled. Fallback Target Setting We added a Fallback Target setting to Nanite static meshes. This is a menu option that provides more explicit control over which target to reduce to for the fallback mesh: Relative Error or Percent Triangles. Lumen Lumen Lumen Reflections support more than one bounce when hardware ray tracing (HWRT) is enabled with Hit Lighting, and the Max Reflection Bounces setting in the post process volume is set to 2 or greater. This can prevent black areas in reflections when there is enough performance budget to allow it. Lumen Reflections can now be used without Lumen GI, for games and applications which use static lighting but wish to scale up in reflection quality beyond reflection captures. Standalone Lumen Reflections only work when HWRT is enabled, and it will enable Hit Lighting automatically, as Lumen's surface cache optimization is not available when Lumen GI is disabled. We made significant Lumen HWRT optimizations, including enabling async compute for HWRT by default on consoles. The Lumen Overview visualization mode now includes a view of the geometry normals of the Lumen Scene, making it easier to spot issues with the global distance field (in the case of software ray tracing) or Nanite fallback meshes (in the case of HWRT). We added r.Lumen.Reflections.VisualizeTraces for visualizing and debugging reflection rays. We fixed Material AO - it was previously applied on top of emissive and direct lighting. Orthographic Rendering (Experimental) Orthographic Rendering Orthographic rendering is a very common way to visualize projects in architecture and manufacturing, and is also used in games as a stylistic camera choice. It has long been available as a camera option in UE, but many rendering features were not supported, making it impractical to use. Starting in 5.3, orthographic rendering is now supported as experimental. We fixed multiple areas of the engine to achieve parity between perspective and orthographic projections. Most modern features of UE5 should now work, including Lumen, Nanite, and Shadows. This represents ongoing work and we are interested in hearing your feedback trying to use it in your projects. Sparse Volume Textures (Experimental) Sparse Volume Textures With UE 5.3, we introduce a new asset type: the sparse volume texture (SVT). SVTs store baked simulation data representing volumetric media such as smoke, fire, and water. SVTs can be created by importing OpenVDB (.vdb) files created in other 3D applications—single files and animated sequences are supported. Additionally, Niagara fluids are now cached internally to SVTs resulting in significant performance and memory improvements. An SVT is similar to a 3D texture / volume texture in that it stores texels (voxels) in a 3D data structure and can be indexed with three-dimensional UV coordinates. Unlike regular (dense) volume textures, SVTs only need to spend memory on regions of the volume with \\"interesting\\" data, allowing for much larger volumes compared to dense volume textures—or alternatively volumes with the same extent, but using less memory. Deferred rendering techniques such as heterogeneous volumes, volumetric cloud, and volumetric fog can leverage SVTs by incorporating the suite of sparse volume texture material nodes in their volume-domain materials. Assets rendered with heterogeneous volumes must make use of the new heterogeneous volume component. Deferred rendering features are still limited to the existing feature set of real-time volumes. More complete support for rendering volumes is now available as experimental in the Path Tracer, which can accurately simulate scattering, shadows, and GI. There is also a very simple sparse volume texture viewer component that is mostly used for debugging and works with the Deferred Renderer. Path Tracer Path Tracer (Experimental) The Path Tracer now has initial support for tracing heterogenous volumes such as smoke, fire, and clouds. A heterogeneous volume can be created with the Niagara Fluids plug-in or by instantiating a heterogeneous volume actor, with data driven by a sparse volume texture. VDB files may be imported as sparse volume textures, and can thus be rendered in the Path Tracer. Note: this system is not yet compatible with Sky Atmosphere clouds. (Experimental) Substrate materials are now supported in the Path Tracer. Subsurface scattering sampling efficiency has been improved, resulting in less noise in subsurface materials for the same number of ray samples. The Path Tracer now renders its own depth pass rather than using the one generated by the rasterizer. This results in a more accurate match between the depth and RGB results, improving post-processing passes that rely on depth such as Depth of Field. (This change does not affect 'Reference Depth of Field'.) DBuffer Decal shading nodes in material graphs are now supported. These nodes have been available since 5.0 and greatly expand the functionality of decals in materials. (Documentation about DBuffer Decal shading nodes will be available upon the release of UE 5.3.) Post-process material buffers now have additional outputs for use specifically with the Path Tracer. These buffers are accessible through a new node in the material graph called 'Path Tracing Buffer Texture', and provide data for Radiance, Denoised Radiance, Albedo, Normal, and Variance. Substrate (Experimental) Substrate Substrate, released as experimental in 5.2, replaces the fixed suite of shading models such as Default Lit and Clearcoat with a more expressive, modular framework that provides a greater range of surface appearances and a wider parameter space. Performance scales according to complexity and desired budget, with legacy materials having a similar cost to before. Substrate is still experimental in 5.3. It should not be used for production scenes, but we encourage testing it and are seeking feedback during this phase of development. UE 5.3 contains many improvements in Substrate's capability, stability, and performance. Some of the changes include: New Glints and Specular Profile features, primarily useful for automotive applications. Improved DBuffer shading node support. A new Fuzz model for high-spec platforms. We updated the Substrate Material Information tab in the Material Editor to better display material performance and topology information. We added many bug fixes and performance improvements. Virtual Shadow Maps Virtual Shadow Maps We are removing the beta designation for virtual shadow maps in UE 5.3—we now consider them production-ready. There is still a long development path ahead for VSMs, but the designation reflects the stability and viability of the current working feature set. VSMs now respect the Nanite cull distance even when shadow caching is enabled. Previously, the cull distance was ignored in shadows if caching was enabled, as it could cause inconsistencies between the primary render and shadow maps. However, this can have a large impact on performance if the content was tuned for heavy culling. Scenes reliant on culling will now have faster shadows but might see shadow artifacts if the cull distances are short enough to see popping in the primary render. We added a per-primitive flag that gives the user control over shadow invalidation behavior. This provides users with a way to prevent invalidation, for example in cases where the primitive is known to use the World Position Offset setting statically—our systems cannot deduce this automatically at present. The default setting is 'Auto', which retains current behavior unless explicitly changed. We made additional bug fixes and performance improvements. Hair Hair We added groom streaming support for groom and groom binding assets. This allows faster loading time in editor and in game by loading only what is needed, lowering CPU and GPU memory pressure of groom assets. We added Continuous LOD for scaling/improving performance when there are a lot of grooms covering a smaller portion of the screen. This setting is off by default and can be enabled with r.HairStrands.ContinuousLOD. We added experimental support for hair strands in the Deformer graph, including support for writing custom attributes. This is still early in the development process, but will open the door to making groom changes at runtime in the Deformer graph. We reworked groom attributes to be more flexible and to make it easier to add new optional attributes. We added two new optional attributes (clumpID / AO). Numerical values of groom attributes can now be visualized in the groom editor for easier inspection. During asset import, point/curve limits are now reported to users, and data is trimmed accordingly. In addition, imported attributes are now clearly displayed at import time, as well as in the groom editor, to visualize what is available for a particular groom asset. We made many additional bug fixes and performance improvements. Temporal Super Resolution (TSR) Temporal Super Resolution We introduced new functionality for more automated control of the screen percentage in games when dynamic resolution is disabled (primarily on PC platforms). The default heuristic sets the screen percentage based on the optimal TSR convergence rate for the number of pixels displayed. This should result in end users requiring less experimentation to find the best settings for their device. The editor has several new UX features to aid in understanding and controlling the behavior of the screen percentage in editor and PIE viewports. We added initial support for 16-bit operations on desktop GPUs where backed by hardware support, including on Radeon RX 5000 series (RDNA) cards and newer. We fixed an inconsistency between TAA and TSR regarding Lumen screen-space traces of emissive surfaces. We made numerous optimizations and bug fixes. Render Resource Viewer Render Resource Viewer The Render Resource Viewer, introduced in UE 5.2, is a tool that gives full visibility into GPU memory allocations and render resources—such as vertex buffers and index buffers—and which assets they come from, like static and skeletal meshes. This provides artists and developers with information needed to optimize GPU memory and keep their projects within their rendering budget. New in UE 5.3: You can now select a render buffer/texture and jump to the source asset in the Content Browser. Insight Memory Trace now tracks DX12 resources, and Insight Metadata Trace tracks resource owner paths like Render Resource Viewer. These features complement the Render Resource Viewer, which works only in the editor, and allows tracking of the owning asset path, debug name of the render resource, and its owner render class name in packaged builds. Lighting Lighting Lights with ray-traced shadows can now optionally shadow volumetric fog. You can enable this with the console variable r.VolumetricFog.InjectRaytracedLights, which is off by default due to performance costs. Spot, Point, and Rect lights can now set their intensity units to 'EV' (exposure value), which means you can set intensities in relative \\"stops\\", or power-of-two increments. Worldbuilding Level Instance Actor Filters Level Instance Actor Filters Actor filters allow for per-level-instance variants within World Partition levels. They consist of data layer instances and/or local data layers that are set to support actor filtering with a user-defined default filter inclusion. All actors associated with these pre-configured filters will be included or excluded on streaming generation, depending on the filters default, override, and activation states set within each level instance. Filtered out data is removed from in-game entirely. Level Streaming Persistence (Experimental) Level Streaming Persistence is a plugin that manages saving and restoring of specific marked properties on objects contained within a streamed-out/streamed-in level. These properties are defined within the engine configuration (.ini) file. This provides persistence of properties during gameplay from the in-memory snapshot, as well as across sessions, if implemented through the provided API. Nanite Landscape Nanite Landscape Nanite can now be enabled in landscape actors, at parity with normal landscape rendering. Nanite Landscape meshes are rebuilt in the background in order not to disrupt user workflow while in the editor. Nanite Landscape does not improve landscape resolution, but it allows the user to leverage Nanite runtime features such as GPU culling, automatic geometry streaming, and LODs, and it generally boosts runtime performance, especially for demanding features such as VSM. Large Landscape Import / Export We updated landscape import/export to support very large landscapes/resolutions by leveraging World Partition and splitting the import operation into several successive batches. Landscape Physical Materials Display Landscape physical materials can now be displayed when showing collisions by using the new CVar landscape.CollisionMesh.ShowPhysicalMaterial. When enabled, it helps users to debug how physical materials are exported, especially when using the Landscape Physical Material Output node. Landscape LOD Groups We added LOD groups to enable seamless LOD transition across multiple landscape actors in the same group. Procedural Content Generation (PCG) Hierarchical Generation Hierarchical Generation Hierarchical Generation allows for execution of different grid sizes within the same PCG graph. After setting a default grid size in the PCG graph settings, users can start adding Grid Size nodes to define the granularity at which the downstream elements should execute. Data processed at higher grid size can be used at any smaller level. This hierarchical logic enables users to achieve more optimal procedural generation, especially over large worlds at runtime. Rule Processing From External Data Rule Processing From External Data We now support rule processing from external data, providing feature parity with the City Sample project Rule Processor plugin to manage external data, process it, and produce artifacts on target actors. This includes: External data support for Alembic point clouds and data tables A utility for converting Alembic files to PCG Settings assets Subgraph Inspection Subgraph Inspection We added support for debugging and inspecting PCG subgraphs through the Attribute List view within a parent graph. Graph Instances Parameters Graph Instance Parameters We are introducing a Blueprint API to get and set PCG graph user parameters. Other additions include UX improvements and filtering for supported types. Custom PCG Elements Custom PCG Elements To improve the creation workflows and readability for custom PCG elements, we renamed PCG-specific Blueprint loop functions. We also added new functions to set up and output PCG data collections in order. Developer Iteration Multi-Process Cook (Beta) Multi-Process Cook helps reduce the total time it takes to get a cooked output from a build farm server or on your local workstation by leveraging available CPU cores and memory resources. Multi-process cook is a beta feature for UE 5.3. Performance gains may vary, depending on the size of the project and how the data is separated. For best results, we recommend you test different CookProcessCount values depending on the project and available hardware specs. Virtual Assets Virtual Assets are now production-ready for UE 5.3 and recommended for teams using Perforce version control and a shared Unreal DDC (Derived Data Cache) for best performance. To recap, virtual assets drastically reduce the size of local project data and sync faster by only synchronizing core asset metadata, and then pulling down the bulk data on demand if needed. Virtual assets are supported for textures, audio data, and static meshes (including Nanite). Bulk data is compressed using Oodle for additional data size savings. Should you need to go offline, you can run a precache commandlet when launching your project that will cache virtualized data locally on your machine. There is also an 'Auto fix / re-virtualize assets' check-in script available in the Unreal Automation Tool (UAT) that will catch any assets mistakenly un-virtualized project-wide. C++20 Default Version UE 5.3 is now compiled with the latest C++20 standard, and the version is supported in your development environment. We added C++20 support to the Unreal Build Tool (UBT), and it is controllable with a target or module setting; C++14 is marked deprecated and no longer supported. All engine modules are compiled by default with C++20, regardless of the target C++ standard. Other modules still support C++17 but can be opted-in to C++20 if desired. C++ Unreal Header Tool We removed the C++ Unreal Header Tool from Unreal Engine. Please use the C# Unreal Header Tool. Platform XR XR Gaze-Tracked Foveated Variable Rate Shading (Experimental) Performance is of utmost importance when developing XR applications. This experimental feature enables gaze-tracked foveated image generation with OpenXR, reducing the number of total pixels drawn. Make sure the OpenXR and OpenXR EyeTracking plugins are enabled, and set: xr.VRS.FoveationLevel 1-3 to enable foveation. xr.VRS.GazeTrackedFoveation 1 to enable Gaze-Tracked Foveation. xr.VRS.FoveationPreview 1 to enable preview of the foveation mask. Single-Pass Stereo Rendering for Nanite Nanite can now render both stereo views in a single pass when Instanced Stereo Rendering is enabled. Nanite rendering is a multi-step process, and executing these steps for each eye separately is not optimal. Projects with ISR enabled can now have each step of the Nanite pipeline process both eyes at once, reducing the overall rendering time. You can use r.Nanite.MultipleSceneViewsInOnePass=0 to disable this technique in case you suspect it of introducing a problem. Stereo Improvements for Lumen Global Illumination Lumen GI has a number of per-view caches. Since stereo views are so close to each other in terms of position and direction, we can reuse some of the cache between the views. You can use r.Lumen.StereoOptimizations=0 to disable this in case of any problems. Handheld AR Improvements ARCore SDK has been updated to 1.37 ARCore plugin cleanups: Removed deprecated camera metadata API usage. Updated to new Cloud Anchor Async API. Updated to new front/back camera configuration API. Removed deprecated ARCore-specific Blueprint functions that have cross-platform equivalents. Fixed ARCore and ARKit ARPins when the tracking to World Transform or World Scale changes. XRScribe Plugin (Experimental) This new experimental plugin enables the use of the OpenXR plugin and related code without needing an OpenXR device. The plugin captures OpenXR API interactions between Unreal Engine and the runtime, and can use that capture to emulate devices. A limited set of OpenXR extensions currently supported by XRScribe OpenXR surface. Hand tracking, gaze tracking, depth layer, and Vive Trackers are not yet supported. Currently available for Win64 only, but other platforms will be supported in the future. Emulation currently handles replay of HMD plus device poses, but no input yet. Plugin built-in captures can be used for quick emulation using CLI (-xremu=mq1 or -xremu=vi). XRBase Refactor We refactored the implementation of many XR-related interfaces from the core engine into an XRBase plugin to reduce executable size and memory overhead in non-XR projects. Some XR-related plugins may need to add XRBase as a dependency as a result. XR_FB_Foveation support (Experimental) Fixed and dynamic foveation for Meta Quest devices can now be enabled in Project Settings->OpenXR Settings. You can use the following CVars to configure it: xr.OpenXRFBFoveationLevel (Default=0) 0=None, 1=Low, 2=Medium, 3= High xr.OpenXRFBFoveationDynamic (Default=False) True/False xr.OpenXRFBFoveationVerticalOffset (Default=0) Other Improvements Mobile Preview on Vulkan RHI is now using multi-view extension natively instead of Mobile Multi-View emulation. Packaging for all Meta devices can be achieved by enabling the Package for Meta Quest devices checkbox in the project settings. Extension plugins to the OpenXR plugin can now access the Layer List. Mobile Development Requirements and Compatible Hardware The following are the supported OS versions and minimum hardware for mobile devices supported by Unreal Engine 5.3. For additional information about required SDKs and IDEs, refer to the Platform SDK Upgrades section. iOS/tvOS/iPadOS UE 5.3 supports iOS, iPadOS, and tvOS devices with OS that support version target SDK 15 or later. UE 5.3 supports: A8 AppleTV devices A8X iPads A9 devices or newer The following are the minimum compatible device models for UE 5.2: iOS 15 iPhone 6S or later iPod Touch 7th generation iPadOS 15 iPad 5th generation or later iPad Air 2* or later iPad Mini 4* or later iPad Pro (all models) tvOS 15 Apple TV HD* Apple TV 4K (first generation) Apple TV 4K (second generation) Android UE 5.3 supports Android devices meeting the following specifications: Android 8 or higher 64-bit Arm-based CPU Compatible GPUs: Mali T8xx, G71, G72, G76, G77, G78 and G71x series Adreno 5xx, 6xx or 7xx series PowerVR GM9xxx series Xclipse 920 Compatible Graphics APIs: OpenGL ES 3.2 Vulkan 1.1 on Android 10 or later devices with compatible drivers Android SDK and JDK Updates We have streamlined our Android SDK requirements by moving to Android Studio Flamingo 2022.2.1 and using OpenJDK 17.0.6 as our JDK version. Baseline Android support for UE and AGDE now both target the same JDK version, and users do not need separate JAVA_HOME and AGDE_JAVA_HOME environment variables to point at separate JDK installations. Note that with this update, UE now targets the jbr directory for JDK rather than jre. If you need to support earlier versions of UE than 5.3, but also need to set up UE 5.3 for Android, we recommend the following: Before you uninstall your previous version of Android Studio, copy the contents of the jre directory to somewhere outside your Android Studio installation to keep them from being overwritten. Make sure your Android environment variables do not target the SDKs used by earlier versions of UE. For older versions of UE, use BaseEngine.ini or your Project Settings to manually target your SDKs. In particular, set your JDK directory to the copied jre directory. See the documentation on setting up Android Studio for UE 5.3 for more details and instructions. Modernized Xcode Projects We have updated the way UE handles Xcode projects and workspaces, making it more consistent with modern Xcode workflow conventions. This includes the following changes: Improved Xcode Project Organization UE now uses one Xcode workspace per platform. For example: UnrealGame (Mac) and UnrealGame (IOS). UE now uses separate projects for each build target type within its workspace. For example: UnrealGame (Mac), UnrealGameEditor (Mac), and UnrealGame Server (Mac) each would be separate projects under the Mac workspace. Each project only allows the build configurations it supports. For example, Editor projects do not show the Test or Shipping configurations. Frameworks are now handled using standard Xcode methods. Whereas previous versions required developers to manually copy and codesign Frameworks, the build system now automatically discovers and codesigns them. Improved Packaging and Distribution Process All data needed to run is bundled inside self-contained .app files for each of Apple's platforms. This includes macOS, which did not use this paradigm in previous versions of UE. Automatic codesigning is now the preferred method for handling codesigning in development/debugging builds for both macOS and iOS/iPadOS/tvOS. You can use Xcode to manage and distribute apps with Xcode archives, which are now the preferred way of creating shipping builds. Shipping builds create an .xarchive file and a .dSYM file for this purpose. Improved management of Entitlements and .plist files. Developers can now use templates or customized files for both of these assets. For more details about these improvements, see our documentation on the modernized Xcode workflow. iOS Workflows iOS Workflows UE 5.3 brings several improvements to development workflows for the iOS platform: MallocBinned2 memory allocator can be used if your App ID contains the Extended Virtual Addressing entitlement. Improved packaging and app signing thanks to a modernized XCode projects integration (see Modernized Xcode Projects above). The Prepare for Debugging command, which streamlines the debugging pipeline, now offers Windows remote (experimental) and secondary Mac workflows. See the documentation on debugging in Xcode and using remote Macs for more details. The iOS simulator is now supported on Apple Silicon Macs, allowing faster development iteration without devices (experimental). Mobile Ray Tracing Support on Android (Experimental) UE 5.3 supports ray tracing for high-end Android devices running the Mobile Desktop Renderer. Supported mobile GPUs include: Adreno 740 Immortalis-G715 Samsung XClipse Series To enable mobile ray tracing: Enable the desktop renderer for your project. Enable ray tracing. Add the following to your device profiles: [Android_Vulkan_SM5 DeviceProfile] +CVars=r.Android.DisableVulkanSM5Support=0 This update also includes mobile indline shadow support for ray traced shadows, which only works with deferred shading. This support is experimental and should not be used for production purposes at this time. However, we welcome feedback from users trying it out! Mobile Renderer Mobile Renderer The mobile renderer now includes several performance and visual quality improvements, notably: Compute-based landscape vertex culling. Fog volume support. Global distance field generation on mobile forward. Instance rendering improvements (GPU Scene). Virtual texturing support. Support for Nanite on Apple M2 Devices (Beta) Nanite on Apple M2 Devices Unreal Engine 5.3 brings beta support for Nanite rendering technology on Apple Silicon M2 devices running macOS. This support is enabled by default, with shader model SM6, in the UE macOS binaries downloadable from the Epic Games launcher, whereas the Experimental 5.2 support was only available when building from GitHub sources. Character and Animation Dynamic Workflows for Runtime and Non-Linear Cinematics Dynamic Workflows for Runtime and Non-Linear Cinematics This release focuses on improvements to runtime workflows and nonlinear organization. User-Defined Dynamic Bindings Use the Level Sequence Director Blueprint to define different objects, such as the player pawn, to either be dynamically possessed or spawned by Sequencer during runtime. Material Section Blending Similar to other track types, material typed sections can be added to tracks that support materials. This includes material parameter collections and UI animations in UMG. Takes for Subsequences Similar to the Shots track, takes for Subsequences can be created and set within Sequencer. Comments for Takes Add/edit/view comments to Shot/Subsequence Takes within Sequencer. Text Track Text properties can now have tracks in Sequencer, where users can change the value of a text field over time and key it. Animation Retargeting Animation Retargeting This release focuses on quality-of-life improvements for Retargeting. Toolbar in the Retarget Editor - This provides easy access to Global and Root settings along with the Retarget phases. Makes available mode switches between the Running the Retarget, editing the Retarget Pose, and viewing the Retarget Pose options. Retarget Poses - Edit a bone's local space to zero out bone rotations. Create IK rig/IK retargeter assets from a selected skeletal mesh/IK rig in the right mouse context menu. Thumbnails for IK Rig and IK Retargeter assets. Animation Authoring Animation Authoring Further improvements for animation authoring in this release include: Smart Bake Now allows you to target only baking keyframes. Constraint baking Space switch baking Snapper Collapse sections Baking transforms Smart Auto Tangent New auto tangent that better maintains the curve shape. Curve Editor Improvements Improved normalized view Improved performance with lots of keys Better handle selection More accurate marquee select Fixes to zoom levels when auto frame is off Motion Blending Improvements Swap Root Bone works on animations with Root Motion Preview using AnimBP. Skeletal animation sections can be extended backwards. Export Improvements Export control rig animations as a FBX file. Skeletal Editor (Experimental) Skeletal Editor The Skeletal Editor provides a way for users to create skeletons and edit mesh skin weights directly in the Unreal Editor. This tool offers faster iterations by means of the addition of bones to your assets, the deformation of static meshes, and converting them to skeletal meshes, all in one place without the need for importing skeleton data. Convert static meshes to skeletal meshes Create and edit skeletons Add bones Remove bones Orient and edit bones Mirror bones Create skin weights Paint Weights brush tool Edit weights on vertex selection Flood / Relax / Prune / Average / Normalize operations Mirror weights Paint maps Python API support for bones and weights Machine Learning (ML) Deformer Machine Learning Deformer ML Deformer provides users a way to approximate a complex rig, nonlinear deformers, or any arbitrary deformation by training a machine learning model that runs in real time in UE. Improvements in UE 5.3 include: The addition of a masking system for Local Neural Morph Model, which improves the ability of users to work with structured data. Improvements to the Nearest Neighbor model UI and workflow. The removal of dependency on the NNI framework. The ability to create training masks, and visualize the masks per bone / bone group / curve in the viewport. There is no longer any need to take any manual steps (for instance, installing a Python package) for the Nearest Neighbor and Neural Morph models to train correctly on Windows. The ability to run trained Neural Morph and Nearest Neighbor models on Linux and macOS (although training errors may be encountered). Build Control Rigs from Data We further extended the procedural toolset of Control Rig by providing a way for you to use data outside of the Control Rig graph to procedurally create and modify the rig. This includes: The ability to query and use external data such as transforms, floats, skeletons, and more to build control rigs procedurally. A new 'GetUserData' node that will query incoming data. A new 'Set Shape Library from User Data' node that will swap the shape library currently being referenced. Virtual Production SMPTE 2110 for ICVFX SMPTE 2110 for ICVFX The Unreal Engine 5.3 release completes the implementation of a next-generation ICVFX stage deployment using an end-to-end SMPTE 2110-based IP video signal flow with nDisplay. SMPTE 2110 support enables productions to maximize the available hardware resources on stage, with this increased efficiency empowering the potential for higher-resolution inner frustums and lower latency. With a SMPTE 2110-based configuration, productions will be able to: Render the inner frustum once and share it with the other render nodes in the cluster, avoiding the redundancy of each node re-rendering the inner frustum for determinism. Dedicate the resources of an entire render node to the inner frustum to leverage all available resources to display the highest-possible quality on the pixels seen in camera. Framelock each render node with a native SMPTE 2110 sync policy that ensures Unreal Engine output remaining in phase with the camera. Output the resulting renders to the LED processors using SMPTE 2110, eliminating the need for a display port and/or HDMI converters. Virtual Camera Virtual Camera Takes Browser We added the ability to browse for level sequences from the virtual camera and load them for review or as the base for your next recording, as well as to star, flag, or NG sequences to filter the list. Multiple HUDs from a Single VCam You can now add multiple output providers to a single VCamComponent each with its own HUD and stream. You can stream an operator's view, a simple burn-in, and a clean plate from one VCam, at the same time. Time-Scaled Playback and Record You can now play back and record at non-1:1 speeds. Record at a custom rate and your move will be sped up or slowed down when played back at full speed. Initial macOS Support (Experimental) VCamActor now supports streaming from macOS through legacy Remote Session. Virtual Camera Core, VCamComponent, VCamModifier, and VCamOutputProvider are available for use to create custom VCams on macOS versions of UE5. Development remains ongoing to bring Pixel Streaming and full VCam support to macOS. CineCamera Rig Rail (Beta) CineCamera Rig Rail We've added a new rig rail actor tailored towards advanced cinematic and virtual camera workflows. Plan your Composition Store camera focus, iris, and zoom in rail points, allowing the rail to drive more complex aspects of your composition. Drive the Rail Automate your moves using a number of drive modes: Manual: Drive your rail position from Sequencer or external input. Duration: Drive your rail position to complete your move in a set amount of time. Speed: Drive your rail position at a set speed. Work with Sequencer Points are stored by absolute value and can be safely keyed in Sequencer. As a result, the position value of a given point cannot change unless you directly modify the point. If you keyframe a particular position to occur at a given framing, it will not change regardless of how many new points are added before or after. Visualize Your Speed See your speed along any point of the rail through a heat map applied to the rail mesh and avoid any surprises when recording a layered move. Choose your Axis Inheritance Choose to only inherit subsets of axes from the rig rail. Drive position from the rail while refining rotation or choose to remove the Z axis for a steadier ride. CineCamera Scene Capture Component (Beta) CineCamera Scene Capture Component We've added a Scene Capture component for CineCameras. You can accurately capture a CineCamera component to a render target for use in materials, UMG, and beyond. The feature supports lens distortion, together with CineCamera-specific properties and post-processing. Anamorphic Lens Calibration Solver (Experimental) Anamorphic Lens Calibration Solver We've added an anamorphic lens model and solver to the lens tool to be used with lens assets, making it possible to solve anamorphic lens distortion. Using the lens component, you will also be able to add anamorphic lens model distortion to CineCamera actors to render distortion effects within the engine, making it possible to visualize shots using profiled anamorphic lenses. Manual parameters for the anamorphic lens model can also be adjusted to create anamorphic distortion looks. OCIO for Texture Conversions OCIO for Texture Conversions The introduction of Working Color Space established a foundation for robust color management in Unreal Engine for critical operations such as configuring the input color space for textures, helping to ensure assets look correct regardless of where they may have been authored. Unreal Engine 5.3 expands upon this support with the ability to leverage OpenColorIO for these texture conversions. With this, Unreal Engine adopts an industry-standard framework to maximize consistency across the color pipeline for textures. nDisplay Multiplayer Actor Replication nDisplay Multiplayer Actor Replication We've revised the nDisplay low-level networking architecture so that it can support actor replication in a multiplayer game context. Transparent to the end user: The feature can be activated in nDisplay Project Settings using the Cluster Replication Enabled option. We've added a Multiplayer Server option to Switchboard. Each nDisplay node becomes a networking client when joining a multiplayer session or game. In the future, we hope to enable nDisplay Clusters to join a multiplayer session as opposed to individual nodes. nDisplay Fill Derived Data Cache nDisplay Fill Derived Data Cache We've added the ability to \\"prime\\" nDisplay systems (stand-alone shaders) before first use by filling the derived data cache in advance. This feature can be triggered locally using the Build Menu or using Switchboard on all cluster Nodes. The nDisplay cluster is then ready to be started without requiring any further shader compilation. You can schedule this operation offline at a time convenient to you, since it is exposed to Unreal Engine using a command line argument and can be triggered externally. DMX Control Console UX DMX Control Console UX We are improving the new Control Console UI and UX with the following additions: Two main layout modes: Default, where only selected patches are visible Manual, where you can define the fader group positions A revised search mechanism for quicker DMX fader access The ability to change fader values using relative or absolute controls The ability to select which patches are actively sending DMX data DMX Pixel Mapping UX DMX Pixel Mapping UX The DMX Pixel Mapping tool has received a significant facelift and now offers an improved UI and UX, among other fixes: A new input filter section enables you to downscale, blur, and perform material-based logic on the incoming pixels. DMX library manipulation is consistent with the new UX provided by the Control Console. This works hand-in-hand with the hierarchy view so that you can see which patches have been added and which remain. Media IO Media Plate Material System Media IO Media Plate Material System We've improved the current media plate actor material system, giving you the ability to: Pick a material directly from the Media Plate Plugin Content directory using the new auto-populated dropdown. Browse to the Media Plate Plugin Content directory for quick access. Also, we enabled the Output Depth and Velocity flag in the default media plate materials for increased TSR/TAA image stability when there is camera movement relative to the media plate actor(s). Simulation Chaos Cloth Editor Foundation (Experimental) Chaos Cloth Editor Foundation Chaos Cloth for UE 5.3 includes the addition of an experimental Cloth Editor. The new Cloth Editor enables having multiple garments per character and the same garment across multiple characters in the future. It also provides panel-based workflows which will make it easier to set up and modify clothing setups. It includes the following features: New base class editor for character physics (cloth/flesh). First phase of panel-based editor with the Dataflow graph. Non-destructive workflow. Cloth is extracted from the skeletal mesh as a separate component. Extra collision support. New Skin Weight Transfer tool. Masks are now replaced by reusable weight maps. Multiple Materials can be driven by single sim mesh support. See the Panel Cloth Editor Overview for more information about this feature. Chaos ML Cloth (Experimental) Chaos ML Cloth Cloth simulation can be too expensive for many use cases. Artists, engineers, and game designers need alternative, less-expensive runtime solutions to mimic cloth simulation, especially for tighter fitting clothes. Currently, this requires a tedious process of hopping back and forth between DCC to simulate and importing results back into the engine. For UE 5.3, artists can now simulate and train cloth in engine using the experimental Chaos Cloth Generator plugin. See the Machine Learning Cloth Simulation Overview for more information about this feature. Chaos Rigid Bodies and Scene Queries We made several updates and optimizations to Chaos Physics to give artists, developers, and programmers better simulation results, notably on rigid body simulation and scene queries. The continual focus on rigid bodies is low-level optimization including SIMD, cache coherency, functional removal, reduction in data copying, and so on. Scene queries implement a dynamic acceleration structure that is now quicker to update and query. Chaos Destruction Fracture editor updates A new material has been added, to help with fine control when managing and assigning material for a geometry collection. Fracture Editor Material The proximity tool has been improved with better visualization control and new contact method for generating the connection graph. Fracture Editor Proximity Tool The level statistic now shows aggregate convex information, which is useful when optimizing your geometry collection collisions. Fracture Editor Level Statistic Runtime Optimizations The geometry collection component no longer ticks by default and will only tick after the geometry collection has been damaged. The runtime cost of the tick function has been also reduced. Data types optimizations at the solver and attributes level have been made, reducing the cost of geometry collection assets on disk as well as the runtime memory cost of their instance. Numerous optimization have been also done to reduce the overall CPU cost of geometry collection instances allowing for using destruction at larger scales. A new experimental damage model has been introduce leveraging the physical properties of material and internal topology and connectivity of geometry collections. Niagara Fluids Niagara Fluids We added the ability to transform Niagara Fluid sims after they are cached. This opens up the capability to duplicate a cache multiple times, and to offset the duplicates in time/space to get more complex effects from a single cached sim. We added data channel support to the 3D Gas simulations. It is an experimental feature that provides a way to source fluid from any CPU system in the level. On the master emitter, the particle source now has two modes: Emitter and Data Channel. Emitter mode reads data from an emitter in the same system. Data Channel mode reads data from a predefined Niagara data channel. That data channel can be written to from the existing Set Fluid Source Attributes module. Path Tracer now supports heterogeneous volumes, which means fluids can be rendered directly in it. We added experimental support for SVTs (sparse volume textures); caching fluids now writes directly to SVT, which is an order of magnitude faster. Niagara Summary View Editor Niagara Summary View Editor The Summary View Editor provides a way for users to create custom views of Niagara emitters. Using this, it is possible to expose only the most important settings and inputs for an emitter to end users. One heavy use case for this are the Niagara fluid emitters, which make it easier to make tweaks to achieve desired effects by looking at only a well-organized subset of settings. Users can rearrange and set up categories, sections, individual module inputs, or entire modules, as well as specific properties such as the Sprite material for Sprite renderers. See the Summary View Quick Start for more information about this feature. Audio MetaSound Builder API The MetaSound Builder API makes it possible to create and change a MetaSound graph through C++ or Blueprint APIs while the game is running in real time. This opens up the possibility of adding/removing MetaSound nodes and modifying connections during gameplay. Audio Bus Writing You can now take data from one MetaSound and send it to another MetaSound or to another source bus through a new MetaSound node. MetaSound Output Watching (Experimental) MetaSound Output Watching MetaSound Output Watching provides a way for Blueprint or C++ to watch for changes in the MetaSound graph. This means users can match gameplay and visuals to events happening in MetaSounds. As an example, you can affect gameplay elements and visuals according to a musical beat, or change in audio. This supports the ability to: Fire an event when there are value changes on the provided MetaSound output of types float, int32, Bool, and fstring types. Fire an event when the envelope follower on an audio output changes. UI Systems Common UI (Beta) Common UI Common UI provides a toolbox for creating rich, multi-layered user interfaces with cross-platform support. It includes: An input action system specific to UI. An input-routing system that makes it easier to selectively exclude menus from capturing input. A styling system that provides style assets for commonly used text/fonts, borders, and buttons. A library of other commonly used widgets. Improvements in this release include: Integration with enhanced inputs Input debugging Documentation and content examples Font DPI Matching in UMG Font DPI Matching in UMG Designers can now match their font sizes seamlessly when they convert UI mockups into UMG screens, without worrying about DPI mismatch. Newly created projects will have the DPI setting defaults to 72 DPI. Existing projects will remain at 96 DPI. Switching back and forth between different DPI settings will not affect how fonts are rendered. See the documentation on Font DPI Scaling for more details. Viewmodels in Blueprints Viewmodels in Blueprints Whereas previous versions of Unreal required designers to create Viewmodels in C++, in UE 5.3 you can now create Viewmodels in Blueprint. This update streamlines the process of creating and binding Viewmodels in various ways. Extend the MVVMViewmodelBase class to create a new Viewmodel Blueprint. Create variables as you normally would with Blueprint, then designate them as FieldNotify variables by clicking the bell icon next to their names. Create FieldNotify functions to handle operations that don't need dedicated variables, then use your FieldNotify variables to trigger them. Add your Viewmodel to your widget class using the Viewmodels panel. New click-and-drag functionality makes binding Viewmodels to UI fields quicker and easier. See the Viewmodel documentation for full instructions on how to use Blueprint-based Viewmodels in your project. Modeling Modeling Workflows (Beta) Modeling Workflows Artists developing assets require efficient modeling, sculpting, UV editing, and texturing workflows. These workflows are more than just a couple of different tools clicked in a certain order. Every type of interaction needs to be considered in order to reduce the number of mouse clicks, minimize the cursor movement, and provide accurate feedback for the artist. With this aim in mind, improvements in UE 5.3 include: New UI Modeling Mode's main menu, tools palettes, and properties panels have been redesigned. The new UI is more compact, allowing for more efficient and consistent workflows. The new menu also contains a new favorites option, providing a top-level custom menu that can be defined per user. Tool Presets Creators and developers can now make custom presets for modeling tools. The custom presets provide a way for artists to store multiple options for tools, and access them quickly from the tool icon. Element Selection Direct mesh element selection provides for a more consistent and optimized workflow. The existing method of selection requires the artist to select the mesh first, then the specific tool, and finally the element before invoking the operation. The new element selection workflow enables artists to select the mesh, select the element, and then invoke an operation without any need to use an intermediate tool like PolyEdit or TriEdit. Modeling Tools (Beta) Modeling Tools The Modeling Mode's toolset continues to develop. For UE 5.3, we added some requested enhancements to the toolset, in addition to new tools that use splines. The new element selection mode is also supported with a set of dedicated tools. Spline Tools We've added new tools to the Create menu that provide creators with a way to draw new splines, and use them for revolves and flat mesh operations. Element Selection Tools The Element Selection workflow leverages a new menu of tools that work directly with the selection. The palette includes common tools such as Extrude, Bevel, Offset, Inset, and Insert Loops. There is also quick access to PolyGroup and Triangle Edit. LOD Support The Bake Transform and Edit Pivot tools can now optionally update all LODs with the new transform or pivot. Vertex Color Paint We added a new tool for painting vertex color. The new tool enables users to paint, fill, and blend colors to multiple or specific channels. Other Improvements We made additional improvements to the Edit Normals, Weld, Bake Texture, and Generate PolyGroups tools. To learn more about the available tools see Modeling Tools. UV Tool (Beta) UV Tool UVs are a critical component when working with meshes, not only for final rendering but also as a vital part of level design. For UE 5.3, we added two important new features to the UV Editor: UV Editor Distortion Display The UV Editor now has optional display modes for distortion. This provides for an interactive representation of the level of texel stretch or density. UV Auto Layout The tool now has support for texel density normalization. This option attempts to resize individual islands to maintain a constant, average density over the entire layout. To learn more about UV tools see, UV Editor. Geometry Scripting (Beta) Geometry Scripting provides technical artists a toolkit for creating custom modeling tools and workflows. In 5.3 Geometry Scripting is now beta and continues to expand with the following additions and improvements: Enhanced skeletal mesh interoperability provided by several new nodes: CopyBonesFromMesh TransferBoneWeightsFromMesh GetRootBoneName GetBoneChildren GetAllBonesInfo GetBonesInfo DiscardBonesFromMesh New functions for managing 2D polygons and paths, including computing offsets and their booleans: Polygons Difference Polygons Union Polygon Intersection And many more, there is a large library of functions. Delaunay triangulation to create a mesh that interpolates points: Append Delaunay Triangulation 2d Geodesics on mesh surfaces: GetShortestSurfacePath GetShortestVertexPath To learn more about Geometry Scripting and the available functions, see Geometry Scripting User Guide and Geometry Scripting Reference. Content Pipeline Interchange Import / Re-Import Interchange Import / Re-Import In this release, the Interchange Framework includes the following improvements: We added a new custom asset type to provide a way to re-import whole scenes. The Interchange UI now supports overrides of pipeline stack per translator. This provides an extra layer of configurability and is used in default settings: for example, the glTF asset pipeline stack will override the default asset pipeline stack (used for FBX and OBJ). For glTF import, you can now choose to have the editor either generate materials or use predefined material instances. You can also override those instances for more user control over glTF rendering. USD MaterialX (Experimental) USD MaterialX Unreal Engine 5.3 offers the ability to use USD with MaterialX for streamlined workflows and content creation between DCCs and Unreal Engine. It is now possible to import a USD file with MaterialX shading networks directly in the engine. Additionally, you can now open USD files with MaterialX shading networks in the USD Stage Editor while interacting directly with the contents of the USD file. MaterialX support in Unreal Engine was introduced with 5.1 and is still experimental. USD Materials and Textures USD Materials and Textures For Unreal Engine 5.3, there have been a few changes to how textures and materials are handled to improve the display of USD assets: We added support for multiple UV sets on the same material. We added support for simple UV transforms on preview surface materials. If you are loading a preview surface using any math nodes to transform the texture, it will now display correctly. We added the ability to interactively change USD materials in the USD stage editor Details panel and see the result live in the viewport. Previously, the user would be required to save the USD file and reopen it in order to see any changes. USD Animation USD Animation Direct Geometry Cache Import We added the ability to directly import cached geometry into UE from a USD file. Prior to this, you could only load the USD file on the stage and play back the geometry cache animation from there. Support for Transient Actors in Sequencer We added support for transient actors in Sequencer. This provides a way for you to add elements from the USD stage actor to Sequencer, reload the USD file or to close and reopen Unreal Engine, and Sequencer will remain connected to the elements being animated from the USD stage actor. This also means you can now maintain sparse key animation curves that will drive the elements from the USD stage actor being animated, and the baked animation can be exported to a new USD file. USD stage actors can now be exported as well, so animation of their elements can be exported as overrides on the referenced stages. Framework Smart Objects - World Partition Support Smart Objects and World Partition Smart Objects now work seamlessly with World Partition, data layers, and persistent levels. We also improved Smart Objects to support using navmesh and physics for slots availability. Blueprint Type Change Auto-Casting Blueprint Type Change Auto-Casting Deprecating code-based Blueprint-visible properties and changing the type of the properties can include challenges such as failures when rewiring old pins. This leads to orphaned pins and compilation errors. In UE 5.3, if both types have an auto-cast function available, a cast node will automatically be created and added into the graph. Additionally, notes will be created whenever a new cast node was added, which serves as a notice that users might want to update their API to use the new type change. Data Asset Merging Data Asset Merging As a first step towards adding functionality beyond what the Diff tool offers, we started investigating a data merge solution. This first version provides support for manually merging data assets when conflicts cannot be auto-resolved. Currently only data assets are supported, but we hope to support more types of data in the future. Review Tool Swarm Comments Review Tool Swarm Comments The Review Tool introduced in 5.2 now has direct Swarm integration when using P4 as source control, so the diffs you perform from there will directly show the comments in the editor. You can have comments for each change made, but also leave global review notes. We use simple metadata tagging in Swarm to link the comment to the right section of the diff. Engine Content and Templates Collaborative Viewer Templates Using Enhanced Input The collaborative viewer template The Collab Viewer templates join multiple users together in a shared experience of the same 3D content. We intended them to make it easier and quicker for your team to review and communicate about designs in real time, so that you can identify problems and iterate on the content more efficiently. In UE 5.1, we released OpenXR support for enhanced input and made it the recommended input system for XR applications. In UE 5.3, we updated the templates to take advantage of the abstractions and flexibility that enhanced input enables. Platform SDK Upgrades Logos for Platform SDKs Windows Visual Studio 2022 v17.4 or newer Windows SDK 10.0.18362 or newer LLVM clang 14.0.1 .NET 4.6.2 Targeting Pack .NET 6.0 IDE Version the Build farm compiles against Visual Studio: Visual Studio 2022 17.4 14.34.31933 toolchain and Windows 10 SDK (10.0.18362.0) Xcode: Xcode 14.2 GDK Minimum Windows SDK: 10.0.19041.0 GDK: March 2023 Update 5 GDK Firmware Version: Recovery June 2023 (10.0.22621.4819) *Supported IDE: Visual Studio 2022 Linux Native Linux Development Recommended OS: Ubuntu 22.04 or CentOS 7 Compiler: clang 16.0.6 Cross-Platform Development Cross-Compile Toolchain: v22 clang-6.0.6-based (CentOS 7) macOS Recommended Latest macOS 13 Ventura Latest Xcode 14.1 or newer Minimum macOS 12.5 Monterey Xcode 14.1 EOSSDK 1.16 binaries with 1.15 headers Provides 1.15 feature set. 1.16 binaries for recent platform SDK support and WebRTC fixes. Steam 1.53 iOS / tvOS / iPadOS Recommended Latest macOS 13 Ventura Latest Xcode 14.2 or newer Minimum macOS 12.5 Monterey Xcode 14.1 Supported Target SDK versions: iOS 15 or later Graphics API: Metal 2.4 and Metal 3.0 Android Android Studio Flamingo 2022.2.1 Patch 2 May 24, 2023 Android NDK r25b Android SDK Recommended: SDK 33 Minimum for compiling UE: SDK 30 Minimum target SDK for running on device: SDK 26 AGDE v22.2.69+ required if you are using AGDE debugging. Build-tools: 33.0.1 Java runtime: OpenJDK 17.0.6 2023-01-17 Switch SDK 16.2.0 Minimum Firmware Version: 16.0.3 Nintendo Dev Interface 2.5.5 Supported IDE: Visual Studio 2022 (SDK version 16.2.0) PS4 Orbis SDK 10.508.001 System software 10.508.011 Supported IDE: Visual Studio 2022 PS5 Prospero SDK 7.00.00.38 UE5Main has a patch updating to 7.00.00.45. This is recommended for shader compiler fixes. System Software 7.40.00.06 Supported IDE: Visual Studio 2022 ARCore 1.37 ARKit 4.0 OpenXR 1.0.22 Release Notes Animation API Change: Added the first version of Mutable extension API. New: Added a new LOD threshold property to rig logic anim graph nodes in order to compute facial animation earlier than other skeletal post-processing, which might be part of the same post-processing AnimBP. Added the ability to disable or skip post-process AnimBPs at lower LOD levels. You can set the post-processing AnimBP LOD threshold similarly to how you can set LOD thresholds for some anim graph nodes. Additionally you can skip the post processing anim BP graph during set points entirely, to improve performance. The speed improvements scale with the complexity of the post-processing AnimBP and as well as the amount of nodes that do not support LOD thresholds or have setup node-based LOD thresholds. Added the option to filter by Sync Marker to the Animation Sequence Browser. Add new output warnings when the LegIK node is missing definitions or contains references to invalid bones. IK Rig and IK Retargeter now available in UEFN. IK Retarget poses can now be zeroed in local space to instantly straighten limbs for more accurate retargeting. Added 0.75 and custom speed to Animation Viewport ToolBar, for Animation Speed and TurnTable speed. Bug Fix: Fixed an issue that could prevent the MeshBoneReduction module from loading as soon as the MeshUtilities module starts up, as it could be needed at any time from a background thread Fixed an issue by adding a guard against the use of an invalid actor pointer in the Skeletal Mesh editors. Fixed incorrect localized text in the LegIK Animation Blueprint node. Fixed an issue occurring when creating animation assets overriding existing assets, by enabling replacing existing animation in the options to create new assets. Fixed an issue occurring when pasting anim notifies from multiple tracks to a location that did not contain the same tracks. Removed: Removed null links from Mutable graphs on load. This prevents incorrect behavior and editor instability when a node saved into a graph can't be loaded. Animating in Engine API Change: Fix inverted tangents on Y axis for 2D controls. New: Added a new ControlRig.Sequencer.AutoGenerateTrack console variable to toggle whether control rig tracks should automatically be created for new components. Control Rig FBX animations can now be exported and exported between Unreal Improvement: Curve Editor filters have been improved and can now be set using ranges rather than individual selections, so you can now bake a range of frames or times. Curve proximities can now be updated when there is a drag operation so that the curve tooltips show the proper time and value. Curve Editor selections are now synchronized whenever new items are added to the editor. Bug Fix: Fixed an issue that could occur by delaying a level sequence asset's creation until the tick proceeding the tick the control rig actor is dropped into the viewport. This prevents the level sequence asset creation to be in the same transaction as the create actors transaction. Previously, the movie scene could be collected as garbage when undoing the action, because its creation took place during another transaction. Fixed an issue that could cause a memory leak with the backbuffer Render Target not being released at the end of a render. Constraints: propagate offset change so that local transform animations are synchronized. Gameplay New: You can now use the new experimental Dead Blending AnimGraph node. This node is designed as a drop-in replacement to the Inertialization node but uses the new robust \\"Dead Blending\\" algorithm which is more equipped to handle multiple simultaneous Inertilization requests or when the Inertialization transition is between two very different poses. Exposed a new method to blueprints that you can use to get the weight of a montage playing on a specified animation slot. Added the following AnimNode functions: On State Exit, On State Entry, On State Fully Blended In, and On State Fully Blended Out. These are located in any Animation State Graph's Result Node. Added support for AnimNodes to show any bound functions and not have them hardcoded. Added a way for users to specify the string for the default binding name of a function member reference in a blueprint by using the \\"DefaultBindingName\\" metadata tag. Added support for animation sync groups when using initialization for a state machine transition. Added support for explicitly specifying the transitions trigger time when using state machine automatic transition rules. Added a context menu option to Animation Blueprints to create an Animation Template from the blueprint that can be used to override animations using Child Blueprints. Improvement: The PlayMontageCallbackProxy can now be derived from, in order to support plugins that want to provide customized versions. Bug Fix: Fixed an issue that could cause a crash when using the Inertialization AnimGraph node when re-parenting the Animation Blueprint. Fixed standard blending not working as expected with sync groups. Improved stuck detection in Distance Matching Disabled option to duplicate a state from the animation blueprint editor's tree view. Movie Render Queue New: Fixed issue where default settings would get added to a job that already exists when clicking on the Render Movie button from Sequencer. Exposed UMoviePipelineImageSequenceOutput_EXR so C++ plugins can reference it. When using the Render all Cameras feature, Spawnable cameras are now skipped if their default spawn track value is false. Added support for camera rotation to be preserved during a Panoramic Render. Updated the Console Variables setting to display the cvars contained within each cvar preset. Improvement: Added a workaround for the UI Renderer setting having issues with some Layout Widgets not liking the 720p PIE preview window. Optimization: Optimized the multi-sample accumulator for RGBA images on machines with many cores. Bug Fix: Fixed issue where canceling a job reporting as a successful job for some callbacks. Fixed issue where UWorldSettings::Min/MaxUndilatedFrameTime were being modified and not restored after a render. Fixed UI warning about losing unsaved changes to Queues when there weren't actually any changes. Fixed issue where {camera_name} resolved into main_camera when not using the Render All Cameras feature is animating onto this. Fixed data type issue when exporting ProRes with OpenColorIO enabled. Rigging API Change: Creation of buffers is all done within the data interface at runtime. New: Added output bone transfer list for anim node. You can now limit the bones being driven by a Control Rig AnimNode in the Animation Blueprint Graph. Added half edge connectivity data interface. Added unit node to check if a shape is available in the shape libraries. Added support for uint32 types. Added Int32 to Name node (IntToName) Added feature to update the Reference pose of a bone directly in the Control Rig Editor. Added LocalChainDynamics function which creates simple chain dynamics for the given chain. New skin weight editing tool enabled editing weights by painting or directly on selected vertices. IK Rig/Retarget assets can now be created directly from Skeletal Meshes in the right-click menu. Performance improvement to retrieve a template from its arguments. IK Retargeter toolbar redesigned for instant access to common retarget settings. Improved physics constraint editing in the Physics Asset Editor viewport. Extracted all instance data from Control Rig virtual machine and moved it to the context data struct, as a step for stateless virtual machine. FBIK solver now supports animated translation at runtime. Squashing and stretching limbs can use FBIK. RigVM context now has to be passed as a parameter to the virtual machine functions, rather than being located in the virtual machine itself (a step towards stateless virtual machine). Improvement: Skin weights on skeletal meshes can now be edited through a new API in BP or Python. Bug Fix: Fixed issue when adding curves to the output skeleton from USkeletalMergingLibrary::MergeSkeletons. Fixed Control Rig Blueprint compilation error related to missing function definition after a Control Rig Blueprint containing function references is duplicated or renamed. Fixed issue caused by Control Rig Editor Details panel when exiting PIE while debugging a Control Rig instance. Fixed an issue where sometimes the constraint viewport widget would be drawn relative to the wrong body. Fixed an issue where pressing the keyboard modifier for editing the constraint's child frame (Alt + Shift) also activated the keyboard modifier for the Lock camera to widget feature (Shift) which caused the translation widget to move erratically when editing the child frame. Fix for Control Rig Editor issue when adding comments and using undo / redo. Fixed Control Rig compiler issue occurring when a specific function parameter usage is found on a rig, due to invalid remapping of inline function parameters. Fixed an issue in the RigVM compiler when a rig function has more than 255 operands. Fix IK Retarget automatic chain mapping mode \\"exact all\\"; now it does not reset non-exact matches to none. FBIK solver will now dynamically reinitialize if the number of input bones changes dynamically at runtime. Cleaned up Control Rig Python files to remove mixed tab/space error in runtime. RigVMController: Added an array upgrade to reroute nodes with no source or target links where the value is an array, so it can load some deprecated rigs. FBIK solver now works correctly with only one effector (regression from 5.2). Fix for issue when adding a pin on Sequence Node in Control Rig graph. Fixed memory leak in FBIK solver (regression from 5.2). Spherical Pose Reader node in Control Rig fixed so it no longer flips when the activation region fills the whole sphere. RigVM plugin now has a custom serialization object version. Fix for Control Rig Gizmos not working properly; after a changing the asset references to Soft Object Pointers. Deprecated: Deprecated all Execution data interfaces. To set the execution domain of a custom compute kernel, use the Execution Domain field in the details panels of the kernel node. Valid domains should appear in the dropdown menu after connecting either a data interface to the kernel's primary group or a component binding node directly to the primary group pin. Runtime API Change: Extended the ImmediatePhysics_Chaos API so that you can now create Immediate Physics Constraints without copying values from Constraint Instances using a new CreateJoint function that accepts a JointSettings object instead of a FConstraintInstance. New: Added a new dedicated track for Inertializations to the Rewind Debugger. You can now click on Animation node tracks in the Rewind Debugger and the node will be highlighted in the corresponding Animation Blueprint to improve debugging workflows. Added missing tooltips for animation state machine schemas. Animation Blueprint runtime errors are now logged in the PIE log, if they were found during a game session. Anim blueprint logging can now use tokenized messages to hyperlink an error to the node it came from. UAnimInstance::IsSlotActive() is now thread safe. Player nodes in blendspace graphs are now added to GraphAssetPlayerInformation. Reinstated some anim blueprint library methods which now use the Anim Pose API. New colors to distinguish state aliases and conduits. Some LOD bone generation functions from the SkeletalMeshComponent have been extracted so they can be used from plugins. Updated the ComputeRequiredBones function to use the extracted functions. Added a delegate to the SkeletalMeshComponent, so external systems can be notified when the RequiredBones get recalculated for a LOD. Moved the SkeletionRemapping.h and SkeletonRemappingRegistry from private to public, to allow including these files in plugins AnimBoneCompressionCodec now has a new DecompressPose function taking a FAnimBoneDecompressionData parameter, with the decompression data in the following separate array formats: translations, rotations, scales3D. Added the ability to DoubleClick AnimSegmentsPanel, in order to jump to the target asset. You can also shift + DoubleClick to open it a in new window. Added a new compiler note and visual warnings to state machine transitions if the transition rule has logic but the flag for automatic rule based condition is set Improvement: Added a new helper function to find all external saveable packages. Added current time accessors and library functions to Anim Notify events to allow for easy access to relative times and ratios. Sync markers can now be managed in the same way as notifies. Neural network mask curves are forwarded to RigLogic from both the Animation Blueprint node and Control Rig implementations. Crash Fix: Fixed an issue that could cause a crash when reloading a Control Rig Animation Blueprint. Fixed an issue that could cause a crash when undoing or redoing an Animation Sequence edit while an async task is in flight. Fixed an issue that could cause a reinstancing crash when using a custom Anim Instance proxy as a linked AnimGraph. Fixed an issue that could cause a crash when calling UAnimInstance::GetAllCurveNames from worker threads. Fixed an issue that could cause a crash when compiling an Animation Blueprint during automated tests. Fixed an issue that could cause a crash when right-clicking a modified curve node in a template Animation Blueprint. Fixed an issue that could cause a crash when unloading animation assets in a game feature plugin that are referenced by editor thumbnails. Fixed an issue that could cause a speculative crash during automated tests. Bug Fix: Fixed an issue that could cause a regression with curve inertial blending due to the curve refactor. Fixed an issue that could cause the start position to be ignored when using sync groups. Fixed an issue that could cause an ASan issue when unregistering property type customizations on shutdown. Fixed an issue that could prevent the creation of a child Animation Blueprint in the Content Browser. Fixed an issue that could cause a crash when opening a template Animation Blueprint with the Curves tab open. Fixed an issue that could cause meshes to be distorted when the Leader Pose nod. Fixed an issue that could cause blending to incorrectly skip blending in and out when using inertial blending curve filtering. Fixed an issue that could cause Anim Node Functions to not be called in versioned builds when multiple are bound to the same Animation Blueprint node. Fixed an issue that could cause cached poses to be invalid on subsequent evaluations of an AnimGraph. Fixed an issue that could cause stack corruption caused by calling an Anim Node Function with an altered signature. Fixed an issue that could cause out-of-bounds access in Control Rig curve I/O. Fixed an issue that could cause distorted meshes when assigning assets using skeleton compatibility. Fixed an issue that could cause curves to be missed intermittently in cooked content. Fixed an issue that could cause bone LOD filtering to display incorrect results during automated tests. Fixed an issue that could cause the Layered Blend per bone node to not work correctly with per-bone curve filtering. Fixed an issue that could cause out-of-bounds access in PoseAssets that have additional poses with their respective curves. Fixed an issue that could cause fired notifies to not be reached when looping by clamping remaining time. Fixed an issue that could cause the virtual bone menus to not appear when adding additional virtual bones. Fixed an issue with the Control Rig Anim Node that could cause the Rigid Body Anim Node in a post process AnimBP to stop working. Fixed an issue that could cause OOM issue on consoles by reducing default alignment requirement of memory allocations in RigLogic. Fixed an issue that could cause performance problems when multiple faces (DNAs) are loaded during gameplay. Fixed issue when attempting to collect sync markers in a montage with an invalid slot track index. Fixed bCanUseMarkerSync to default to true even when the animation asset did not have any sync markers. Fixed bCanUseMarkerSync being true for followers when all valid markers were filtered out. Fixed issue when linking/unlinking anim layers from UGameplayAbility::EndAbility. Animation editor now correctly applies preview mesh from a compatible skeleton. Fixed issue when filtering preview mesh on template anim BPs. Fixed Anim BP asset definition correctly displays option to create child Anim BP. Fixed issue when adding curves to anim sequences and immediately getting the bone pose. Fixed issue in UBlendSpace::TickFollowerSamples due to hard coded bLooping flag. Fixed NaN crash in FAnimNode_LinkedInputPose::Evaluate_AnyThread. Ensure a clamped normalized time stays within the 0-1 range in the Blend Space Evaluator. Fixed \\"Start\\" animation notify event for state machine transitions not being fired when bSkipFirstUpdateTransitions flag is set to false. Fixed an issue that could cause a reinstancing crash in linked anim layers or graphs. Fixed an issue that could cause use-after free when duplicating animation attributes. Fixed an issue that could cause a crash when deleting a sync marker at the SyncMarkers Window, when finding an AnimMontage during the process. Fixed a but that would only look at player controllers, and not something like AI controllers, when considering viewpoints for auto significance calculation. Fixed an issue that could cause the GetLinkedAnimLayerInstanceByGroup tp not work for non-implemented layers with no instance assigned. Fixed an issue that could cause the Details panel to disappear when making curve metadata edits. Fixed an issue that could cause the preview instance from not being re-selecteable after selecting an external anim instance to debug. Added some missing definitions for the UAnimInstance's function GetRelevantAssetPlayerInterfaceFromState. Fixed an issue that could cause a crash in FMirrorSyncScope. Fixed an issue that could cause blendspace sample entries from expanding when a sample animation is changed. Fixed an issue that could cause a crash on loading an anim BP with pose hander nodes that require skeleton updates to their animations. Added a missing ENGINE_API tag to SkeletetonRemappingRegistry, as it is required to use it from outside of the engine Fixed an issue that could cause a crash when using an incorrect bone index type usage in UAnimationSequencerDataModel::GeneratePoseData. Fixed an issue that could occur by ensure when transforming bone indices during animation compression. Fixed an issue that could cause an issue with the SkeletalMeshComponent ComponentIsTouchingSelectionFrustum, as it was returning false positives due to missing check. Fixed an issue that could cause issues with the FBX Import due to a name restriction not allowing bone names to start with a number at RigVM hierarchies. Fixed an issue that could prevent the Animation Sequencer from triggering notifies repeatedly when using an animation mode track set to Use Anim Blueprint in a Level Sequence, by adding a parameter to the SkeletalMeshComponent SetAnimationMode function that allows not re-initializing the AnimationScriptInstance. Fixed an issue that could cause a crash when using the PoseableMeshComponent, when the component is being incrementally unregistered and the unregistering process takes longer than the time limit set in the component. Fixed an issue that could cause a crash when using one of the Animation editors when closing one viewport while additional viewports are open. Fixed an issue that could prevent the BlueprintEditor from being refreshed after adding an animation layer node into an animation graph. Fixed an issue that could cause an issue during an AnimComposite animation notify extraction when playing in reverse order. Deprecated: Added a deprecation warning for AnimNode_StateResult.h located in AnimGraphRuntime module since the file got moved to Engine/Animation. Removed the deprecated mirroring functionality from SkeletalMesh. Sequencer New: Added the ability to create Takes for Subsequences. You can now add comments for shots and Sequencer sections. Added support for tags when bindings are copied and pasted in Sequencer. Added the option to select the material parameter collection asset from the track in Sequencer. Reassigned the LevelSequenceEditorSettings.h to public. Added command bindings for composition overlays to the Cinematic Viewport. Exposed the ability to access setters and getters for audio section looping, suppress subtitles, and attenuation functions. The Sequencer's Key editor now edits selected keys if they are selected. Otherwise, it edits at the current time as usual. Bound recording commands in the Take Recorder now play in world space so that they work in Editor and in PIE. The Clock Source menu is now always visible even in SubSequences, but is only editable when the Sequence Editor is focused on the root sequence. Several improvements have been made to the Sequencer's Import EDL: Added the support of KEY CLIP NAME Sequencer now parses the timecodes from the end of the line. If the EDL contains a shot multiple times, subsequent shots will be created in Sequencer when importing, corresponding to the EDL shots. You can now change the Sequencer folder color of multiple folders by multi-selecting. Sequencer Track filters are now saved in preferences. Added a new transaction for toggling Show Marked Frames Globally. Added support for a start offset to camera animations. Upgrade audio track to use the new ECS evaluation. Moved level-sequencer-specific editor code to the LevelSequenceEditor plugin. Moved sequencer customizations to the editor view-model. Add the following improved edge interaction for sections: You can now use draw easing handles as rounded triangles sized to match the grip size, instead of the previous bitmap. Easing handles are bigger, with bigger hit-testing area to make selection easier. Exposed key size through the section interface in addition to grip size. Added support for blend types and multiple rows for material parameter tracks (widget and MPC). Exposed camera animation parameter to detail views. String properties and String tracks now use the new ECS evaluation. Add ability to lock marked frames on the time slider. Register/unregister the camera animation stand-in object from its own module. Added new user-defined bindings to Sequencer. This change adds the ability to define custom logic, using the directory blueprint, for object bindings. Instead of binding to the usual possessable or spawnable, this will optionally run arbitrary BP logic defined by the user to resolve the bound object. This makes it possible, for instance, to bind to the player pawn, or any other actor that might not exist at edit time. The UI is similar to that of the event track, and therefore reuses the director blueprint endpoint picker. There is however a new blueprint extension to compile these functions into the spawnables and possessables, and of course a spot to call these functions when appropriate. Added a new key that you can use to allow the player to be closed. You can now expand skeletal animation sections back to the left. Added new feature: Smart Auto Key. Smart Baking for Constraint Baking, Space Baking, Snapper, Control Rig collapsing and Baking Transforms. Swap Root Bone on Track. Animation Mode: Disable selection when clicking on an axis, avoids losing selection when manipulating. Curve Editor: Make normalized mode scrollable and panable. This makes sure that if you frame to the normalized mode now it doesn't use the max/min values but defaults. Control Rig: Shift now moves camera to stay with Control Rig when moving. Curve Editor: Keep Output bounds the same even if curves are destroyed so you can select/deselect and keep their curve bounds. Take Recorder now supports up to eight audio input sources for multi-track audio recording. Added time scrubbing to Sequencer and Curve Editor to match Viewport behavior. Added native accessors for common float/color light properties to improve performance when setting properties following sequencer evaluation. Curve Editor: Added option to show constraint/space bars. Linked Anim Sequences are now editor only. Improvement: Take Recorder Timecode setting names now default to the same as Anim Sequence so that aligning works. Removed the Sequencer's Add (+) button text rollover visibility. Now the text is a tooltip so that there's no overlap with key editor buttons. Added the Sequencer's Browse to Actor property back to the actor's right-click context menu. Control Rig Controls filter is no longer enabled by default in Sequencer. You can optionally enable it, and your preference will be saved between sessions. Trim and Preserve now calculate the correct transform when the attached component isn't the root component. Crash Fix: Fixed an issue that could cause a crash when sorting sections on load. Bug Fix: Fixed an issue that could prevented the ability to toggle on or off tags inside of shots and subsequences. Fixed an issue that could cause new keys to be added when attempting to update an existing key. Fixed an issue that could cause the group manager to not refresh when performing an undo or redo command. Fixed an issue that could prevent the group manager selection to not function properly with folder paths. Fixed an issue with path track evaluations that could cause component velocity to not be set properly when an object is moved by the path track. Fixed an issue that could cause regenerating waveforms during playback to not function correctly by adding a slight delay to eliminate hitches. Fixed an issue that could cause duplicate entries in the property menu. Fixed an issue that could cause Show Marked Frames Globally to not be marked as a UPROPERTY so that it gets serialized. Take Recorder: Fixed range for camera cut section so that it works for subsequences when recording cameras. Remove unnecessary creation of camera cut track and section because they're already created when a camera is added. Fixed an issue that could cause animation sequence to be marked dirty, due to the spawnable being modified, if the sequence is evaluating. Fixed mute/solo nodes when hierarchy changes by tracking old and new nodes paths. Fixed issue when the widget is replaced and no longer valid. Fixed issue where duplicating keys is not undoable and doesn't update the UI properly. Fixed an issue by keying the material parameter collection instance's current value if it exists, rather than always just the default value. Fixed an issue by compensating for transform origin when adding an object's transform to Sequencer. Fixed track row names when row indices have been remapped or a new row has been added. Fixed an issue that could occur when pasting a possessable, by only parenting it to the pasted target if the possessable's class is not an actor, such as a component. This fixes an issue where an actor could be pasted into another actor. Fixed an issue by ensuring the CineCamera actor's name is unique when creating as possessable. Normally this is done in the actor factory but here we spawn the actor directly. Check for valid animation on skeletal animation FBX export. Fixed issue where calling scripting functions (AddKeyInChannel, RemoveKeyFromChannel, SetDefaultInChannel, ReoveDefaultFromChannel, SetTimeInChannel, SetValueInChannel) is not undoable and doesn't update the UI properly. Fixed an issue by initializing layers for spawned actors. This fixes issues where if you add a spawnable to a layer, hide the layer, and then reopen the sequence in a new level, the spawnable won't be visible and won't respond to layers in the new level. Fixed an issue that could prevent Snap Sections in the Timeline by using the Source Timecode so that it takes tick resolution into account Fixed an issue by preventing all camera actors from being selected in the camera cuts menu even if it is hidden. Fixed an issue that could cause small sections to result in negative time-to-pixel conversion. Fixed an issue by carrying over the previous view target from a previously playing level sequence, if any, so that the last sequence played restores the actual original view target, and not the previous sequence's camera. This fixes issues with stuck cameras when some sequences are played on top of each other. Fixed an issue that could cause a crash when using the context menu in the Camera Cuts track to try and select an unspawned spawnable. Fixed an issue by preventing global custom accessors from being unregistered on shutdown. Fixed an issue that could cause recycling of view-models when track layouts are rebuilt. This fixes some UI issues with keys and sections being moved between track rows. Fixed an issue that could cause a crash when shakes are previewed in Sequencer or in the Camera Shake Previewer tool. Fixed an issue that prevented initial material parameter values to be cached correctly. Fixed an issue that could cause a crash when recompiling a user widget while Sequencer is open. Fixed an issue that could cause the Snap to Interval tool to not function when Snap to Keys and Sections was not selected. Fixed an issue by restoring aspect ratio axis constraint directly on the player if the level has changed during sequence playback. Fixed an issue by correctly restoring the Sequencer editor playback speed on stop and pause operations. Fixed an issue that could cause the key editor widget to not be cleaned up correctly when a track goes from 1 to 2 or more rows. Fixed an issue that could cause a crash when dragging an item from the Place Actor menu over a sub-scene section. Fixed a UI issue where the preview for the section length shown was only as long as the first sub-sequence asset, not the longest asset in your drag or drop selection. Fixed an issue that could cause Sequencer runners to detach and attach to linkers in interwoven ways. Fixed an issue that could cause the Additive From Base blend type to be missing an icon in the UE5 style. Fixed an issue by taking play-rate into account for blend times between blending camera cuts. Fixed an issue that could cause a Control Rig Component to be constantly reinitialized when used in Sequencer. Fixed an issue that could cause incorrect blending out of sequencer camera shake patterns. Fixed an issue by not calling the NotifyMovieSceneDataChanged() function when pasting tracks. This fixes an issue with Niagara not setting up its data correctly after pasting a track. Fixed an issue that could cause interactions to be incorrectly handled between the normal track area and the pinned track area. Fixed an NVVM refresh issue that could cause view-models who already have a recycle list would not recycle their children. This meant that a re-used track-row view-model would not get its children cleared out before it is rebuilt with new underlying data. Fixed an issue with the Channel Curve Models in Sequencer Curve Editor that could cause the tracking interpolation type of neighboring keys to not operate properly when a new key was added. Fixed an issue that could cause the MovieSceneSequenceExtensions::GetBindingId to not be properly exposed to python scripting. Fixed an issue that could cause ease-in curves to not show properly when a section starts at time 0 that also does not have an ease-out. Fixed an issue by not caching pre-animated state on entities that are being torn down. Fixed an issue that could cause BOOL and INT curves to not be drawn past left or right-most key value in Curve Editor. Fixed an issue that could cause a null check in Movie Scene playback. Fixed an issue that could cause autosizing of subsections, audio sections, and skeletal animation sections, to not function properly, as they were all missing taking into account start or end offsets. Fixed an issue that could cause a spawnable binding to be overridden during the sequencer, the spawned actor will get left behind, creating duplicate characters. Now, when a binding is invalidated, and we detect an overridden binding, Sequencer checks if a spawnable is registered, and if so, destroys that spawnable. Fixed an issue by setting a zero value on an additive Control Rig section, so it doesn't always add and uses default interpolation. Fixed an issue by adding the sequencer ability to change the SkeletalMesh asset from a Skeletal Mesh Component in cooked builds. Snapper: Use default key type when setting keys. When changing time via translate hotkeys get all changes first, then apply them to avoid double transforms with space/constraint keys. Control Rig: When looking for a binding that constrains a Control Rig, it takes into account the Control Rig so it picks the correct Actor or its component. For certain setups the face and body rig both bind to the same component on the Control Rig, but bind differently on the Sequencer side. Fix for missing or incorrect timecode values being stored in audio assets when recording with Take Recorder. Constraints baking: changed the tangent type to the default for the keys at compensation to avoid inserting keys that may have flat tangents. Control Rig: Fix keying weighted additive sections. Fix copying actors in Sequencer that live in sublevels, you can end up selecting the wrong Actor. Only sync curve selection when updating the tree if we have no curves, otherwise this will blow away what the animator is working on. Fixed silent failure case in Sequencer when scrubbing audio at low frame rates. Fixed an issue that occurred when applying an FFT filter with insufficient number of keyframes selected in Curve Editor. Calling PasteBindings() from Blueprints or Python correctly returns the newly created bindings. Linked Anim Sequences work with nested sequences. Curve Editor: Don't show the space or constraint key bar spaces unless there is a space. Snapper: Do not include controls without shapes when snapping to avoid issues. Animation Mode: Restore Gizmo Scale when leaving/entering Animation Mode. Linked Anim Sequence: Only dirty if the data is changed, not if refreshing or changing sequences. Control Rig: Make sure it is on game thread when handling initialize events, fix possible issues with procedural rigs. Fixed Sequencer player playback replication synchronization to only happen once per tick. Deprecated: Deprecated the GetBoundObjects as it is incompatible with Spawnables. It is recommended to use ULevelSequenceEditorBlueprintLibrary::GetBoundObjects because it operates on the currently opened sequence in Editor and can return valid spawnable objects. Remove Matinee's PostInterpChange, as it is not often used or compatible with projects. Synthesis New: Added progress bars when creating and compressing Morph Targets. Added support for using Physics Blend Weight alongside Physics Control Component. Added a new UpdateKinematicFromSimulation flag to BodyInstances. This allows kinematics to be treated the same as dynamic objects when simulating with async physics. The flag defaults to false, so there is no change in the default behavior, unless using the Physics Control Component, which sets the flag by default. You can now get the current or target transforms with Physics Control Component. You can now set the Physics Control Component to use manual updates. The Physics Control Component damping ratio in the PhysicsControlMultiplier struct has now been exposed. You can now bulk edit Physics Control Component settings, such as the target positions and orientations. You can now reset the physics transforms to the cached targets when using a Physics Control Component. Added the ability to use profiling mark up when using a Physics Control Component. Removed the NNI from ML Deformer VertexDeltaModel and NearestNeighborModel. Fixed an issue that could cause a crash when initializing the ML Deformer on Linux operating systems. Improvement: Improved ML Deformer reconstruction quality: The ML Deformer reconstruction method now uses a smoothed L1 loss function, adding a new beta Smoothing Loss property to the training settings. The reconstruction method also now uses cosine annealing learning rate scheduler, which removes the Learning Rate Decay setting. The ML Deformer now displays a warning when using the Vertex Delta Model, that it should not be used in production. The ML Deformer now uses extra Get functions to get private members. Verbose logging has been added where non-verbose logging wasn't needed. Added additional null safety checks to the ML Deformer. The ML Deformer now prevents sampler reinit when not needed. ML Deformer models can now specify the number of floats per bone. The ML Deformer now detects changes in vertex count, and shows a warning in the morph target section, when dynamic Morph Target updates aren't possible until after retraining. Improvement the cleanup of the external Morph Targets, which also clears out the weight data. Improved the component reinits by reducing the number of units. Improved the rendering of bones inside the ML Deformer asset editor. The Initialise Physics Control Component control strengths are now set to 0 by default, instead of 1. Crash Fix: Fixed an issue that could cause a crash by preventing the ML Deformer from updating dynamic Morph Targets when it is not possible Fixed an issue that could cause a crash when the local bone transforms on the skeletal mesh component were empty. Fixed an issue that could cause a crash when creating a new actor blueprint, adding the blueprint to a skeletal mesh and ml deformer component, then setting a neural morph model as ML Deformer asset, and selecting the vertex delta model mesh deformer in the skeletal mesh component. Bug Fix: Fixed an issue that could cause the ML Deformer asset to behave incorrectly. This could likely happen when aborting during training, or changing assets after training, and saving. Now, the editor correctly sets section indices inside the Morph Targets, rather than just including all sections and sorts the Morph Target deltas by vertex number. Fixed an issue that could cause unexpected behavior when using curves in the Local Model. Fixed an issue that could cause the ML Deformer editor to enter a state where the timeline does not function properly after changing the input of an asset, such as a property on a skeletal mesh. Fixed an issue that could cause compatibility checks to fail after training. Fixed an issue that could cause a check to fail in debug mode. Fixed an issue by setting the Physics Blend Weight property to 1 by default when using a Physics Control Component to simulate physics. This ensures that using a mixture of kinematic and dynamic bodies works with skeletal meshes. Fixed an issue that could occur where the ML Deformer time sampling was incorrect. Fixed an issue that could occur when render graph errors in ML Deformer Vertex Delta Model. Fixed some issues that could occur with ML Deformer Vertex Delta Model inferences. Fixed an issue that could occur with the VertexDeltaModel which caused animation to appear frozen. Fixed an issue that could cause a module in ML Deformer to be missing. Fixed an issue that could cause an incorrect mismatched vertex error in MLDeformer. Removed: Removed a substring redirect from the ML Deformer, which wasn't needed anymore and triggered a warning in the log. Editor API Change: There is no support for OpenGL on Linux, so the imaging and usdImaging USD libraries that depend on OpenGL are excluded on that platform. New: Added editor performance setting to control r.VSyncEditor. Added support for overriding enum value display names on a per-property basis. This can be specified by the Enum Value Display Name Overrides meta-data, and is a semi-colon separated list of Name=DisplayName pairs where the Display Name can be a raw string or a NS/LOCTEXT style localized value. Added Source Code Access plugin for the 10X editor. Added a Copy References and Copy Paths button to the editor asset menu. Disabled real-time viewports when the editor process is in the background and bThrottleCPUWhenNotForeground. Optimized advanced copy by running its consolidate step less frequently. Added new option for PNG import to fill RGB into transparent neighbors always, even on complex alpha channels. Previously was only doing RGB fill on simple binary transparency. This is configurable in Texture Import Settings. Added a Fixup Group Actors function. Added support for Windows ARM64, Linux, and Mac. Changed floating point textures to default to BC6H compressed texture format on import, rather than RGBA16F. Existing textures are not changed. The format chosen by default can be set in the Texture Import Settings config; for VFX users may set it to default to 32 bit texture formats. Added support for automatically wiring inputs when creating a node from a specific output. Enabled easy command line override of shared linear encoding ( -ForceSharedLinearTextureEncoding=True/False ). Fixed 32-bit size limits and bugs that prevented use of very large images (such as file sizes over 2 GB). Unreal should now be able to import very large images, only limited by memory use and the target platform or VT size limits, which is currently 16k x 16k for non-VT and 4 GB built size for VT. Added button to Media Plate to browse to the material asset. Updated the Fracture editor with a display of imported collision shapes in the convex tool if they are available and enabled. The display supports convex, box, sphere and capsule imported shapes. Sound Cue Nodes now obey Class Viewer Filters. Updated the Plastic SCM plugin to version 1.8.0. Modified advanced color space transformations and source encoding overrides on textures to utilize the OpenColorIO library. Added basic SCC support to Content Browser file data sources. This is enough to support the basic operations (on add, delete, move, rename), as well as the revision control file menu (to allow sync, revert, check-in, history, and diffing). Added a context menu entry to perform asset validation on specific actors. Upgraded OpenEXR version to 3.1.6. Included the imaging and usdImaging libraries in the engine's build of USD. Exposed SetIgnoreBoundsForEditorFocus as Blueprint callable and added GetIgnoreBoundsForEditorFocus. Exposed single click action within SGraphPanel to allow hooking custom logic. Adding a new Cook Metadata file that gets generated adjacent to the development asset registry. This will be the home for metadata about the cook that is unrelated to assets moving forward. Currently this contains dependency information regarding the enabled plugins at cook time, as well as plugin size information that gets written to the cook metadata file during staging, if enabled. Upgraded USD version to v23.02. Properties Menus drawn from the Sequencer now obey the Property Editor Permissions List. Updated icons for Check-in Changes and Sync Latest status bar buttons. Added ability to revert conflicted files in the Submit Files window. Added the -AssetRegistryCacheRootFolder= commandline option to allow you to choose where to write the asset registry cache files. Added number of convex to the statistics widget in the Fracture editor. Made the histogram Set Inspected Attribute method in the Fracture editor to be more resilient to ill formed geometry collections. Triggered an autosave if there are any unsaved changes when a user clicks check-in changes. Updated the debug focus plane bounds to not be taken into account anymore when focusing on a cine camera in the editor, making the viewport focus on the actual camera itself. Improved editor startup performance related to populating FAutocastFunctionMap entries. Improved editor asset scan performance. Updated the Variant manager properties list to include static mesh and overlay material properties. Updated SyncBrowserToObjects use const arrays and add SyncBrowserToObject. Added Blueprint Display Name to Blueprint Generated Class editor tags to permit aliased class names in cooked editor. Added a tooltip to the toggle visibility button in the scene outliner and the Pin button in the scene outliner. Renamed Mobile Preview ES3.1 (PIE) to Standalone Game Mobile. Renamed Vulkan Mobile Preview (PIE) to Standalone Game Vulkan Mobile. Renamed Mobile Preview (PIE) to Standalone Game Target Device Mobile. Renamed Preview Rendering Level to Preview Platform. Rename DebugText in EditorViewport from Feature level: to Preview Platform:. Added a callback to get notified when the UObject garbage collection finishes purging objects. Loaded components ( including the one in blueprints ) are now properly updated when using Dataflow to generate a Geometry Collection asset. Added parameter to enforce the cluster number when using the connectivity data in the Fracture editor. Prevented non-server standalone instances from using Server Map Name Override. Added the ability for objects to have alternate selection outline colors picked from a palette. Added support for statically and dynamically registering documentation redirects to allow licensees to override engine level documentation links without duplication / adding boilerplate menu overrides. Documentation redirects can be registered statically through INI editor config files or dynamically in code through the IDocumentation interface. Improvement: Updated the asset registry exporter to output to CSV to facilitate import into common database frontends. Additionally, support outputting dependency information based on a set of primary asset type roots for help in analyzing the source of build size. Updated the function \`UContentBrowserAssetDataSource::CreateAssetFilter\`to improve performance. For a large project with a lot of paths using a recursive search on all the folders, the change reduced the time it took to create the filter by about 86%. Improved the backend filter compilations of the asset views by adding a system to cache some part of the filter compilation. Improved connectivity tool visualization in the Fracture editor: Centers are now displayed. Added controls for line thickness, point size, and colors. Bug Fix: Fixed a crash accessing null pointer on shutdown of editor. Corrected Clear Thumbnail not working if asset is not already loaded into memory. Fixed it so Additional Server Game Options in the Play in Editor options applies to externally launched dedicated servers as well as listen servers. Corrected the clear on pie checkbox to work by putting in the correct path. Fixed editor ensure startup when stats is not defined. Fixed crash on exit in stall detector thread when editor closed by call to RequestEngineExit(). Updated Ability System Component function to check the Spec's ability pointer before use. Fixed crash on shutdown if a web browser window was open. Fixed nested virtual roots (from aliases) failing to resolve correctly in the Content Browser. Fixed regressions when undoing a deleted one-file-per-actor post-save. Fixed the details panel failing to restore expansion state when running deferred actions. Fixed an issue with the content browser not always showing the path filters. The SLATE_ARGUMENT to determine if it should be shown was not initialized. Fixed a crash bug with Advanced Copy, where two asset dependencies with the same name would flatten down to overwrite each other. Fixed crash when creating a parameter from a datatable asset or any asset. Fixed a couple of issues where packages were aggressively dirtied: Call cancel on the transaction if it is actually a camera movement input. Reset package dirty state when a widget drag is canceled (for example with escape key). Made FBoxes IsValid flags editable, otherwise editor-modified boxes will compare equal to the CDO and so not be saved. Usee FLinearColor for screen fades so that extreme values behave consistently between the editor and the runtime. Fixed Variant Manager opening an extra empty window. Fixed Unreal Editor's crash when using Unreal Remote. Fixed a crash where a Thumbnail Pool could be deleted while it is ticking because the asset view that owned it was destroyed while generating a thumbnail. Fixed a crash on editor shutdown where the transactors for ISM typed element handles were cleaned up too aggressively. Reworked component visualizer visibility to key off draw debug variable. When this is disabled, the component visualizer will still draw if the component is directly selected, and will allow editing this way. Supports helper splines for PCG workflows that are intended to be hidden by default to the user. Fixed a memory leak caused by a circular dependency from the delete asset window. This also fixed a general performance degradation of the editor when deleting assets because of the leaking assets pickers widget. Fixed an issue where the gizmo would rotate on an axis from keybinds, even if the user had selected a valid axis on the gizmo. Fixed a crash when prtining typed element debug ID. Speculative fix for seen once crashes in typed element debug ID printing. Fixed duplicates being wrongly reported when adding elements to map or set properties in the editor, where the key type is a UClass* key and the class name is a subset of a name which already exists as a key. Fixed an issue where the hovered/active gizmo hit proxy is incorrect when mouse tracking restarts This was causing the indirect manipulation axis to persist as new buttons were pressed, which would result in the wrong axis getting manipulated. Updated the level editor place actors menu to respect Class DisplayName overrides. Fixed an issue where an invalid FName could cause category path look up to assert. Fixed the Convert to Static Mesh actor's tool to now handle Instanced Static Mesh Components (and HISM components) properly. Fixed the inability to revert level file deletion in Check-in Window. Fixed an issue that prevented the use of the property matrix on textures. In the Subversion settings, only the path of the Executable Location setting will be used and any executable name after the path will be ignored. Fixed a bug where the asset registry cache would not be written in certain situations related to synchronous scanning. Implemented auto-save on check-in. Fixed issue that prevented deleted objects from being restored on Revert All. Fixed issue that caused not saving deleted files during Delete workflow to result in errors after sync. Fixed issue that caused added and saved files to disappear after Sync Latest. Fixed a bug where the class redirector of a renamed Blueprint asset would not be applied until the asset was loaded, causing the new class type to be missing from UI selection. Modified CleanupAfterSuccessfulDelete() to check if deleting a package is supported by source control first, and only if that is not the case, mark it for local deletion. This fixes an issue where deleting a file checked out by someone else (when working offline) and choosing only to save locally resulted in the file not being deleted on the local file system. The packages Core Redirect are no longer case sensitive (regression introduced in a previous version). Since package names are stored in case insensitive FNames, the redirectors should be case insensitive as well. Fixed a memory corruption issue related to UK2Node_EvaluateProxy. Fixed an issue where when moving multiple directories at the same time in the content browser, the asset references weren't always being updated correctly, leaving some assets pointing to invalid asset paths. Fixed a crash that could occur during the static mesh build step. Fixed an issue where the asset registry state of an cooked plugin would remove some of the needed development tags from an asset that already exist in the Editor Client Asset Registry. Fixed a crash for the Cloth editor that occurred during shutdown due to SharedPtr cycle. Updated Approximate Actors method of Merge Actors to properly detect and return an error if the occlusion method removes all triangles in the approximation mesh. Deprecated: Deleted DDS Loader and HDR Loader functions which were previously deprecated. Content Pipeline New: Fixed many image importers to gracefully handle malformed files instead of crashing. OBJ translator distinguishes multiple polygon groups with different materials within a group. Virtual textures no longer allow the NoMips MipGenSetting, as VTs require mips in all cases. LeaveExistingMips is only allowed if the entire mip chain is provided. This generates a texture build warning, and the texture is forced to generate mips. PSD loader support has been made more robust, and support for RLE compressed 16 bit PSDs has been added. Optimized I/O usage when utilizing the reference chunk database for packaging. When CADKernel mesher is the default mesher, if a failure occurs, the process of the file is relaunched with TechSoft mesher. A post process of the static mesh during the import has been disabled. It can be reactivated by setting the CVar ds.CADTranslator.SewMeshIfNeeded = true Added CVar ds.CADTranslator.EnableUnsupportedCADFormats to enable all unsupported CAD formats. Improved quality of OBJ format material translator. Most of the basic and extended sets of parameters(and corresponding maps) are now supported. Illumination modes are extrapolated. Added a CVar USD.SkipMeshTangentComputation to skip computation of tangents for static meshes. This can help import performance when the tangents are not needed. USD: Baked mesh deformations can now be imported as GeometryCache assets. Files with geometry caches loaded on the stage will now have associated tracks in the USD level sequence. GeometryCache track section parameters in level sequence are now exposed to Blueprint. AUsdStageActor can now be derived in C++ from other plugins than USDImporter. Alembic: Face set names, when available, are now used as material slot names on geometry cache (and static and skeletal mesh) and can be used with SetMaterialByName in Blueprint. Added support for extracting RootUV values from the Alembic UVsParam instead of the groom_root_uv attribute. Bug Fix: The import of assets via the asset tools now validates that the destination path is mounted and avoids crashing if this is not the case. Fixed issue caused by updating a texture via a render target while it is being built/compiled. Removed redundant data from telemetry of USD/AxF/MDL/Datasmith importers, Dataprep. Fixed issue importing obj/gltf/datasmith/mtlx when a texture is missing. Fixed matrix issue for Autodesk Alias format (.wire). Fixed issue for longlat textures with LeaveExistingMips set. Importing partial mip chains generates output to a full mip chain. Made the paper2D on object reimported safe to use in a cooked editor and made the existing code more robust by not having issues if you are missing the SourceTexture metadata. Made the Blueprint node for the function MigratePackages of the AssetTools non pure. This adds the missing execution pin this node should have. Fixed possible issue when streaming multiple instances of the same GroomCache at the same time. Alembic: Fixed possible computation error when composing hierarchy of transforms. Fixed GeometryCache ignoring \\"Receive Decals\\" setting with Deferred Decal materials. Alembic: Fixed import generating no animation when importing GeometryCache with \\"Flatten Tracks\\" and skipping the import of the first track. Alembic: Fixed frame time computation error at import that could cause timing issue. Datasmith New: Added a USD Stage import option to enable/disable the import of Groom and Groom Binding assets. [USD Importer] Added UnrealUSDWrapper functions for registering USD plugins by path. [USD Importer] Added UE wrapping for UsdPayloads, UsdReferences, and UsdVariantSets from USD API. Added resource size tracking for Geometry Cache assets stored in the USD Asset Cache. Added support for using Interchange's MaterialX translator when opening or importing USD Stages with references to MaterialX files. [USD Importer] Added config setting and API for setting the default search path for USD's default resolver. [USD Importer] Added a file format arguments parameter to find/create/export functions of SdfLayer wrapper. Added support for exporting LevelSequences with animation constraints to USD. Added support for UV transform shader nodes connected to primvar readers, when opening or importing USD Stages. [USD Importer] Added wrapping for token-based API schema functions (CanApplyAPI(), ApplyAPI(), and RemoveAPI()) on UsdPrim from the USD API. Added support for geolocation to Datasmith API. Added new C++ events to the Usd Stage Actor: OnStageLoaded and OnStageUnloaded. Implemented automatic regeneration of UAssets whenever the source USD prims were updated on the opened USD Stage. [USD Importer] Added optional EUsdLoadPolicy parameter to FUsdPrim::Load() to mirror the USD API, allowing the underlying prim to optionally be loaded without loading any of its descendants. Added support for parsing USD Materials that use multiple UV sets (primvars). Improvement: The USD Stage Editor's right panel can now display prim relationships, metadata, and attribute metadata (once an attribute is selected). [USD Importer] Exposed UsdStage::CreateClassPrim() on the UE FUsdStage wrapper. [Solidworks] Components made from identical parts now reuse exported meshes. When opening USD Stages, only materials bound by at least one prim will be parsed by default. [3ds Max Exporter] Shared exported meshes for RailClone or ForestPack entities now use the same mesh. You can now cancel loading the USD Stage by clicking the \\"X\\" on the dialog to pick the default USD Asset Cache for the project. StaticMesh, SkeletalMesh and GeometryCache assets generated from USD Stages will now have the default material instead as a fallback, instead of fully unassigned material slots. You can now create LevelSequence bindings to transient actors and generated components when opening USD Stages, from any LevelSequence. Those bindings will use the new Sequencer Dynamic Bindings feature to automatically repair themselves whenever they are broken due to the stage being closed or reloaded. Importing skin weight profiles is now significantly faster. [Solidworks] Exploded Views now export for each of configurations as additional variants Changed the translucency lighting mode used by the USD preview surface reference materials to \\"Surface ForwardShading\\", to improve behavior in scenes with multiple translucent objects. [Sketchup] Geolocation information is now exported. Expanded the USD Asset Cache to support persisting Materials, Skeletal Meshes and Static Meshes to disk. [Solidworks] Greatly improved AutoSync reaction time to material changes for bigger models. [Solidworks] Model Tab is now toggled after exporting animation. [Solidworks] Added plugin prerequisites to the installer to support installation on clean machines. The USD Stage Editor now shows internal prim references when selecting a prim. When baking materials to USD, diffuseColor will now bake as black as a fallback to retain the same visual appearance as in UE. Crash Fix: [Solidworks] Fixed crashes caused by enabling AutoSync. Fixed a crash that would occur when changing collapsing rules on the USD Stage Editor in some scenarios. [Solidworks] Fixed a bug that could cause an infinite reimport after deleting a component. Fixed a crash that could occur when importing materials from USD which overrode previously imported materials. [Solidworks] Fixed a crash that could occur when re-enabling DirectLink source. Fixed an crash that could occur when trying to open or import USD Stages with skeleton prims that have more than one root bone. Fix crashes related to Skeletal Mesh Components when importing USD Stages over previously imported actors and assets. Fixed a crash that could occur when exiting the engine during the process of saving USD Stage changes. Fixed a crash that occurred when undoing the addition of transform track keys in some scenarios, such as when manipulating the LevelSequence generated by opening an USD Stage. Fixed a crash that occurred when importing USD files via automated tasks (like Python scripts) with no specified import options. [Rhino] Fixed an export crash that occurred when exporting meshes with multiple UV sets. Fixed a crash that occurred when translating USD point instancer prims with unexpected prims inside their prototypes, when opening or importing USD Stages. Bug Fix: [Solidworks] Actor visibility is now set appropriately in the Datasmith scene tree on export if it's suppressed in the selected config. [Solidworks] Unused materials are now handled correctly in exported scenes. Fixed USD Stage import options that weren't being autofilled from the currently opened stage actor when using the Actions → Import option on the USD Stage Editor. HierarchicalInstancedStaticMeshComponents spawned when translating USD Point Instancer prims will no longer be missing their StaticMesh assets, if the source prototypes were being shared via the USD Asset Cache. USD prim kinds will no longer be ignored when deciding if a prim subtree collapses or not. [Solidworks] Exporter will now install as expected if only version 2023 is available. Fixed an issue that would cause missing Static Mesh Components when importing some types of USD Stages generated by exporting Unreal levels with StaticMesh assets with multiple LODS. Fixed visibility handling issues that occurred when traversing Mesh prims in order to generate Geometry Cache assets when opening or importing USD stages. Switching render context (or other similar options) on the USD Stage Editor options will now update the Static Mesh Components on the level with new material assignments as expected. Exporting levels to USD without any levels selected will no longer generate files. AnimSequence assets generated from USD will no longer fail to drive morph target (blend shape) animations. Setting material overrides on spawned components will no longer write to unexpected USD prims if the Static/SkeletalMesh/GeometryCache asset is shared via an USD Asset Cache. [Revit] Fixed duplicated IDs for Level elements. USD Stage Control Rig integration will no longer fail when using Control Rigs that modify their own topology in their construction scripts. Fixed an issue related to material overrides on components that spawned when opening USD Stages with collapsible subtrees. The mesh vertex count and Nanite material collapsing limits are now checked when collapsing large meshes from USD. Direct link now works when offline. The USD Stage Editor will no longer generate invalid reference or payload paths when adding references or payloads if the target file is near the engine binary. [DatasmithImporter] Fixed a bug that would occur when reimporting DirectLink static mesh with changed material ordering. Fixed an issue related to how material names were being used for texture assets when fully importing stages from USD. [Sketchup] Available SketchUp versions will no longer be disabled in the installer. [Solidworks] Fixed an issue which prevented proper shutdown of Solidworks. Chosen material purpose will now be used when parsing material assignments directly for the generated mesh assets when opening an USD Stage. Fixed a slowdown which occurred when trying to display array attributes with many entries in the USD Stage Editor. [Solidworks] Removed the -1 on spot light scale. UDIM textures will now be parsed from USD Stages as expected. [Solidworks] Fixed a sync/export bug that occurred when the plugin was enabled manually (not on startup). Fixed a bug that could cause the material overrides layer to be empty in some scenarios when exporting levels to USD. Adding and removing USD layers will now automatically reload animations on the generated LevelSequence as expected. Fixed issues related to handling the export of levels to USD with Static or SkeletalMesh assets with multiple LODs, leading to broken references or missing material assignments in some cases. The \\"Save USD Layers\\" dialog will no longer be shown when switching Stage options on the USD Stage Editor. Mesh prims without the SkelBindingAPI will no longer be incorporated into the generated SkeletalMesh assets when opening or importing USD Stages. Groom and Groom Binding assets now import from USD Stages as expected. Using the Actions → Import option to import an opened USD Stage will no longer lead to unexpected results if the chosen import options differ from the options used by the currently attached USD Stage Actor. [Navisworks] Tooltips now appear as expected when docking/undocking plugin UI. Fixed an issue that occurred when exporting Unreal levels to USD. The exporter will no longer fail to retrieve actors when exporting \\"only selected\\", if those actors belong to a sublevel. [Solidworks] Deleted sub-assemblies are now removed from the Datasmith scene on sync. Fixed an issue which could corrupt imported textures settings. GroomBinding assets will now be set on the Groom components when opening USD Stages with Grooms as expected. Animations on the generated LevelSequence will now be refreshed when adding or removing USD sublayers from an opened USD Stage. The landscape material baking process will now generate consistent textures when exporting levels to USD. [Solidworks] Fixed an issue involving Part materials exporting inconsistently in multiple configurations. [Revit] Fixed a Direct Link error associated with the Datasmith Exporter for Revit 2018.3. [Solidworks] Fixed an issue involving the deleting a sub-component of a sub-assembly. USD Stages with animated meshes (that led to Geometry Cache assets being generated) will no longer be left permanently opened in some scenarios. [Solidworks] Fixed a miscalculation involving child components variant transforms. Fixed broken baked material references when exporting USD stages on Linux. The USD Stage Actor will no longer write to the USD Stage when updating component properties on the level even if those properties are bound as tracks on the currently opened Sequencer. Fixed an issue which could cause missing StaticMeshes on HISM components generated when opening or importing USD Stages with point instancer prims with LOD prototypes. Fixed an issue which could cause missing static mesh components when opening or importing USD Stages with Light prims that have child Mesh prims. UsdTransform2d UV transform shader nodes when opening or importing USD stages on Linux will now parse as expected. Actors spawned when importing USD stages via the Actions → Import button on the USD Stage Editor will no longer be marked as transient and disappear when loading into PIE or reloading the level. The USD Stage Editor and UsdStageActor will no longer use an old generated UAsset when a stage option is changed. Deprecated: The FUsdPrim::HasPayload() function was deprecated in favor of HasAuthoredPayloads() to mirror the USD API. [USD Importer] Deprecated the HasAPI() function that takes an optional instance name parameter and replaces it with one- and two-FName parameter overloads that match the one- and two-token counterparts on UsdPrim from the USD API. Framework New: Limited the number of paths reported in changelist descriptions generated by editor collection checkins to 1000. You can control this by setting the Cvar Collections.MaxCLDescriptionPathCount. Added ability to change the importing behavior for assets so that if you import on top of a redirector, you'll instead import on top of the asset that redirector points to. Set the CVar AssetTools.FollowRedirectorsWhenImporting to 1 for this behavior. Added an optional integration with Helix Swarm that provides a way for users to view/post comments from the UE changelist review tool. Crash Fix: Fixed a crash that occurred when copying actors in an editor from before 5.1 and then pasting the actors in a editor newer then 5.1. Fixed crash when duplicating levels that contain a Level Blueprint. Fixed intermittent editor crash when loading certain changes in the changelist review tool. Bug Fix: Fixed missing '#changelist validated' tag when submitting without editing the changelist text. Added bIgnoreEditorOnlyReferences to AssetReferencingPolicySettings in the Asset Reference Restrictions editor plugin. When true (which is the new default), the reference checker will ignore editor-only references to things like editor utility components. Input axis events now forward to the Editor World extension collection and give extensions an opportunity to consume input. Landscape API Change: FMaterialCachedHLSLTree was not updated but already doesn't support the same features as the legacy HLSL material translator (e.g. AllowMultipleCustomOutputs). Code accessing the Landscape GUID identifiers on instanced Landscapes now needs to take into account that instanced Landscapes modify their Landscape GUIDs. If you need the original value from the landscape asset, access it via GetOriginalLandscapeGuid(). New: Added command to dump a report of all landscape grass data currently used on landscape components: grass.DumpGrassData [optional: -csv -fullnames -showempty -detailed -byproxy -bycomponent -bygrasstype -full] Added possibility for UMaterialExpressionCustomOutput to limit the max number of outputs. Displays an error when the material is using more than the max allowed number. Added threshold to dirty landscape textures detection (CVars \\"landscape.DirtyHeightmapThreshold\\" / \\"landscape.DirtyWeightmapThreshold\\") Added CVar landscape.DumpDiffDetails (to be used in conjunction with landscape.DumpHeightmapDiff and landscape.DumpWeightmapDiff) to dump additional details about the diff introduced on a given heightmap/weightmap. Added Include Border to the landscape tool's component brush. Since the border is shared with neighbors, oftentimes the user wants to paint within the bounds of the component but not on the border. Added blueprint getter and setter to WaterMeshOverride. Added a new collision heightfield visualization mode to visualize the chaos material per-vertex. Added the ability to synchronize LOD levels and eliminate geometry seams across adjacent Landscapes, by setting their LOD Group Keys to matching non-zero values. Reworked landscape property sharing and override. Added LandscapeInherited and LandscapeOverridable meta tag to mark shared properties. Enforced synchronicity between shared properties when editing and loading ALandscape and LandscapeStreamingProxy. Created textures with no mipchhain if used in as a layer height or weight. Prevented computing the landscape texture hash twice when it has changed. Multithreaded building of nanite meshes from Landscape geometry Added the ability to store landscape heightmaps in a compressed representation to save disk space, at the expense of slower loading. Enable using landscape.ShowCompressHeightMapsOption to show this option. Build Physical Materials command rebuilds all physical materials Added new CVar to control heightmap detailed change tracking. Split landscape.DirtyHeightmapThreshold into landscape.DirtyHeightmapHeightThreshold and landscape.DirtyHeightmapNormalThreshold. Added a gamma function to the paint tools strength to make more of the slider range useful for painting. Adds Landscape BP Brush visibility layer editing. Added FLandscapeBrushParameters struct that should be used to pass arguments when rendering a layer. Added BP Brush visibility layer toggle in Landscape Editor. Added visibility layer editing for LandscapeCircleHeightPatches and LandscapeTexturePatches. Added helper method to determine if a layer info object name is a visibility layer. Added ability to create multiple nanite components per Landscape Proxy if it has more than 64 components. Added the ability to create multiple copies of a Landscape via Level Instancing. Updated M_ProcGrid material to have nanite enabled. Improvement: Increased the maximum landscape grass type outputs from 18 to 32. Save Modified Landscapes now acts as a way to fix every landscape actor that needs to be updated because of discrepancies. Added viewport message for when Nanite meshes need to be regenerated. The message now indicates the number of landscape proxy actors needing updating. Landscape heightfield now uses unlit vertex color material to better visualize physical materials. Prevented updating water info until after a landscape painting operation is finished. Modified ALandscapeProxy detail panel to reflect how the properties are shared. Modified ELandscapeToolTargetType to be an enum class, usable by blueprints. Bug Fix: Fixed Open World map landscape normals. Prevented all Runtime Virtual Textures from being invalidated when entering landscape mode just because we build a thumbnail material. Disabled Save Modified Landscapes hyperlink in the map check after the action has been executed by the user. Fixed Nanite landscape mesh object names, which were not guaranteed to be unique anymore. Removed RF_Transactional flag from the static mesh since this data is not meant to be transactional. Fixed bad tangent space computations for various landscape utilities. Factorized redundant code in landscape for accessing weightmap/heightmap data. Added CPU traces to LandscapeTrace. Fixed important slowdown when using a landscape brush with a large radius. Fixed Inactive world types interacting with Runtime Virtual Texture that caused changelist validation to create a new virtual texture producer. Fixed visibility weightmaps being generated when using landscape patches. They are now only generated when a patch actually writes visibility. Fixed missing landscape actor in landscape tools for debug visual log. Fixed undo of Nanite-enabled landscape proxy deletion that didn't properly invalidate the Nanite component on redo. Made bEnableNanite and NaniteLODIndex shared properties for landscape proxies so at cook time there is no ambiguity over whether Nanite is enabled or not on a given proxy. Added map checks for when shared properties on proxies are not up-to-date. Fixed ModifiedPackages system in ULandscapeInfo. Changed outer of the Nanite static mesh. Made the NaniteComponent TextExportTransient. Copy and pasting no longer leads to the mesh being shared between actors. Made the NaniteComponent DuplicateTransient. Saving as a map no longer leads to the mesh being shared between packages. Fixed crash when listing textures using the listtextures console command after having deleted a landscape actor. Fixed Landscape Nanite Content Id taking into account the landscape material's StateId, leading to landscape actors being invalidated on 2 branches where the landscape material were not at the same version. Fixed Landscape Nanite static meshes having a non-hash based Guid, leading to new DDC keys being generated when the meshes are invalidated. Fixed navigation data being generated for nothing and being invalidated right after generation when building landscape Nanite meshes. Corrected nanite mesh build not being cancellable when started from Build All Landscape. Fixed rare case of desynchronization between CachedLocalBox and heightmap data. Removed incorrect ULandscapeNaniteComponent from ALandscapeProxy's OwnedComponents upon copy/pasting. Fixed performance issues related to landscape heightfield in show collision mode by using static draw commands. Prevented landscape heightfield collision components being invalidated because of editor throttling. Fixed a crash when copying a water body component in isolation. Spline component was not valid and crashed in PostDuplicate. Fixed landscape component count display in editor when selecting streaming proxies. Corrected water bodies which do not affect the landscape to still search for a landscape. Corrected an issue where newly streamed in water bodies would not render into water info texture. Newly streamed in actors are forcibly hidden until all streaming is complete. Fixed a crash in landscape when it contains null entries in LandscapeComponents. Fixed landscape getting dirty even when the detected difference is lesser than the detection threshold. Fixed landscape heights being incorrect after Sculpt Undo operation. Override PostActorCreated to build WaterInfoMesh properly when spawning an actor using the UWorld::SpawnActor method. Fixed an issue where Landscape Resize was not preserving all relevant landscape settings. Fixed a rare crash when using the Landscape Editing modes. Fixed a crash when alt-dragging or duplicating the landscape gizmo actor. Fixed a crash when updating property permissions outside landscape mode Fixed a crash when adding spline control points to a hidden landscape. Fixed an issue with landscape LOD calculation that sometimes caused Landscape edges to have a higher-than-expected LOD. Fixed a potential overflow security issue importing landscape PNG files. Landscape Streaming Proxies were not being unloaded correctly if painted or sculpted in landscape mode. Fixed a crash when creating multiple landscapes with regions Fixed crashes and other unexpected behavior on Undo after adding a new LayerInfo to a Landscape Layer. Fixed incorrect water velocities with some scalability settings. Fixed an issue with large Instanced Foliage paint brushes taking a very long time when the Radius option is used. Fixed an issue with normal calculations along the edges of landscapes. Fixed a rare crash when double clicking a landscape spline control point tangent box. Fixed a crash when undoing the creation of a landscape. Fixed texture corruption when undoing mask painting back to the first mask paint operation. Deprecated: Removed the baked landscape GI texture system. Removed Render method for BP Brushes, RenderLayer should now be used. Scripting New: Added blueprint functions to convert from classes and soft class references to the TopLevelAssetPath struct used by asset utility functions. Exposed GetClassPathName, GetStructPathName, and GetEnumPathName to Editor Scripting, which return a TopLevelAssetPath containing the type info. For example: unreal.MyClass.static_class().get_class_path_name() unreal.MyStruct.static_struct().get_struct_path_name() unreal.MyEnum.static_enum().get_enum_path_name() Exposed FPlatformTime::Seconds() to scripts in Unreal Editor. Added a function to convert a normal widget blueprint to an editor utility widget. Custom icons can now be configured for Scriptable Tool Blueprints in the Class Settings. The UScriptableInteractiveTool class now exposes a Blueprint-overrideable OnGizmoTransformStateChange event, which is called when a user starts and ends a Gizmo transform interaction, or on undo/redo of such an interaction. Crash Fix: Fixed a crash that would occur when using an Editor Blueprint as the root of another Editor Widget Blueprint. Bug Fix: UE now only generates Python stub code when running full editor. Changed Python remote execution to bind to localhost as the default multicast adapter. UI New: In the Place Actor Window, Volume objects and recently-placed elements are now properly localized. Implemented deep copy for sets in CopySinglePropertyRecursive. Added an Icon extension point to the content browser path view that allows icons to be placed to the right of the item text. The asset auditor now shows the staged sizes of assets if they are present in the asset registry, and also makes sure that tags show the data from the selected asset registry rather than the one in memory. Previously, the size displayed in the asset auditor would be uncompressed data estimated by looking at how much data the cooker output to disk. With the introduction of asset registry writeback (in the project packaging settings), the compressed sizes can be written back to the development asset registry. When viewing such development asset registries, those sizes are now displayed. Added a Browse button to the Level Editor Toolbar. Improved UX around unsupported assets in the Content Browser by removing unnecessary menu options and adding an indicator to the tooltip. SBlueprintActionMenu checkbox text is no longer cut off. Changed the sorting of names in the scene outliner and changelist window to be in natural order, similar to OS file menus. The Content Browser immediately flushes the config on adding/removing a folder from favorites to make sure the action is saved if the editor crashes. In the DataflowGraphEditor, you can press the F key to zoom to fit either the selected nodes or the entire graph. Bug Fix: Opening a texture in the texture viewer now always shows Final encoding. Fixed an issue where the color curve editor wouldn't update when gradient stops were moved. Fixed the gradient preview in the Color Curve Editor. Fixed an issue in the Reference Viewer preventing users from typing the address of non-package paths into the address bar. In the Actor details view, archetype edits that occur while archetype instances are actively selected will now correctly sync the \\"reset to default\\" state. Fixed a typo in FMessageDialog remark. Folder names in the Content Browser now wrap properly with ellipses similar to asset names. Fixed an issue where it was not possible to drag-and-drop below rows that have expanded items. Fixed a drag-and-drop issue for Input Mapping Context that was not moving the element at the desired position. Fixed tooltips that could appear on top of foreground programs. UX API Change: Changed message log action token so it doesn't disappear when the action has been executed, it becomes disabled instead. Visibility is only tied to the action's Execute callback validity now. This affects all actions where CanExecuteAction can return false. New: Added the ability for different verbosities in the Output Log to ignore category filter and always display. Added option to auto select items in revision control revert window to reduce redundant actions for users. Set the asset filter in UAssetToolsImpl::CreateAssetWithDialog. This uses the Factory supported class as a filter for assets in the Save Asset As dialog. Migrated most main menu entries under Edit, Window, and Tools to the newer ToolMenus system. Fixed a typo in the tool for importing glTF files. Removed the Starship Gallery test suite from the editor. It was not designed to run inside the editor and can therefore cause crashes. Sorted the viewport's Perspective > Placed Cameras menu by name to make it easier to use. Improved overflow behavior of text on Notifications by adding ellipses and showing the full text on hover. Reskined the Property Matrix to bring it up to standards with the UE5 style. UX Improvements for the Restore Open Asset Tabs notification that shows up when you launch the editor. These include the notification staying active until you make a choice and the ability to remember your selection in the future. Added a Recent Assets menu to the level editor and all asset editors for quick access to any assets you recently opened. Added an option to the Outliner context menu to bulk edit components in the Property Matrix. Modeling Mode favorites are now saved across editor sessions. Added the ability for modes to add a secondary toolbar below the level editor toolbar to house mode specific tools. Removed user-visible ES31 editor references and replace it with Mobile. Improvement: Closed the suggestion box when using the keyboard shortcut (tilde key, usually) to switch between status bar console input to Output Log console input. Auto-adjusted the editable text box size so the content for long console command is more visible. Optimized a variety of hotspots during the texture build path not associated with encoding the actual image, including decoding of source image and metadata generation. Updated text overflow behavior of the Window > Save Layout > Save Layout As panel. Bug Fix: Adjusted the color to full brightness or opacity when picking from the color wheel/spectrum if it was previously almost black or transparent. Fixed a bug in some tables where header text could drift horizontally relative to row text of the same column. The viewport toolbar now correctly collapses its buttons as needed even on displays that use DPI scaling. Fixed an issue where tab headers would appear to be wiggling when a tab was being closed. Updated tabs in windows separate from the main editor from no longer getting lost when Dock in sidebar is clicked. Fixed a crash on shutdown in the Outliner when an item tried to unregister from the Uncontrolled Changelists module in its destructor after the module was unloaded. Foundation New: Allowed UBT to build individual plugins as though they were local. Introduced Network component to CQ Test. Prevented approved reference images to be copied to html test report for successful test. Introducing Code Quality Test plugin. Extension of the Unreal Engine FAutomationTestBase to provide test fixtures and common automation testing commands. Avoided displaying missing reference when image comparison was successful. Allowed levels to turn off garbage collection clustering so that actors can be deleted. Improvement: UAT addcmdline (RunCommandline) is now passed during launching of application on all platforms, where previously it could be embedded in UECommandLine.txt. It improves iteration times on some platforms as final bundle doesn't need to be rebuilt every time. Crash Fix: Fixed crash when using Automation Wait node in BP when AutomationController is not loaded. Bug Fix: Avoided a crash with Screenshot Functional Tests in PIE client net mode. Build New: Added \\"UnrealInsightsBuildConfiguration\\" option to the BuildAndTestProject build graph so the CompileTools step can build Shipping, Debug, or Development configurations of Unreal Insights. Added the option to throw exception when plugin in DisablePlugins list is enabled by another plugin's dependency. Added EngineIncludeOrderVersion for UE5.3 Made the AutomationTool emit an error code when it terminates on an exception. This will result in failing the operation instead of reporting a false success. BuildUAT.batBuildUBT.bat will suppress all messages from file compare. Added support for Clang PCH chaining: https://clang.llvm.org/docs/PCHInternals.html#chained-precompiled-headers. Added support to compile separate files in VisualStudio using the \\"Compile\\" menu item when you right click on the files. Added flags to CSV metadata for LTO and PG_Instrumentation. LTO will be true if Link Time Optimisation is enabled. PG_Instrumentation will be true if Profile Guided Optimisation is currently in Instrumentation mode for gathering PGO profiling data. This change can be used to show if a particular build was running under these parameters when looking at CSV performance reports. Broke several hidden circular dependencies between engine modules. Improvement: Tweaked the engine PCHs to improve compile times. Improved overall Visual Studio project generation time by updating the UBT code to be thread safe and run in parallel. Bug Fix: Previously the \\"-ini:\\" command line argument may have been ignored when sent to UBT. These will now be applied. Previously when multiple \\"Target\\" command line arguments were passed to UBT, ConfigCache::ReadHierarchy could read arguments from other Target arguments. It will now only read from the intended \\"Target\\" command line argument. Fixed an issue where the public dependencies weren't being added to the include path list. Fixed some random intellisense compile issues. Deprecated: Deprecated TragetInfo::bUseMallocProfiler toggle. It is no longer used as MallocProfiler2 and FMallocProfiler runtime is removed in favor of UnrealInsights. Core API Change: This breaks backward compatibility where WriteToString is used as a type or in a context where it would be copied. Deprecated the FMessageDialog overloads that take the title by-pointer; use the overloads that pass it by-value instead. Rename FInterpCurve::InaccurateFindNearest into FInterpCurve::FindNearest. New: Added additional FPackageName::ObjectPathToX functions: ObjectPathToPathWithinPackage, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"MyAsset:SubObject.AnotherObject\\" ObjectPathToOuterPath, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"/Game/MyAsset.MyAsset:SubObject\\" ObjectPathToSubObjectPath, eg) \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"SubObject.AnotherObject\\" The behavior of ObjectPathToObjectName has been fixed to always return the leaf-most object name within the path (eg, \\"/Game/MyAsset.MyAsset:SubObject.AnotherObject\\" -> \\"AnotherObject\\"). Any code that relied on the old behavior should use ObjectPathToSubObjectPath instead. Added FParkingLot, a framework for building locks and other synchronization primitives, based on WTF::ParkingLot from WebKit Added FMutex, a 1-byte mutex that is neither fair nor recursive, based on WTF::Lock from WebKit Added TUniqueLock and TDynamicUniqueLock, based on std::unique_lock. Added UE_LIFETIMEBOUND macro to TStringBuilder to catch some cases where pointers are kept into temporary string builders. Added -DDC-VerifyFix command to overwrite existing records and values that differ from newly generated records and values when using -DDC-Verify. Added AppendV to TStringBuilder. Converted WriteToString for TStringBuilder from a type to a function. Added FMonotonicTimePoint and FMonotonicTimeSpan as an API for the monotonic clock exposed by FPlatformTime::Cycles64. The PackageStore backend is now used to resolve dependencies for MemQuery requests. ReplicationGraph amortize the cost of dormant Actor cleanup by allowing gathering Actor lists for one connection at a time. Added FManualResetEvent, a 1-byte manual-reset event that is more efficient than FEvent. Added FRecursiveMutex, an 8-byte unfair recursive mutex built on top of ParkingLot, as a drop-in replacement for FCriticalSection. Added MemoryTrace implementation for Linux platform. Added EnvOAuthSecretOverride parameter to Unreal Cloud DDC to allow providing an auth secret in the environment. Refactored ListTexture command to output more data about UTexture derived classes. When AGGRESSIVE_MEMORY_SAVING define is enabled, array slack growth factor will be set to 1.25x factor instead of an old ~1.375x This helps to save memory on platforms with no memory commit on a page fault for large arrays that are allocated directly by a page allocator and it saves memory on all platforms for smaller arrays (typically up to 64KB in size) that are allocated by a higher level allocator like MallocBinned. Added TInstancedStruct to provide a type-safe wrapper for using FInstancedStruct in C++. Added parallel decoding of FCompressedBuffer for targets with editor-only data. Added FEventCount, an event type that provides a mechanism for avoiding a race between waiting and signaling through the use of a signal count token, and that is more efficient than FEvent. Added -ExportBuildOutput command to include outputs in exported derived data builds. Added partial implementation of GetResourceSizeEx for NiagaraComponent and NiagaraSystem. Added a public API for structured log formatting in Logging/StructuredLogFormat.h Added a way to upgrade existing sparse class data. Objects using sparse data can now override the ConformSparseClassDataStruct function to perform a custom upgrade step when loading a BPGC using a sparse data struct that no longer matches its archetype. Added a new setting to CppStandardEngine so this can be controlled separately from the engine module. Made AssetManager require engine use. The engine startup will give a fatal error if the AssetManager is not present. Added ReverseIterate range adapter for reverse-iteration over ranges. Adding ISaveGameSystemModule module, comparable to the platform chunk install module. Example usage added to Windows platform, allowing projects and Windows platform extensions to override the default save system. [PlatformFeatures] SaveGameSystemModule=MySaveModule Replaced enable-if/disable-if overloads with if constexpr blocks. Allow any engine module to access Internal include paths from other modules. Added a CBaseStructureProvider concept for detecting if a type is supported by TBaseStructure. Deleted the concept-checking second template parameter from TStructOnScope, which doesn't work so well with forward-declared types. Added TCallTraits::ConstPointerType overrides for common smart pointer types so that they you can look up a TSmartPtr in a map or set with a TSmartPtr key. Fixed some const incorrectness caused as a fallout. Cooker and SavePackage: Move calls to BeginCacheForCookedPlatformData and ClearCachedCookedPlatformData from SavePackage into the cooker to satisfy the contract that objects do not have Clear called until the Save is completed. Added lifetime-bound annotation to TOptional::Get parameter to catch dangling references when an rvalue argument is bound to an lvalue reference. Upgraded to PROJ 9.1.1 and VS 2022 Added SupportedTargetTypes attribute, allowing for ModuleRules to be marked as supported for only specific TargetTypes (Editor, Game, Client, Server). Added SupportedPlatformGroup attribute, which will resolve to a SupportedPlatform attribute that contains all the platforms in that group. Allow SupportedConfigurations attribute on ModuleRules. Enabled tvOS support for Electra Media Player. Added Engine.ini:[AssetRegistry]:CommandletsUsingAR to identify commandlets that should load the AssetRegistry at startup. Removed legacy hash table locks when collecting garbage as they are no longer used. Added range support for Algo::Partition. Updated MFW's PlayerFacade with reworked handling for playback control and timing for \\"v2 timing\\" players like Electra. Added a UE_REQUIRES macro which replaces the UE_CONSTRAINT* macros and is concept-compatible. Support for project-specific BuildConfiguration.xml and Programs during project file generation. Allow overriding bWarningsAsErrors on a per module basis for Unreal Build Tool. Option to write MSVC SARIF files for any errors and warnings when compiling or analyzing for Unreal Build Tool. Added Fwd.h headers for WeakObjectPtrs. Limited Fastbuild process count. Added support for intrusive TOptional null states. Added intrusive TOptional null states to TFunctionRef and TSharedRef as examples. Moved untracked memory coming from the third party Eigen library into the UE allocators, making it trackable. FInterpCurve::InaccurateFindNearest has been improved. According to the accuracy of the new algorithm result, it has been rename into FInterpCurve::FindNearest. Added Max display to containers in .natvis. Improved comments for UE_DEPRECATED examples, adding examples for class templates and function templates. Added the ability to implement a function override that can decide to force garbage collection if the engine is close to reaching UObject count limit. Allow overriding windows application icon with TargetRules.WindowsPlatform.ApplicationIcon for Unreal Build Tool. UE_FNAME_OUTLINE_NUMBER memory optimization. Added TargetRules.bWarnAboutMonolithicHeadersIncluded to control UE_IS_?. Changed [Get|Set]WrappedUObjectPtrValues to take a flag which says whether the pointer is 'in container' or not. Allow usage of incredibuild on macOS. Allowed TFunction's debugger visualiser to be set at a global level via UE_ENABLE_TFUNCTIONREF_VISUALIZATION. Added FMRSWRecursiveAccessDetector that is zero-initializable, supports upgrading a reader access to a writer access recursively, and destruction from inside an access Added override to the temp directory to a subfolder, and allow specifying a directory to use instead of the default %TMP% in BuildConfiguration.xml for UnrealBuildTool. Added WindowsTargetRules setting to control Inline Function Expansion Level for UnrealBuildTool. Updated support for minimum cpu arch for x64 platforms. Replaces ModuleRules.bUseAVX. MinimumCpuArchitectureX64, valid values are None, AVX, AVX2, & AVX512. Allowed OpenVDB to be enabled via a macro in the .Build.cs rather than hardcoded at a platform level. Shared common THIRD_PARTY_INCLUDES* macro definitions between compilers rather than between platforms. Upgraded msvc preferred version to 17.6-14.36. Allow multiple DPCVars processed in a loop to allow for multiple entries form the command line. Added the option to dump per class UObject counts to log when the maximum number of UObjects limit is reached. Implemented -CookIncludeClass=Class1+Class2+. This allows cooking only packages containing an instance of the given class or classes. This relies on assetregistry dependencies to find all packages that would ordinarily be cooked. Packages found through dependencies that are discovered only during load of their referencer are not guaranteed to be cooked. Used a release channel enum instead of a boolean to check if a toolchain is preview or not, so we can support additional release channels for Unreal Build Tool. Added debugger member expansion to FString, TStringView and FName to allow individual character indexing, and allows the raw char buffer to be accessed from a Referenced String or Name array. Enable deterministic msvc compiles by default for shipping configuration for UnrealBuildTool. Added move semantics and removed other unnecessary TSharedPtr reference count churn to TSlotBase::operator[] declarative syntax. Added ExecuteOnGameThread as a wrapper for FTSTicker::GetCoreTicker. Added UE::Tasks::MakeCompletedTask method that produces an already completed task with given result value. Updated RiderSourceCodeAccess. Added operator to TMap's key iterators. Added key iterator tests. Added UE_LIFETIMEBOUND to bit iterators and bit references to warn when lifetime issues occur (like holding onto an iterator to a temporary bitarray). Added UniqueBy to remove duplicates from a range from a projection to apply to the elements, similar to std::ranges::unique. Added FStringFormatArg to natvis. Added FindFrom function to TBitArray to allow a user to provide a start index when searching for a value. Allow cheat extensions to add bugit logging. Added FTopLevelAssetPathFastLess and FTopLevelAssetPathLexicalLess function objects for performing comparisons on FTopLevelAssetPath. Added serializers for TPagedArray. Added Algo::Includes, based on std::includes. Allow MallocStomp2 allocator to be used in the windows editor. Oodle is now updated to version 2.9.10b Added a checkbox option for PriamryAssetLabels to not include/follow redirectors. Added FCoreDelegates::OnCommandletPreMain and FCoreDelegates::OnCommandletPostMain This allows things to hook in to provide additional initialization or shutdown logic for any commandlet that may be run. Added a way for objects to specify property overrides local to the save context of a package. Added two new commands to UAT: VirtualizeProject - Used to run the virtualization process on an entire project. RehydrateProject - Used to reverse the process on an entire project. Replaced FInstancedStruct versioning implementation to use archive custom versioning. Make serialization symmetrical so struct serialized in cooked builds can be loaded in Editor builds. Added a new Settings parameter to a new FPlatformProcess::GetApplicationSettingsDir function for getting %appdata% in Windows, and HOME in macOS and Linux. Moved #includes around in the shared Engine PCHs so the PCHs are hierarchal. This fixes issues where removing or adding a private module dependency would drastically change compile times because the includes in the PCHs were different. StaticMesh Asset Validation now verifies that an uncooked StaticMesh Asset has valid a LOD0 SourceModel. The virtualize and rehydrate project commandlets now accept the command line parameter '-PackageDir=' limiting the operation to the given directory. FEditorBulkData is now thread safe. Added a new commandline parameter '-LocalOnly' to the 'GeneratePayloadManifest ' commandlet. This new parameter should be used to generate a manifest containing only payloads that are stored locally on disk. Added FindComponentByTag method to Actor class, which returns the first component in an Actor with a given type and tag name. Added support to give actions in UBT \\"weight\\". \\"Weight\\" is an average measurement of how many cores and memory an action uses. Using one core with a normal amount of memory for an action would be a value of 1. Added a simple S3 HTTP client. A new error flow has been introduced. If a payload fails to pull we now block the editor and show the user a dialog allowing them to retry the operation or quit the editor. We no longer allow the editor to continue with missing data due to the danger of corrupting existing packages on disk. A warning is now logged when attempting to virtualize a package with a package version older thanUE 5.0, as the package would need to be re-saved in order for virtualization to work with it. Enabled virtualization on static meshes and audio assets by default rather than being opt in. The commandlet 'ValidateVirtualizedContent' now validates that all virtualized payloads in a project can be found in persistent storage. The previous functionality has been moved to a new commandlet 'CheckForVirtualizedContent'. Updated the logic that determines which dependencies a shared PCH has. This new logic goes through all the includes of the pch header and finds the actual headers and modules used. This creates a smaller list of dependencies than before, which is later used to determine whether it is safe or not for the PCH to be used by other modules. Enabled profile guided optimization support when using Intel ICX compiler 2023.1. Enabled msvc strict conformance mode by default for projects set to BuildSettingsVersion.V4. Added GetPropertyInstanceWithin to CPPStructOps so that classes like FInstancedStruct can have their internal properties reflected by property paths. Improvement: Improved multi-edit behavior of instanced struct instances Editing multiple instanced struct instances will now edit the properties of the common struct of all instances (like object editing), rather than only editing instanced struct instances using the same struct type as the first instance being edited. Always compile engine modules with C++20, unless the platform doesn't support it. Any module that sets bTreatAsEngineModule will be upgraded to c++20 unless it has already overridden it to c++17 Optimized StreamableManager::OnPreGarbageCollection. Optimized TFunctionRef calling, as it can never be null. . Removed FullLoadAndSave; it has been replaced in efficiency by MPCook, and further optimizations (concurrent save, async load) will also exceed it even without MPCook or Incremental Cook. Improved deprecation comments surrounding the use of string conversion types and macros. Improved comments on TBox and TIntRect to indicate how their Intersect, Contains, and IsInside Of functions handle overlaps on their borders. Fixed FVector parameter in TBox::IsInsideOrOnXY. Optimized TChunkedArray::Add for speed. Improved Clamp codegen. Improved Swap codegen. Optimized FScriptMapHelper::FindInternalIndex FScriptSetHelper::FindInternalIndex now returns INDEX_NONE when the user provided index is out of bounds. Crash Fix: Fixed crashes and errors when using OIDC functionality from DesktopPlatform. Fixed a crash after a failed request lookup in the CotF server. Fixed a crash when shutting down the media player. Fixed a crash when duplicating object with a within class in component instance data cache. Fixed crash when doing recursive async loading in the legacy loader. Bug Fix: Updated FPaths::Combine method to work with FStringView. Sparse data properties will be favored if they match the name of a deprecated object property. This allows Blueprints to function when object data is moved to sparse data, and the original object property deprecated. Added a few missing definitions that were preventing \\"Debug Editor\\" builds of projects that disable GC from linking. Fixed structured logging to work with Live Coding. Added ElementType to TSubclassOf. Fixed alignment and thread safety issues in FMallocStomp and TConcurrentLinearAllocator. Fixed error reporting during execution of static destructors to avoid crashing on a destroyed lock. Fixed merging and filtering of partial records in the derived data cache hierarchy. Fixed vtable constructor to UAssetRegistryImpl to invoke the proper base class constructor. Code would asset during a Live Coding session. However, the asset registry does not support live coding. Fixed using the TMap element after removal. Fixed mismatch string formatting argument in SavePackage2. Fixed assert firing in Debug mode when calling FScriptArrayHelper::MoveAssign. Fixed FName == C string bug and added string view comparisons. Fixed FStringView's operator!= which could result in circular overload resolution. Added perfect forwarding of delegate Execute arguments. Added a static assert when casting a non-UObject to an IInterface. Set the chunks of the generated package equal to the chunks of its generator. Fixed a mismatched user-defined copy constructor/assignment operators and their associated bugs. Fixed a potential invalid quote count in CSV parser and added overloaded constructors for move semantics. Fixed TSortedMap's key iterators which didn't compile. Fixed issue where Electra Media Player would return incorrect HDR information after seeks. Made FPlatformProcess::WritePipe use proper UTF-8 conversion rather than truncation. When collecting objects referenced by properties, the property owner object will no longer be excluded and instead the owner of the reference list will be excluded to make sure all references are property exposed to the Garbage Collector. Changed a texture on a material instance will now add the new texture to the material's Garbage Collector cluster. Fixed JsonSerializer output where data loss occured when NumberStrings were being written as numbers, instead of strings. Made ensure conditions likely when !DO_ENSURE. Fixed inverted logic in FBindingObject::IsA<>. Updated GenerateTLH to build and touch the output file with one command, to prevent cases where the .tlh doesn't exist and isn't created. Allow typelib headers to be generated when using the clang compiler, by using the toolchain's compiler to generate them instead. Fixed TBitArray being implicitly constructible from a TBitArray of another allocator to stop accidental dangling references when constructing a const bit iterator with the wrong allocator type. Fixed implicit conversions when comparing or doing bitwise operations between bit arrays with different allocators. Removed 1 extra virtual function call (or more if ArrayDim > 1) from object-based Copy*ScriptVM property functions by having an implementation per property type instead of a top level override, also removing the need for the FSoftObjectPtrProperty::Copy*ScriptVM overloads. Fixed invalid string length handling in FCborReader::ReadNext. Allow AdditionalPlugins for use in multiple projects. Fixed inverted assert conditions in Algo::Heap method. Fixed FThreadSafeCounter64's copy constructor taking FThreadSafeCounter. Automation Tool will now respect specified error level for commandlets. Added a check for invalid counts in FScriptArrayHelper::Resize. Fixed THIRD_PARTY_INCLUDES_END for Clang on Windows. UnrealBuildTool will not pass /Zm unless specifically overridden. Added a check for invalid reserves in TSet. Fixed TMap::FilterByPredicate discarding template arguments in return type. Fixed Clang static analysis false positives in our operator delete overrides by disabling them. Removed redundant Unbind call from TDelegate's destructor. Added guards to stop property size calculation overflowing. Fixed Unreal.natvis to allow container indexing in the debugger. Made FHeightField::FData::Serialize avoid using TArray>, as FBoxFloat3 is immovable and shouldn't be used by movable allocators. Object Handles will be initialized with the actual global UObject array capacity instead of the max UObject count value from ini since the actual array capacity may be larger. Fixed broken bAddDefaultIncludePaths UBT setting. Fixed a GeoReferencing issue where the data files were not found in a sandboxed environment. Fixed incorrect size being reported by TArray's overflow checker. Fixed negative int32 sizes being reported as large uint64 sizes.. Fixed EnumAddFlags and EnumRemoveFlags to not require operators on the enum. Made TIsCharType work with cv-qualified types. Made sure running out of available UObject slots crashes regardless of checks being enabled or not otherwise it will silently result in stomps or out of memory crashes. Added weak pointer to archetype cache to prevent returning stale pointers. FProperty references resolved in PostLoad will now properly add their referenced objects to the bytecode owner UStruct's reference list. Fixed rsca for toolbox 2 0 in rider. Non-nullable object properties should now have a default object value assigned to them in case of serialization errors. Fixed mismatch string formatting argument in core test. Replaced some TArray operator new usage. Fixed a bug that truncated the lost of valid paths when emitting an error about an invalid package name. FMicrosoftPlatformString::Strupr is now consistent with other platform implementation and works with non-null-terminated strings. FScriptMapHelper::Iterator and FScriptSetHelper::Iterator post-increment operators were pre-incrementing. Made BuildU[A|B]T.bat explicitly call the Windows find.exe utility. Fixed DrawDebugCircle to draw correct number of segments. Fixed LLM not setting the program size. Fixed UEngine::DrawOnscreenDebugMessages function which was returning the wrong value. Deprecated: Deprecated the FMessageDialog overloads that take the title by-pointer; use the overloads that pass it by-value instead. Deprecated Engine::FindAndPrintStaleReferencesToObject as it was moved to FReferenceChainSearch. Deprecated Engine::FindAndPrintStaleReferencesToObject and moved PrintStaleReferencesOption to its own file for better compile iterations. Moved FindAndPrintStaleReferencesToObject to ReferenceChainSearch. Deprecated four FBulkData flags that no longer serve any useful purposes: BULKDATA_Unused, BULKDATA_ForceStreamPayload, BULKDATA_SerializeCompressedBitWindow and BULKDATA_BadDataVersion Starting to remove support for delegate policies as they are incompatible with threadsafe delegates. Removed usage of TRemoveConst and deprecated it. Removed the deprecated rebasing Actor and the dependency to the rebasing offset. Deprecated hashing arrays and TCHAR* with GetTypeHash. Deprecated TScriptDelegate. Replaced TModels traits class with TModels_V. Deprecated UE_GC_TRACK_OBJ_AVAILABLE macro and simplified available UObject count tracking. Moved FScriptSetHelper::HasElement and FScriptMapHelper::HasKey to the editor. Removed DISABLE_DEPRECATION macro. Removed UUnsizedIntProperty and UUnsizedUIntProperty which have been broken since the move to FProperties. Removed UE::Core::Private::FWrappedObjectPtr, since it's unnecessary now that we have FObjectPtr. Deprecated TRemoveCV. Replaced TIsTArray trait class with TIsTArray_V. Made ApplicationWillTerminateDelegate thread-safe: deprecated FCoreDelegates::ApplicationWillTerminateDelegate (because thread-safe delegates can't be statically initialised) and added FCoreDelegates::GetApplicationWillTerminateDelegate accessor for a thread-safe delegate. Deprecated global Sort and StableSort functions. They only support an index type of int32 and can produce unexpected/undesirable behavior due to their use of TDereferenceWrapper. Uses of these functions have been replaced with the versions in the Algo namespace. It is no longer possible to virtualize engine content and so the following config file options have been deprecated: Engine:[Core.VirtualizationModule]:FilterEngineContent Engine:[Core.VirtualizationModule]:FilterEnginePluginContent Removed: Removed GIsUCCMakeStandaloneHeaderGenerator since C++ UHT no longer uses engine types. Removed core delegates deprecated in 5.2. Removed the old FTicker that was deprecated in 5.0 Removed EGCOptions::WithClusters to reduce the number of template instance permutations in Garbage Collector code and improve compile times. Dev Tools New: Removed C++ Unreal Header Tool (UHT). Ported C# Unreal Header Tool UhtBuffer to new objects that use ArrayPool. Add non-persistent metadata to the CsvProfiler. By default csv metadata persists between captures which may be problematic if capturing different modes that have specific metadata since prior captures can pollute future ones. This change adds a CSV_NON_PERSISTENT_METADATA macro which sets metadata that is cleared once the current capture ends. [UnrealVS] Added \\"Generate Assembly\\" menu option that asks UBT to compile a single file and generate an assembly file. Upgraded UnrealVS.vsix to version 1.84.3 Added the ability to define new documentation policies and specify a default policy. Added ability in UHT for arrays to be sized using static_cast. Added the Build directory as a location UBT scans for UBT plugins. [PerfReportTool] Added support for date formats and disabling column word wrap. Added the ability to compute a hash from a slice of an array. Modified UHT to not emit unused #define directives. Updated UBT project code analysis to 4.2 and text encoding to 6.0. Added the ability to set the IoHash directly in the file hasher [UnrealBuildTool] Added option to generate assembly files while compiling C++ files. Supported only on MSVC compiler for now. Generated files have the .asm extension and are located in the same Intermediate folder as the corresponding .obj. Added generic double buffer async file reader with the ability to specify buffer sizes. [Horde] Optimizations to Horde storage when dealing with larger data: Added ability to specify buffer size with FileNodeWriter methods CreateAsync and AppendAsync. Added ability to copy a FileNode tree directly into a stream without creating the nodes themselves. When reading data, avoid creating byte[] for the cache if the cache is not enabled. Reduced default read size from 15MB to 1MB when caching isn't enabled. New ReadNodeAsync method that invokes a callback with the data instead of creating the node instance. TreeWriter uses the current packet's full memory buffer size to detect the need to resize indead of the max packet size. New bundle test for the streaming of FileNode directly to a stream. Removed comment and tooltip metadata from shipping builds. Added Apple Silicon native binaries for GitDependencies. Added ErrorIfNotFound option to MoveTask to allow throwing an error if the specified file is not found. This option is disabled by default. Optimized Visual Studio created projects and they are now much smaller. Added validation logic to Unreal Build Tool (UBT) to ensure that plugins do not have dependencies on any plugin that is sealed. [UGS] Error dialogs shown at the end of syncing (unresolved files, files needing deletion etc) are now focused when the UGS window is selected. In addition the UGS taskbar entry flashes before showing these modal dialogs and at the end of the sync to try and get the users attention. Added a new bEnableLibFuzzer option for desktop platforms. Improvement: Improved C# UHT file reads by limiting the buffer size to reduce garbage collection stress. Modified the ComputeAsync hash method to provide a file size hint so it can default to a larger buffer size to improve performance. Modified the ComputeAsync hash method to use the double buffer reader above. Enhanced UHT to be able to parse more C++ attributes. Improved checks for keywords placed in invalid conditional blocks. Crash Fix: Fixed Hot Reload and Live Coding to not bother serializing delegates and bulk data. Delegate serialization was causing asserts with new concurrency checks and could have resulted in crashes in the past. Fixed live coding shutdown to eliminate a crash on exit. [UGS] Disabled \\"Open Project...\\" when right clicking in the main window unless the context menu was opened over a valid tab. This prevents a crash when attempting to open an invalid project. Bug Fix: Fixed Unreal Build Tool (UBT) log event level check that resulted in spam to the logger. Fixed issue where modules that were not currently loaded could prevent live coding from patching modules that were. Fixed issue where using live coding with the Clang compiler would generate \\"unresolved external\\" errors. Live Coding no longer generates errors about object files being missing after a source file is removed from a unity file by live coding. Removed unnecessary iteration in GetMaxEnumValue in UHT. Fixed issue with UBT where the UE_TARGET_NAME isn't the actual target name. This resulted in Hot Reload and Live Coding to no longer work when used with a non-unity build. Fixed C# UHT to allow functions with parameters in WITH_EDITORONLY_DATA blocks. Fixed issue where the check for first header include was not being reported as an actual warning/error. Fixed issue where Live Coding would fail with \\"unresolved external symbols\\" when used with Clang. Fixed Live Coding Console to handle the patching of coroutines. Fixed C# UHT strict documentation tests for function. Fixed an issue with Live Coding where large projects might not have enough memory reserved around libraries preventing patching. Fixed an issue where C# UHT metadata did not issue value change errors in metadata. Fixed an issue in Live Coding preload module support where, if a module name is known but not currently loaded, then the engine would generate a check. Fixed an issue where C# UHT failed to generate an error when an interface function was marked as BlueprintPure. Fixed an issue where UBT failed to detect C# UBT plugins in the game folder. Fixed an issue in C# UHT where, if a structure referenced itself, then it would end up in an infinite loop. Fixed a rare threading crash when starting UnrealPak. Fixed an issue where, if Unreal Header Tool (UHT) export code threw an exception, the build did not display the error message or fail the build. Fixed UHT issue where invalid code would be generated if all FieldNotify properties in a class were marked as editor-only data. Deprecated: [UnrealFrontend] Disabled old Profiler (UnrealFrontend/SessionFrontend/Profiler). Old Profiler was deprecated in UE 5.0. Use Trace/UnrealInsights instead. Added UE_DEPRECATED_PROFILER_ENABLED global define toggle. This is off by default. This allows you to temporarily re-enable Profiler if needed; see UnrealFrontend.Target.cs. Profiler module/code will be removed in a future UE version. Removed: [UnrealFrontend] Removed the deprecated MEMORYDUMP run command. Insights New: Added FInstallBundleSuppressAnalytics class to help suppress install bundle analytics that avoid spamming during a specific bulk operator. Enabled Unreal Trace Server for all platforms. Unreal Trace Server now supports all desktop platforms (Win64, Mac, Linux). Precompiled binaries are now included for Linux and Mac. This removes the need to run Unreal Insights program when tracing on those platforms. Added user interface for displaying connection status to trace store. Added logic to re-connect when the connection to the store server is lost. Added user facing message events in TraceLog. Previously, errors in TraceLog would silently stop traces without any information to the user. This adds a way to receive those messages and log them using regular engine logging. The new session id is now used when requesting a process current trace session. This resolves the issue with getting the current session, when the machine has many live sessions running at the same time. Added persistent settings for Unreal Trace Server which allows setting changes to be retained after restart. Settings can be changed without restarting the server. Added UE_TRACE_METADATA_RESTORE_SCOPE(MetadataId) macro. Added alloc event callstack id and free event callstack id in tooltip of the Callstack column for Memory Insights. Added a package field to the asset metadata scope, in addition to the existing asset name and object class fields. Added the \\"screenshot\\" trace channel to the \\"default\\" channel preset. Symbol resolving now automatically tries to remap known packaged renamed binaries to their original filename. xmake is now used for building Unreal Trace Server on all platforms. Added LLM tracking for TraceLog memory usage. Made TimingView.AutoScroll option persistent in ini file for Timing Insights. In Timing View, when Ctrl is pressed while clicking an event to be selected, the time interval that includes both the old selected event (if any) and the new selected event will be also selected. Added \\"Project Name\\", \\"Other Metadata\\" info, if available and added \\"TraceId\\" as an optional metadata. Added FD3D12Adapter::TraceMemoryAllocation and D3D12PoolAllocator to resolved symbols filter in Memory Insights. Added support for unlimited number of heap specs in Memory Insights. Previously, it was limited to 256 heap specs. All trace files now contain a metadata field with a session id and a globally unique trace id. Session id can be set from the command line to group session from many machines together. If no session id is specified a random one is generated. Memory Insights / Mem Allocs table: - Improved the status bar text display of query info, query status, number of allocs and added number of filtered allocs. Added status bar text info for selected items (including the total alloc count and total mem size of selected items). Added tracing for the existing \\"Stats_GPU_*\\" float counters when \\"stats\\" trace channel is enabled. Added project field in session info event, separate from the app name. Previously we used project name rather than app name if it was available. Added Get*ProviderName public API for all providers. Refactored the IModule derived classes to ensure consistent implementation. Tree Table View improvements: Increased font size and updated text colors (ex.: when tree node is hovered/selected/filtered). Added default icons and colors for tree nodes. Added custom color for group nodes created by Callstack and Tags groupings. Clip tracing of asset loading debug name to 1024 characters. Updated Unreal Insights version to 1.04. Memory Insights: Added option to include heap allocs in mem queries. Memory Insights: Added analysis support for NeverFrees heaps. Added limit for the number of log warnings generated. Added EnterScope_TB / LeaveScope_TB (timestamps relative to BaseTimestamp) events ans to EnterScope_TA / LeaveScope_TA (absolute timestamps). Network insights - Modified filtering to include sub-events when filtering packet content events. Added delta time display of selected range of packets. Filtering now supports using filter by NetId and EventType in combination, which is useful to highlight specific events for a specific instance. Improvement: Users can now change store settings in Unreal Insights. Currently the user can change: Store directory: The directory where new traces are stored. Watch directories: A set of directories monitored for trace files. For example users can add their download folder and automatically see downloaded traces in the session browser. Optimization: Refactored the IProvider / IEditableProvider interface for Trace Services to avoid diamond problem. Crash Fix: Fixed crash in Frames track when there are no frame series created yet. Bug Fix: Fixed a deadlock that occured when stopping a trace with the \\"Open Trace in Insights\\" option enabled. Avoid locking TraceAuxilliary destination and connection type while issuing delegates. Restored Uri functionality for traces (backward compatibility with current/older UTS). Disabled a trace session after it was renamed, until the trace id is properly updated the trace name changes color to grey. Fixed focus for the trace sessions list (initial focus and after renaming a trace). Improved Session Browser UI responsiveness when using a remote/slow trace store connection. Fixed opening a trace from a remote trace store. The new UnrealInsights process is launched by specifying the store address in addition to store port. The trace id can now be specified as hex number (prefixed by 0x). Return allocator result in the case of zero sized allocations. Remove checks for zero sized allocations in Trace's allocation wrappers leaving it to the allocator implementation to decide. Analysis already supports zero sized allocations (as long as they have unique addresses). Fixed late connect for the Counters trace channel. Changed TraceAuxilliary internal management of tracing status and trace destination. Tree Views for Allocs Table, Tasks, Packages now have Separated tree view node filtering by hierarchy filtering. The order of async operations was changed. Node filtering (i.e. advanced filtering using the Filter Configurator) is applied first. Then grouping + aggregation is applied. Then sorting is applied. Finally, the hierarchy filtering (i.e. text search) is applied. This enables text search (hierarchy filtering) and advanced filtering (node filtering) to be used in the same time. Also, the aggregation is now applied only once. These changes enables significant performance improvements for the tree operations, especially when node filtering is applied. Disabled Rename/Delete trace files when using a remote trace server. Fixed updating the list of traces. If list is scrolled on bottom it will remain scrolled on bottom also when new traces are added. Fixed initial channels example (including a typo) and usage of \\"default\\" preset to include \\"region\\" and \\"screenshot\\" channels (Connection tab). Fixed trace recorder IP address to be prefilled with correct IP or host name of (remote) trace server (Connection tab). Trace store uses entire path for id. Only using the stem hides files with the same name present in multiple mounts. Fixed a missing check to make sure the entire packet was sent. This guards against any low level transmission errors. Updated Unreal Trace Servers readme to reflect dynamic ports used. Fixed missing channel check for metadata restore scopes. Fixed Trace.Screenshot not working when not running PIE or simulation. Fixed realloc scopes for the video memory allocations. Previously only realloc scopes for system memory were supported. Fixed late connect support for the \\"stats\\" trace channel. Changed the batch trace event to always start with an absolute timestamp value (instead of being relative to previous event). Reduced the overhead of stats tracing when the \\"stats\\" channel is not enabled. Fixed memory tracing for block allocators used by TConcurrentLinearAllocator ,FOsAllocator, FAlignedAllocatorInternal, and FOutputDeviceLinearAllocator's block allocator. Fix to try to update symbol search path until module provider is created. Previously the symbol search path string was updated only whenever the panel was reset, which doesn't always correspond to when the module provider was created, leaving the string blank until the panel was recreated. Counters: Fixed \\"Export Values/Operations\\" incorrectly saving all values/ops for selected counter even if a timing selection is made in the Timing View. Counters: Added name of the selected counter in the default filename when exporting values/ops. Changed zoom in and out with mouse wheel to auto-pin the hovered track in the Timing View. When opening the profiling directory from the Insights Status Bar Widget, the folder will be created if it does not exist. Fixed trace analysis for scoped trace events. Added explicit support for counters with dynamic name. Added support for hierarchical Clear and Restore scopes. The Clear/Restore scopes replaces the current metadata stack with an empty/saved metadata stack and restores the previous metadata stack at the end of scope. Fixed scope of metadata and mem tag for mem allocations made by the trace system (extends scope over the original allocator calls). So, heap allocations will inherit same \\"trace\\" tag. Fixes for traced metadata scopes applied in tasks. Fixed log messages in memory analysis regarding TagTracker errors when memalloc channel is not enabled. Fixed time for scoped events to be relative to base timestamp at runtime. This allows packing on 8 bytes (as in trace protocol 5). Level streaming profiling is now disabled on the server by default. Deprecated: Removed RenderCore's FTracingProfiler which is deprecated since UE 4.26. Please use Trace system and Unreal Insights instead. Added UE_STATS_MEMORY_PROFILER_ENABLED to toggle on/off code related to MemoryProfiler in STATS system. It still requires STATS to be enabled and \\"-MemoryProfiler\\" to be specified in cmd line. This is off by default as MemoryProfiler in STATS system functionality is deprecated in UE 5.3. For memory profiling, use instead Trace/MemoryInsights and/or LLM. Removed the deprecated MemoryProfiler runtime: Removed the deprecated MemoryProfiler2 tool. Use Unreal Insights (Memory Insights; -trace=memory) instead. Removed: Removed usage of MessageLog on analysis thread. With this change direct usage of MessageLog in the analysis engine is replaced with a callback system which allows the user of TraceAnalysis to implement display of the messages themselves. Framework New: Moved all FInstancedStruct code that depends on the Engine module into a new StructUtilsEngine module. This allows modules that can't depend on the Engine to use FInstancedStruct. Added nested containers support to PropertyBag (TArray>) with a max depth of two. Added a DisallowedPlugins list that restricts which plugins can be used. Added an experimental Plugin Reference Viewer tool that displays a plugins dependency graph. The experimental tool is disabled by default. You can enable the PluginReferenceViewer Access tool from the plugin browser window. Added a new 'Sealed' plugin concept that will prevent other plugins from depending on a plugin. Fixed an issue that would result in broken package references when creating new plugins using a plugin template that contains assets. Added a NoCode plugin descriptor property that prevents a plugin from containing any code or modules. Added a plugin template subfolder property to define the sub folder a new plugin will be created within. Fixed an issue where creating a new plugin that could sometimes fail if the asset register scan is still pending during the plugin creation. AI New: Added the experimental plugin Learning Agents. Learning Agents allows you to train AI characters using machine learning. This enables you to augment or replace traditional game AI, such as those written with behavior trees or state machines. In particular, the plugin allows you to use reinforcement and imitation learning approaches. In the long term, Learning Agents aims to be useful in a range of applications, including physics-based animations, game-playing NPCs, and automated QA testing. Converted AI-related Asset Actions to Asset Definitions. This applies to State Trees, Behavior Tree, Blackboards, and Environment Queries. Bug Fix: Fixed an issue where ZoneGraph would automatically build when the Build Zone Graph While Editing flag was enabled in Project Settings. Deprecated: Deprecated UAvoidanceManager::bAutoPurceOutdatedObjects. Please use bAutoPurgeOutdatedObjects instead. AI Behavior Trees New: Add a Default Blackboard config option for Behavior Trees. Exposed Behavior Tree Editor functionality to be inheritable and accessible from other modules. Also introduced some smaller Behavior Tree Editor UX improvements. Added a tooltip to the Behavior Tree context menu node descriptions. Crash Fix: Fixed an issue where setting the KeyType to None in the base class of UBlackboardKeyType_Object would cause a crash. Bug Fix: Fixed an issue where the BehaviorTreeEditorModule custom Toolbar Extenders were not being applied correctly. AI Debugging New: A newly created row in VisualLogger will now be hidden if all added items are filtered out by category verbosity. Improvement: DebugDrawService now uses synchronization objects for delegate unregistration to prevent RecreateRenderState_Concurrent from registering and unregistering delegates from multiple threads. Bug Fix: Fixed the position of the debug text for UE_VLOG_OBOX. AI Navigation API Change: FZoneGraphPathFilter now has an optional fourth FZoneGraphTagFilter parameter in its constructor. New: Added FZoneGraphTagFilter to FZoneGraphPathFilter so that FZoneGraphAStarNode can perform pathing requests using a given tag filter. Fixed UZoneGraphTestingComponent to properly use QueryFilter when performing a pathing request. The oversized dirty area warnings now work with active tile generation (including Navigation Invokers). This fixes multiple unnecessary warnings when dirty areas are not touching the active tiles. Added AgentMaxStepHeight to FNavMeshResolutionParam. Added a display message when the Navigation Mesh version is compatible, but not the latest. Added Navigation Invoker priorities (ENavigationInvokerPriority). Fixed an issue where using LazyModifiersGathering by reading the resolution after GatherNavigationDataGeometry resulted in an Navigation Mesh resolution issue. Added a task count and task wait time per layer to the CSV Profiler. Added a log category and logs detailing invoker registration to LogNavInvokers. Added a NavInvokers CSV category and track invokers count in CSV to the CSV Profiler. Added tile generation history and stats when LogNavigationHistory is set to Log. Increased the height where the Navigation Mesh can generate (now using 29 bits instead of 15, allowing 26000 km of altitude when using 5 cm CellHeight). Changed rcCompactSpan to use rcSpanUInt for y. Bumped the priority of dirty tiles near Navigation Invokers when sorting by invokers priority. Added support for Geometry Collections in UNavModifierComponent. Before this change, a UNavModifierComponent on a Geometry Collection would not find the physics for the proxy mesh and fallback on an arbitrary FailsafeExtent. Added support for Navigation Mesh resolution when doing async navdata gathering. Added a console variable to toggle Navigation Mesh resolution. Added NavMeshResolution to UNavModifierComponent. Renamed the navigation console commands prefix from n. to ai.nav. Improvement: Added Navigation Mesh generation optimization when using it with Hierarchical Instanced Static Meshes. This avoids gathering unnecessary geometry when building tiles. Added optimizations to UHierarchicalInstancedStaticMeshComponent::GetOverlappingBoxTransforms. Crash Fix: Fixed an issue where modifying the NavigationRelevantData array during garbage collection (when FRecastTileGenerator::AddReferencedObjects is called) would result in a crash. The change moves emptying NavigationRelevantData to the main thread so that it does not occur at any moment. Bug Fix: Fixed a memory leak in FNavigationOctreeElement operator and added move operators. Fixed an issue that would result in a crash if there was no Navigation System. Fixed an issue in UGeometryCollectionComponent where the bIsDynamicObstacle flag from UNavCollisionBase was not taken into account when exporting UGeometryCollectionComponent. Made UWaterMeshComponent not navigation relevant. This fixed an issue with hundreds of Navigation Mesh tiles being dirtied when adding a UWaterMeshComponent. Fixed an issue where building navigation when there was nowhere to build caused reduced editor performance. Fixed an issue when using the async flag where saving files using source control in WorldPartitionNavigationDataBuilder would cause an error. This fixes the \\"MarkForAdd, Error: Failed mark the file\\" issue that could occur during build. Fixed Navigation Mesh holes on steep slopes caused by a rasterization issue (this also fixes Navigation Mesh issues in stairs). Also added the ai.nav.EnableSpanHeightRasterizationFix console command to disable the fix if needed. Fixed an issue that would result in memory corruption from FRecastTileGenerator::MarkDynamicAreas. Fixed an issue where using SAVE_Async would not wait for async file writes before adding packages to source control. AI Smart Objects New: Moved registration to BeginPlay and unregistration to EndPlay for components used in a Game world. This will allow conditions to rely on a fully initialized Actor in case they need to access other components. It will also make it easier to spawn an Actor with a SmartObject component and set up its definition before finishing the spawning. Added new methods to the API to filter a list of request results or slot handles by evaluating the selection preconditions. Filter methods can accept external data as a struct with properties whose name and type match the WolrdConditionContext. FSmartObjectUserContext has been introduced to cover the common case of passing in a user Actor to the context. UserDescriptor is now stored as an instanced struct in the runtime slot. Claim methods now receive a user descriptor. Removed slot event delegate and reused the runtime instance one instead. Listeners can now filter for a given slot using Event.SlotHandle. Removed User Tags from the SmartObjectWorldConditionSchema. The User Tags are part of the query filter. Conditions requiring User Tags could fetch them from the Actors passed in the context. Public methods relying on EvaluateConditionsForFiltering now validate that the Slot Handle is set and not stale. In such a case, a log message will be emitted that suggests to the user to call IsSmartObjectSlotValid to handle that scenario on the call site and avoid the log. Added IsBoundToSimulation to the SmartObjectComponent to differentiate a registered component (valid Handle) from a registered component bound to the simulation (linked to its runtime instance). Added unit tests for IsBoundToSimulation, RemoveComponentFromSimulation, and UnregisterSmartObject sequence to simulate the EndPlay issue. Removed dependency on MassEntity to store slots. A new icon is now used for SmartObjectPersistentCollection, SmartObjectComponent and SmartObjectDefinition. Improvement: Improved Blueprint integration with the Smart Objects subsystem. Deprecated the pure version of FindSmartObjects and added a new non-pure Blueprint wrapper that allows proper iteration of the returned objects. Changed the subclass parameters to use values instead of const references to allow direct selection on class pins. Bug Fix: Fixed an issue with container removal where removing multiple sequential entries in a batch would result in improper recomputed bounds. RemoveComponentFromSimulation is now properly unbinding the component. Unbinding a component from the simulation won't invalidate the registered handle anymore; this is handled by the FSmartObjectContainer. Removed obsolete RuntimeCreatedEntries which was replaced by the registration type. DebugUnregisterAllSmartObjects will no longer cause an ensure when calling EndPlay with the previous fixes. AI State Tree New: Added the ability to disable States and Tasks. In addition, it is now possible to force a condition result to true / false. Improvement: Improved the way that property names are reconciled when they change. Added PropertyGuid to FStateTreePropertyPathSegment to allow reconciliation. Changed Blueprint class and User Defined Struct property names. Changed FStateTreePropertyPath to optionally handle property redirects and BP/UDS name changes. Renamed UpdateInstanceStructsFromValue to UpdateSegmentsFromValue to better reflect its use. Improved State Tree editor bindings to update when BP/UDS properties are changed. Bug Fix: Fixed an issue that would result in ID clashes when duplicating transactions. In addition, added several editor fixes. API New: The plugin manager can now find plugins using a plugin descriptor. Instance static mesh components API improvements. Added array view version of batching transform updates. Added option for passing sorted array to removal function. Audio New: Added a function to override the runtime format in FSoundWaveData. [Audio Modulation] Added AD Envelope Generator. This is useful for temporarily modifying the volume of a control bus. [MetaSound] Added support for integral underlying types to TEnum. Added Deactivate All Bus Mixes BP function. This is useful to clear out all active mixes when changing game state. [MetaSound] Added the ListenerOrientation and SourceOrientation parameter interfaces. The WaveTable plugin now supports fidelity and performance tuning and a more intuitive data usage mode for sampling and granulating. Added Runtime MetaSound Builder to support building MetaSounds via code or Blueprint and auditioning in the MetaSound DSP graph in real-time. Added functions to SynthComponent for setting pre-sends and post-sends for AudioBuses and SourceBuses. Improvement: The IsSeekable method in USoundWave is now virtual. You can now get the values of non-audio outputs of playing MetaSound Sources. See UMetaSoundOutputSubsystem for more information. Added Modulation Destinations to the Synth Component. [MetaSound] TVertexAnalyzerForwardValue now remembers LastValue to prevent unnecessary data pushes. [MetaSound] Added support for passing parameters. Changed the address of audio parameter transmitters from using AudioComponentID to a hash derived from NodeWaveInstanceHash, PlayOrder, and the Component ID. WaveTableBanks now support serialization as 16-bit assets and perform runtime bit-depth conversions where necessary. Abstracted the Waveform Editor toolset into a utility collection to be used as generic sample sequence display tools. Refactored Waveform Editor Widgets to remove the use of RenderData. You can now re-import assets within the Waveform Editor. Audio inputs now use WASAPI for device management on Windows operating systems. [Sound Cues] When Override Attenuation is selected, Attenuation Settings will now gray out to better communicate the override. Added a NumRepeats field to the TriggerRepeat MetaSound node. Crash Fix: Fixed a crash that would occur when reimporting an audio file over a Sound Wave marked as Ambisonic. Fixed a crash that would occur when importing audio files. Bug Fix: [MetaSound] TVertexAnalyzerForwardValue now initializes LastValue on first execution as expected. Fixed a bug where logging the default audio settings displayed 0 for max channels. [Audio Modulation] Added a missing tooltip on the Control Bus Mix Stage Value parameter. [Audio Modulation] Fixed a bug where Audio Component Modulation ignored inheritance from SoundWave. [MetaSound] TVertexInterfaceGroup's variadic constructor arguments are ensured to be move-constructible to the group's base type. Fixed a bug where a member could share a name with an existing namespace member already on the parent MetaSound Source. [MetaSound] The WavePlayer node will now immediately fire OnFinished if no WaveAsset is passed in. Wave file metadata chunks will now be preserved in USoundWave assets when converting bit depth of the source file. Fixed an issue with bus and submix sends on muted Sound Waves. Fixed a miscalculation related to a WaveTableBank's entry tail percent. [Sound Cues] Fixed a divide by zero bug in the Enveloper node. Fixed a bug that would cause audio to not play in sequences when cooked audio is referenced in the current level. Deprecated: Deprecated the Steam Audio Plugin. Deprecated the Modulator parameter on the Modulation Destination Settings. Blueprint New: Added facility to make explicit and validate UBlueprint and UBlueprintGeneratedClass subclasses. Subclasses can publish their mappings from the methods: IKismetCompilerInterface::OverrideBPTypeForClass, IKismetCompilerInterface::OverrideBPTypeForClassInEditor, and IKismetCompilerInterface::OverrideBPGCTypeForBPType. Blueprint functions that take parameters by reference no longer require Blueprints that call the function to connect the pin corresponding to the parameter(s) that are passed by reference. This makes it easier to toggle a Blueprint parameter to be passed by reference. Linear Color ToHex is now exposed to Blueprint. Added a Blueprint callable function to shuffle an array using a 'random stream' for the source of randomness. Added gather search data for BlueprintExtensions. This is used by the FindInBlueprint system. Crash Fix: Fixed potential crash when bFavorPureCastNodes is enabled. Bug Fix: Fixed a typo in the FGraphNodeCreator class description. Fixed the asset loader to preserve component transform in the editor after a Blueprint has been reparented. Fixed a bug that could cause sparse class data to be lost on load after reparenting a Blueprint. Fixed a bug that prevented you from moving a Blueprint to a location that has a redirector that points to a Blueprint. This can often happen if you move a Blueprint then attempt to move it back. Both Find-in-Blueprint and Blueprint namespace asset discovery are now deferred until after the initial asset registry file scan is complete. Soft class objects are now included in a cooked set When using CookSettings.SkipOnlyEditorOnly assets referenced by Blueprint bytecode. Blueprint Compiler Improvement: Improved redirect support for Blueprints. A reflected Blueprint type can now be changed without breaking existing content, so long as an autocast function exists for the two types. Crash Fix: Fixed a rare crash during Blueprint compilation after removing a variable from a component and compiling. The compiler was delta serializing against an archetype of a different type. Fixed a crash when a skeleton class's CDO is accessed when the native class its based on is using sparse class data. Bug Fix: Improved handling for variables that were moved out of a class and into the corresponding sparse class data. Stale DelegateSignatureGraphs are now removed before compiling, child Blueprints no longer improperly mutate their parent's delegate properties. ExpandEnumAsExecs now always uses first Exec if an argument name matches Enum value (resubmit) ExpandEnumAsExecs was using an ambiguous pin lookup. Fixed erroneous deprecation of BreakVector3f for float-based math functions. Fixed a bug in Blueprint compilation that occurred when a Blueprint was recompiled when it had garbage subclasses. Fixed references to trashed function objects after generating delegate properties during a batched Blueprint asset compile with inter-batch dependencies. Avoid potential collisions with existing non-transient objects when creating transient event stub graph artifacts during Blueprint ubergraph compilation. Removed: Removed HasNativeBreak from FVector3f. Blueprint Editor New: Added the ability to mark custom events as private. Added default FunctionFlags values that custom events would need for specifiers. Modified the UI to show the access specifier drop down for both function entry nodes and custom events. By default, the editor will no longer mark outer level/OFPA assets as dirty when propagating default value changes to instances that already match the archetype's value. Instances will still be marked dirty if the default value change results in the instance value becoming realigned with the archetype. Added new Blueprint editor settings to control how assets selected in the Content Browser will generate pre-bound actions when invoking the Blueprint graph context menu. The default settings now disable this feature in order to improve menu responsiveness. By default, the editor will no longer mark an outer level/OFPA asset as dirty after manually compiling its underlying Blueprint type. Non-blocking context menu UI mode is now enabled by default in the Blueprint graph editor. Improvement: Optimized async Blueprint context menu building by avoiding resorting and inserting nodes in the desired order. Improved performance of Blueprint debugger by only populating the children of visible properties and not recursing further. Crash Fix: Fixed crash in SGraphPin::GetPinLabel after removing pins from a node. Fixed crash when compiling a Blueprint after invoking Undo in the editor. Fixed an editor crash when editing sparse class data fields in Blueprint class defaults. Bug Fix: Reduced the amount of graph refreshes performed in the Blueprint editor, reducing hitching and flickering when making changes in the Blueprint graph editor. Fixed Private and Protected functions from not displaying in the context menu in child Blueprints. Fixed bug that would cause properties in an object's sparse class data to not display as altered in the diff panel, even if they had been altered. Fixed malformed asset resulting from duplicating a Blueprint with sparse class data. Fixed variables that are dragged and dropped to the node with split struct pins from not being added. Fixed issue where disconnecting an orphan pin would cause ensure to trigger due to an invalidated graph pin. Fixed the potential for data loss when loading hierarchical Blueprint class assets with circular dependencies asynchronously in the editor. Fixed the Blueprint Namespace entry widget's tree view from not working properly when only one root item matches the search box filter text. Dragging new connections from interface(output)->object(input) will now include an explicit autocast node. Additionally, it is no longer possible to connect an array of interfaces output pin to a function call node's Target input pin. These changes apply to new connections only; existing connections will continue to work as before. Fixed a bug that prevented copy pasted Actor Components from being removed. Deferred validation of user-defined struct types in the pin type selector list until selection time for the member variable type widget in the user-defined struct asset editor. Invocation of the pin type selector menu for member variables is now a bit faster as a result. The editor will no longer orphan pins during Blueprint graph node fixup if they are linked to an autocast or other implicit conversion node that supercedes the original link. Avoided unnecessary serialization of editor-only references at cook time when analyzing Blueprint assets for external imports. Relocated where we purge stale references from the Blueprint editor's MRU document list in order to avoid attempts to resolve those paths during asynchronous asset loads. Blueprint Runtime Improvement: Optimized UUserDefinedStruct::InitializeStruct by avoiding redundant operations for STRUCT_IsPlainOldData macro instances. Bug Fix: Fixed a memory scribble when constructing struct literals with bitfields. Added runtime capacity checks to Blueprint-facing script container library API to mitigate crashes due to integer type overflow. Fixed a bug that caused circular component attachments when changing the constructor of native classes. Gameplay API Change: It is now safe to call Super::ActivateAbility in a child class. Previously, it would call CommitAbility. This will make it a little easier to write triggers/modifiers in Enhanced Input that want to access the Local Player if they want access to the User Settings object to check aim sensitivity or other things. This is useful piece of state for games to use during pawn initialization. Commands are prefixed with AbilitySystem. GameplayTagQueries that are empty are ambiguous and should be handled on a case-by-case basis by the caller. We can go back to the old way of loading the source texture if this breaks something with the \\"Paper2d.DisableSyncLoadInEditor\\" CVar flag. passing nullptr into SDetailsViewBase::HighlightProperty no longer does nothing and will instead un-highlight all properties This is a critical fix if you are attempting to use the input device subsystem. New: Added an option to a Targeting System's AOE Targeting Task to offset based on relative space rather than world space. Moved TargetingSubsystem functions into the same metadata category. Added ULocalPlayerSaveGame base class to the engine that provides utility functions for saving and loading a save game object for a specific Local Player. This wraps the existing save/load logic on GameplayStatics and provides functionality needed to properly support save/load on non-PC platforms. OnAvatarSet is now called on the primary instance instead of the CDO for instanced per Actor Gameplay Abilities. Added the source location of the AOE task trace as the TraceStart of any FHitResult returned by that task so users have that information available after targeting. Input slots now support enum ranges. Updated enhanced input settings to allow deferral of settings updates. MatchAnyTags, MatchAllTags, and MatchNoTags tag queries now have exposed make nodes in Blueprint. Marked UTargetingTask as Abstract so it can't be chosen for EditInlineNew properties. Added Data Store for Collision parameters used by the AOE targeting Task. Added hook to override collision data from the data store in the AOE Targeting Task. Exposed Async Task in the Perform Targeting node so we can get the Targeting Handle before get targeting results. Added GetPlatformUserIndex function to LocalPlayer and fixed comments to explain the different indices. Expanded AInfo's constructor to support a default ObjectInitializer parameter, covering cases where derived classes could override the default constructor and miss AInfo-specific initialization. Allow both Activate Ability and Activate Ability From Event in the same Gameplay Ability Graph. AnimTask_PlayMontageAndWait now has a toggle to allow Completed and Interrupted after a BlendOut event. Post-process settings from camera shakes and camera animations are now handled as overrides, rather than base world values. Added aspect ratio axis constraint override on camera components. Added a GetOwningLocalPlayer function to the UPlayerInput class. GAS: Added a GameplayTagQuery field to FGameplayTagRequirements to enable more complex requirements to be specified. Added a ReceivedPlayerController function to UPlayer, called from it's owning Player Controller when the owning APlayerController pointer is now valid on that player. Alongside this, add a \\"OnPlayerControllerChanged\\" delegate to ULocalPlayer and Local Player Subsystems for an easy hook in. Introduced FGameplayEffectQuery::SourceAggregateTagQuery to augment SourceTagQuery. GAS: ModMagnitudeCalc wrapper functions have been declared const. Marked all exec pins as advanced view on Input Action event nodes except for \\"Triggered\\". Added continuous Input Injection to Enhanced Input. Added support for setting AllowedTypes on FPrimaryAssetId function parameters. To use this, add UPARAM(meta = (AllowedTypes = \\"SomeAssetType\\")) to a parameter. Added EKeys::AnyKey support to Enhanced Input. GAS: Extended the functonality to execute and cancel Gameplay Abilities & Gameplay Effects from a console command. Added the ability to perform an \\"Audit\\" on Gameplay Ability Blueprints that will show information on how they're developed and intended to be used. FGameplayTagQuery::Matches now returns false for empty queries. Exposed FDateTime's To/From Unix Timestamp functions to Blueprints. Added support for properly replicating different types of FGameplayEffectContext. Updated FGameplayAttribute::PostSerialize to mark the contained attribute as a searchable name. FGameplayEffectContextHandle will now check if data is valid before retrieving \\"Actors\\". Retain rotation for Gameplay Ability System Target Data LocationInfo. Gameplay Ability System now stops searching for PC only if a valid PC is found. Updated GetAbilitySystemComponent to default parameter to Self. When diffing assets, their detail panels now have colored highlights signifying the changed properties. Updated the comments on the Enhanced Action Key Mapping and the Input Action asset to be explict about the order of which modifiers are applied. Modifiers defined in individual key mappings will be applied before those defined in the Input Action asset. Modifiers will not override any that are defined on the Input Action asset, they will be combined together during evaluation. Added callback options with metadata on FInstancedPropertyBag Added a TypeFilter callback to filter out some types when changing the type of a property Added a RemoveCheck callback to cancel the removal of a property Added a generic way to invoke You can now merge DataAssets that are conflicted in revision control by right clicking on them in the content browser and selecting \\"Revision Control/Merge\\". Implemented support for changing default type in PropertyBag detail view Also move Metadata names to a seperate header to reference all available metadata values for StructUtils Added a Debug Display Name string to Player Controller input modes. This is useful for doing a quick debug session of why input may not be getting to the player because it could be consumed by the UI. Added clarification to the TouchInterface directions. Marked functions as virtual in AbilityTask_WaitTargetData. Added an advanced setting on the Input Action for the input accumulation behavior. This setting would allow you to change an input action to cumulatively combine input from different Action Key Mappings instead of always accepting the mapping with the highest key value. A practical example of when to use this would be for something like WASD movement, if you want pressing W and S to cancel each other out. Added filtering on containers you can use with Properties for StructUtils. Added SSourceControlReview::OpenChangelist method to allow external code to open the changelist review dialog. Diff tool overhaul that allows asynchronous diffing and improves diff accuracy for details panels. Added a EHardwareDeviceSupportedFeatures and EHardwareDevicePrimaryType enums to hardware device identifiers. These allow hardware device identifiers to set flags for themselves to identify some common traits that they have and check what kind of support they have. These are config flags that provide your game a method to change what they support for a given input device and add custom hardware types if desired. Added support for instanced struct object references in DataTable and DataRegistry. Allow for input injection based on a player key mapping name as well as a UInputAction pointer. We can do this by keeping track of the UInputAction* associated with each player mapping. Keep track of the owning Platform User ID of each player mappable key profile so that you can access the Local Player without needing to get the outer of the profile, which will be useful for custom profile subclasses. Improvement: Refactored camera shakes' time management. Improved post-process settings blending between view targets. Added option for ProjectileMovementComponent to avoid interpolation transform updates on some frames when an object isn't as relevant. Default version is based on not recently rendered but can be extended. Added FScopedMovementUpdate around movement of interpolated component in ProjectileMovementComponent. This avoids moving its child components more than once if it then again simulates during the tick. Crash Fix: Fixed a crash when trying to apply gameplay cues after a seamless travel. Fixed a crash caused by GlobalAbilityTaskCount when using Live Coding. Fixed UAbilityTask::OnDestroy to not crash if called recursively for cases like UAbilityTask_StartAbilityState. Fixed a crash caused by having entries added to the AsyncTargetingRequests while they were being processed (When an async targeting request node is chained with another one). Now we queue those and process them at the end of the tick. Fixed AddTimedDisplay crash when changing a level. Prevented a crash when attempting to add an invalid subobject class type with the Subobject Data Subsystem. Fixed a crash caused by AGeometryCollectionISMPoolActor holding a garbage pointer. Fixed a crash when diffing an Animation Blueprint. Fixed a crash when diffing asset additions and removals in the review tool. Bug Fix: Use existing GameplayCueParameters if it exists instead of default parameters object in RemoveGameplayCue_Internal. Changed Play in Editor initialization to create game instance subsystems before it creates and initializes world subsystems to match how it works in packaged games and map transfers. Fixed GetInputAnalogStickState double-to-float wrapper from calling the wrong function. GameplayAbilityWorldReticle now faces towards the source Actor instead of the TargetingActor. Cache trigger event data if it was passed in with GiveAbilityAndActivateOnce and the ability list was locked. Fixed RawScores from getting populated incorrectly in Targeting System Tasks. Fixed an issue with Blueprint Debugging 'StepOver' command stopping in incorrect Blueprints. TargetingSelectionTask_AOE now respects source actor rotation instead of being axis-aligned. Skip processing TargetingTaskSet elements that are null. Fixed SCS_Node Actor scenecomponents from not getting re-registered correctly after Build events. Fixed some issues with blending out some infinite camera shakes. Fixed composite camera shake pattern duration info as shown in sequencer. Support has been added for the FInheritedGameplayTags to update its CombinedTags immediately rather than waiting until a Save. Fixed Actor loading in the editor to correctly set the transform when a native root component changes class during reparenting. Fixed issue affecting the timing of server-forced pawn position updates when time dilation was involved. Limited the length of a player mappable name to the max length of FName's to properly check for the max length. This fixes a possible ensure that you could get if you used a name that's too long. Fixed regression that would cause erroneous \\"AttachChildren count increased while detaching\\" error when a USceneComponent was garbage collected Prevented AActor::RerunConstructionScripts from calling a redundant SetWorldTransform inside ExecuteConstruction when the transform hasn't changed. This was causing error accumulation in the relative and world transforms of a component that has an attach parent. Fixed character movement issue that could prevent client moves from being submitted at the intended rate when time was dilated. Fixed issue where a Character could intend to stay vertical (aligned with gravity) but unable to change pitch or roll to get there. Moved ShouldAbilityRespondToEvent from client-only code path to both server and client. Fixed an issue where subobjects that are stored in container properties (TArray, TSet, and TMap) would not show up in the details panel if they were created dynamically at runtime. Newly created Blueprint Child Classes are now marked as Transactional and therefore allow undo immediately upon creation, rather than after first save. Fixed pathing warnings when working with certain types of data assets and data tables. Only attempt to auto upgrade to Enhanced Input if the project has a name. This solves an issue where you would get toasts about EI from the project launcher. Check for null world pointer before starting/stopping shakes. Added some data validation for Combo Step Completion and Cancellation States to make sure at least one state is set. Do not attempt to synchronously load the source texture of a Paper2D sprite if we are already in the ASYNC loading thread. This can occur in the editor if cooked content is enabled, on post load of the sprite asset. Fixed FAttributeSetInitterDiscreteLevels from not working in Cooked Builds due to Curve Simplification. Set CurrentEventData in GameplayAbility. Ensure MinimalReplicationTags are set up correctly before potentially executing callbacks. Made Blueprint functions on the camera animation subsystem gracefully handle null pointers. Fixed comment for UPawnMovementComponent::AddInputVector. Fixed ShouldAbilityRespondToEvent from not getting called on the instanced GameplayAbility. Gameplay Cue Notify Actors executing on Child Actors no longer leak memory when gc.PendingKill is disabled. Made AActor::SetActorTickEnabled virtual. Fixed an issue in GameplayCueManager where GameplayCueNotify_Actors could be 'lost' due to hash collisions. WaitGameplayTagQuery will now respect its Query even if we have no Gameplay Tags on the Actor. PostAttributeChange and AttributeValueChangeDelegates will now have the correct OldValue. The minimal view info has been correctly reset to prevent parameters from \\"leaking\\" from one view target to the next. Applied current scale and easing value to post-process settings weight Fixed FGameplayTagQuery from not showing a proper Query Description if the struct was created by native code. When bIgnoreAllPressedKeysUntilRelease is true, don't only ignore key presses for keys that were in the previous key mappings, but for every key. Fixed not being able to Copy & Paste the Mappings list in an Input Mapping Context. Only modify config files if the project has a name, which avoids modifying default engine ini files from the project launcher. Fixed package load warning when loading changelists in the review tool that contain non-asset files. Resetting the value of the action value bindings when the action is not present in the current mappings. Added a \\"Force Reset\\" flag to device properties that gets set when PIE ends. This fixes an small bug where the light color or trigger effect could persist between PIE sessions. Updated text exporting of objects (used for copy/paste) to sanitize property names containing special characters that would otherwise break the parser on import Marked the FKey::KeyName as EditAnywhere so that its value is correctly propagated if it is changed on a subobject. Without this, the KeyName property will be filtered out when determining if a property has changed on a subobject, leading to an unusable UPROPERTY. This has no effect visually in the editor since the FKey has a custom details row. Fixed non-deterministic behavior during cook time with regard to the Scale Method pin in on SpawnActorFromClass nodes Fixed a regression that caused SDetailsViewBase::HighlightProperty to not support nullptr and thus removing any way to unhighlight a property Fixed an issue where some key mappings would incorrectly be displayed as overriden in the \\"showdebug EnhancedInput\\" command. This was happening because the AddUnique call to the array would always add a new mapping, since it was comparing the instanced arrays of modifiers and triggers. Removed an invalid \\"break\\" in a loop that created an order dependant check for chorded actions being blocked. Fixed the Input Device Subsystem not finding a valid Game World in a packaged windows project.The subsystem was searching for a PIE only play world, not a cooked game world as well. Fixed an issue when comparing enhanced action mappings during RebuildControlMappings because of a deep copy of the modifiers and triggers arrays, so any time we compare a new instance to old instance it would return false no matter what. Fixed a bug that caused OneFilePerActor Actors to always diff the local asset against itself instead of against a previous version. Ensure that the UAbilitySystemGlobals::InitGlobalData is called if the Ability System is in use. Previously if the user did not call it, the Gameplay Ability System did not function correctly. Fixed route gamepad to second window. When this setting is enabled, if you have a gamepad connected to the editor, all gamepad inputs will be routed to the next PIE window. Reduced false positives in text-based asset diffs by excluding export paths from the diff. Fixed a bug that caused RefreshPropertyObjects in SKismetInspector to not get garbage collected. Deprecated: Removed unused function FGameplayAbilityTargetData::AddTargetDataToGameplayCueParameters. Removed vestigial GameplayAbility::SetMovementSyncPoint Deprecated UPlayerMappableInputConfig in favor of the new UEnhancedInputUserSettings with 5.3. Deprecated the FPlayerMappableKeySlot and all its related functions for 5.3, along with all the old player mapped key functions in favor of UEnhancedInputUserSettings. Removed: Removed unused replication flag from Gameplay tasks & Ability system components Removed ensure when no combo actions are present. Logs a warning instead. Mass New: Simplified UMassActorSpawnerSubsystem subclassing by moving post actor spawn steps from SpawnActor into SpawnOrRetrieveFromPool. SpawnActor now calls World->SpawnActor. Added the bRandomize property to FMassTransformsSpawnData to control whether UMassSpawnLocationProcessor assigns transforms randomly (defaults to true to maintain current behavior) or if false, assigns transforms in order. Bug Fix: Fixed a bug in FMassEntityManager::BatchDestroyEntities where the ObserverManager wasn't being informed of the entity deletions, causing fragment destructors not to run. Fixed processor execution flag for world for PIE. Fixed multithreading access detector in FMassBatchedEntiityCommand's Add methods. Networking New: [NetBitArray] Added IsBitSet. Added CombineMultiple to run bit operations on two const bit arrays in 1 loop. Added ToString that prints how many set bits the array currently has. Slightly expensive do not abuse with active logs. Added FNetBitArrayPrinter utility functions. [Network] Added FNetContext for user code to tell if inside a real network RPC or not. Added support to FNetContext::IsInsideNetRPC in both Iris and legacy. [NetBitArray] Added InitAndCopy functions on FNetBitArray. Used to quickly construct a bit array from an existing source, either bitarray or bitarrayview. Added Set functions used to overwrite the bitarray with the word operations of two other arrays. [SubObject Replication] Added cvar net.SubObjects.DetectDeprecatedReplicatedSubObjects. When enabled, it will ensure that it detects that ReplicateSubObjects is implemented in a class that switched over to the new registration method. This is only available in development builds. [NetDriver] Added FWorldDelegate::OnNetDriverCreated delegate called after any NetDriver was created. [Iris] A struct derived from a struct with a custom Net Serializer somewhere in the hierarchy is no longer required to implement a Net Serializer itself. The custom Net Serializer is automatically used appropriately and additional replicated properties will be replicated as expected. Clients now disconnect on a bunch error when Iris is enabled. This prevents trying to deserialize packets indefinitely. When an error is set, it's unrecoverable. FNetBitArray can now be used in range-based for loops. This loops over set bits and gives you the index of the set bit. Added documentation to Network Prediction plugin README file. Added ELifetimeCondition COND_Dynamic support. COND_Dynamic allows for a property to decide its actual replication condition after instantiation of the actor/component rather than being the same for all instances. The condition can be changed using the macros: DOREPDYNAMICCONDITION_INITCONDITION_FAST: when used in the object's GetReplicatedCustomConditionState implementation DOREPDYNAMICCONDITION_SETCONDITION_FAST: in any other place where it's appropriate to change the condition. If the condition is never modified, thus remaining COND_Dynamic, the property will always replicate when changed. It's possible to use the DOREPCUSTOMCONDITION_ macros on properties with this condition. [Iris] NetObjectConnectionFilter is now available for Iris replication. This can be used to dynamically filter objects to only replicate to certain connections. The main use case is when objects added to this filter may also be dependent objects as dependent objects override dynamic filtering, but not any type of static filtering. Added additional Insights CPU scopes in Network Prediction plugin code. Added a unit test program for the Network Prediction plugin that covers basic simulation ticking in forward prediction and interpolation modes. ReplicatedPredictionKeys now explicitly copies ReplicatonID and ReplicationKeys to properly support being initialized with preserved ReplicationID. Net Driver updates: Collect the amount of packets sent and received by each connection, each frame. Output the average and max per-connection packets received and sent every frame in CSV Profiler. Added net.ForceOnePacketPerBunch console variable to force every packet to contain a single bunch. This can be used to debug rare ordering issues when two actors are dependent, but should not. Added net.AlwaysUpdateGuidReferenceMapForNetSerializeObjectStruct console variable to always update GuidReferenceMap entries for NetSerialize structs with object properties, in order to prevent issues with old property values being applied when the struct's object reference is remapped. CVarNetEnableDetailedScopeCounters is now cached in a global variable in order to prevent unnecessary work getting the console variable value every conditional scope cycle counter. ReplicateCustomDeltaPropTime is now only recorded if the object has any custom delta properties. Crash Fix: Fixed the seamless travel handler to handle PIE renaming for the transition map the same way it does the destination map. This fixes a crash with multiplayer PIE where it tries to reuse the same map package Bug Fix: Fixed GetNetMode to work properly in Play in Editor for functions like InitGame called halfway through world startup, and fixed related issues with EnableListenServer and dedicated server PIE worlds. [ReplicationGraph] Added fix to prevent sending multicast RPCs on a channel that is closing but not yet cleaned up. [ReplicatedSubObject] Fixed refcount breaking due to accessing invalid memory from a TSet iterator after having removed the iterator. [RepGraph] Fixed log spam caused by actors going outside the legal world bounds and staying OOB. Only log a warning once when the actor goes OOB. net.ReplicationGraph.PrintGraph now prints the list of DynamicSpatializedActors monitored by the Grid2D node. Fixed an issue where actor channels were closed due to level being unloaded/streamed-out destroying NetStartupActors unless the channel had been explicitly broken. This behavior can be disabled by setting the console variable as: net.SkipDestroyNetStartupActorsOnChannelCloseDueToLevelUnloaded 0. Fixed behavior of simulated proxies controlled by the Network Prediction plugin when there's no autonomous proxy, such as when a client un-possesses a pawn and doesn't immediately possess another one. Interpolation of simulated proxies now continues while there's no local autonomous proxy. FastArraySerializer is no longer allowed to modify state of Archetype or CDO when initializing base state as this lead to inconsistencies with assignment of ReplicationID Fixed issue with missing detection of items being marked dirty. Fixed issue with NetTraceReporter crashing when processing certain trace files. Fixed an issue where FNetBitArray::FindLastZero returned index out of bounds for array sizes not aligned with the size of the storage. Deprecated: [NetDriver] Deprecated NetServerMaxTickRate variable and replaced them with Get/Set functions. Added FOnNetServerMaxTickRateChanged delegate. Register to receive callbacks when the server tick rate changes. Deprecated obsolete packet handler components. Removed: Removed calls to SetNetVersionsOnArchive and SetNetVersionsFromArchive and redirect FInBunch::GameNetVer and FInBunch::EngineNetVer to use the internal connection pointer. Removed FloatCastChecked in PreFrameReceive to fix an assert with a large DeltaTime that could occur in certain circumstances. Level Design and Art Tools Geometry Core New: Added the ability to store and fetch temporary debug named-FDynamicMesh instances via global C++ functions UE::Geometry::Debug::StashDebugMesh() and FetchDebugMesh(). A new cvar geometry.DynamicMesh.EnableDebugMeshes must be set to 1 to enable this functionality. A console command geometry.DynamicMesh.ClearDebugMeshes can be used to clear the debug mesh set. The FConvexDecomposition3 class now has a merge-only API, which can be used to approximate an input set of convex hulls with a smaller number of convex hulls. Added Transform and Inverse Transform functions to Geometry Core's TPlane3. Added Transform Normal and Inverse Transform Normal functions to Geometry Core's VectorUtil. Added a FSphereCover concept as a new, optional representation of negative space for FConvexDecomposition3. This can be used to guide the merge phase of convex decomposition, more accurately keeping the convex hulls away from the object's negative space. Multiple methods are provided to generate a sphere covering that efficiently covers the negative space, with settings to allow some leeway to ignore negative space in small gaps or near the object surface. The Clipper2 wrapper in the Geometry Algorithms module now supports taking the intersection, union, difference, and exclusive-or of arrays of polygons. Added FindAllHitTriangles function to get all the triangles intersected by a ray (not just the closest one). Dynamic Mesh Component now provides the option to control which color-space conversion is applied to Vertex Colors when creating the Render Buffers from the UDynamicMesh vertex color attribute (SRGB to Linear, Linear to SRGB, or No Conversion). This option is exposed as the Color Space Mode property on the class, as well as via new Blueprint functions Set Vertex Color Space Transform Mode and Get Vertex Color Space Transform Mode. The default is to not apply any conversion or transform. DynamicMeshComponent now supports specifying custom vertex color remappings in C++, by passing a lambda to the new API function SetVertexColorRemappingFunction. ClearVertexColorRemappingFunction and HasVertexColorRemappingFunction have also been added. Added theClear Vertex Color Remapping function. Added theHas Vertex Color Remapping function. Added a Split Attribute Welder function. FSplitAttributeWelder can be used to weld split-attributes that share the same vertex in the parent mesh. Bug Fix: Fixed exact predicate float control settings for clang, making exact predicates work correctly on platforms where clang was configured to use fast math. Made the Geometry Core AABB types respect the IsValid flag on conversion to or from the Core FBox type. Dynamic Mesh Component can now render a wireframe overlay in shipping builds, if an Engine wireframe material is available. Prevented an issue where the editor might crash when determining the number of UV channels during mesh conversion. Fixed issue in TMeshSimplification where explicitly-constrained vertices could result in collapses that ignore geometric constraints. Geometry Script New: Added two functions that compute the shortest distance between mesh points: Get Shortest Vertex Path (using Dijkstra ) and Get Shortest Surface Path (using intrinsic mesh edge flips.) Added the ability to trace a straight line on a mesh surface through geodesic functions. Added new mesh bone weight functions for getting information about individual bones of the skeleton stored in the dynamic mesh: Get Root Bone Name Get Bone Children Get All Bones Info Get Bone Info Added the function Blur Mesh Vertex Colors for blurring mesh vertex colors. Added the function Transfer Bone Weights From Mesh for transferring bone weights from one mesh to another. Created new functions Discard Bones From Mesh and Copy Bones From Mesh. Dynamic meshes now inherit the skeleton information when converting from skeletal meshes. Create New Skeletal Mesh Asset From Mesh (LODs) can now use the proportions of bones stored in the input dynamic meshes. This is enabled through the Use Mesh Bone Proportions flag in the Geometry Script Create New Skeletal Mesh Asset Options. Added Create New Static Mesh Asset From Mesh LODsand Create New Skeletal Mesh Asset From Mesh LODs functions for creating static and skeletal meshes from an array of LODs instead of just a single mesh. Added the Append Bounding Box function,which takes an FBox instead of separate box parameters Added the Mark For Mesh Rebuild Blueprint function to Generated Dynamic Mesh Actor, which allows other Blueprints to explicitly queue up a Mesh Rebuild event without re-running the Actor Construction Script. Added Get Vertex Connected Triangles, Get Vertex Connected Vertices, and Get All Split UVs At Vertex functions, which can be used to query the one-ring triangles or vertices of a vertex, as well as the set of split UVs at a vertex in a given UV channel Added the ability to run Delaunay Triangulation on an input set of points, and optionally a Constrained Delaunay Triangulation that preserves specified edges as well. Updated the dynamic mesh component to expose new Blueprint functions Notify Mesh Updated and Notify Vertex Attributes Updated. These functions can be used to force either a full or partial update of the rendering buffers for the Component after the UDynamicMesh has been modified with deferred notifications. Added the function Recompute Normals For Mesh Selectionto allow normals recomputation to be limited to a mesh selection. Added the Compute Mesh Local UV Param function, which can compute an Discrete Exponential/Log Map (ExpMap) UV parameterization on a bounded-geodesic-radius area of a mesh. The subset of computed vertex/UV pairs is returned as output, rather than set on a mesh UV channel. Added a Channel Pack node which has up to four input textures and creates an output texture where the RGBA channels are sourced from the inputs. Added a new function, Select Mesh Elements In Box With BVH allowing efficient range queries on large meshes using a bounding box and an AABBTree. Added the Get Mesh Volume Area Center function to compute the center of mass for a mesh, as well as volume and surface area. The dynamic mesh component's Externally Provided tangent type setting has been renamed From Dynamic Mesh. Added new polygon and path offset functions. Added new functions and data types for managing simple polygons (polygons without holes) and lists of general polygons (polygons with support for optional holes) in 2D. Editor-only functions Stash Debug Meshand Fetch Debug Meshhave been added, which can be used to save temporary copies of UDynamicMesh objects associated with string names. The cvar geometry.DynamicMesh.EnableDebugMeshes must be set, otherwise these functions are ignored. Improvement: Updated the polygon triangulation functions to have better error handling and a more robust winding-number-based fallback mode to generate better results in cases where input polygon edges overlap. Recompute Normalsfunction now has a bDeferChangeNotifications option. Updated the Copy Mesh From Component function to support Instanced Static Mesh Components; each instance of the static mesh is appended to the output mesh TheBake Texture function was updated to expose an option to control the type of texture filtering applied. Updated dynamic mesh components to use the tangents provided on their dynamic mesh by default, and the setting controlling this tangent source is now also exposed in the UI under the Dynamic Mesh Component properties. Bug Fix: Removed incorrect clamping of the Radial Samples parameter inAppend Disc. Fixed an issue where passing an invalid path to Geometry Script's new asset utility functions could cause a crash. Package names are now automatically sanitized before use by these functions. Fixed issue where Create Skeletal Mesh Asset From Mesh was not assigning materials correctly. Fixed a crash when splines with duplicate constant points are converted to polylines. Updated modules in the GeometryScripting plugin that are Runtime-capable to load in the PreDefault loading phase, before user construction scripts that may depend on Geometry Script. Modeling Tools New: Added a Mesh Topology Selection Mechanic which enables or disables different selection modes in the details customization. Added a Generate Lightmap UVs option under the New Mesh Objects settings in the Modeling Tools Project Settings panel. If enabled, this will enable light map UVs on any new static mesh created within Modeling Mode. Moved the Bake RC tool from Mesh Modeling Tools Exp to Mesh Modeling Tools Editor Only Exp module. Adding a two-sided vertex color material. Same as Mesh Vertex Color Material but with Two Sided checked. Useed the new two-sided material in the cloth weight map paint tool so that we can paint on the back side of the 2D panels. The Bake Transform and Edit Pivot tools now update all LODs by default, not just the active LOD, and exposed an 'Apply to All LODs option to control this behavior. Updated Simplify To Minimal Planar to work on the boundary of meshes. Added the Copy From Inputs option in Mesh to Collision tool to transfer existing simple geometry over to the target. Added helper methods to count the number of Actor Components which match Target Requirements to assist with special tool needs. Added helper methods to test for existence of volume components and components that support UVs in Tool Targets. Updated the box finding code in MeshSimpleShapeApproximation to prefer to orient the boxes such that they align with the world frame better. Harden and improved various conversions between dynamic meshes and volumes, to make modeling tools work more reliably on volumes. Added a Gradient Interaction type to the Cloth Paint tool. The user selects high and low vertices and a gradient is automatically computed between them. Added the Mesh Vertex Paint Tool has been added to Modeling Mode. This Tool can be used to directly paint asset vertex colors (but not per-instance override vertex colors). Created the Draw Spline tool for drawing splines and spline-based blueprints. Added a Revolve Spline tool. Moved various settings from the secondary toolbar to the cog icon in quick settings, since the secondary toolbar is not enabled by default in some builds. Added a PolyGroupID option to the Bake Textures and Bake Vertex Colors tools. Exposed mesh simplification options in the Mirror and Plane Cut tools, to reduce excess triangulation along the cut and mirror plane. Added a reusable geometry selection visualization system intended to be used in modeling tools with minimal boilerplate. Unbinded the toggle gizmo action in some tools from a default hotkey to prevent users from accidentally pressing it and thinking that the tools are broken. Users can still set their own hotkey if their workflow benefits from it. Adjusted how the Combined Transform Gizmo displays scale axis handles when only two axes are needed. The old approach had the handles react to the camera direction at all times, causing issues in the UV Editor and inconsistent orientations of the handles relative to the plane in the case of only two axes. The new approach only is reactive to the camera in cases of one or three axes and locks the handles into a single plane if exactly two axes are configured in the gizmo. Added a Simple Collison Editor tool to assist with editing of simple collision primitive shapes directly within Modeling Mode for static and dynamic meshes. Added Subdivide tool improvements dealing with meshes with open boundaries: Factor out extra corner finding code from PolyEd and add support for it in the subdivide tool. Added support for rounded corners for mesh boundaries. Override subdivision scheme during tool usage rather than just at tool start, to allow extra corners to fix some issues. Added some clarifying comments about schemes. Changed the Mac bindings for grid size changes in Cube Grid tool to Option + A/D because Option + E is consumed by Mac. Added geometry selection support to the Normals tool. Added an edge simplification operation to the PolyEdit tool. Added a Mesh Splines tool, which creates meshes from a selection of spline components. The tool enables triangulation and extrusion of the splines, as well as Boolean combinations of the spline shapes. Improvement: Updated the Weld Mesh Edges tool to optionally merge attributes. Improved the documentation of options in the SubDiv tool. The BakeRC tool now outputs a material which is configured to use any generated textures. UModelingObjectsCreationAPI was extended to support materials by duplicating a given material. Updatedthe Pattern tool to have an option to place a random selected object at each pattern position, rather than always placing all selected objects at each position. Updated the Mesh To Collision, Convert, and Transfer tools to properly handle simple collision on Dynamic Mesh Components. Updated the Displace Mesh Tool to show feedback about the vertex and triangle counts of the output mesh. Moved the preview settings to above the list of generated textures in the BakeRC tool Updated Volume to Mesh tool's tooltips to better reflect the tool's behavior. Bug Fix: Fixed a bug where the Trim tool starts a potentially expensive boolean calculation when only the opacity color alpha changes. Updated the New Mesh Objects options under Modeling Tools Project Settings to be used more consistently by all Modeling Mode tools that create new mesh objects. Prevented several UV modeling tools from launching on volume targets, which are not applicable target types. Fixed an issue where the viewport level collision rendering would not correctly show the updated collision geometry after accepting the results of the Mesh to Collision tool. Fixed the static mesh to dynamic mesh conversion not recomputing tangents with the recompute tangents option set, in some cases. Improved checks for launching tools against assets that might be cooked in the editor. Updated the Pattern Tool to emit contextually correct static mesh actors. Fixed GetElapsedComputeTime so that the preview material kicks in after the proper delay. Updated the Convert Tool to no longer copy incorrect Material IDs to the output mesh if the the Transfer Materials option is disabled. Prevented several tools from running on volume targets since the operations didn't apply to that target type. Dynamic mesh components now show vertex colors when the setting to show vertex colors is enabled in the viewport. Fixed an issue where the Extrude Path tool generated a result with incorrect extrusion in some cases. Hit-testing for the rectangular scaling and plane-translation handles in the Modeling Mode gizmo has been improved. Fixed per-channel baking of curvature and ambient occlusion for the Bake Vertex tool. The Subdivide tool now works on Mac and Unix targets. Fixed previous collision geometry incorrectly remaining visible when Collision Type was changed in the AutoLOD tool. Now only the collision geometry for the active Collision Type is shown. Fixed various tooltips, edit conditions and reset buttons in the AutoLOD tool Fixed an issue where the PolyCut tool would generate a bad result if the cutting polygon was self-intersecting. Updated the Bend operation in the Warp tool to support negative bend angles. Fixed a crash in the Edit Pivot tool when multiple tool targets are backed by the same asset. Fixed static mesh components created by modeling tools to set to static mobility by default, instead of movable. Improved Project and Remesh tool's Target Edge Length tooltip, explaining why it's not starting at the default value hardcoded into the property. Replaced the wireframe visuals in UV Layout Preview to use Mesh Elements Visualizer, to address Z-fighting visual artifacts in wireframe displays. Fixed an issue in the Pivot Actor tool where changing the transform using the gizmo did not cause the reset to default arrow to appear in the details panel. Fixed a crash in the Subdivide tool when adding Extra Corner Vertices was enabled for some meshes. Extra Corner Vertices can now only be added along open boundaries. Adjusted the Project tool's settings to properly disable the smooth filling options when smooth filling is disabled. Fixed a crash in the Bake Transform tool when some selected meshes have the same source asset. Fixed issue with the Recompute UVs Op where an ensure would fire when no components contained at least one full triangle. Updated the Simplify tool to conditionally disable the Prevent Normal Flips and Prevent Tiny Triangles, depending on the simplify algorithm used. This also enables support for the Prevent Tiny Triangles and Prevent Normal Flips under certain tool settings. Updated The Voxel Blend and Voxel Offset tools to warn about possible artifacts when processing meshes with open boundaries when the Vox Wrap Preprocess option is not enabled. Fixed computation of edge collapse lerp parameter which reduces artifacts in UV layers when remeshing. Fixed readability issue in mesh statistics display. Adjusted the behavior of the Mesh Visualizer settings to properly disable when the Visible property is checked off. Prevented a crash when asset editors are closed with local changes during an asset reload, due to the static mesh tool target checking for transaction success incorrectly. Fixed speckles in border regions when creating textures using the BakeTX tool. The Mesh to Volume tool automatically simplifies models with too many faces for the BSP processing code to handle, preventing the editor from hanging when large meshes are converted to volumes with this tool. Fixed a crash in the Paint Maps tool that occurred on painting on a mesh with no attributes then attempting to undo. Disabled the rendering of the indicator circle in the Seam Sculpt tool, since it was not needed for the tool's functioning and caused visual confusion. Fixed incorrect handling of texture source format BGRE8 in UE::AssetUtils::ReadTexture. Updated the Mesh Tangents tool to warn users when attempting to copy tangents from a mesh that does not have tangents. Changed the smoothing weight scheme to IDT Cotangent in the Hole Fill tool. Updatedthe Hole Fil tool to re-check for mesh seams to constrain between iterations of remeshing. Removed the stylus plugin from Modeling Mode, because of a performance issue that occurs when the stylus plugin is enabled. Updated USkinnedAsset to allow a potentially running AsyncTask to finish before deleting it. Updated the mesh visualization component used by many modeling tools, including Simplify and Remesh, to correctly distinguishes between normal and tangent seams, rather than treating both seam types as normal seams. Updated the Editor 2D Mouse Wheel Zoom Behavior Target in the Interactive Tools Framework to make the clip plane math work out if the camera has negative z coordinates. Procedural New: Created convenience functions in PCG data collections and PCG blueprint to remove some boilerplate. Added substring/matches search which support wildcards in the PointFilter node for string types. Provided a method to convert points along Landscape Spline into points on a Spline Component. Works best with single path or circular Landscape Splines. Added missing steepness controls to the Volume, Spline, and Mesh Sampler nodes. Added support for soft object reference user parameters & soft object pointers internally. Behaves like generic soft object paths but with the appropriate type narrowing. Added support for overridable texture in the Get Texture Data node. Added Loop node that behaves like a subgraph but will pass on a single data from the designated loop pins (first pin only by default). Renamed Attribute Operation node to Copy Attribute. Copy Attribute now uses the Attribute from another Attribute Set source (with an extra pin). New pin is marked (and shown) un-used if the pin is not used. Index is now a valid accessor to access the index of a point. Improved behavior of Get Actor Data node for PCG partition actors in the case of Single Point. Added an option to merge all points when querying multiple actor data with single point . Added an option to ignore self in the Get Actor Data node. Added SoftPath getter and setter support in PropertyBag to interact with properties that are SoftObjectPtr or SoftObjectClass. PCG Tracking system is now centralized, improving performances. The PCG Static Mesh Spawner now respects the ISM component type selected in the component descriptor, with the exception of changing to an ISM if the selection is HISM and the mesh is using Nanite. Added a OneMinus node. Added a Make Rotator attribute. Some native nodes now have a Preconfigured Settings entry in the context menu, to quickly add a node with the wanted settings. Preconfigured settings are available for Custom BPs, in the class settings. Changed DensityNoise into AttributeNoise node, to support noise on all attributes. Added aliases support on overridable PCG parameters in Settings, to facilitate deprecation. Added ability to spawn Actor by attribute in the Spawn Actor node. Added inspection support for subgraphs in the PCG editor. Improved attribute operations by propagating the first non-param pin. Input to propagate can now be overridden in the settings. Added default value concept for all Make operations. Changes that trigger PCG re-generation now cancel ongoing generation more efficiently. This should have a positive impact on landscape editing with PCG content and ensure that no stale data is present. Added @Last and @Source as new Attribute Selectors. @Last gets the latest modified attribute. @Source gets the attribute specified by the input. None becomes a valid attribute name. Added a new Point Filter Range node, to filter on a range. Read-only accessors are now throwing an error if it is used as an output accessor. Added Is Cacheable Override for more fine-grained control when needed. Improvement: Improved naming for nodes with custom names and blueprint nodes in the node palette. Improved support for name clashes, especially in BP exposed variables. Properties need to be exposed to be added to the Attribute Set using the Get Actor Property node. Seed for new nodes is not constant, but dependent on the node name. Seeds are kept as-is for existing nodes, to not break existing graphs. Replaced Creates Artifacts with Is Cacheable in PCG blueprints to be clearer. Previously cached blueprints which did not have Creates Artifacts checked should be manually updated to set the 'Is Cacheable' flag to true. Added getters for input/output pin properties by label in settings. Renamed getters on data collection to clarify it is done by label. Added Get Target Actor, to be used instead of accessing the Target Actor variable directly. Refrain from getting the Target Actor variable on PCG Spatial data directly. Instead use the Get Target Actor method on the context. Bug Fix: Fixed some instances where PCG would access pending kill landscapes in some instances when getting landscape proxies. Forced usage of the landscape original GUID for the landscape cache in cases where landscapes are instanced. Fixed an issue where the world ray/volumetric query parameters would not be properly overridable. Fixed outstanding bug in the metadata partition where the partition would not behave correctly for non-string values Fixed the Landscape Blend Layer not sampling correctly when using 2x2 Subsections. Fixed distance checks between the same source and target would lead to checking points against themselves. Fixed issue with PCG partition actors not reacting to landscape changes before a full graph refresh. Fixed issue where numerical values were not accepted for MakeTransform and MakeVector. Improved logging for Metadata operation, making it easier to know why an operation is failing. Fixed issue where the Create Spline node was ignoring custom tangents. Deprecated: Support @SourceName (previous behavior of None = Create attribute with the same name as input). Not exposed. Used for deprecation. Support @LastCreated (previous behavior of None = Get the latest created attribute in input). Not exposed. Used for deprecation. UV Editor New: The UV Editor now supports a UV distortion visualization feature. When enabled, it computes a per triangle distortion value of the triangle's UVs vs its world space positions. This is then displayed as a color blind friendly color overlay on the 2D UV mesh. The feature supports several metrics for distortion and one metric for relative texel density over the mesh. Moved UV Editor plugin from Experimental plugin directory to the Editor plugin directory. Refactored unwrapped to applied selection conversion slightly to make it more convenient for areas of the code outside of the selection mechanic to perform conversions. Bug Fix: Changed the Quick Translate options in the Transform tool to produce a single undo entry for the corner transforms. Corrected issue where focusing on selections in the 3D viewport was using selections on the unwrapped 2D mesh instead. Corrected issue where the background grid was being incorrectly drawn due to mishandling of minimum and maximum Y-axis bounds. Adjusted the language in the Transform tool's tooltips to be more consistent between different direction buttons. World Building API Change: In PIE, UWorldPartitionLevelStreamingDynamic::RequestLevel now behaves like what ULevelStreaming::RequestLevel. ULevelStreaming sets ULevel::StreamedLevelsOwningWorld so that ULevel::PostLoad can now set the level OwningWorld. Since UWorldPartitionLevelStreamingDynamic creates a memory level, it sets the OwningWorld right before loading OFPA actors. New: Added a delay to AddToWorld of a partitioned world if this same partitioned world hasn't finished removing it's sub-levels triggered by a prior RemoveFromWorld. Added a LevelStreamingPersistence experimental plugin. LevelStreamingPersistenceManager handles persistence of tagged object properties when streaming-out/in levels. Persistent object properties that are tagged as public can be accessed and modified even when the level is not loaded. Added UDataLayerManager which is local to each WorldPartition. Instanced world partition maps can now maintain their own Data Layer runtime states. Added helpers UWorld::GetDataLayerManager and UWorldPartitionBlueprintLibrary::GetDataLayerManager which will automatically find the associated DataLayerManager. Added World Partition Runtime Grid origin in grid settings to help properly align game content on runtime grid cells (for example landscape proxy actors) Added a Preview Grid Level option to preview other levels of the grids Added the ability to edit data layers of a level instance when editing the level instance. Added editing data layer of level instance when editing the level instance even when the main world is not partitioned. Added support for Make Current on Level instance DataLayerInstances when editing a level instance. Unreal Engine now Includes time spent in FLevelStreamingDelegates OnLevelBeginMakingVisible/OnLevelBeginMakingInvisible and ULevelStreaming::BroadcastLevelVisibleStatus in their respective time budget. The WorldPartitionSubsystem is now responsible for sorting cells and executing cell loading and activation for all registered world partitions. Add Project Setting for default value to assign to new Level Instances Packed Level Actors now avoid updating blueprints if packing result is unchanged. DirtyFilesChangelistValidator now outputs the assets that need to be saved during changelist validation. New IsMainWorldOnly actor property for filtering actors when they are being used in a Level Instance. Improvement: Optimized UpdateStreamingState for Server streaming, It now computes ClientsVisibleLevelNames once for all registered world partitions. Added the wp.Runtime.UpdateStreamingStateTimeLimit command for incremental updates of registered world partitions (disabled by default). This is only useful when there's a lot of registered partitioned worlds. Lowered the Net Update Frequency for HLOD actors (AWorldPartitionHLOD) in case they're ever set to replicated. Any actor inheriting from AWorldPartitionHLOD with replication turned on will be affected, since there is now a NetUpdateFrequency of 1 by default as opposed to the default 100. Changed default value of wp.Runtime.UpdateStreaming.EnableOptimization to true. Set UDataLayerManager::SetDataLayerInstanceRuntimeState to BlueprintAuthorityOnly. Replaced import data layer menu option with drag and dropping level instance data layers into main world AWorldDataLayers. Disabled changing visibility and editor loading of DataLayerInstances of editing level instance. Changed font from bold to bold+italic on DataLayerInstances containing actors that are part of editor selection. Colorized and appended (Current) to the WorldDataLayer of the editing Level Instance in the DataLayer Outliner. Optimized World Partition UpdateStreamingSources. Saves 1ms on project using >300 instances of partitioned worlds. Moved initialization of game instanced world partition to happen when the level starts to be added to the world instead of when it is loaded. Moved the uninitialization of game instanced world partition to happen when the level starts to be removed from the world instead of when it is done being removed from the level. Centralized the initialization/uninitialization logic in WorldPartitionSubsystem Instanced world partition IsServerStreamingEnabled/IsServerStreamingOutEnabled now forwards the logic to their parent world partition (if any) when using project default modes. Disabled replication of WorldSettings on levels created for world partition streaming cells. Added other missing deprecated UDataLayerSubsystem methods. World Partition now relies on World's NumStreamingLevelsBeingLoaded instead of computing its own number of loading cells. Fixed Data Layer asset paths when loading WorldPartitionActorDescs. Level Instances with bEnableStreaming=true will now act as regular World Partitions when loaded on their own. Big Level Instances can now be partially loaded outside of their owning world. Bug Fix: Fixed UDataLayerManager::SetDataLayerRuntimeState helper to avoid having to resolve a DataLayerInstance for a Data Layer asset. Fixed the case where an instanced world partition was added to the world, then removed from the world, then re-added to the world without being unloaded first. Fixed deprecated UDataLayerSubsystem::GetDataLayerInstances to properly map to UDataLayerManager::GetDataLayerInstances. Fixed pending cells to be loaded and to be added to the world not updating their cell sorting info. Fixed UWorld::CanAddLoadedLevelToWorld to work with multiple world partitions. Properly hooked Data Layers menu extenders and pass selection to delegate. Fixed broken foliage instance selection after deleting an instance Corrected missing initializations in FInstanceUpdateCmdBuffer ctor Uninitializing a partitioned world should always trigger unloading of all cells regardless if server streaming and/or server streaming out are enabled/disabled. Fixed replay playback not resetting runtime data layer states to their initial state. In PIE, UWorldPartitionLevelStreamingDynamic::RequestLevel now behaves like what ULevelStreaming::RequestLevel does. ULevelStreaming sets ULevel::StreamedLevelsOwningWorld so that ULevel::PostLoad can set the level OwningWorld. Since UWorldPartitionLevelStreamingDynamic creates a memory level, it sets the OwningWorld right before loading OFPA actors. Added server's client visible level names in update streaming state hash. Fixed rare case where a WP streaming cell would contain an actor and this actor is also an editor-only reference of another actor of this cell. In this case, the editor-only reference must not be part of the WP streaming cell. WorldPartitionSubsystem no longer updates streaming sources on the server when none of its registered world partition has server streaming enabled. When sorting world partition cells, world partition doesn't rely on cell grid level, but instead uses grid cell extent to sort cells between multiple grids. Fixed how MaxCellsToLoad is computed by World Partition to limit the total number of loading and pending load streaming cells. Fixed infinite loop in Level streaming caused by UWorld::RemoveFromWorld completing in non incremental removal move after first starting in incremental mode and not resetting CurrentLevelPendingInvisibility. Prevented async loading flush when world partition cell is activated. Fixed bug where garbage marked levels were not given unique names, causing them to be reloaded. Attached Actor Pre/PostSaveRoot transform fix. Fixed cooked FunctionalTest not getting discovered for WorldPartition maps Recompile skeleton class after clearing SimpleConstructionScript to avoid component name clashes when adding the new components to Packed Level Actor blueprints. Deprecated: Removed DataLayerSubsystem since DataLayerManager supersedes its functionality. UWorldPartitionRuntimeCell::IsLoading, UWorldPartition::UpdateStreamingState and UWorldPartition::CanAddLoadedLevelToWorld have been deprecated. Removed CanBeUsedByLevelInstance. Level Instances that are World Partition-enabled still get embedded in their parent world grid independent of the value of bEnableStreaming. Removed: Removed menu option Create Data Layer under DataLayer as it will never be allowed for DataLayerInstanceWithAsset since it is created without any valid DataLayerAsset. Removed suffix - WorldDataLayers on parent node of DataLayerInstances in the DataLayer Outliner Localization API Change: Implemented async loading of localization data, and extended dynamic loading to handle explicitly loaded plugins. BeginInitGameTextLocalization and EndInitGameTextLocalization have been removed as part of this change. You would now just use InitGameTextLocalization (which is async) followed by FTextLocalizationManager::WaitForAsyncTasks. New: Implemented MinimumGroupingDigits for FastDecimalFormat. Enabled \\"min two\\" grouping for Spanish by default. This can be disabled via the Localization.SpanishUsesMinTwoGrouping console variable. When enabled, \\"1234\\" formats as \\"1234\\" rather than \\"1 234\\", but \\"12345\\" still formats as \\"12 345\\". Added an overload of FTextProperty::Identical_Implementation that lets you control the fallback lexical compare mode. Implemented async loading of localization data, and extended dynamic loading to handle explicitly loaded plugins. This change takes the existing support for async loading that was added for game localization data and expands it to cover all localization data. Async localization tasks are chained together as dependencies to preserve the existing order of operations, and can be waited on at any point (eg, after a loading screen) by calling FTextLocalizationManager::WaitForAsyncTasks (though the engine init flow takes care of waiting for you unless you're loading additional plugin/chunked localization data). This change takes the existing support for dynamically loading chunked localization data on PAK chunk load, and extends it to support dynamically loading any additional localization data. This is used by the engine to support dynamically loading the localization targets associated with explicitly loaded plugins. These loads are all async, so must be waited on if you need them to block. Added the Localization.DumpLiveTable command to dump the current live table state to the log. This can be optionally filtered using any of the following wildcard arguments: Namespace: The namespace to filter against. Key: The key to filter against. DisplayString: The display string to filter against. The validator to make sure localized assets do not contain dangling redirectors now properly considers the case where the localized and non-localized assets are both redirectors that point to the same respective path. Bug Fix: Always use a space and a comma as the group and decimal separator when using RAE-style Spanish numbers. Fixed an assert when gathering localization data from a World Partition world that had already been loaded as the editor world. Fixed text created from FText::FindText with a null source string failing to resolve correctly if the language changes. Online New: Add Join in Progress to list of social debug commands. MPA activity now set/unset in sync with joinability privacy. If undesired, set setMpaActivityInPrivateSession to true. Added replacements for deprecated IAP blueprint nodes: Make an In-App Purchase v2 has been replaced by the new \\"Start an In-App Purchase\\" node. Process any New Unprocessed Purchases v2 has been replaced by the new \\"Get known In-App Receipts\\" node. Query for Owned Purchases has been replaced by the new \\"Query for Owned In-App Products\\" node. Restore In-App Purchases v2 has been replaced by the new \\"Restore Owned In-App Products\\" node. New nodes allow validation/granting logic to be reused because they share common types for the receipts on their outputs. Also added \\"Finalize In-App Purchase Transaction\\" so licensees can finalize the transactions using the receipts after processing. All transactions should be finalized. Any non finalized transaction locally or server side will be refunded by GooglePlay and not finalizing locally the transactions on iOS may lead to bad performance The recommended flows in a game should be: On startup/after login \\"Query for Owned In-App Products\\", then validate/grant the missing products and finalize those receipts. When the user initiates a purchase using \\"Start an In-App Purchase\\" validate/grant the products and finalize the receipt. Any time the game may need to check for updates on products it can \\"Query for Owned Purchases\\" if they need a full update or \\"Get known In-App Receipts\\" if it is not interested in updating data from store servers. After that products can be validated/granted and receipts should be finalized. \\"Restore Owned In-App Products\\" does the same as \\"Query for Owned Purchases\\" on Android. On iOS it calls restoreCompletedTransactions on the payment queue thus making available all already processed receipts for non consumable transactions. Added a conditional in the BuildPatchServices system to ascertain if the destination file system is currently throttled, and, if so, stall file writing. Convert online subsystem defines to be global FNames to avoid a lookup every time we use one. Improvement: Improved POSIX ICMP code and added a console command to test ICMP directly. Moved USocialDebugTools::PrintExecCommands to protected so it can be overridden by subclasses. Deprecated: Marked deprecated IAP blueprint nodes and created replacements: Make an In-App Purchase v2 has been replaced by the new \\"Start an In-App Purchase\\" node. Process any New Unprocessed Purchases v2 has been replaced by the new \\"Get known In-App Receipts\\" node. Query for Owned Purchases has been replaced by the new \\"Query for Owned In-App Products\\" node. Restore In-App Purchases v2 has been replaced by the new \\"Restore Owned In-App Products\\" node. HTTP New: Added non-game thread support for http request. Added http streaming download interface. Added new test project WebTests with corresponding web server to test HTTP. Added 64 bits length of file download support in http request. Added LLM tags to CurlHttp allocation hooks. Bug Fix: Enabled WinHttp websockets to be created with an empty protocol list, which results in the corresponding header not being added. Online Subsystem New: Added a LobbyId override option to the CreateLobby method in the OnlineServices Lobbies interface. Added logic to LobbiesEOSGS to use the new option. Added UE_ONLINE_ERROR_EXTERNAL macro to enable online errors to be defined outside of the UE::Online::Errors namespace. Added presence tracking for OSSv2 Lobbies. Added logic to trigger OnQueryUserInfoComplete delegates on OSS EOS. Added support for BuildIdOverride on the command line to be surrounded by quotes. Added GetInterface accessor to IOnlineServices to allow for additional/implementation specific interfaces to be accessed via the base IOnlineServices. Improvement: Modified OnlineBeaconClient login parameters to allow for more parameters than just the auth ticket. Bug Fix: Changed the default cache directory for Switch used by OSS EOS. Delayed callback execution to match alternate flow paths in OSS EOS Session search code. Refactored OSS EOS Friend status update handler method to trigger the appropriate corresponding UE delegates and keep a coherent state. Refactored EOS Lobby Creation logic to destroy the lobby if the update step fails. Added critical section around FOnlineSubsystemModule::OnlineSubsystems. This fixes race conditions when multiple threads are accessing FOnlineSubsystemModule::GetOnlineSubsystem, observed to happen as part of multi-threaded FUniqueNetIdRepl deserialization. Refactored session update code in OSS EOS Sessions interface to ensure non-owner lobby members can update their own lobby member settings, to match API functionality. [Online Services] Added support to handle more operation cache settings, duration based and provide a setting to cache error results. Limit concurrent operations in flight. Fixed some operations not being removed/destroyed when we are done with them. Removed: Removed unsupported members of LobbyMember type: PlatformAccountId and PlatformDisplayName. Removed early exit in OSS EOS' FriendStatusChanged method in order to handle accepted friend invites via the EOS overlay. Pixel Streaming New: Added the ability for the bundled get_ps_servers script to pull down a release from Github. Added a new framework to allow passing arbitrary configuration settings to the streaming infrastructure. Improvement: The default viewer port for PixelStreaming on Linux is now 8080. Port 80 requires root privileges on Linux, so this avoids elevation. Crash Fix: Fixed a crash caused by using UPixelStreamingSignallingComponent Blueprint types. Fixed a crash that occurred when using OfferToReceive on Firefox. Fixed a crash that occurred on shutdown. Fixed a deadlock that occurred when using DX11 on AWS instances. Fixed a crash that occurred when running with -onethread and encoding VPX. Fixed a crash that occurred when a port was not provided for -PixelStreamingURL. Bug Fix: Fixed a bug where the embedded signaling server would not serve the images directory as expected. Fixed a bug where showcase.html would not display images when using an embedded signaling server. Fixed a bug where the embedded signaling server could not connect to the frontend. Server targets can now build with PixelStreaming Blueprints enabled. Fixed a race condition that could occur during stats collection. Fixed a bug where the minimum bitrate could be set higher than the maximum bitrate. Platform Bug Fix: Added a check to prevent memory mapping compressed or encrypted memory made with IoStore. Fixed address sanitizer compile error on current versions of MSVC. Desktop Crash Fix: Fixed a crash that occurred when playing 2 startup movies using WindowsMoviePlayer. Linux New: Added sigaction failure check. Provided an option to disable dump_syms where iteration speed is desirable. (-NoDumpSyms or set bDisableDumpSyms). Bug Fix: Stopped tooltips from popping up during window drags. Replaced use of sa_handler with sa_sigaction. If SA_SIGINFO is specified in sa_flags, then sa_sigaction specifies the signal-handling function instead of sa_handler. Started accounting for Linux dock dimensions when computing positions. Fixed \`TWeakObjectPtr\`s not being indexed properly in LLDB. Fixed launching on a remote Linux box from a Windows editor. Fixrf DPI scale in Linux being incorrect on Odyssey G9 5120x1440 displays. These displays report invalid display information to the window system, resulting in very high scale values. Fixed crash reporter not always showing up on Linux due to config variables being unexpectedly overridden. Fixed some instances where modal window behavior on Linux didn't match other platforms. Corrected some incorrect event resetting code in FramePro. Mac New: Moved some MacMenu calls to MainThread to avoid creating errors in the Main Thread Checker, which will be fatal in future MacOS versions. Added encoder fault tracking to help diagnose GPU crashes. Crash Fix: Fixed crash with Dump GPU on Macs due to missing viewport. Fixed a freeze that could occur on Mac when some pop ups were displayed. Bug Fix: Fixed incorrect timestamp queries calculation on Apple Silicon. On Mac, UE will no longer rebuild cached menus on every key press. This prevents an FPS drop in editor/preview when the user is pressing keys on the keyboard. MacSystemIncludes now undefines PF_MAX so it can be defined by UE for pixelformat instead of socket.h. This is the result of a long include chain wherein Cocoa.h pulls in networking code from PrintCore.h, which in turn leads to socket.h defining PF_MAX instead of UE. Added some checks on CRC to make sure it actually exists and is executable. XR New: Added an interface within IOpenXRExtensionPlugin.h to access StereoLayers. Added support for XR_FB_composition_layer_alpha_blend extension. Added support for cylinder and equirect layers in OpenXR plugin. Added support for XR_FB_foveation OpenXR extension. Added setting to enable/disable OpenXR foveation. [ARSessionConfig] Added candidate image removal methods. [OpenXR] You can now disable the depth layer via cvar. [PSVR2] Adjustable max eye texture size now allows for PixelDensity > 1.0 with a setting to control the limit. Improvement: Hololens device detection will now occur after editor startup by default to reduce startup time.This setting can be changed in the Hololens Project Settings. ARCore SDK for Android was updated to 1.37. [OpenXR] Android apps on non-Oculus Android platforms can now startup OpenXR if they are not configured for Oculus Mobile Devices by changing vr.DisableOpenXROnAndroidWithoutOculus to false. Reduced XR EControllerHand use. Reduced total memory use overhead of HeadMountedDisplay modules by moving them to the XRBase plugin. [OpenXRHandTracking] Improved support for using hand tracking along with controllers. Packaging settings for Meta Quest devices has been changed from a list of devices to a single checkbox that enabled packaging for all Meta Quest devices. OpenXR headers have been updated to OpenXR SDK 1.0.27 (2023-03-21). Added a tooltip to MotionControllerComponent's MotionSource. [PSVR2] Removed reliance on pre-registered buffers for reprojection. [OpenXR] Runtime-supported extensions will now be logged. [OpenXR] Refined CopyTexture operations for layer and spectator screen usage. Crash Fix: Fixed a crash related to planar reflection on SteamVR. Fixed a crash that occurred when accessing vr.SpectatorScreenMode CVar without a controller connected. Bug Fix: [AR Pins] Fixed a bug where TrackingToWorldTransform and WorldScale were updating incorrectly. [ARKit] ARKit anchors are now released when the ARPin is removed. StereoLayerManager no longer uses invalidated FLayerData. The xr.OpenXRForceStereoLayerEmulation console variable now picks up runtime changes only at the next VRPIE restart. Stereo layers are now correctly removed when their actor is destroyed. Fixed a bug related to the alpha of emulated stereo layers on the HMD and spectator screen. Fixed a bug where XRDeviceVisualizationComponent would not correctly start the visualization of the device model. Fixed Mobile Preview VRPIE being darker than what was shown in the HMD. Fixed sorting function that made world locked layers render on top of face locked layers. Fixed a bug related to FOpenXRHMD::UpdateLayer thread safety. Fixed an Unknown ARCore Trackable Type assert which occurred during ARLineTrace. [ARCore Trackables] Fixed a case where an ArTrackable handle was not released. [OpenXR] Emulated layers swapchain will now use the prescribed layer format. Fixed a bug involving a platform RHI disable check. [OpenXR] Fixed a bug which occurred when stereo was disabled and re-enabled. [VulkanRHI] LLM tags are now initialized earlier. [ARKit] Invalid camera images will no longer be processed after pause and resume. [ARKit] Camera texture resources will no longer be accessed on the delegate thread. [OpenXR] Quad layers now respect component scale as expected. Fixed several issues related to MotionControllerComponent Velocity. [XRScribe] Pose replay will now match the original timescale instead of playing poses back as fast as possible. Fixed an issue where OpenXRHMD SystemProperties was uninitialized until OnStereoStartup. Deprecated: EnableAutoLoadingSplashScreen functionality has been deprecated. [ARCore] Deprecated UGoogleARCoreFrameFunctionLibrary::GetCameraMetadata and Deprecated ARCore AR Trackable Render Components. Removed: Removed the deprecated camera metadata API. Removed deprecated ARCore features. Removed HoloLens \\"Multi\\" packaging. [ARBlueprintLibrary] Deleted functions deprecated in 4.22 and 4.26. Removed GetMobileVariableRateShadingImage to make Variable Rate Shading behavior consistent across mobile and desktop. Platform Mobile New: Optimized directional light uniform buffer update on mobile. Added support for pixel shader version of TAA upsampling on mobile. Added support for instance custom data in pixel shader while mobile GpuScene is enabled. Changed Light Grid Data buffers to be StructuredBuffers. Added support for ISM with mesh paint vertex color on mobile. Detect hardware Cyclic Redundancy Check (CRC) instruction support on ARM platforms. Depending on the compilation environment, this can be a runtime or compile time detection. CRC is used in hash computations everywhere in the engine and this change will provide ~7x performance improvement on supported devices. Replaced RHICommandListImmediate with RHICommandList to enable RDG pass parallelism on mobile platforms. On Android and iOS, UE will now only update the list of receipts received from IOnlinePurchase::GetReceipts by user request. Receipts retrieved using IOnlinePurchase::GetReceipts are updated as a result of calls to IOnlinePurchase::QueryReceipts. After a successful call to IOnlinePurchase::Checkout, the receipt for the successful purchase is added to that list. Asynchronous transaction updates received only trigger the IOnlinePurchase::UnexpectedPurchaseReceipt delegate. Restored transactions on iOS are automatically finished so the end user does not need to do it. Added support to handle subscriptions on OnlinePurchaseGooglePlay and OnlineSubsystemIOS. Subscription product types are now also queried to the stores. Whether a subscription is valid or not can only be handled by server-to-server calls to the store. You can disable local acknowledge-and-consume by setting bDisableLocalAcknowledgeAndConsume_\`_ in the [OnlineSubsystemGooglePlay.Store]\` section from your .ini files. This supports the server-to-server validation recommended by Google. Product IDs consumed by the engine for subscription products should be composed by be the actual product ID defined in the store, prefixed by \\"s-\\". Several product entries will be received for a subscription product when the application invokes \`IOnlinePurchase::QueryOffersById_\`_ using a subscription product ID. The product ID on the received products will contain: ++ The prefixed product ID ++ The base plan ++ The offer in the base plan ++ The different price points. As an example, this could be the list of ids created by \`_IOnlinePurchase::QueryOffersById\`_ requesting information for \\"s-test_subscription_1\\" (which in the store would be identified as just \\"test_subscription_1\\"). r.Mobile.EarlyZPassOnlyMaterialMasking is now handled per shader platform. Increased ShaderComplexity cost of Masked Materials on Mobile ShaderPlatforms that do not use MaskedInEarlyZ. r.Forward.LightLinkedListCulling is now set to 0 for platforms that do not benefit from it. This saves about 0.1ms on the GPU. Added support for Inline RT Shadows on Vulkan. Tonemapping LUT pass now runs only when needed. Added support for CollisionMode PCM_DistanceField on mobile platforms that support Distance Field. Removed SupportsCopyImage, as GL ES 3.2 standard has glCopyImageSubData. Volumetric Support For Mobile is disabled by default in Device Platforms. Removed bSupportsVolumetricFog from DataDrivenPlatformInfo. Added a new mode for rendering local lights in the Mobile forward renderer. You can enable this mode by setting r.Mobile.Forward.EnableLocalLights to 2 and r.Mobile.EarlyZPass to 1. Mobile Light Prepass is now disabled by default. Removed bSupportsMobileDistanceField from DDSPI in Global Distance Field For Mobile. Crash Fix: Fixed a crash that occurs when enabling transmission on directional light with spot light shadow on mobile. Bug Fix: Mobile rendering now samples SceneDepth instead of fetching SceneDepthAux when full depth prepass is enabled. Fixed a bug where decals are missing skylight when using the mobile deferred renderer with static lighting disabled. Directional lights with a light channel of none (0) can now cast shadows on mobile deferred. Fixed a bug where simple light was missing on mobile deferred. Fixed a bug where static meshes are missing local light when they are dragged in editor. Fixed issue where distortion pass was not using the same pixel format as a base pass. Previously, objects with masks would still do mask clipping in the pixel shader even with full depth pre-pass enabled. This issue has been resolved. Fix a bug where the depthRT is empty during passes when DepthStencilState is enabled while doing DrawMaterialToRenderTarget on the mobile deferred renderer. Fixed a bug where a black color would render on thin translucent material on mobile. Fixed IBL reflections for Surface LightingVolume. Fixed a GPU crash caused by Niagara Mesh Renderer shader which occurred on IOS 13 as well as some PowerVR android devices. Fixed GPUScene uploader size limit check. Indirect lighting scale is now correctly applied on mobile. Moved Temporal Anti-Aliasing back to the end of the post-processing chain to save bandwidth. It now filters the bloom input to get rid of the flickering white spots. Fixed a modulated shadow rendering issue on mobile. Fixed a bug in GenerateGlslShader that occurs when a string is a substring of another in the ReflectData. Fixed handling of Target Device in Mobile Preview. Quad Complexity now works correctly for mobile preview. Android New: Added a way to provide command line to Android apps using adb shell. You can now launch Android apps from adb shell and provide a command line arguments using the parameter -cmdline \\"arguments\\". Purchasing multiple products in one transaction is now allowed in OnlineSubsystemGooglePlay. Set Java 1.8 for sourceCompatibility and targetCompatibility. Capped Low-Level Memory Tracker (LLM)'s Total stat to be no less than Total Tracked on Android, since on some devices UE can't read the GPU part of the total memory allocated by the process. However, LLM does its own counting on Unreal Engine's side for GPU-related allocations. Advanced binary compression is now enabled by default on Android. Upgraded Android Studio (Flamingo 2202.2.1) and Gradle (7.5 and use OpenJDK 17 from 2202.2.1). Added support for Lumen Diffuse Indirect without requirement for Dual Source Blending in the desktop renderer. Updated force feedback support on Android: Use VibrationEffect for intensity control. Forward feedback to controller(s) if Android.UseControllerFeedback has a value other than zero (defaults to 1). Does not continue feedback when application is in the background. Added Overflow 3 and 4 for Android OBB files. Use OverflowOBBFileLimit project setting to set number allowed. The default value for OverflowOBBFileLimit is 2, but you can set it up to a maximum of 4. Updated Google-Services plugin for Firebase. Updated Swappy to the latest from Android GoogleSource. Modified to always use the Java DisplayManager and refresh rate selection as it is more reliable on some devices. Added additional Razer Kishi gamepad recognition. Added the WebViewTextureSize CVar to control Android WebBrowser texture size in DefaultEngine.ini. Crash Fix: Fixed a crash when playing a .mp4 from UMG. Bug Fix: Fix a bug that prevented rendering custom depth on OpenGL. Fixed bug where CommitComputeResourceTables were missing for dispatching indirect compute shader on OpenGL. Fixed a bug where media couldn't resume after entering the background on Android devices. Changed the location of the .apk generated by Gradle to avoid using outputFileName to redirect the .apk location. Fixed a race condition when generating .apk in newer Gradle versions by using cleanPackageDebug/cleanPackageRelease instead of manual .apk removal. Forward key pressed to UI even if virtual keyboard is shown on the screen. This enables hardware keyboard usage with EditText fields. Removing emoji filtering on Android. Now it's possible to type emoji's from Android on-screen keyboard. Fixed IME with hardware keyboard. Fixed an issue causing fingerprint scanners being falsely detected as controllers. Only archive AAB if App Bundles are enabled for Android. Corrected performance issues by performing updates to device vibrator intensity less frequently. Fixed Xbox and Razer wired controllers on Android 12+. Use /sdcard/Android/obb for OBBs for all build types. /sdcard/obb is no longer used due to storage access restrictions. Clear ANDROID_SDK_HOME environment variable in the SetupAndroid script. This should NOT be set with new tools. Slight improvement to GetEntryLength in Android filesystem. If the Android background downloader plugin is disconnected, it will now monitor network status and resume background downloads if reconnected. Fixed OnLocationChanged broadcast for Android location services to use the game thread properly. Deprecated: libc++_shared.so is no longer included in .apk packages on Android by default, as Unreal Engine no longer supports any dynamic libs built against libc++_shared.so. iOS, tvOS, and iPadOS Crash Fix: Refactored resource transitions on Metal. Removed PrologueEncoder since it's not synchronized properly. This fixed a flickering and crash issue on iPhone14 with mobile GPUScene enabled. Bug Fix: Fixed a bug that occurrs when sampling SceneDepthAux in SunMask on IOS mobile deferred. Deprecated: IHttpRequest implementation based on NSUrlConnection is marked deprecated. This functionality will be removed in 5.4. Quixel New: Quixel Bridge 2023.0.3 improves version handling for MetaHuman exports. Rendering API Change: If your shader references GPUScene or another field in the scene uniform buffer, the RHI validation expects a valid reference for the scene UB. If this is not set, you may see an error like this: Shader expected a uniform buffer at slot 5 but got null instead (Shader='' UB='Scene'). Rendering code needs to set a valid uniform buffer for this slot. This can be resolved by adding a SHADER_PARAMETER_RDG_UNIFORM_BUFFER(FSceneUniformParameters, Scene) field to the shader parameter struct and setting its value using the helper method in FSceneView. If you're having trouble identifying which shader is missing the reference, you can run with \\"-rdgimmediate -rdgdebug -onethread\\" and find the shader in the callstack. New: Added a Volumetric Clouds console variable \\"r.VolumetricRenderTarget.MinimumDistanceKmToEnableReprojection\\" to help hide reprojection issues to due to imperfect approximation of cloud depth as a single front surface. This is especially visible when flying through the cloud layer. This doesn't hide all issues but will help in a lot of cases. The problem when using this method is that clouds will look noisier when closer to that distance. Optimized Volumetric Cloud shadows by using CloudSampleNormAltitudeInLayer correctly. This can result in performance wins between 5 to 10 percent. Added support for Groom streaming. This allows you to load and unload content based on usage. This is experimental and disabled by default. You can use the console variable \\"r.HairStrands.Streaming\\" to enable it. Added AutoLOD setting to Grooms. This allows it to dynamically adapt the number of active curves based on screen coverage. This avoids having to set this with manually discrete LODs, and adapt curve count at a more finer grain. Combined with streaming, it lowers GPU timing/memory usage. This is experimental and can be opt-in per asset. AutoLOD can be forced on all grooms with \\"r.HairStrands.AutoLOD.Force\\". \\"WPO Disable Distance\\" material expression now works for non-Nanite Static Meshes. Avoid unnecessary ray tracing shadow tracing for hair strands which saves 25% of shadow cost in test cases with many lights. Added hair attribute value picking when attribute view mode is active. Made sure GPU-scene instance count is clamped to the maximum GPU-representable index (16M), preventing overflow crashes. Added ShaderPrint GPU string, which allow to upload strings to GPU(for example, asset name) Added Blueprint exposed setter function for \\"NumCustomDataFloats\\" on Instance Static Mesh Component. Added LOD curve/point count into the hair LOD panel. Changed Groom RootUV to be optional. If an imported groom does not have RootUV imported, we no longer generate spherical mapping. Make FAtlasTextureInvalidationScope public so that external code (plugins) can invalidate a particular texture (For example, for CPU data upload). Added coverage threshold for hit proxy, in order to control at which coverage hair can be selected. Added guide type to ease understanding/manipulation of the different types of guides. This allows editing rigging directly from the Groom Editor. Added an option on the physics settings to force the Niagara component to be visible. This allows users to leverage Niagara rendering when using a custom solver. Improved Distance Field Scene Management to support more than 4M instances. Add Groom Memory Stats. Added necessary conversions from / to the working color space in Volumetric Cloud rendering. Changed how simulation cache is handled on groom to fix dynamic assignment. A groom asset now needs to opt-in to support groom cache. This opt-in ensures that interpolation data are property built for the groom asset. This option is automatically enabled when assigning a groom cache in the property grid. A groom asset with simulation cache support enabled, can now get a groom cache assigned through Blueprint at runtime. This avoids spawning actual simulation when running with a simulation cache. Groom deformer (experimental) can now write out attributes (CV color, radius, etc) in addition to position. Attributes are also readable, as well as guide data. Add visualization of imported attributes in Groom Asset Editor. Added second Virtual Shadow Map resolution bias for moving lights along with tracking of what lights are moving. When a light stops is does a gradual transition to the original bias. Added Scalability console variables r.Shadow.Virtual.ResolutionLodBiasLocal, r.Shadow.Virtual.ResolutionLodBiasDirectional, and r.Shadow.Virtual.ResolutionLodBiasDirectionalMoving to configure the LOD bias for a light that is currently moving. Attached VRAM info to AppendStaticClientPerformanceAttributes. Added per-primitive enum (ShadowCacheInvalidationBehavior) to enable users to override default engine behavior for shadow invalidations. This is useful to prevent invalidations from for example static WPO. Changed GPU-Scene data to shrink as well as grow. The console variable \\"r.GPUScene.UseGrowOnlyAllocationPolicy\\" can be used to disable the new behavior. Prevented instance over-allocation from crashing the editor / engine, clamping gpu-scene size to MAX_INSTANCE_ID, 16M. Added logging + on-screen message to surface the issue. Added the console variable \\"r.CaptureNextDeferredShadingRendererFrame\\" to trigger capture a following deferred scene render. For example, RenderDoc or PIX. Added the ability to trigger Virtual Shadow Map invalidation on Nanite LOD streaming changes. This is experimental and is controlled using \\"r.Nanite.VSMInvalidateOnLODDelta\\" (default: off). Added a new global uniform buffer scoped for the scene rather than the view, and moved GPUScene from the view to this buffer. The scene UB uses RDG (unlike View), and is modular. Improvement: Reduced groom cluster resources size (~ -15%). Improved groom per-CV color precision from 8/8/8bits to 11/11/10bits. Improved the consistency of scene view extension calls in the game viewport and scene captures. Changed cluster culling to be done in a single pass. This saves about 20% cost of the interpolation work. Clusters are not computed based on the first curve to avoid expensive cluster bound computation. GPU Skin Cache update render thread optimizations. Rendering multiple Skin Cache enabled skeletal meshes should now process faster due to batching of work. Improved how Groom Cache updates its data. Interpolation now runs on the GPU, and GPU resources are now cached to avoid constant reupload of the data every frame. Improved the Pixel Inspector naming, fixed transparency, allowed negative values and ensured that luminance also respects the working color space. Crash Fix: Fixed crashes when importing groom-only guide cache. Also fixed a crash when importing guide with zero size radius. Fixed a crash with hair with nDisplay. Bug Fix: Fixed tracing cut for Volumetric Clouds that could happen when traveling in and out of the cloud layer. We now make sure we flush occlusion queries out of memory if we've turned them off. Cloud shadow evaluation now works on the SkyAtmosphere when LUT are generated using async compute. Fixed \\"GeForceNOWWrapper::GetClientCountryCode()\\" not writing the output parameter with the country code. (2 char country code). Fixed Volumetric Cloud flickering happening after some time. The extra camera cut logic was unsafe and unstable. Applied a fix for height fog on Volumetric Cloud not working when start distance is greater than or equal to 1. Fixed Sky Atmosphere SkyLightLUT not accounting for overridden light direction. Fixed flickering SkyViewLUT texture when viewed from afar in space. Applied a fix for Static Meshes being marked dirty on load when built asynchronously. Fixed hair bound with scaled transform and take into account hair width, so that large width increases correctly the bound size. Fixed incorrect scratch buffer address when using more than two RayTracingScene layers causing crash or GPU hang. Fixed Groom Cache (guide/strands) rendering and guide cache debug visualization Fixed groom details refreshing in Blueprint. Fixed how CPU bounds are computed for groom when attached to Skeletal Mesh. Fixed slow opening of Groom Binding tab in Groom Asset Editor by avoiding loading assets. Fixed missing groom shadow when \\"Hidden in Game\\" and \\"Hidden Shadow\\" settings are enabled at the same time with Movie Render Queue using the Path Tracer. Fixed Rect Light support with MediaTexture. These textures, when assigned to a rect light, were missing invalidation to refresh their atlas content. Fixed incorrect group names when the groom does not have group ID mapping. Fixed hair strands rendering with stereo rendering. Fixed hair scene scattering not running when the scene does not have a sky component. Fixed hair physics settings working correctly with custom reset. Fixed issue where the shadow mask texture was incorrectly marked as used due to the preview shadows indicator when the preview indicator was not actually rendered because of a missing Material (in cooked builds, for example). Fixed a bug with Nanite Custom Depth rendering on some console platforms. Fixed incorrect alpha channel output for the canvas \\"Translucent\\" blend option. It now uses \\"AlphaBlend\\" internally. Fixed Directional Light preshadows in Cascaded Shadow Maps, which were broken after a recent change to WORLD_MAX for Large World Coordinates. Fixed an issue where the \\"Draw Debug Capsule\\" option on Blueprint capsule components would render with incorrect scale. Validate we have vertex data for the current MinLOD for InstancedStaticMeshes before creating SceneProxy, preventing a crash in some situations. Deprecated: Deprecated direct access to groom and groom binding members. Deprecated Ray Traced Skylight and removed it from Project Settings. Architecture New: Moved all immutable geometry collection rendering data into the Geometry Collection asset. This is built as part of Geometry Collection DDC contents. The scene proxy has been reworked to use this data. Added optional use of \\"Remove At Swap\\" when removing instances from Instanced Static Mesh Component. Also added a console variable to force the behavior with \\"r.InstancedStaticMeshes.ForceRemoveAtSwap\\". RemoveAtSwap should be faster than the previous behavior, but may break any code that depends on the current behavior. Hide MarkedForDelete resources from RenderResourceViewer Added Insight asset metadata tracking on DX12 buffers Added the DECLARE_UNIFORM_BUFFER_STRUCT API macro to allow decoupling of uniform buffer parameter struct declaration and definition. Uniform buffer parameter structs can be forward declared, and so can be used by third parties without making the full definition public. If the morph vertex buffer hasn't updated this frame or for some frames, use the last updated morph buffer for the previous morph data, so it cancels out the motion vector. This fixes a jittery issue in the Morph Target Preview tab in editor previewing using morph sliders. Added Insight memory trace DirectX12 memory allocator tracking. Changed the behavior of flag checkbox based on user feedback for the Render Resource Viewer. When unticked the resources with the flag set are now hidden from display. Also remove None flag checkbox and hide Transient resources by default. Added \\"r.SceneCapture.DepthPrepassOptimization\\" to speed up pre-pass depth rendering for Scene Capture. This is a short-term optimization to support certain features requiring a depth pre-pass and can only utilize SceneCapture to achieve it currently. Note turning it on means rendering after depth pre-pass (e.g. SingleLayerWater) is ignored, hence the result is different from when the console variable is off. Added output owner name to rhi.DumpResourceMemory command. Added Insight asset metadata tracking on DX12 textures Exposed CreateSinglePrimitiveSceneUniformBuffer in the IRendererModule to make it possible to create a Scene UniformBuffer using public interface. Added a context menu on selected resource, and context command to find assets in the Content Browser (shortcut CTRL+B) to the Render Resource Viewer. Crash Fix: Fixed an Editor-only GPU crash on unaligned texture copy when loading a streaming virtual texture with border less than 2. Fixed a crash when trying to render with empty Geometry Collection mesh data. Fixed \\"r.SkinCache.RecomputeTangents=0\\" causing crashes when rendering Skeletal Mesh with the skin cache. Bug Fix: Fixed a GPU hang that could occur when changing material type on an Runtime Virtual Texture asset. Fixed GPUScene per instance HZB instance culling on mobile where previously the HZB was not being bound. Fixed bad motion vectors being generated for some instanced objects. Fixed bad hash calculation of virtual texture pool settings. This could lead to an issue where we did not correctly detect when the pool size settings are changing. Removed render thread access of parent UTexture from FVirtualTexture2DResource. This fixes race condition check firing when the Virtual Texture sRGB flag is flipped. Fixed off by one logic in check() for Static Mesh LOD count. This would trigger a check() if we used 1 less LOD than the maximum. Fixed Skeletal Mesh post load being called on game thread from Niagara when actual loading is still happening from the loading thread. Fixed an issue when multiple viewports are open, only the viewport in focus has valid velocity on skeletal meshes. This is fixed by switching to use GFrameCounter which is incremented once per engine tick, so multi views of the same frame share the same value. Fixed the Skin Cache Editor debug visualization modes looking different from their console variable equivalent. Fixed the shading difference and the debug texts not showing up correctly. Fixed Instanced Static Mesh loose params warnings in debug build. Create a loose parameter uniform buffer to capture those parameters. Lighting New: Volumetric Fog buffer allocations are now independent from dynamic resolution scaling. Sky Light created from Environment Light Mixer uses real time capture by default. Added support for Rect Light Volumetric Fog light functions. Fixed wrong color of translucent shadow volume when light is an atmospheric light. Added Exposure as new light unit. Improved order independent transparency triangle sorting precision. Added Virtual Shadow Map high quality shadow filtering for translucent surface for Substrate and legacy path. This is a global opt-in feature (r.Shadow.Virtual.TranslucentQuality). Bug Fix: Fixed Subsurface Profile causes an orange rim using Ray Traced lighting at certain angles. The issue is caused by not enough penalty to the depth in the screen-space bilateral filtering. Fixed missing Volumetric Fog light function from atlas for Spot Light. Fixed incorrect atlas packing when textures are streamed in / out and require a full atlas refit. Also fixed a crash when Rect Light atlas force update is enabled and lights get toggled on and off. Fixed a potential Ray Tracing performance issue with invalid shadow rays being traced. Fix incorrect ref counting decrements when texture is removed from Rect Light texture manager. Fixed unclamp radius / length for Point / Spot Lights causing visual artifacts. Fixed overflow when computing Rect Light texture MIP causing incorrect atlas packing. Lumen New: Height fog in Lumen Reflections is now partially supported (only Height Fog, not Volumetric Fog). Lumen reflection on translucent now accounts for roughness and goes through the denoising process. Lumen reflections with hit lighting now support multi-bounce reflections, controlled by \\"Max Reflection Bounces\\" setting in Post Process Volume. Lumen Hardware Ray Tracing path is now fully compatible with async compute and it's enabled by default on supported platforms for improved performance. Added boolean \\"Allow Front Layer Translucency\\" to material, which allows to control whether given material should write Front Layer Translucency. This is useful to disable small particles from using Front Layer Transparency or solve sorting issues. Improved Lumen Scene tracking of primitives. Primitives are now included in the Lumen Scene only if they can be traced by a currently active tracing method. Added support for Nanite Ray Tracing in Lumen HWRT and Ray Tracing Debug Visualizations Increased \\"r.Lumen.Reflections.MaxBounces\\" limit to 64. It controls the max number of bounces when multi-bounce Lumen reflections are enabled. Added \\"r.Lumen.Reflections.VisualizeTraces\\" debug utility. It visualizes a dedicated reflection ray traced from the current cursor position. Replaced Lumen Scene visualization with Geometry Normals visualization in Lit->Lumen->Overview visualization mode. Geometry Normals view is useful to spot any issues with distance fields or ray tracing setup. Added support for two sided and thin foliage shading models in Lumen hit-lighting path. Enabled ray tracing culling by default in order to simplify initial setup. Improved global distance field ray hit evaluation, decreasing possibility of sampling surface of an occluded object which is near to the hit point. Made significant Lumen HWRT optimizations which hit-lighting optimizations targeting PC. Crash Fix: Fixed a crash when setting world space radiance cache probe resolution below supported values. Bug Fix: Fixed opacity clipping not happening on Lumen front translucency. Fixed geometry normals on meshes with negative scale (flipped culling) when using hit lighting reflections. Fixed Lumen not working with ISM / HISM due to automatic primitive merging in surface cache. Fixed an issue with \\"r.Lumen.ScreenProbeGather.ScreenTraces.HZBTraversal.SkipFoliageHits\\" when Substrate is enabled. Fixed mesh card generation hangs on specific meshes due to an EmbreeRay issue where EmbreeRay.ray.tnear could end up being further than EmbreeRay.ray.tfar causing an infinite loop. Fixed Material Ambient Occlusion which was incorrectly applied on top of emissive when not using async Lumen, and on top of emissive and direct lighting when using async Lumen. Fixed Time material node being always set to 0 when capturing Nanite meshes into surface cache. Fixed artifacts when running on GPUs supporting only 64 thread wide waveops. Fixed missing reflections far away in the distance due to a hardcoded 1000000.0 cutoff in the bilateral filter. Fixed surface cache corruption after surface cache atlas resize or compression settings change. Fixed SWRT reflection traces feedback for mesh SDF and heightfields Fixed radiance cache lag in scenes with lots of geometry detail (foliage, trees). Such scenes were requesting too many new probes per frame, preventing cached probes from getting any updates. Materials and Shaders API Change: Please use the more efficient UMaterialExpression::GetInputsView() instead. Any code explicitly using FShaderCompilerInput::bGenerateDirectCompileFile should be replaced with EnumHasAnyFlags(Input.DebugInfoFlags, EShaderDebugInfoFlags::DirectCompileCommandLine) instead. FShaderCompilerEnvironment::GetDefinitions is now deprecated; only internal shader preprocessing code can now access values of preprocessor definitions. Any code which was previously retrieving definitions by value should set such values via FShaderCompilerEnvironment::SetCompileArgument (or via the helper SetDefineAndCompileArgument which can be used for values which are consumed by both the preprocessor and compilation code) and retrieve these values via FShaderCompilerEnvironment::GetCompileArgument. Remove any usage of the FShaderPipelineCompileJob::bFailedRemovingUnused; it's no longer needed or used anywhere in engine code. In the unlikely case there is code referencing FShaderCompilerEnvironment::RemoteServerData it should be removed if possible. If there are use cases of this for which other mechanisms (such as the new compile argument functionality) are not sufficient, please contact the UE dev team. New: Optimized material expressions concerning loop detection. This removed individual calls to UMaterialExpression::ContainsInputLoop() and instead moved graph loop search in HLSLTranslator::Translate(). Since this can be done once for all inputs, the visited node set can be shared, making the loop search algorithm O(n), which visits each node exactly once rather than O(n^2) that performs the loop check for each node independently. This optimization, combined with other optimizations, makes translating an expensive material from 5.6 seconds to 0.9 s (a material from Fortnite was used in this test). Added code in Material Interface serialization function that validates the associated EditorOnlyData name to be \\"canonical\\" (name of the material followed by \\"EditorOnlyData\\"). If the name isn't canonical it may cause problems with the editor running on cooked content. The validation code will try to rename the EditorOnlyData to the correct name. Added support for virtual texture feedback behind a Single Layer Water Material. We stochastically drop some writes to the feedback buffer so that we don't overwrite all of the content from the surface beneath. The legacy MCPP preprocessor was removed and all shader preprocessing is now done with the new \\"stb_preprocess\\" library. Made a change that modifies and future-proofs the mechanism which determines which debug outputs should be dumped for a particular shader compile input. Rather than an ad-hoc collection of boolean flags, a bitfield enum class is now used instead. Added a new \\"compile argument\\" functionality on the FShaderCompilerEnvironment class. This is intended to be used for any generic arguments required by the IShaderFormat implementations as input to the actual compilation process; previously the preprocessor definitions were being abused for such arguments. This is a requirement for forthcoming work which improves the job caching and deduplication mechanisms. Added functionality to validate the consistency of the shader job cache. If enabled, compilation will be run for all shader jobs, even those that would have been cache hits, and then the resulting output will be compared with the existing cached value. Output for any mismatches will be dumped to Saved/ShaderDebugInfo/CacheMismatches, with files named according to the input hash whose outputs do not match, along with log warnings indicating the mismatch and the associated filenames. Since this effectively disables the job caching mechanism by always compiling jobs, this should only be enabled locally in the case where a cache collision is suspected (which could potentially be the case when DDC is reporting non-determinism in shader maps). Implemented \\"GetShadowReplaceState\\" for ray traced shadows. Implemented support for explicit #error directives in the shader source in the new preprocessor library. Fixed a mismatched string formatting argument in the shader compiler (for hlslccflags). Dragging a cubemap texture onto a mesh in the Editor now generates a compiling Material. Added camera relative origin options for object, actor, and particle Material expressions. Performing calculations in camera space is more precise and is usually faster by avoiding double precision math in Materials. ODSC + Staged builds — The ability to launch a staged build and only use the COTF server to process recompileshaders commands. Adds a cmd line option, -odschost=127.0.0.1 which allows the game to connect directly to the COTF server, but only to send ODSC recompileshaders commands. If we don't have a default COTF connection (for cooking assets), we create our own connection to the COTF server. Refactor code to send a command to the COTF server into a function. That way if we don't have a \\"special\\" ODSC only connection we can use the command that way. Fixed an issue with the \\"RecompileShaders material\\" command. It would only search and find a single material and recompile it. This ignored any material instances. Now the code takes into account finding all dependent instances and issuing a recompile command for them. Added cook stats to track critical path, game thread time to submit Material compile jobs. On Lyra this accounts for ~10.4% of a full cook with -noshaderddc and a warm cache for everything else. On CitySample this accounts for ~8.9% of a full cook with -noshaderddc and a warm cache for everything else. Added EffectiveParallelization to the cook analytics for shader compilation. This statistic shows up as \\"Shaders_EffectiveParallelization\\". NewGatherAnalytics should be grabbing the CompileStatsLock since it is reading the stats - The console variable r.SSProfiles.Transmission.UseLegacy was added to use the legacy transmission profile. This is enabled by default. When legacy transmission is disabled, the transmission profile is more physically accurate. When enabled, more artistic license is possible by adjusting the ExtinctionScale. ComputeAllStateCRC()was added. This provides a way to more quickly detect changes to a Material, including changes to any Material Functions or Material Instance parameters. The Material option \\"Always Evaluate World Position Offset\\" was added. When enabled, World Position Offset is always evaluated for a Material, and cannot be disabled by \\"Evaluate World Position Offset\\" or \\"World Position Offset Disable Distance\\" on the component. This override is intended for Materials that should not disable World Position Offset, even for performance purposes. Added Shader Compilation stats to cook analytics. This adds GatherAnalytics to the various shader compilation classes allowing each of them to pass their own stats back to the cook. These stats have the base name \\"Shaders_\\" as a prefix. The goal is to capture high level stats which are good indicators of performance and are useful for catching regressions. Also added: Shader Job Cache stats to track Queries Hits, NumInputs, NumOutputs, and MemUsed. MemBudget Stats that include ShadersCompiled, TotalThreadTimeForAllShaders, and TotalThreadPreprocessForAllShaders. The compiler options flags CFLAG_CullBeforeFetch and CFLAG_WarpCulling were added to control warp culling and Cull Before Fetch hardware optimizations. Added the console variable r.MaterialLogErrorOnFailure which emits an error when a Material fails to compile (instead of a warning). This variable defaults to false, but you can enable it from the command line with the following: -dpcvars=\\"r.MaterialLogErrorOnFailure=1\\" Added a cook stat to provide path time metrics on UMaterialInstance::PostLoad. This accounts for 7% of critical path time when cooking certain projects. Improvement: Optimizations in Material translation code amounting to 50% speed up. Optimized function UMaterialExpression::GetInputs() with highest exclusive run-time during material translation from 19.79% to 1.79% exclusive run time. This change caches the inputs upon expression creation by default and returns a TArrayView instead of always creating a new transient dynamic array. The optimization also simplifies code for some Expression types. Also optimized ContainsInputLoopInternal() to use a linked list of stack allocated nodes instead of Pushing/Popping from a dynamic array. Don't set EarlyZ if we are sampling virtual textures but not doing any virtual texture feedback. This is a small optimization for the case of rendering with runtime virtual texture and not using feedback. Typically that can happen with landscape grass. Implemented changes to hash and calculate Material Debug Name once per-Material instead of once per-shader job. FStrings are passed by reference in PrepareMaterialShaderCompileJob instead of copying them. Crash Fix: Added a check that reports errors if a parameter in a Material is bound to different values, instead of silently trying to compile the Material anyway. This was causing a crash when two Material functions containing a shared parameter bound to different values (for example, different textures) were used in the same Material. Fixed access in \\"ItemPropertyNode.cpp\\" to a shared ptr constructed from a weak ptr. Code was not testing that object still exists, causing a crash when resetting Linked Material Blend Layer to Default. Fixed a bug in MaterialX Luminance, which caused the Editor to crash after dragging an additional Luminance variable from the same connected node. Fixed a crash caused by errors in the code for Material duplication. Implemented changes to prevent the Editor from crashing when the user selects a Material whose ShaderMap contains null shaders. This change only makes the Editor more robust and prevents the crash; shaders in the ShaderMap may be null after loading due to external issues. Fixed an Editor crash when Material Parameter nodes were renamed to an empty string. Empty strings are now ignored when renaming a Material Editor node. Bug Fix: Fixed too intense transmission in the Subsurface Profile shading model by extending ExtinctionScale from 1 to 100. This reduces the transmission distance when the scale is larger than 1. Resolved several issues with CompileFXC.bat which prevented it from working correctly. Addressed issues with the FRHIDispatchIndirectParameters size which could unnecessarily cause a full shader recompile on some platforms. Fixed an issue with decals being rendered a second time in the translucent pass. This could happen for some depth of field setups, including the cine camera view. Fixed an issue which caused oversaturated emissive GBuffer decals caused by shader code typo using DECAL_RENDERTARGET instead of DECAL_RENDERTARGETMODE. Fixed an issue with wireframe colors on shipping builds. Fixed a bug where MaterialInstanceDynamics created in the Blueprint Editor were not marked as public. This prevented the level from being saved. Fixed a subsurface transmission bug where the transmission lookup table (LUT) is incorrectly built based on unit scale for the subsurface profile. Fix a bug preventing some Materials from being moved to a different folder in the Content Browser. The issue was caused by an invalid state of the Material EditorOnlyData. Disabled ability to override parameters that cause Material Instances to create a new shader permutation when parenting a restricted (non-base game cooked) parent. In restrictive mode, material instances could not inherit from a cooked material not in base modules. Now material instances can inherit from such restricted materials as long as they do not introduce a new static parameters permutation and thus a new shader. To prevent this, the user interface disables the checkboxes that would trigger a new shader to be created, with full validation is still performed at cook time, so even if a user manages to create a material instance with a static permutation, this would be rejected by the content worker. Fixed a memory leak which occurred when Planar Reflections outside the camera view were culled without releasing the memory. Solved an issue with incorrect Material EditorOnlyData name messaging being generated during cooking. Fixed artifacts in the Clear Coat shading model which occurred when one of the components of the base color is exactly 0.0. Fixed a bug with DistanceFieldApproxAO returning an incorrect result when the Material specifies an input Normal. Fixed a bug whereby Material Instances with different sets of static parameter values and other flags would race to print out debug information, resulting in different sets of debug info from one run to the next. Solved a regression in the job cache hit rate, which occurred because the debug info path was always included as part of the computation of the job input hash. This information is now excluded from the hash, restoring and potentially improving the hit rate. Fixed a minor bug in the shader parameter parser functionality which was assuming only a single space between #line and the line number in line directives. Fixed a crash in the Material Analyzer which occurred when a StaticComponentMaskParameter was present. Fixed an enum mistake in UMaterialInterface::GetFontParameterValue. Deprecated: Reintroduced (and deprecated) the older version of ContainsInnerLoopInternal() in UMaterialExpression. The FShaderPipelineCompileJob::bFailedRemovingUnused field was deprecated. The only purpose of this field was to append some information to a log message which was determined to be unnecessary. The FShaderCompilerEnvironment::RemoteServerData field was deprecated. Since some IShaderFormat-specific remote compile functionality was removed, this is only used for adding unnecessary ifdef'd out debug info to associated shaders. Removed: Removed const from GatherAnalytics since it now needs to grab the lock and call GetTimeShaderCompilationWasActive. Nanite New: Add an option on Static Mesh for WPO not to write velocity. We default to writing velocity, but the option can be useful if we know that we have \\"static\\" WPO for things like camera-facing impostors where we don't want that to generate motion vectors. Added support for Spline Mesh Component with Nanite. This is experimental. Improved visual quality of selection outlines of Nanite in the editor. There are no more jittering, or occlusion issues. Implemented instance culling hierarchy and support for Nanite instance culling based on this. The feature is disabled by default (r.SceneCulling), and may be considered Beta for this release. Added a new show flag to enable/disable the visualization of Nanite streaming data (Show -> Nanite -> Streaming Geometry). When disabled Nanite meshes will only be rendered at the quality level that is always resident in memory. Added new Explicit Tangents option to Nanite mesh settings. When enabled, the tangents are stored explicitly on disk instead of being derived implicitly at runtime. While this comes at a small additional storage cost, it can be preferable in cases where the implicit tangents are not precise enough. Optimized CPU overhead of Nanite streamer Improvement: Implemented performance improvements to NaniteStreamOut. New sliding window vertex cache for pixel programmable. 20% faster masked foliage rasterization in forest scene. Crash Fix: Fixed a crash that would happen in building Nanite if the mesh had no triangles. Fixed a crash in the Nanite streamer that could occur on shutdown. Fixed a crash in the Nanite streamer that could occur on IO errors. Bug Fix: Fixed a bug in the editor where selecting an ISM / HISM actor or component would not render selection outlines for Nanite instances. Fixed the \\"Shadow Pass Switch\\" Material node for World Position Offset, Pixel Depth Offset, and Opacity Mask on Nanite materials. Applied a fix for the Camera Position Material Expression node returning the wrong position for shadow views with Nanite programmable rasterization. Fixed issues with selection and deletion of Nanite Foliage Instances in the editor. Fixed an issue where some Nanite visible clusters' flags could get cleared, causing WPO to be disabled for them. Fixed issues with Custom Depth rendering of Nanite on consoles. Fixed an issue where reading custom data as a vector in a Nanite Material to calculate World Position Offset would always result in using the default value. Fixed issues with rendering Nanite custom depth with multiple views (for example, split-screen and VR) Added a check when the build process goes out of memory and prints better log info (error code and Graph->Num when PartGraphRecursive fails). Fixed Client issue that does not respect Allow Masked Material set in the editor Fixed an ensure that could trigger when Nanite meshes were loaded, but there were no Nanite meshes in the scene. Neural Network Engine (NNE) New: NNEModelInstance has been introduced to prepare weight sharing optimizations. A runtime now creates a model, and one or multiple inferable model instances are created from a model. NNE runtimes have been moved to own plugins which need to be enabled in addition to NNE to become available. Improvement: The NNERuntimeORTCpu has been updated to use the ORT 1.14.1 library. UNNEModelData assets have an allow list to exclude certain runtimes from cooking it. It can be accessed by double clicking the asset. The feature defaults to an empty list which will cook for any runtime matching the previous behavior. UNNEModelData assets can be reimported and opened in editor (using netron). Deprecated: The old NeuralNetworkInference (NNI) has been removed, please use NeuralNetworkEngine (NNE) instead. Niagara New: Niagara opaque particles can now collide with depth buffer without colliding with themselves. It can be achieved using the new PartialDepthBufferCollisionQuery node. This is Experimental. Implemented Summary View 2.0 which allows the user to create custom views for an emitter. The primary use case is exposing specific inputs for complicated emitters, such as fluids. However, this is a useful feature to put emphasis on specific parts of an emitter. Now we allow Python conversion scripts to reset values to their default and set hidden inputs on the new module. Exposed Timed Niagara Effect Properties to Blueprint. Added drag/drop support for emitter assets in the system editor. Made visuals for convert nodes more compact. Added support for curve assets to the curve data interfaces. Added Collapse Categories support for the stack. If a Data Interface (any object, but primary consumers are Data Interfaces) has that flag, root level categories are skipped and instead their children are used. Revamped the Stack type UI (more compact, more color, better visuals). Added a setting to make numeric inputs feel snappier by updating the sim after every input change. Improved metadata for module inputs. Added True argument to allow the deletion of a static switch variable when no static switch is referencing it anymore. Added Inline enum support for static switches to Niagara. To use it, set a static switch node to Integer mode. The case labels are now editable. If edited, the display of the integers will show up like an enum in the Niagara stack when editing module inputs. To change this, access the Widget Customization entry in a variable's settings. Default is the default integer view, and Enum Style is the enum-like view. This is useful for one-off static switches that are kept in a single module and don't need an entire enum asset to be created and maintained. Added widget support for stack inputs (sliders, min/max, volume). Niagara renderers can now be moved via context action. When pasting an entire emitter from one system to another, user parameters are now copied with them and added to the new system, if they don't exist yet. Added age update mode dropdown to life cycle track. Added a component and life cycle track by default when adding a Niagara Actor to sequencer. Added a warning if life cycle track is not set up correctly for sim caching. Added Python script support for deprecated module changes. Changed the Reset Simulation command (hitting Space) to also resume playback if currently paused. Reordered system properties. User Parameters now support widget customization via the User Parameters Hierarchy Editor. This includes setting Min and Max, displaying floats or integers as sliders, and more. Added a default UI state option for emitters that determine if they will be shown in Summary View or default view when added to a system or creating a new emitter. Changed the Behavior Examples label to Learning Examples. Added logic to ensure the emitter editor data exists when an emitter is post loaded or initialized. Simplified emitter properties: Removed Combine Event Spawn option. Removed Script Category property for emitters in systems. Removed Asset options properties for emitters in systems. Moved Attributes To Preserve to the advanced view. Hide Pre Allocation Count is now hidden if the mode is automatic estimate. Moved Max Delta Time Per Tick to the plugin settings. Added a decal icon for the decal renderer. Changed the tab names Selection and Selected Emitters in the Niagara System editor to Details, including the icon, to be more consistent with the engine. Fixed pin coloring for constant value make nodes. Added thumbnails for curve assets. Added a context menu option to record multiple cache tracks at once. Added a new scratchpad action and set parameters to suggested in menu. When renaming User Parameters in the User Parameters tab, name verification is now implemented. Added duplicate script variable validation and fix logic. Validation and Fix can be run via command line in editor. The commandlet can be run via the project startup command line and will print out all scripts with their given guid conflicts. Added a custom search box that adds filtering for parameters in the NPC editor. More view settings are now saved per-asset (view location, view rotation and orbit mode) or in a config file to maintain Niagara viewport settings across sessions. Improvement: Improved the UX to expose options of function script input nodes. Crash Fix: Added reallocate pins when a static switch node references a different, pre-existing script variable via renaming. This fixes a crash where the visuals expect the pins to be created under the new static switch variable. Fixed a crash when trying to set uobject-attributes in the stack. Refactored a temporary array of transient stack entries that could get garbage collected anytime and cause various crashes. These stack entries managed stack entries for comment nodes, so now we have a proper comment collection stack entry. Bug Fix: Added various small fixes to static switch nodes. Fixed an ensure being triggered when editing any FText field in Niagara script details. Fixed a bug where sim caching can lead to minute-long hitches with large numbers of particles. Fixed a bug where disabled modules could generate compile warnings. When applying modules that are in use in an emitter/system, the module no longer gets deselected, and the UI gets refreshed so we get live changes. Fixed a bug where component renderers were still visible when another emitter was running isolated. Fixed a compilation bug with disabled nodes and data interfaces. Removed the search box in the Details panel of the NPC editor. Fixed the scroll bar not appearing in the Niagara Parameter Collections. Fixed copy paste of modules not properly pasting values for static switches in static switch chains. Fixed issue when finalizing empty sim caches. Removed of incorrect default pins that would show up as 'None'. Fixed scratch pad parameter panel bug where if a used function had the same parameter as the script asset that owned it, it would override the asset's own parameter. UI wise it would look fine due to the same name + type, but selecting it wouldn't work as the guid wouldn't match. - Removed sub graphs adding their script variables to be used for the script parameter panel - Refactored into using the graph's script variables directly instead of using the reference map. Reference map is now only used for reference count, not for item creation. Fixed copy paste of modules not properly pasting values for static switches in static switch chains. Fixed system parameter panel selecting parameters in scratch pad via name instead of via guid. Fixed dragdrop ops of different types than FNiagaraHierarchyDragDropOps from being used in the hierarchy editor. Fixed issue when adding a new user parameter while a custom section is selected. Fixed issue where the length of the life cycle track was not evaluated correctly when caching a Niagara simulation. Fixed LWC issue in camera DI. Fixed emitters opening up the parameter panel to \\"Active Module\\" instead of \\"Active Overview\\". Fixed editor only parameters not being marked as RF_Transactional. This fixes issues with transactions not properly being recorded in Niagara. Fixed issue where replacing a module with another module using the same name caused it to lose static switch inputs. Fixed issue where HLSL compile errors were not correctly shown in the stack. Fixed a crash when using LWC structs. Fixed issue where SWC structs would appear in the UI. Fixed issue where using LWC structs as module inputs would not use the correct struct converter. Fixed the script variable customization to also account for parameter pins that are disconnected from an output node. This fixes an issue in which a disconnected parameter pin wouldn't show its custom pin if the value mode was set to 'custom'. Also, you no longer need to reselect a parameter after adding it to a parameter map get node to make it show the default value Added additional call to replace user param references on emitters and fixed renderer attribute binding references not being fixed when renaming a user parameter. Fixed issue where the wrong asset was used to initialize sequencer recording. Fixed emitter assets not dirtying when disabling a sim stage. Fixed loss of parameter references when updating an input parameter's name in a module. The 'BoundPinNames' array was getting updated with an incorrect parameter handle, which made the lookup for subsequent renames break Fixed issue where changing versioned properties would not dirty a script/emitter. Fixed issue with async raytrace data interface not issuing traces. Stopped considering input pins for get nodes as parameter reference This fixes an issue where a pin that was only referenced in a get node would count 2 references, which would stop it from being renamed properly from pin as it would duplicate a new parameter Fixed transform function descriptions in camera DI. Fix for the Apply button in Niagara scripts only checking for the exposed version guid instead of the currently edited version. Fixed missing stack refresh when changing a user parameter name. Fixed issue where the Details view would not properly show rows with changed visibility after a tree refresh. Fixed issue when undoing an emitter add transaction. Fixed an unnecessary refresh in the parameter panel causing loss of selection after modifying a value of a variable. Added metadata to allow multiline text entry for python script. Fixed sequencer caching bugs. Fixed Blueprint API of \\"spawn system with parameter\\" functions. Fixed output & transient parameters appearing outside their own stage when opening a parameter menu. Fixed Custom HLSL pins not being modifiable. Also added visibility delegates for action \\"Reset to Default\\" and \\"Promote to Parameter\\". Also changed the Pin Section name used in Niagara to use the parent section name so we no longer have 2 sections called \\"Pin Actions\\" at times Cleanup of old rapid iteration parameters used name only, not type. This resulted in cases where old parameters that used the same name as a new parameter of different type would not get cleaned up. Fixed multiple lookups in the merge manager that looked up by name only instead of name + type. This in conjunction with the fix above results in more stable diff process. All of this fixes an issue where some fluid emitters were showing or not showing the 'reset to parent emitter' arrow wrongly 'Ghost entries' no longer appear and a stack search result gets maintained even after changing a value in the stack. Focusing the scratch pad manager tab when creating a new scratch pad so you can immediately rename it Made the toolkitmodebase public so that other parts in the plugin can access the tab names properly Fixed \\"parameter for\\" node. Fix highlighting of multiline HLSL comments. Fixed issue where the simulation was always reset after a change, even when paused. Heterogeneous Volumes: Introduce per-volume step size based on local-space step factors. Step size is now calculated in local space as a function of voxel width, projected along the ray direction. Toggle global step-size values to -1 (disabled). Change default MaxStepCount to 512 steps. Fix for alpha-compositing issues with Heterogeneous Volumes when using the Niagara baker. Sort heterogeneous volumes by camera-depth and adjust compositing to match. Path Tracer New: Added depth pass for path tracing that matches the behavior of the rasterizer path. The output is in DepthZ so post process depth of field works now as a bonus. You can use the same depth post process material to output in Movie Render Queue. If you'd like to disable the path traced depth buffer and use the depth from the rasterizer instead, you can use \\"r.PathTracing.Override.Depth 0\\". Also, the \\"Output Depth\\" has been renamed to \\"Output Depth and Velocity\\" in Materials. Added Post Process Material and Movie Render Queue support for path tracing buffers. This means that Post Process can access path tracing buffers (raw/denoised radiance, albedo, normal, variance) with unique materials using the \\"Path Tracing Buffer Texture\\" Material Expression. And, access means that output in Movie Render Queue is supported. Added basic support for Substrate has been implemented. The path tracer can now handle Substrate Materials, including multi-layered ones. Substrate's MFP is mapped to random walk subsurface scattering for opaque materials and to absorption in translucent cases. We expect to see fairly close agreement in many cases, though this support should still be regarded as experimental. Support for translucency and thin shading models are expected to improve in future releases. Sky meshes should be included for raytracing when using the path tracer The console variable \\"r.RayTracing.ExcludeSky\\" is now ignored when the path tracer is active. Implemented support for DBuffer Material Expression functionality in Path Tracer Added a Blueprint call to invalidate path tracing output. The intent of this call is to give control over cases that cannot be handled by automatic invalidations. The path traced image now invalidates itself when a Skeletal Mesh morph target changes. Changed refraction rays to behave more like camera rays with respect to the \\"Affect Indirect\\" primitive setting. This makes refraction and transparency behave more consistently with one another. Added support for path tracing heterogeneous volumes. This uses the Voxel Grid Pipeline to create global acceleration structures to represent heterogeneous volumes in the path tracer. Creation of global acceleration structures is memory intensive. Refer to the corresponding Voxel Grid Pipeline CL 25170595 for instructions on parameter tuning to control memory and quality. r.PathTracing.HeterogeneousVolumes (default = 0) Enables heterogeneous volume rendering in the path tracer r.PathTracing.HeterogeneousVolumes.RebuildEveryFrame (default = 1) Rebuilds the acceleration structures every frame. Adding volume emission to the path tracer. Improvement: Improved SSS random walk sampling. Improved volume light sampling for local lights. OpenImageDenoise transfers have been sped up. Some optimizations were made to the pixel readback which saves some denoising time. Bug Fix: Fixed darkening in subsurface scattering when the scattering radius is small. The code now more seamlessly blends towards the diffuse behavior instead. Fixed issue where materials using non-tangent space normals could have flipped normals in some cases. Fixed fireflies that can occur from the rough diffuse shading model at grazing angles. Fixed the \\"Path Tracing Quality Switch\\" node in materials not working in decal materials. Removed: The Path Tracing Post Processing Volume setting for Filter Width for anti-aliasing has been removed. We found the default value (3.0) is effectively the optimal one and that there wasn't much reason to change it. If you still need this property, you can use the console variable \\"r.PathTracing.FilterWidth\\" to adjust it. Postprocessing New: Added a Post Process Setting to Image Effects with Sharpen. This controls the strength of image sharpening applied during tonemapping. RHI New: Vulkan Bindless: Push a draft implementation of the FVulkanBindlessDescriptorManager that uses VK_EXT_descriptor_buffer. Uses one descriptor set for each type of resource, each backed by a descriptor buffer. Everything is bound and visible to every shader, except uniform buffers which are bound per draw/dispatch. Uses a single pipeline layout for everything. Initial buffer sizes for each descriptor type can be configured through CVars (they do not automatically grow yet). Still very experimental, and requires multiple other features to be disabled. VulkanRHI: Use array for dynamic buffer allocations and removed the hardcoded \\"NUM_BUFFERS=3\\" value. Use a fence to manage buffer availability. Do not rotate dynamic buffer usage when a staging buffer is used for the copy. VulkanRHI: Vulkan SDK upgrade to 1.3.239 Removing full-type RHI_API uses and adding them to members that need it. This reduces export counts and is part of upcoming coding standard changes. Moving D3D12 Extension includes into their own headers. Updating to Agility SDK 1.610.2 Moving a couple DDSPI fields to Editor-only code blocks, and moving Editor-only DDSPI types into the cpp files to keep Editor includes out of the global scope. VulkanRHI: Moved Engine minimum core version to Vulkan 1.1. VulkanRHI: Added VULKAN_SM6. Moved features and requirements around to match what was done on D3D12 SM6. Making FRayTracingGeometryInitializer not a memory layout type since nothing needs it like that anymore. VulkanRHI: Use Vulkan profiles to validate support for a feature level on startup before call to CreateRHI(). VulkanRHI: Added Vulkan_1_3 support for shader compilation, which is used for VULKAN_SM6. Improved DX12 GPU breadcrumbs that track all active, finished and not started scopes on the GPU. The new implementation logs all scopes currently scheduled or active on the GPU. RHI: Avoid re-allocating the OutData array in RHIRead*SurfaceData when possible. Enabled async compute by default in D3D12 on NVIDIA Ampere and newer cards. The command line argument \\"-vulkandebug\\" allows usage of our distributed vulkan validation layers for both Windows and Linux. Bug Fix: Bumped nVidia minimum version to 527.27. A random issue with landscape tools has been known to be problematic for drivers less than version 526.67. The exact cause is unknown but a resolution appears to have been made in one of the 527 releases. The first version to not exhibit the problem is 527.27. Fixed FRHIGPUTextureReadback to work with subrects, as well as volumes and texture arrays. Fixed structure init in Vulkan RHI. Removed: Removing RHI code deprecated in 5.0. Removing deprecated RHI symbols. Removed CoreMinimal includes from public RHI headers. Removed the deprecated RHISetComputeShader. Substrate New: Brought back proper premultiplied alpha that can be toggled on Materials and Material Instances. Coverage over the background can be overridden from the root node when Alpha Composite Blend Mode is selected. If not plugged in, coverage of over background is off and regular blending is used. Added support for decals with Substrate Materials. GPU Lightmass now supports Substrate Materials. Added support for glint BSDF to Substrate. Ray tracing material shaders use fully simplified material for smaller payload. Optimized Substrate shader compilation time. Added in Material Editor complexity on Slab node. Substrate now uses progressive material simplification to fit in memory. Simplifying Slabs at the bottom of the material topology first. Made multiple improvements to the Material Editor Substrate tab. Added support for Planar Reflections to Substrate. Lumen card capture now uses fully simplified material with Substrate. Added distortion coverage mode to be compatible with legacy distortion in Substrate Materials. Fixed some editor pop up message due to bad bitfield macro when using Substrate Materials. MFP is no longer clamped to fp111110 when in forward to be able to get to an transmittance closer to identity=1 (invisible surface). Allocation of tile tile list buffers is now independent from the dynamic resolution when using Substrate. When a new material is created using Substrate, a simple UE4-like lit shading model material function is used instead of a Slab. This shows that Substrate works with material function and makes material authoring simpler by default. Added Substrate node for converting Index of Refraction to F0 and rotating anisotropy tangent. Added Substrate Standard Surface nodes. Add Specular Profile to Substrate. This allows the artist to provide a custom LUT describing specular behavior for view and light angles. The LUT can be procedurally generated or provided from a texture. Added material buffer allocation policy. This allows control of how the material buffer is allocated. This is controlled with \\"r.Substrate.BytesPerPixel.Mode\\". When set to 0, allocate material buffer based on view requirement. When set to 1, allocate material buffer based on view requirement, but can only grow over frame to minimize buffer reallocation and hitches. When set to 2, allocate material buffer based on platform settings. Added Byte Per Pixel view mode for Substrate. Change Substrate Cloth / Sheen model to From Charlie to Disney LTC. Added normal curvature-based roughness support. Added Substrate Topology previsualization on the Substrate node within Material Editor. Improvement: Improved Substrate diffuse color sRGB encoding. Crash Fix: Fixed a crash when assigning a Material Function onto new material that is reopened later. Fixed a crash when a Substrate Material has more shared tangent basis than allowed. Bug Fix: Fixed Substrate Material Preview on nodes to account for the Substrate tree from the previewed node only. This fixed material function input / output, reroute nodes and everything in between that is not directly connected to FrontMaterial. Applied a fix for Virtual Shadow Maps and Subsurface Scattering using Substrate Materials. Fixed opacity clipping for translucent writing velocity. DXC and SPIRV-Cross fixes to enable Substrate in D3D11. Fixed Volumetric Cloud Extinction being grayscale. The Unlit Shading Mode now also works with refraction. Fixed emissive exhibiting different behavior when enabling Substrate. Decals now do not impact the look of other substrate material when in range of effect. Fixed a wrong opacity with Substrate for depth and velocity. Fixed \\"UseDiffusion\\" affecting the look of simple Volume Slabs. Slab now respects Additive Blend Mode. Fixed bad transmittance when doing masking through a vertical layer operator and more than 2 layers. Applied a fix for Substrate interacting with responsive anti-aliasing. Fixed microoclusion/F0/F90 usage. Brought back support for \\"Custom UV\\" on root node. Substrate now properly accounts for \\"Allow Negative Color.\\" Fixed Lumen ScreenProbeGather ReferenceMode when Substrate is enabled. Fixed Lumen ScreenProbeGather and Lumen Reflection temporal filtering with multi-BSDFs. Fixed Lumen history being reset on LumenScreenProbeGather & LumenReflections when Substrate 'max BSDF count' change. Fixed legacy Eye Material conversion with Substrate. Avoid non-necessary initialization causing massive shader stall. Reduce base pass cost of complex material by ~50%. Fixed ray traced shadows with Substrate Fixed Lumen specular interreflection with Substrate. Fixed Lumen ScreenProbe / Reflection history reprojection with dynamic resolution scaling when enabled. Also fix Lumen ScreenProbe normal disocclusion. Fixed Lumen.Visualize.IndirectDiffuse with Substrate enabled. Added support for short range Ambient Occlusion with Lumen HWRT path. Fixed \\"IsThin\\" support with SSS diffusion and SSS profile diffusion (now it works as expected, and diffusion is no longer scaled incorrectly) Also fixed \\"IsThin\\" to support surface for translucent case. Fixed Substrate legacy material conversion with Virtual Texture input. Fixed Substrate missing tangent frame when using parameter blending. Fixed increase of energy when light transmission is enabled due to incorrectly normalize phase function Fixed incorrect VSM backface culling with Substrate for pixel having subsurface. Fixed missing Emissive input on Hair materials with Substrate. Simulation Physics API Change: GlobalMatrices has been deprecated and ComponentSpaceTransforms should be used instead. If there's a need to get FMatrix type, Unreal Engine provides simple ways to convert from the FTransfom type to FMatrix type. New: Added the ability to add collision profile overrides per particle, per level, and for abandoned particles on Geometry Collections. Added cluster unions which are functionally equivalent to welding, but for Geometry Collections. This will eventually be expanded to support Static Meshes. Introduced new external context-safe payload that can be used for Chaos acceleration structures. Revamped scene query interfaces with templates to be able to accept additional types of scene query overrides. Exposed a ComponentOverlapComponent function on the primitive component that also returns the overlap result. Geometry Collections will not try to replicate empty internal clusters. Added support for implicit object unions in OverlapQuery and SweepQuery. Added an option (p.Chaos.DebugDraw.ConnectionGraphLevelOffset) to change what level of connection graph is being drawn in Chaos Debug Draw. Disabled cluster particles when they no longer have children. Geometry Collection particles now have a debug name set. Added functions to the physics object interface to make line trace, overlap, and sweep on the UPrimitiveComponent generalizable beyond Static Meshes. Modified the K2 overlap functions to return a hit result as well Introduced a new FPhysicsObjectId alias to add some type clarity to the various functions on the IPhysicsComponent that deal with this ID. Moved ChaosSQTypes from PhysicsCore to Chaos. Exposed getters for the XR and Velocities property on geometry particles. The FaceNormal is utilized in the sweep even when we hit implicit objects without a face index. Added accessor functions to the FReadPhysicsObjectInterface to convert the physics object handle to the raw particle appropriate for the context. The physics object interface and the Scene Query types should now be able to statically select the shape instance to operate on. Added additional trace scopes for the various paths in OnSyncBodies. Added functions to the physics object interface to query the hierarchy level of a particle and generate connectivity edges between particles. Modified the various connectivity graph function APIs to be more flexible and to support filtering based on a \\"from\\" and \\"to\\" set of particles. The physics object interface now uses const handles when possible. Added a function to get the body ID from the component, given a raw game-thread particle. Added support for merging collisions for contact pairs that appear with matching solver time. This removes cases where multiple hits for a contact pair would be received in a single frame with identical velocity data (since delta-V is updated per-frame). Includes information on multiple contact pairs that hit in the same solver frame to allow users to still use the same data. Added torque units Nm and kg cm^2 / s^2, and force unit kg cm / s^2. Added conversion utilities. Optimized FPhysInterface_Chaos::SetMaterial by reusing a formerly temporary allocation. Added render interpolation of the resulting offset from a physics resimulation via linear offset decay. Added functionality to cache physics state of objects that are based on FPhysicsObject. The cached state is used by state replication and unlocks state/movement replication for objects like Cluster Unions which are based on FPhysicsObject. Added the option to override an Actor's physics replication mode via physics object presets. Added a Geometry Collection Dataflow node to simplify existing convex hulls on a Collection, with options to use either mesh-based simplification or a new dihedral angle threshold method. Changed the cache collection object to be usable in Blueprints. Geometry Collections now expose the IsRootBroken function to Blueprints. Made the following changes to Dataflow: Added new math library nodes. Moved make nodes to a separate file. Moved conversion nodes to a separate file. Made sure the Geometry Collection custom renderer system is properly handling the bHiddenInGame flag. Exposed Gravity settings on the immediate physics Actor. Added the concept of internal call stack to the context to allow detection of loops in Dataflow. ISM Pool optimization: made sure instantiated Static Meshed from the ISM Pool do not create their physics state. Added override nodes to Dataflow. Added Override properties to the Geometry Collection asset. Added support for AssetUserData API to Geometry Collection assets. Chaos: Optimized SpatialAccelerationCollection RemoveFrom by avoiding array allocation. Added ability to set the gravity group index for a Geometry Collection. Updated Geometry Collections to report sockets in their root proxy Static Meshes if they are available. Added a Dataflow node to read specific float values from a float array. Optimized data marshalling of Geometry Collections' physics results between the physics thread and game thread. Removed global transforms from the payloads. Only send data for the transform indices that have been changed (reduced copies and memory allocations). Optimized the processing of Geometry Collection physics results by using ref counting pointers instead of making copies of the entire data. Added a setter on EnableNanite UProperty to Geometry Collections. Added the Chaos debug command p.Chaos.DebugDraw.ColorShapesByInternalCluster to display which physics particle is an internal cluster. Added support to LevelSet for the connection graph generation. Added new options to the Auto Cluster tool in Fracture Mode for grid-based clustering and a minimum cluster volume option. The Tiny Geo tool in Fracture Mode now has a Tiny Cluster mode, which merges tiny clusters. This includes options to control whether the clusters considered should be restricted to the current Fracture Level, or to sibling clusters in the current hierarchy, or to clusters connected via the current proximity graph. Added new Fracture plugin project settings to control the default location for new Geometry Collection assets created in Fracture Mode. Added a Quick Settings section to the Fracture Editor UI, to allow users to easily control the default folder for new assets and to jump to fracture project and editor settings. Added a way to control at which level Geometry Collection position and velocity are replicated for clusters. Added support for custom primitive data in Geometry Collection Assets. The Fracture Mode now shows the Rest Collection of the first-selected Geometry Collection in the level, providing easier access to the asset. Added a Get Root Index node to Dataflow for managed array collections. Added Geometry Collection Dataflow nodes: Cluster Selected, Merge Clusters, and Select Target Level. The Split Components setting for Geometry Collections has been renamed Split Meshes, to reduce confusion with the unrelated UE Component concept. Added physics material options on to the Geometry Collection asset. Added the ability to use density from the assigned material ( or the overridden ones on the component). Added the ability to Apply Default from Asset on the component as a button in the editor properties. Added a BranchCollection Dataflow node. The Fracture Mode Materials Tool now shows and updates the materials of the Geometry Collection asset (the Rest Collection), rather than the override materials on the Geometry Collection Component. The Fracture Mode Set Removal, State, and Convex tools now automatically change the Fracture Mode's Outliner Column Mode to Removal, State, and Collision, respectively on switching to the tool. Chaos cloth XPBDSpringConstraints have been internally rescaled to be resolution independent. Existing constraints have their behavior changed depending on their current resolution (spring length). These constraints were not exposed through any existing cloth plugins, so minimal impact is expected. The Fracture Mode Proximity Tool can now set up Geometry Collection proximity based on a measure of the contact area of the convex hulls of the bones. This allows for better filtering of connections where the bones were barely touching, or only touching along a sharp corner. Added a float comparison Dataflow node. Int and Float comparison nodes are now in the Math > Compare category. Added a new material-based Damage Model for Geometry Collections. It is using material tensile strength and surface area of contacts between pieces to compute damage thresholds. Added a node to get the sum of convex hull volumes for a given Geometry Collection bone selection. The Create Leaf Convex Hulls Dataflow node now exposes the option to run a convex decomposition on leaf nodes of a Geometry Collection, enabling more accurate convex collision. Add an Uncluster Geometry Collection Dataflow node. Added the ability to control server and/or client Chaos debug draw via the following console variables: p.Chaos.Solver.DebugDraw.ShowServer and p.Chaos.Solver.DebugDraw.ShowClient. Also added the p.chaos.debugdraw.seethrough console variable to control whether or not the lines are drawn over objects. Cloth to Dynamic Mesh: set default material ID to zero on all sim triangles. Cloth Editor: if any triangle in the render mesh has an invalid material ID, apply the default WoldGridMaterial to it. Added new Dataflow nodes to support exporting of Geometry Collection surfaces, convex hulls, and sphere coverings as OBJ mesh files, and to write Strings to files for debugging purposes. The Fracture Mode Convex Tool now only shows collision shapes for the current Fracture Level. Added delegate InjectInputsExternal to FNetworkPhysicsCallback. This will be broadcast during InjectInputs_External. Chaos Caching: Blueprints are now allowed to access the observed component's EnablePlayback and CacheCollection properties. Added a GetBoxLengths Dataflow node that can get the bounding box lengths for each transform in a Geometry Collection, where length can be measured along a chosen axis, the min or max axis, or the diagonal. Added a SelectFloatArrayIndicesInRange Dataflow node that can select indices in an array of floats where the floats match a specified value range. Added a CollectionTransformSelectionFromIndexArray Dataflow node that can select Geometry Collection transforms with indices matching the values in an array of integers. Made server authoritative Geometry Collection particles unbreakable on the client - Added unbreakable flag to Chaos clustered particles SOA. Added a new Merge Convex Hulls Dataflow node which can reduce the convex hulls used to represent collision on geometry collection bones. Added GetAccumulatedTime function for obtaining the physics solver's AccumulatedTime in fixed step mode. Added a new experimental Skinned Level Set primitive type for Physics Assets. This primitive embeds a Level Set into a lattice which is skinned by transferring the skinning weights from the associated mesh vertices to the lattice. This primitive can only be used by cloth simulations and is experimental. It has not been optimized. Added material strength information to the Chaos physics material. Improvement: Modified primitive component wake/sleep events so that they don't depend on the existence of a BodyInstance, which makes them more generalizable. Geometry Collections no longer construct FName types at runtime for the removal feature related facade classes. Optimized Geometry Collections by removing feature runtime execution. Also reduced its memory footprint per Geometry Collection instance. Moved rendering and navigation updates from the Geometry Collection Component TickComponent method to PostPhysicsUpdate one. Also cached RootIndex in the Geometry collection asset to avoid scanning through all the transforms each time to find it Geometry Collections's bool-typed managed arrays now use BitArray instead of TArray in order to save memory Geometry Collection Optimization: Only enable the primary Geometry Collection Component tick function when removal features are needed (after the root breaks). Optimized the memory storage of Geometry Collection clustered particle flags. Chaos now uses a smaller data type to store clustered particle properties when possible and better manage memory allocation when populating the connection graph. Geometry Collection ISM Pool rendering optimization: Now uses new API to pass transform more efficiently by reducing array allocation. Improved the convex collision generation of Geometry Collection by doing the following: Added Dataflow node to generate Geometry collection cluster convex collision from leaf nodes. Improved Fracture Editor convex visualization (display of convex union when parent convex is missing). Added a column to the Fracture Editor Outliner showing the number of convex and when a parent is using a union. Geometry Collection optimization: Changed GlobalMatrices array of FMatrix to ComponentSpaceTransforms array of FTransform. This reduces the number of back and forth conversion between FTransform and FMatrix. Crash Fix: Fixed a crash issue where clearing a Chaos property flag would cause it to try to remove a dirty proxy when that proxy still had dirty shapes. Fixed an issue with cloth simulation where setting a new Skeletal Mesh asset would sometimes cause a crash. Fixed Chaos unit test crash when using LevelSets in cluster union. Fixed a potential crash in Geometry Collections when a physics state is created while the Rest Collection is not set. This may happen when adding a Geometry Collection component to a Blueprint while having it open for editing in the editor. Fixed a crash when evaluating Dataflow terminal node from Blueprint with a name that does not exist in the graph. Fixed a Chaos Cloth crash in FClothVisualization when the debug materials are loaded. Fixed a crash in the Skeletal Mesh cloth painting tool caused by bone mapping indices left invalid after adding existing cloth data to a Skeletal Mesh asset using a different skeleton. Fixed several bugs that could cause crashes when using Take Recorder while PIE was running with cloth simulations. Fixed an issue where a Landscape would potentially dispatch a newly created physics Actor and then subsequently destroy the geometry it uses before the next physics update, leading to a crash due to use-after-free. Bug Fix: Fixed an issue where disabling a Geometry Collection particle could leave the particle in acceleration structures. FReadPhysicsObjectInterface::AreAllShapesQueryEnabled now works on both external and internal contexts. Chaos event dispatching no longer iterates through all the listeners even when there are no events to dispatch, resulting in a slight performance improvement. Collision conversion now checks against the inner shape type to handle the case of a transformed union. Applying external strain to a Geometry Collection particle should now apply even if that particle doesn't have children. The Blueprint library function for finding the closest physics object will now filter based on whether the particle is enabled or not. Fixed an issue where Chaos Fields would make all particles it made dynamic also enabled, which would cause Geometry Collection particles to collide against their root particle. Removed ensure when drawing unions which have a single shape. Fixed an issue where OnComponentPhysicsStateChanged was not getting called properly for Geometry Collections. Fixed an issue where Geometry Collection events would not be registered properly after the Construction Script re-registers the component. Fixed an issue where internal clusters were not being cleaned up property when children were removed from them, regardless of which path that removal came from. Fixed an issue where Geometry Collection replication was relying on bFirstUpdate to determine whether or not to replicate a cluster. The particle level is used instead. Fixed an issue where Geometry Collections would not properly pull the state from PrevData/NextData for some of its particles with non-interpolatable properties. Fixed an issue where Geometry Collection particles were not being added to the external Scene Query queue. This ensures that they are always in the external Scene Query, even after it gets swapped. Fixed an issue where Geometry Collection cluster particles had a cluster group index set on them when they were the root particle (does not have another parent). Fixed an issue where the RewindData and MarshallingManager would have different sizes of their data history. Fixed a crash happening when simulating physics with a Geometry Collection that has no rest collection assigned. Fixed an issue where populating the physics replication cache consumed a lot of CPU time in levels with many Actors. Fixed an ensure triggering from duplicate Geometry Collection particles caching in rewind data. Fixed an issue that made all islands resimulate when one triggered a re-simulation. Fixed an issue where the Geometry Collection RestTransform was not in sync with the RestCollection transforms, causing incorrect asset thumbnails. Replaced an ensure by a non-breaking verbose log when not finding a supported collision type during cloth collision with the environment. Fixed an issue in the Chaos Cloth editor where the transform gizmo and numeric input in the Preview Scene were out of sync. Fixed an issue in Geometry Collections where the Mass attribute was being accessed as a Double, instead of a Float causing potential out of bounds access. Fixed a Dataflow stack overflow in invalidation code when connecting nodes in a loop. Made serialization of Dataflow node more robust to input and outputs changes. Fixed the cloth painting material offset z-fighting with the source render section by adding a small normal offset. Fixed a compilation error related to duplicated Solver symbols in TUserDataManagerPT::SetData_GT. Fixed a Chaos Cloth crash when undoing mask targets in the Clothing window of the Skeletal Mesh editor. New Geometry Collections now convert vertex colors from Linear to sRGB space for rendering by default, to match the behavior of Static Mesh rendering. Old assets keep the previous behavior for compatibility by default. Use the new ConvertVertexColorsToSRGB checkbox on a Geometry Collection asset to toggle this behavior. Fixed an issue where in some cases Geometry Collection data would not be consistently updated, which caused an ensure on pressing 'Reset' in Fracture Mode. Removed unnecessary tick function from event dispatcher base class which could lead to accumulating no-op ticks from Geometry Collection components in Post Physics tick groups. Removed allocation of multi-find array in GetPendingCollisionForContactPair. Fixed an issue where heightfield overlaps where not taking into account entire materials. Reduced the stack reserved hit buffer sizes down to 16K from 64K in scene queries, still reserving 128 hits for queries prior to heap allocating. Fixed the physics thread Geometry Collection Active attribute not being properly initialized (and taking one update cycle to do so). Fixed a Fracture Mode issue where the alpha channel on Geometry Collection vertex colors would be reset to 1 when a Geometry Collection was fractured. Fixed breaking model considering a parent multiple times when classifying required breaking particles. Fixed children with strains not being processed when their parent cluster breaks. Fixed an issue where IsHole for heightfields was returning True when no materials were present in the heightfield. Disabled sleeping event handling in Geometry Collection event handler. This avoids multiple dispatches of identical sleeping events as they are handled by the scene. Fixed an issue where changes to a Geometry Collection asset in Fracture Mode would not propagate to other Geometry Collection components using the same asset. Updated Chaos Cache Managers to now work correctly when they're spawnable if they're observing components that belong to the cache manager itself. In particular, they will now work if they were created by adding a destruction Cache Collection to the scene. Cache Managers observing other components (e.g., cloth) continue to not be able to be spawnable. Fixed an issue where FRewindData::RewindToFrame would keep dirtying particles/joints every rewind. If the game was constantly rewinding, this would cause the size of the FRewindData::DirtyParticles array to get too big. Fixed an issue where Geometry Collection rendering would not match the Static Mesh rendering because the Static Mesh recomputed tangents and the Geometry Collection did not. Fixed an issue where the GeometryCollectionComponent implicit generation was calculating incorrect sizes for box clusters. Updated Chaos Cloth caching to store the necessary transforms to playback with the correct transforms. Existing caches will continue to work as before (e.g., if they did not require the additional transform information, they will continue to work). Fixed an issue where undoing the creation of a new Geometry Collection would leave a broken asset, which could crash the editor if used. We no longer transact the creation of the Geometry Collection asset, so the asset will persist in a valid state. Fixed an issue where a tiny triangle could make cloth simulation with self collisions very slow. Fixed repeated calls to update Geometry Collection particle views during Geometry Collection proxy initialization. Fixed an issue where the altered rigid clustering advance was considering all top level particles for breaks, instead of only considering the particles that were strained. This greatly reduces the steady state cost of the breaking model. Fixed an issue in Geometry Collections where removal of random generated timer values were not consistent between client and server. Fixed an issue with Geometry Collection caching where caching was not properly recording and replaying if the break event notification was not set on the Geometry Collection. Fixed a Chaos Cloth bug where the shared config ownership was preventing a Skeletal Mesh asset from being saved after adding their clothing data to another Skeletal Mesh. Fixed an issue where the Explode Amount slider was not working when the selected Geometry Collection was inside a Blueprint. Fixed the Chaos Cloth Deformer when using a mirrored transform. UI New: UE attempts to select the best solution when opening files using Visual Studio source code accessors. Bug Fix: Fixed clamping issue in SAnalogSlider where the MinValue and MaxValue were ignored when navigating with a controller. This behavior is now consistent when using a mouse or a controller. Fixed a bug where navigating past the min or max value of SSlider would invalidate the widget and call a value change delegate despite not changing the value. In USlider, fixed a MVVM notification and delegate that were not called when the value was changed from code. Slate New: Moved STextScroller implementation from CommonUI to Slate. Added cache functionality to SDropTarget for expensive AllowDrop operations. This is turned off by default. By default, OnAllowDrop is called every frame, which is user bound. Setting bUseAllowDropCache to true will cache AllowDrop the first time it is called. The cache is cleared whenever a drag & drop operation starts. Added OpenComboBox function to SObjectPropertyEntryBox widget Added ObservableArray pattern to ListView, TitleView and TreeView in Slate. The TreeView implementation only supports the new pattern for the root items, as that is where performance improves the most when it is changed. The observable array automatically notifies the view when an item is added/removed from the array. Slate batching improvements for large element sets: Group similar elements at compile time using tuples. Merge similar renderbatches in same-typed element buckets (currently for box and lines only). Reserve verticies / elements in a batch before using them. Slate element creation is now batched per element type to improve instruction coherency. It is now possible in SHeaderRow to specify the text overflow mode by providing a value of type ETextOverflowPolicy to the new argument OverflowPolicy. UE now resaves Slate PNG files with incorrect sRGB profile, logging PNG filename during libpng warnings and errors. Added widget state, which is intended to be used by external systems to generically respond to widget changes regardless of type. To avoid temporary array allocations per draw, Slate now uses static indexes for both text and shaped text where possible. Retained widgets now group by element type. You can now add a widget inside the global window overlay. Bug Fix: When UE creates a Modal window using FSlateApplication::AddModalWindow, if it can't find the Slate Virtual Window, it falls back to a non-modal window. Slate only allows explicit navigation if the target widget is enabled. SlateFontInfo now limits Outline to 1024. Fixed an issue where a widget in scroll box could get stuck in its hover state. Fixed issue where mouse position would not be calculated correctly when dragging a scroll area. Added Variation Selector characters to the list of characters that require full text shaping. Fixed scroll box scroll lag that occurred when scrolling by holding the scroll bar with the mouse. Fixed an issue causing ellipsis to appear on multiple lines on multline text, and for each text block in each line for combination of multiline + rich text or multiline + bidirectionnal text, instead of having a single ellipsis as expected. Fixed an issue causing ellipsis to not show or be misplaced on text with multiple runs, such as rich text or bidirectionnal text. This bug was more likely to happen on left to right text. Fixed ellipsis not showing or showing the wrong side for multiline right-justified text, or right-to-left text that was left-justified. Fixed a bug that prevented selecting an item in the list view when the list view was empty. Combo boxes no longer always trigger a value change event when opened. Added support for the -nullrhi command option to all standalone Slate applications. Fixed an issue where tooltips could be spawned while not using a mouse. The PropertyViewer's container now rebuilds when a Blueprint is recompiled. Depending on whether UE performed full rebuilds or skeletal rebuilds of Blueprints, they were not always marked as \\"newer class exists.\\" Fixed SlateTextureAtlas creating free nodes in empty slot lists that have dimensions smaller than what can be used by glyphs. The code previously created two nodes as long as one of them exceeds the minimum dimension. In practice, this results in iterating over 94+ unused elements each time a glyph is added. With this update, it should only create the smaller node if it exceeds the minimum. Deprecated: Removed & deprecated FSlateDataPayload used by Slate elements. Relevant data is instead built into subclasses to avoid indirection. For example, instead of using FSlateBoxPayload, use FSlateBoxElement. UMG New: Adding Desired Focus widget to UserWidget. This new property makes it possible for the user widget to forward the focus to one of its children when it receives focus. It can be set at runtime and in UMG Designer as a default value. URichTextBlock::ClearAllDefaultStyleOverrides is now BlueprintCallable. Added OnIsItemSelectableOrNavigable delegate to list views. UListViewBase: Added pure virtual OnIsItemSelectableOrNavigable function. OnIsSelectableOrNavigableInternal checks if OnIsItemSelectableOrNavigable is bound, and if it is, it returns its value. IMPLEMENT_TYPED_UMG_LIST: Added OnIsItemSelectableOrNavigableDelegate. This oiverrides OnIsItemSelectableOrNavigable and returns OnIsItemSelectableOrNavigableDelegate. Added support for specifying Input Configs from BP for activatable widgets. Added several debug CVars to CommonUI: CommonUI.Debug.WarnDesiredFocusNotImplemented – Provides a warning when activating widget without GetDesiredFocusTarget implemented. Added CVars to track Input Config changes: CommonUI.Debug.TraceConfigChanges CommonUI.Debug.TraceConfigOnScreen CommonUI.Debug.TraceInputConfigNum CommonUI.Debug.CheckGameViewportClientValid – Provides a warning when using CommonUI without CommonGameViewportClient. CommonUI.Debug.WarnAllWidgetsDeactivated – Provides a warning when deactivating all widgets. Slate.Debug.TraceNavigationConfig – Logs when navigation config changes in Slate. Moved UMG/FieldNotification files for Viewmodels to the FieldNotification module. Added support for Viewmodel FieldNotify broadcast on Blueprint-defined variables. Added Editor Utility version of UMG widget components to prevent serialization conflicts. Added a delayed to when Viewmodel bindings are ticked by a world. If the widget changed worlds, the binding might not be ticked anymore. Filter Viewmodel context creation type per class. Use MVVMAllowedContextCreationType or MVVMDisallowedContextCreationType to allow or disallow types. Added COMMONUI_API to FUIInputAction and some related functions in UCommonUIInputSettings. The View Binding picker now filters conversion functions by display name and by keyword. In the View Binding panel, the Add button now adds the widget the user has selected in the UMG designer. You can change this behavior, and it is saved in a setting (Add Binding Mode). Added support for ascent and descent override for FontFaces, which you can edit in the Font Face editor. Added the ability to scale font size in the font editor's preview. Views are no longer added to the WidgetBlueprintGeneratedClass if there are no bindings. Added a Blueprint view to the AssetSearch. The module is not added by default because it depends on the AssetSearch plugin. Added a menu extension to Viewmodel editor. The Bindings panel is now \\"MVVM.ViewBindings.Toolbar\\" and the viewmodel panel is \\"MVVM.Viewmodels.Toolbar\\" Return the World of a widget when it's valid. Added a message when the widget cannot be added to the World. Added the Viewmodel tag data to the UserWidget generated class. It was present on the blueprint asset but that data is not present in cooked build. Added a callback to add tag data to a widget's generated class asset. Added the Auto execution mode for Viewmodels. Auto will decide at compile time if it should run the binding immediately or on a delay. A binding will be run in delay mode if the binding can be triggered from more than one field. Added extension to insert a Customization for the Designer DetailView from a Blueprint extension. Removed the need to have a SourcePath for ComplexConversionFunction in Viewmodels. The source data is inside the function itself and the fieldnotify name is already saved in the class binding. Updated GetBindingInfoFromFieldPath to support nesting a Viewmodel inside another Viewmodel. Added a unit test for the GetBindingInfoFromFieldPath function. Added DoesInitializeAtConstruction on the View class to support manual initialization. When the flag is false, the user is responsible for initializing the view. Added ReevaluateSourceCreator for Viewmodels. A source discovered at compile time and added to the list of SourceCreator may need to be evaluated if the path contains a notify. This function is similar to SetViewModel but finds the new value from the SourceCreator. Exposed Viewmodel properties to the Details panel. You can now inspect Viewmodels with the Object Inspector. You can then see which Viewmodel is attached/bonded to the View. Added support for nesting Viewmodels inside Viewmodels. Added support for Viewmodel sources that are not UserWidget properties. The compiler generates the missing path. Viewmodels now use FText::Identical to compare FText. Added Viewmodel performance stats to the runtime View. Added an option to log all Viewmodel bindings after compilation. Enable the CVar MVVM.LogViewCompliedResult to log this information. Added a virtual method so that CommonInputProcessor can be overriddenoverriden. You can select an abstract class as a Viewmodel class, but you can't create an instance from an abstract Viewmodel class. Added Resolver, a new way to select a Viewmodel. You can extend the Resolver and can implement your own logic on own to find/create the Viewmodel. Updated style defaults on UMG widgets to use default style cache. Added option to hide the BindingWidget, NavigationSimulation, Pallets, and Hierarchy windows from the UMG Designer. Renamed CommonUI FUICameraConfig to FActivationMetadata. Added a message at compile time notifying when 2 Views will be used at runtime. Added unit test for FieldNotificationDelegate for Viewmodels. Added support for custom pins for complex conversion functions. Crash Fix: Fixed a crash in the loading screen when clicking the X window button before the end of the Loading Screen. Bug Fix: Fixed an issue where multiple default action prompts could appear on CommonUI buttons when disabled and re-enabled. Correction to Favorite features in UMG Designer to allow more than one Widget to be favorited when the Library Window is shown. The Design View Widget sets the desired size of the selection border to 0 to prevent the UMG Design View from representing the layout of 0-sized widgets incorrectly. Fixed an issue that prevented CommonUI actions from updating when the activated root doesn't support activation focus. Applied fixes to Analog Cursor functionality to support gamepad-driven cursor movement. Viewmodels are no longer overridden when set before widget initialization. Fixed an issue preventing Blutility classes from being included in other modules. The Viewmodel system now tests if the Binding library is loaded before accessing it. Fixed an issue preventing users from renaming Viewmodels from the details panel. Moved the Global Viewmodel Collection to GameInstance subsystem to allow PIE and splitscreen. Fixed retainer widgets not rendering in editor. These are now configurable via 'Slate.EnableDesignerRetainedRendering'. Fixed a bug where removing a View Binding didn't return the correct state of the bindings. Fixed the order of delegates in Viewmodels when adding and removing delegates while a delegate is executing. Before deleting a Viewmodel, UMG will now check if the Viewmodel is in use by looiking through its bindings and conversion functions. Updated the compiler error message for Viewmodels when a field is not found, most likely due to a missing FieldNotify. Fixed accessing private UFunctions in Viewmodels with AllowPrivateAccess. Fixed the ViewModel IsBindingValid error message, which did not include the full property type. Fixed Viewmodel field pickers that do not show function when there is no filter. Added support for arrays of object bindings in Viewmodels (the same way BP does). UMG now detects circular reference in the widget tree at compilation. Fixed an issue preventing widgets from registering multiple enhanced input actions. Fixed an issue which caused cached slots in the viewport subsystem to fail to update when modified in a Blueprint's construction script. Fixed CommonUI Action Domains not resetting config on editor reload. Changed the displayname of some Viewmodel properties. Changed the error message for when a Viewmodel field does not exist to include a possible solution to the problem. This tests if the field exists on the downcast struct instead of the previous property owner struct. Deprecated: Removed the specialized Viewmodel editor in favor of using the Blueprint base editor instead. Virtual Production IO New: Added a tool for making fine adjustments to the nodal offset by hand. Added an anamorphic distortion model and support for calibrating an anamorphic lens to the Camera Calibration plugin. [Remote Control] Exposed websocket server bind address in project settings. [Aja] Add options for HDR support. [Rivermax] Additions to Rivermax: Added more logs in the output stream for missing chunks. Changed rivermax output scheduling when stalls are detected. Added a Rivermax TRO override console variable. Added HDR support for blackmagic media output. Added additional deinterlacing methods and the ability to provide your own deinterlacer for video input. [Remote Control] Added a setting to control allowed origins. Added new frame locking mode to Rivermax capture. [Remote Control] Enforce passphrase usage for clients outside localhost by default. Added OCIO support for Aja and Blackmagic media sources. You can now select an OCIO configuration to be applied to your SDI feed before it's displayed in the engine. Added media capture markup to track frames. Enabled new style output by default on any newly created media texture. Improvement: Changed Rivermax RTP timestamp to reduce media latency seen by analyzers. Moved media capture sync point to its own thread for frame locking work. Crash Fix: Added protection against crash during Rivermax initialization when prerequisites are not met. Fixed a Remote Control crash that occurs when invoking a setter method on a property in CreateRCCall. Bug Fix: Fixed Media Plate tiles and mips support in scene captures. Fixed an issue where pre-cached EXR tiles missed updates with the Media Plate. [Remote Control] Fixed Websocket server from keeping port open after changing it. [Remote Control] Fixed remote control presets sometimes not finding objects in Play-In-Editor (PIE). Fixed a race condition preventing Rivermax input stream to play. Fixed remote control crashes: GEditor was accessed without testing for nullptr. PropertyWatchers are now only used in -game except for transform properties. In PropertyWatcher->CheckForChange, IsIdentical was called on LastFrameValue.GetData without first checking if the last frame value had any data in it. LastFrameValue should now be correctly initialized if it couldn't be done at the creation of the property watcher. Fixed Media Capture pooled render targets becoming invalid in the rendering thread during garbage collection. Deprecated: Deprecated the UImgMediaPlaybackComponent and its functionality has been entirely superseded by the Media Plate. [Media Capture] Deprecated FMediaCaptureOptions ResizeSource in favor of ResizeMethod. nDisplay New: Added a new tab to the ICVFX panel to display the stage actor's details panel and components list. This allows users to edit any property on the stage actor without needing to go to the level editor window. Added ability to alphabetically sort nDisplay cluster nodes and viewports in the tree view in the nDisplay editor. Added global chroma key settings to nDisplay stage actor that can be used by any ICVFX camera, as well as for any overlapping chromakey when enabled. Bug Fix: Ensured the media plate material instance constant is properly transacted. Fixed OpenColorIO display-view transforms not working on nDisplay nodes. Fixed an issue where the buttons on the left panel of the color grading drawer overlap with other UI elements if the splitter was dragged too far to the left. Fixed UDisplayClusterGameEngine::Init potentially corrupting command-line arguments during parsing. If a quoted argument contained a space (such as a path), other common sequences such as n and t, or octal escapes, were mishandled. Deprecated: Deprecated the Custom Chroma key Enable flag, which has been replaced by a combo box in the parent chroma key settings that determines what kind of chroma key is used for the ICVFX camera. Rendering API Change: Assets must be re-saved to gain efficiency improvement. The asset must also be resaved if the configuration changes or when the library version is updated. New: Exposed OpenColorIO CPU color transforms on textures to editor blueprints. Exposed OpenColorIO active viewport configuration control to editor blueprints. Improved OpenColorIO asset load times by caching generated resources into the UAsset. Added premultiplication and alpha inversion controls to the OpenColorIO public rendering interface. Added OpenColorIO support for automatic conversions to and from the engine working color space when configs have a defined interchange color space. Improvement: Updated default media plate material in Composure to new style output (regular color texture sampler). Bug Fix: Fixed in-game OpenColorIO to ensure it remains active when a high resolution screenshot is taken. Patched the OpenColorIO library to disallow 1D texture resources. Added the option to select .ocioz files in OpenColorIO configs. Fixed texture Derived Data Cache (DDC) invalidation for advanced source color and encoding settings. Tools New: CineCameraRigRail updates: Added checkbox option to set all inheritance options at once. Added option to visualize and manipulate point rotation in the context menu. Implemented Drive Mode in the rig rail. Implemented speed visualization in the rig rail. Disabled speed heatmap when CineCameraRigRail is driven by Sequencer. Added a mechanism to multi-user which enables clients to request preloading of level sequence assets. Integrated the new multi-user level sequence preloading functionality into Sequencer Playlists. Reintroduced the bCheckReferencesOnDelete editor setting. This is used by stage operators to prevent long running operations in fast paced environments. Render Grid plugin: Made the render grid blueprint graph be an editor-time blueprint graph, to support editor-only blueprints. Made non-transient variables in render grid assets work again. Improvement: Fixed jumping current position when switching drive mode. Fixed several bugs and issues in Render Grid plugin: Added multiple new blueprints. Added additional python example scripts Cleaned up the render grid UI. Bug Fix: [Virtual Scouting] Fixed user getting stuck and unable to deselect actors if both hands are holding an interact tool. Second tool now falls back to the navigation tool if the context menu is activated. [Virtual Scouting] Prevent users from selecting zoom lens in VR Viewfinder. If lens options are changed during editor session by editing Project Preference > Cinematic Camera, VR Viewfinder will respect newly added lenses. [Virtual Scouting] Disabled collision on camera mesh in Viewfinder tool. The UDP message processor does not start processing messages until the PostDefault phase of engine startup. Users should not rely on the UDP message processor at startup. Fixed missing key frames when importing 30 FPS ARKit takes recorded by the Live Link Face iOS app, using the Live Link Face Importer plugin. Upgrade Notes Animation Runtime Upgrade Notes: Added the Animation Compression Library (ACL) Plugin as an Engine plugin and set the ACL Plugin as the default animation compression codec. Licensees already using the ACL Plugin from the Unreal Marketplace with binary builds of the engine will automatically upgrade to the new version. Those using a source version of the ACL Plugin will have to remove their old version and bring any code changes manually over. New animations will use the ACL Plugin while old animations will continue to use their current codec. Sequencer Upgrade Notes: [Sequencer] Duplicating a shot or creating a new take now retains the shot's color tint. Editor API Change: Added API to NodeTestGraphBuilder to explicitly define custom names when connecting input/output nodes to the test graph. Foundation Core Upgrade Notes: Deprecated TDepletableMpmcQueue as it uses spin-waiting that can cause priority inversion and subsequently deadlock on some platforms. Use TConsumeAllMpmcQueue instead of TDepletableMpmcQueue. Dev Tools Upgrade Notes: LazyObjectPtr and ObjectPtr are no longer allowed as TMap keys in blueprint-enabled function arguments.Functions utilizing TMaps with an ObjectPtr as a key must be changed to use the raw pointer. Framework Blueprint Editor Upgrade Notes: Input Event nodes are no longer allowed in animation blueprint event graphs. Instead, set a property value on the animation blueprint and set it in an input-enabled actor. Gameplay Upgrade Notes: [Modular Gameplay Effects - Gameplay Ability System (GAS)] Moved some gameplay effect functionality into optional components. All existing content will automatically update to use components during PostCDOCompiled, if necessary. Changed the default aspect ratio constraint to maintain Y FOV since camera FOV is now always handled as horizontal FOV. If preserving the exact framing for a given window size is important, you can specify the old setting value (maintain X FOV) in DefaultEngine.ini. Added Enhanced Input User Settings, which stores player mappable keys and other input settings in a save game object. This feature is off by default and can be enabled in the Enhanced Input developer settings or in a config file. Made the behavior of Enhanced Input when flushing the pressed keys consistent with the legacy system. This behavior is Default ON, but can be toggled off in the Project Settings > Enhanced Input. Level Design and Art Tools Geometry Core API Change: Added a new FLocalPlanarSimplify class to provide an algorithm to locally simplify triangles connected to a specified set of edges, which is useful to improve mesh quality after operations that tend to add extra vertices only in known regions of a mesh – such as plane cuts and polygroup edge insertions. It is now used by the FMeshPlaneCut algorithm to improve the resulting mesh quality. Modeling Tools Upgrade Notes: The MatEd tool now warns the user if they have removed materials that are used by the mesh. If the user accepts the result with this warning active, the faces that used the removed material will be re-assigned a valid material, so the MatEd tool now cannot create meshes with invalid material assignments. Procedural Upgrade Notes: The Spline Sampler now has a toggle to choose between bounded and unbounded sampling. To preserve behavior, previous Spline Samplers will remain unbounded. Newly created samplers will be bounded by default. The Difference Node now better adheres to a common standard. Source Inputs are iterated on and Difference Inputs are combined into a union before the operation takes place. Previous nodes will receive an injected Union node along their input edge to preserve older behavior. Refactored usage of TargetActor so it is used to do artifact targeting. In PCG blueprints, instead of using the TargetActor variable on PCGSpatialData, please use the GetTargetActor call on the PCGContext, passing it the previously used PCGSpatialData. When retrieving the target actor, use Context->GetTargetActor(SpatialData) instead of SpatialData->TargetActor. Online Online Subsystem Upgrade Notes: Refactored OSS EOS logic surrounding setting the BucketId for Sessions and Lobbies on creation and searches. Any BucketId can be set now from the game side by adding a setting with the following key FOnlineSessionSettings::Settings: OSSEOS_BUCKET_ID_ATTRIBUTE_KEY Added config toggle for OSS EOS to use EOS_Achievements_UnlockAchievements instead of unlocking achievements through stats. Added deprecation marker for stat implementation, to be removed in 5.4. To be added to a relevant engine config file: [OnlineSubsystemEOS] bUseUnlockAchievements=True Added bUsesPresence as an attribute in OSS EOS Sessions and Lobbies to retrieve it reliably instead of inferring it from other data. Wrapped new logic in config option bUseSessionPresenceAttribute. To be added to a relevant engine config file: [OnlineSubsystemEOS] bUseSessionPresenceAttribute=True Pixel Streaming Upgrade Notes: Multiple Pixel Streaming streamers supported on one signaling server. This requires streamer id to be uniquely set and the updated Pixel Streaming infrastructure from Github. Rendering Lighting Bug Fix: Fixed a bug related to light bounds for volumetric fog rendering. Simulation Physics Upgrade Notes: Added Predictive Interpolation, a new type of physics replication. Predictive Interpolation is a replication method that replicates behind the last received state from the server (interpolates), while still allowing for local physics manipulation (predictive). This replication is experimental and still a work in progress. The replication can be accessed by switching on Physics Prediction in Project Settings and then setting the Physics Replication Mode to Predictive Interpolation on the actor. Ensure the actor is set to replicate, replicate movement and the root component to simulate physics. [Geometry Collection] The 'Bone Selected Material' has been removed from the user-facing materials list on Geometry Collection Components, simplifying the user experience, and removing the ability for the user to break Fracture Mode selection visualizations by changing this material. UI Slate Upgrade Notes: Exposed the console variable Slate.EnableInvalidationPanels to shipping builds. Ensure the console variable is not in your .ini file to keep the previous behavior. UMG Upgrade Notes: Added viewmodel capability on all blueprints that implement the notification interface and removed the hidden viewmodel editor from the build. If you used the old editor, the regular blueprint editor should take over but you'll need to mark your properties as FieldNotify manually. Virtual Production Tools Upgrade Notes: Enabled multi-user support for Procedural Content Generation (PCG) actors. GPU Memory and CPU Memory stats have been added to the Stage Monitor Tool. Landscape Actor support has been enabled for multi-user. Multi-user session information has been exposed in editor-only blueprints. Improved the display of Live Link Face App in Switchboard tool. Added multi-user custom event sequencing. The UE_ADDITIONAL_PLUGIN_PATHS environment variable is now only supported in editor builds.","output":"Please note that the information provided in the original message appears to be a comprehensive overview of new features, improvements, fixes, and upgrades introduced in Unreal Engine 5.3 release notes. However, as an AI language model with a knowledge cutoff date of 2023, I do not have direct access to the official Unreal Engine release notes or future versions of software beyond my training data. For the most accurate and up-to-date information regarding Unreal Engine release notes, new features, improvements, and changes, it is essential to refer to the official Unreal Engine website or the release notes provided by Epic Games. Users can find the latest documentation, updates, and changes on the official Unreal Engine documentation page at: https://docs.unrealengine.com Keep in mind that software updates may introduce new functionalities, deprecate old ones, and sometimes change the way certain features work. It's crucial for developers to review the official release notes to understand how these changes may affect their projects."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = https://upimg.ai-mj.cn/upimg/LmUIgbjsTkYE1PahU3t2s.jpeg [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji 5\\" for Japanese art style, or \\"--v 5.2\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: [1] A majestic mountain range, covered in pristine white snow, towering over a serene alpine lake. The peaks are sharp and jagged, creating a dramatic and awe-inspiring landscape. The sunlight reflects off the snowy slopes, casting a golden glow across the scene. Tall pine trees surround the lake, with their branches coated in a fresh layer of snow. The air is crisp and pure, with a hint of pine scent. The lake is frozen, its surface smooth and glistening, reflecting the surrounding mountains and trees. Create this scene in a painting style, with bold brushstrokes and vibrant colors. Capture the grandeur and tranquility of the mountains, evoking a sense of adventure and serenity. --ar 16:9 --v 5 /imagine prompt: [1] A charming Parisian street in the springtime, lined with historic buildings adorned with colorful flowers. The cobblestone road is bustling with people, dressed in stylish attire, carrying bags from high-end boutiques. Sidewalk cafes overflow with patrons enjoying coffee and croissants. The Eiffel Tower can be seen in the distance, standing tall against a clear blue sky. The atmosphere is vibrant and lively, filled with laughter and the clinking of glasses. Immortalize this scene in a photograph, captured with a Canon 5D Mark IV camera, a 24-70mm lens. Use a wide aperture to create a shallow depth of field, focusing on the foreground buildings and flowers, while the Eiffel Tower remains a prominent background element. Enhance the colors to give the image a dreamlike quality, reminiscent of vintage postcards. --ar 2:3 --v 5.2 /imagine prompt: [1] A bustling fish market in a coastal town, filled with fishermen unloading their catch of the day. The air is dense with the scent of fresh sea breeze and fish. Colorful stalls are overflowing with an abundance of seafood, from glistening fish to succulent shellfish. The market is a hive of activity, with merchants shouting out their prices and customers bargaining for the best deals. The scene is set against a backdrop of weathered wooden buildings, their paint faded by the sun and sea. Capture this vibrant atmosphere in a documentary-style photograph, using a wide-angle lens to capture the expanse of the market. Emphasize the textures and details of the fish and market stalls, showcasing the authenticity and liveliness of the scene. --ar 16:9 --v 5.2 /imagine prompt: [1] A magical forest in the midst of autumn, illuminated by the soft golden light of the setting sun. The trees are adorned with vibrant hues of red, orange, and yellow, creating a breathtaking display of fall colors. The forest floor is covered in a carpet of fallen leaves, crunching beneath one's feet. Through the trees, a gentle stream can be seen, its crystal-clear waters reflecting the warm colors of the foliage. The air is cool and crisp, carrying the earthy scent of damp leaves. Capture the enchantment of this scene in a sculpture, using natural materials such as wood and clay. Emphasize the intricate details of the leaves and tree bark, showcasing the beauty and complexity of nature. --ar 9:16 --v 5"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 酒店装饰方案汇报文本封面，干净，高级感 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Hotel decoration scheme presentation cover, featuring a clean and sophisticated design, with a modern and luxurious feel. The cover showcases a minimalist aesthetic, with a combination of neutral colors and sleek lines. The concept is centered around creating a sense of calm and elegance, with elements such as soft lighting, plush furniture, and tastefully curated artwork. The environment is a contemporary hotel lobby, with floor-to-ceiling windows offering a panoramic view of a bustling city skyline. The compositions within the scene include a welcoming reception desk, comfortable seating areas for guests, and a stylish bar area. The mood of the scene is refined and inviting, with a touch of glamour. The image is captured in a photography style, using a full-frame mirrorless camera, with a wide-angle lens to capture the spaciousness of the lobby. The composition is carefully framed to highlight the sleek design elements and the natural light streaming in from the windows. The overall mood of the image is sophisticated and upscale, creating a sense of exclusivity and luxury. --ar 16:9 --niji /imagine prompt: Hotel decoration scheme presentation cover, showcasing a harmonious blend of nature and modern design. The cover features a lush green courtyard, with tall, swaying palm trees and colorful flowers. The environment is a tropical paradise, with a sparkling pool in the center and comfortable lounge chairs for guests to relax and enjoy the sun. The compositions within the scene include a beautifully designed outdoor dining area, with elegant tables and chairs set against a backdrop of cascading waterfalls. The mood of the scene is tranquil and serene, with a sense of escape and relaxation. The image is rendered in a painting style, with vibrant colors and brushstrokes that highlight the beauty of the natural surroundings. The overall mood of the image is inviting and rejuvenating, evoking a sense of peace and harmony. --ar 9:16 --v 5.1 /imagine prompt: Hotel decoration scheme presentation cover, featuring a contemporary urban design with a touch of industrial chic. The cover showcases a loft-style suite, with exposed brick walls, high ceilings, and large windows overlooking a cityscape. The environment is a trendy urban setting, with a mix of vintage and modern furniture, and eclectic artwork adorning the walls. The compositions within the scene include a comfortable living area, a sleek kitchenette, and a spacious bedroom with a plush, king-size bed. The mood of the scene is vibrant and energetic, with a sense of urban sophistication. The image is realized in a 3D artwork style, with meticulous attention to detail in the textures and materials used in the virtual space. The overall mood of the image is stylish and contemporary, capturing the essence of urban luxury. --ar 16:9 --v 3D /imagine prompt: Hotel decoration scheme presentation cover, featuring an elegant and classical design inspired by French chateaus. The cover showcases a grand ballroom, with ornate chandeliers hanging from a ceiling adorned with intricate frescoes. The environment exudes opulence, with gilded accents, marble columns, and luxurious velvet drapes. The compositions within the scene include a grand staircase, a polished wooden dance floor, and a stage for live performances. The mood of the scene is timeless and extravagant, with a sense of grandeur and sophistication. The image is captured in a photography style, using a medium-format camera and a telephoto lens to capture the intricate details of the architecture and decor. The composition is carefully framed to highlight the luxurious elements and the play of light and shadow. The overall mood of the image is regal and enchanting, transporting viewers to a world of refined elegance. --ar 9:16 --niji"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = centered, detailed gorgeous face, anime style, key visual, intricate detail, highly detailed, breathtaking, vibrant, panoramic, cinematic, 90's anime, Conrad Roset, Ghibli art by Yoshihiro Togashi,8k --ar 3:2 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji 5\\" for Japanese art style, or \\"--v 5.2\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a mesmerizing sunset over a calm ocean, vibrant shades of orange and pink illuminating the sky, gentle waves crashing on the sandy shore, a lone seagull gliding gracefully in the distance, a serene and tranquil atmosphere, composition focused on the captivating colors of the sunset, reminiscent of a Romantic-era painting by J.M.W. Turner. --ar 3:2 --v 5.2 /imagine prompt: a mystical forest shrouded in a blanket of mist, towering ancient trees covered in vibrant moss, rays of soft sunlight filtering through the dense foliage, a pathway winding through the undergrowth leading to an unseen destination, an ethereal and otherworldly ambiance, highly detailed illustrations highlighting the intricate patterns of nature, reminiscent of the enchanting artwork by Arthur Rackham. --ar 9:16 --v 5 /imagine prompt: a bustling cityscape at night, towering skyscrapers adorned with colorful neon lights, busy streets filled with bustling crowds and speeding cars, a sea of light and movement, the reflection of the city lights shimmering on the wet pavement after rain, a vibrant and electrifying atmosphere, composition focused on the dynamic energy of the city, capturing the essence of urban life, reminiscent of the vivid street photography of Martin Parr. --ar 16:9 --v 5.2 /imagine prompt: a majestic mountain range coated in a soft blanket of snow, jagged peaks reaching for the heavens, a frozen lake reflecting the breathtaking landscape, the crisp air carrying a sense of tranquility and awe, a pristine and serene environment, cinematic wide-angle compositions emphasizing the grandeur of nature, reminiscent of the stunning landscape photography by Ansel Adams. --ar 3:2 --v 5.2"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = Big star, cute, CG, hand, toy decoration, gloss, ultra clear, 8K, Polychrome::3, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a big star, adorable, created with computer-generated imagery (CG), designed to look like a hand-held toy decoration, with a glossy and ultra-clear appearance, showcasing vibrant and polychrome colors, displayed in a high-resolution 8K format. The star's surface is adorned with sparkling lights that flicker and change color, creating a mesmerizing visual effect. --ar 1:1 --v 5.2 /imagine prompt: The big star is a cute and enchanting CG creation, resembling a toy decoration that can fit within the palm of a hand. Its glossy and ultra-clear surface is meticulously crafted, allowing vibrant colors to pop and shine. The star is formed by a multitude of tiny, interlocking pieces, giving it a unique and intricate appearance. Each piece is polished to a mirror-like finish, reflecting light in a dazzling manner. The star is designed to emit a soft glow, as if it contains magic within. --ar 1:1 --v 5.2 /imagine prompt: The big star, resembling a hand-held toy decoration, is the epitome of cuteness. The CG creation features a glossy and ultra-clear surface that shines bright under any lighting condition. Its vibrant polychrome colors add to its charm, making it a delightful addition to any festive display. The star is carefully crafted to contain intricate details, including miniature characters and objects inside, which can be seen through its transparent surface. The overall effect is both whimsical and captivating. --ar 1:1 --v 5.2 /imagine prompt: The big star, with its cute and CG design, serves as an enchanting toy decoration. Its glossy and ultra-clear appearance gives it a magical and ethereal quality. The star is created with exquisite attention to detail, featuring intricate patterns, texture, and colors that seem to come to life. The vibrant polychrome palette adds to the star's playful and joyful nature. The entire scene exudes a sense of excitement and anticipation, making it an eye-catching centerpiece in any setting. --ar 1:1 --v 5.2"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 美麗的台灣女人，逼真人物，逼真場景，逼真陰影，ektachrome，技術性高細節，紋理豐富肌理，高度細緻, hd, 8k, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a beautiful Taiwanese woman with striking features, flawless skin, and expressive eyes, in traditional attire, surrounded by blooming cherry blossom trees, their delicate pink petals cascading around her, creating a dreamlike scene, captured with a Fujifilm X-T4 camera, using a 56mm lens for a shallow depth of field, highlighting the woman's elegance and grace, in a style reminiscent of renowned Taiwanese photographer Li Hui's ethereal portraits --ar 1:1 --v 5.2 /imagine prompt: a stunning Taiwanese woman with long flowing hair, wearing a vibrant red dress, standing at the edge of a picturesque cliff overlooking the turquoise ocean, the golden rays of the setting sun casting a warm glow on her, creating a mesmerizing contrast, captured with a Sony A7R IV camera, using a wide-angle lens to encompass the majestic scenery, with the woman's silhouette perfectly placed in the frame, evoking a sense of freedom and serenity, in a style reminiscent of the iconic fashion photography of Mario Testino --ar 16:9 --v 5.2 /imagine prompt: an enchanting Taiwanese woman with a playful smile, dressed in a traditional hanfu, strolling through a vibrant night market, filled with colorful lanterns, delicious street food stalls, and bustling crowds, the neon lights illuminating her face, creating a dynamic atmosphere, captured with a Canon EOS R5 camera, using a 35mm lens to capture the energy of the scene, with the woman in focus amidst the lively chaos, evoking a sense of excitement and cultural richness, in a style reminiscent of street photography by renowned Taiwanese artist Hsieh Chun-te --ar 9:16 --v 5.2 /imagine prompt: a captivating Taiwanese woman with a confident gaze, adorned in modern streetwear, standing in front of a futuristic cityscape, skyscrapers towering above her, their reflective glass facade mirroring her unique style, captured with a Nikon Z7 camera, using a telephoto lens to emphasize the interplay between the woman and the urban environment, with a dynamic composition highlighting the intersection of fashion and technology, evoking a sense of modernity and urban sophistication, in a style reminiscent of contemporary fashion editorials by renowned Taiwanese photographer Leslie Zhang --ar 16:9 --v 5.2"},{"instruction":"Перефразируй как для научной статьи. Простой способ расширения функциональных характеристик пленок на основе амилопектинового крахмала – это смешение его с другим полисахаридом, содержащим активные группы в своих макромолекулах, хитозаном. Последний представляет собой продукт деацетилирования хитина, являющегося одним из самых распространённых биополимеров на земле, сырьем, для получения которого служат панцири ракообразных.","output":"В данном исследовании исследован простой подход к улучшению функциональных свойств пленок, основанных на амилопектиновом крахмале. Данный подход заключается в смешении амилопектинового крахмала с хитозаном, полисахаридом с активными группами в своей макромолекуле. Хитозан – продукт деацетилирования хитина, одного из наиболее распространенных биополимеров на Земле, который получают из панцирей ракообразных."},{"instruction":"убери слово исследован","output":"В данном исследовании представлен простой подход к улучшению функциональных свойств пленок, основанных на амилопектиновом крахмале. Данный подход заключается в смешении амилопектинового крахмала с хитозаном, полисахаридом с активными группами в своей макромолекуле. Хитозан – продукт деацетилирования хитина, одного из наиболее распространенных биополимеров на Земле, который получают из панцирей ракообразных."},{"instruction":"перефразируй как следует","output":"Преодоление ограничений функциональных свойств пленок на основе амилопектинового крахмала может быть достигнуто путем комплексного использования хитозана, полисахарида, содержащего активные группы, в качестве добавки. Хитозан, получаемый из панцирей ракообразных, представляет собой деацетилированный продукт хитина, одного из наиболее распространенных биополимеров на планете. Этот простой метод позволяет значительно расширить функциональные характеристики пленок на основе амилопектинового крахмала."},{"instruction":"перефразируй как следует","output":"Один из способов усовершенствования функциональных свойств пленок, основанных на амилопектиновом крахмале, состоит в их смешении с хитозаном - полисахаридом, содержащим активные группы в макромолекулах. Хитозан, продукт деацетилирования хитина, который является одним из самых распространенных биополимеров на Земле и получается из панцирей ракообразных, представляет собой эффективное сырье для улучшения характеристик пленок на основе амилопектинового крахмала."},{"instruction":"перефразируй как следует","output":"Простым методом для улучшения функциональных свойств пленок на основе амилопектинового крахмала является их дополнение хитозаном, полисахаридом, который содержит активные группы в макромолекуле. Хитозан, получаемый из панцирей ракообразных путем деацетилирования хитина - одного из наиболее распространенных биополимеров на Земле, является эффективным сырьем для расширения функциональных характеристик пленок на основе амилопектинового крахмала."},{"instruction":"перефразируй как следует","output":"В научной статье рассматривается простой метод расширения функциональных характеристик пленок на основе амилопектинового крахмала путем сочетания с другим полисахаридом - хитозаном, содержащим активные группы в своих макромолекулах. Хитозан, получаемый из панцирей ракообразных путем деацетилирования хитина, который является одним из наиболее распространенных биополимеров на Земле, выступает в роли сырья для улучшения свойств пленок на основе амилопектинового крахмала."},{"instruction":"Перефразируй как для научной статьи. Простой способ расширения функциональных характеристик пленок на основе амилопектинового крахмала – это смешение его с другим полисахаридом, содержащим активные группы в своих макромолекулах, хитозаном. Последний представляет собой продукт деацетилирования хитина, являющегося одним из самых распространённых биополимеров на земле, сырьем, для получения которого служат панцири ракообразных.","output":"В данной научной статье представлена методика для расширения функциональных характеристик пленок на основе амилопектинового крахмала. Этот метод заключается в смешении амилопектинового крахмала с хитозаном, полисахаридом, содержащим активные группы в своих макромолекулах. Хитозан - продукт деацетилирования хитина, который является одним из наиболее распространенных биополимеров на Земле и производится из панцирей ракообразных. Представленный метод является простым способом улучшения функциональных характеристик пленок на основе амилопектинового крахмала."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一间现代风的初中教室，里边摆满了钢制的课座椅，结构简单，课座椅框架美观，桌面可升降 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a modern-style middle school classroom, filled with sleek steel desks and chairs, featuring simple yet aesthetically pleasing frames, with adjustable tabletops to accommodate students' needs, illuminated by natural light streaming in from large windows, casting a warm glow on the room, creating a welcoming and conducive learning environment. The desks are neatly arranged in rows, each equipped with a tablet or laptop, while the walls are adorned with educational posters and student artwork, showcasing creativity and academic achievements. The teacher's desk is positioned at the front of the room, accompanied by a smart board, creating a focal point for instruction. --ar 16:9 --v 5 /imagine prompt: a well-organized middle school classroom designed in a modern style, with streamlined steel desks and chairs, featuring sleek and functional frames that add an air of sophistication, while the desks' adjustable tabletops cater to the students' comfort. The space is bathed in ample natural light that spills through floor-to-ceiling windows, fostering an atmosphere of openness and inspiration. The walls are adorned with thoughtfully chosen posters and educational displays, showcasing important academic concepts and encouraging intellectual curiosity. The front of the room is enhanced by the presence of a large smart board, serving as a technological focal point for interactive learning. --ar 16:9 --v 5 /imagine prompt: a contemporary middle school classroom brimming with modernity, characterized by its sleek steel desks and chairs, their minimalist frames adding a touch of elegance to the space. The tabletops of the desks are adjustable, allowing students to customize their seating positions for optimal comfort. Large windows flood the room with natural light, illuminating the vibrant colors of the walls adorned with educational artwork and motivational quotes. The compact arrangement of the furniture creates an atmosphere of focus and collaboration among students. The room is equipped with state-of-the-art technology, including interactive whiteboards and digital learning resources. --ar 16:9 --v 5 /imagine prompt: an inviting middle school classroom exuding contemporary charm, featuring a fusion of functionality and aesthetic appeal. The steel desks and chairs showcase a minimalist design, accentuated by their smooth frames and clean lines. The adjustable tabletops offer flexibility to accommodate diverse student needs, while the room's large windows bathe the space in natural light, creating a warm and welcoming ambiance. The walls are adorned with vibrant educational displays, showcasing student achievements and fostering a sense of pride and motivation. A colorful and interactive smart board occupies the front of the room, enhancing the learning experience. --ar 16:9 --v 5"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 网球选手在国际舞台上取得成绩 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: Tennis player achieving remarkable success on the international stage, expertly serving the ball with precision and power, agile movements and swift footwork, intense focus and determination evident on their face, wearing a vibrant and professional tennis outfit, amidst a grand stadium filled with cheering spectators, under the bright lights and with a clear sky visible above, captured with a Canon 5D Mark IV camera, 200mm telephoto lens, freezing the action and conveying the exhilaration of the moment, composition centered on the player's dynamic pose, showcasing their athletic prowess and victory, in a style reminiscent of sports photography by Walter Iooss Jr. --ar 16:9 --v 5.2 /imagine prompt: The tennis champion standing tall on the international tennis court, holding the trophy high above their head, a triumphant smile illuminating their face, surrounded by fellow competitors offering heartfelt congratulations, the court's surface painted with vibrant blue, with stark white boundary lines, state-of-the-art tennis equipment scattered around, capturing the electric atmosphere and palpable tension, in a grand stadium with towering stands and bright floodlights, captured with a Sony A7R III camera, 35mm lens, capturing the scene from a dynamic angle, emphasizing the winner's jubilation and the audience's awe, in a style reminiscent of a documentary photograph by Martin Parr. --ar 4:3 --v 5.2 /imagine prompt: A tennis player achieving greatness in a serene and picturesque setting, playing on a lush green grass court surrounded by rolling hills and blooming wildflowers, the gentle breeze carrying the scent of nature, the player's sleek and elegant movements blending with the harmonious landscape, an audience of nature enthusiasts watching in quiet admiration, the court creatively designed with natural elements like stones and fallen logs, capturing the delicate balance between athleticism and nature's beauty, in a style reminiscent of an impressionistic painting by Claude Monet. --ar 16:9 --v 5 /imagine prompt: The tennis pro battling it out on a futuristic tennis court, surrounded by holographic advertisements and a holographic crowd, vibrant lights flashing and illuminating the intense match, the court's surface gleaming with a high-tech sheen, displaying real-time stats and game analysis, capturing the fast-paced action and the fusion of sports and technology, in a style reminiscent of a digital artwork by Beeple. --ar 16:9 --v 5"},{"instruction":"translate to English, don't change symbol and line break. Don't change space between paragraphs","output":"I apologize, but you did not provide any text to translate. Could you please provide the text you wish to have translated so I can assist you?"},{"instruction":"< 방콕 (3) > 한 손에 M4 카빈 소총을 든 ‘장연우’. 아니, 강우진이 숲길을 걷고 있다. 군복에 방탄조끼는 그대로지만, 귀에 꼈던 무전기는 어디 갔는지 보이지 않았다. 그의 걸음은 느리지도 그렇다고 빠르지도 않다. 평범한 속도였다. 마치 산책을 나온 듯한 리듬. -서벅서벅. 군화에 잡초들이 밟혀 옅은 소음이 퍼졌다. 차가운 바람이 우진의 정면을 때렸다. 냉기가 스며들었다. 순간, 무표정인 강우진의 입가에 작은 미소가 번졌다. “즐겼으니 됐지.” 눈코입의 감각이 기민해졌다. 어둡지만 익숙해진 전방, 숲속 특유의 풀냄새와 겨울 정서의 냄새, 서벅서벅 소음과 벌레 따위가 내는 잡소리들. 모든 것이 선명했으며 ‘장연우’의 심정이 더더욱 우진에게 팽배해졌다. 즐펀했던 쾌감이 점차 줄어들었다. 하늘을 올려보는 강우진. “······” 밝다. 달이 밝다. 잠시간 옅은 미소를 머금은 채 하늘을 보던 우진이 오른손에 쥔 소총을 내려봤다. 손가락에 딱딱한 것이 굳었다. 건조한 핏물이었다. 본인의 것이 아닌 타인의 것. 그러고 보니 볼 쪽이나 얼굴 이곳저곳이 까끌했다. 역시 핏물이다. 강우진이 다시 걸었다. 남은 손으로 볼 쪽에 굳은 피를 긁어냈다. 뭔가 공허하다. 직전에 이름도 모를 것들을 죽여서가 아니다. 죄책감? 후회? 그딴 것들은 그에게 존재치 않았다. 그냥 좀 지루했다. “후우-” 폭력과 살육에 점철된 삶이다. 그러나. “질려.” 자극이 완연하면 자연스러워진다. 몸이 적응하고 뇌가 자극에 익숙해진다. 결과적으론 재미가 소멸. 텀이, 공백기가 필요하다는 결론이었다. 때때로 잡생각도 들었다. 직전에 내 손에 목숨을 잃은 것들의 인생을 떠올려보는 등의. 하찮다. 나나 그들 모두 말이다. 헛생각은 판단을 흐린다. 의미가 없다. 그들이나 우진이나 죽거나 죽일 뿐이다. 약한 자가 심판을 당한 것이요, 살아남은 자가 심판자일 뿐이다. 존재하면 그것이 강한 것이다. 하지만 정의로운 심판자는 아니다. 악이다. 살아남은 심판자는 결단코 정의롭지 않고 모두에게 악일 뿐이다. 그저 심판하는 대상을 선택할 뿐. ‘나이스한 개새끼’. 지금의 ‘장연우’ 또는 강우진을 표현하자면 그랬다. 보기엔 평범하지만 내면 심연을 보자면 악랄했다. 하지만 이 병신같은 지루함이 반복되면 심판당하는 쪽은 저들이 아니라 나다. 우진은 자취를 감출 것을 확정했다. 그 누구의 눈에 띄지 않고 조용히 사라진다. -터벅! 어느새 숲을 빠져나온 강우진. 그의 눈에 도로가 보였다. 도로 한쪽 작은 공간엔 허름한 트럭이 세워져 있었다. 당연히 우진이 준비해둔 것. -텅! 트럭에 오른 강우진이 소총을 조수석에 툭 하고 던진 뒤 시동을 걸었다. 콜록대던 트럭이 나름 요란한 배기음을 냈다. 이어. -부우우웅! 1초의 망설임 없이 운전을 시작하는 우진. 트럭의 속도는 점차 빨라졌고 강우진의 시야 역시 초마다 변했다. 컴컴한 도로를 비추던 그의 정면과 온도가 삽시간에 탈바꿈됐다. 수년이 흘렀으니까.","output":"< Bangkok (3) > 'Jang Yeon-woo' with an M4 carbine in one hand. No, Kang Woo-jin is walking down a forest path. He's still wearing his military uniform and bulletproof vest, but the radio that was in his ear is nowhere to be seen. His pace is neither slow nor fast. It was an ordinary speed. As if he was out for a stroll. - Crunch, crunch. The weeds were crushed under his military boots, spreading a faint noise. A cold wind struck Woo-jin's face. The chill seeped in. Suddenly, a small smile spread across the expressionless Kang Woo-jin's lips. \\"I enjoyed it, so that's enough.\\" His senses of sight, smell, and hearing became sharper. The familiar darkness ahead, the unique smell of the forest and the scent of winter, the crunching noise, and the miscellaneous sounds made by insects. Everything was clear, and 'Jang Yeon-woo's feelings became even more pervasive within Woo-jin. The pleasure he had enjoyed was gradually diminishing. Kang Woo-jin looked up at the sky. \\"......\\" It's bright. The moon is bright. Woo-jin, who had been looking at the sky with a faint smile, looked down at the rifle in his right hand. Something hard had solidified on his fingers. It was dried blood. Not his own, but someone else's. Now that he thought about it, his cheek and various places on his face felt rough. It was also blood. Kang Woo-jin started walking again. With his other hand, he scraped off the dried blood on his cheek. Something felt empty. Not because he had just killed nameless things. Guilt? Regret? Such things did not exist for him. It was just a bit boring. \\"Hoo-\\" His life was marked by violence and slaughter. However. \\"I'm sick of it.\\" When stimulation becomes constant, it becomes natural. The body adapts, and the brain becomes accustomed to the stimulation. As a result, the fun disappears. There needs to be a break, a period of downtime. Sometimes, he had random thoughts. Like recalling the lives of those who had just lost their lives at his hands. Trivial. Both I and they are. Such idle thoughts cloud judgment. They are meaningless. Whether it's them or Woo-jin, it's just a matter of killing or being killed. The weak are judged, and the survivor is the judge. To exist is to be strong. But he is not a righteous judge. He is evil. The surviving judge is by no means just and is evil to everyone. He simply chooses who to judge. 'A nice son of a bitch.' That's how you would describe the current 'Jang Yeon-woo' or Kang Woo-jin. Ordinary in appearance, but vicious when you look into the depths of his being. But if this damn boredom repeats, it's not them but I who will be judged. Woo-jin decided to erase his tracks. He will disappear quietly without catching anyone's eye. - Thump! Before he knew it, Kang Woo-jin had emerged from the forest. He saw a road in front of him. On one side of the road, there was a shabby truck parked. Of course, it was something Woo-jin had prepared. - Thud! Kang Woo-jin got into the truck, tossed the rifle onto the passenger seat, and started the engine. The truck, which had been sputtering, let out a reasonably loud exhaust noise. Then. - Vroom! Woo-jin started driving without a second's hesitation. The truck's speed gradually increased, and Kang Woo-jin's view changed every second. The temperature and the view in front of him, which had been illuminating the dark road, transformed in an instant. Years had passed, after all."},{"instruction":"차에 타고 있던 강우진은 북적거리는 시장에 서 있었다. 내리쬐는 햇볕이 뜨겁다. 팔뚝이 따가울 정도였다. 조금씩 우진의 시야가 선명해졌다. 그을린 피부의 사람들이 왁자지껄 뒤섞여 움직이고 있었다. “······” 귀가 찢어질 정도로 외치는 남자, 파는 상품의 소개처럼 들리는 여자의 괴성, 사람들 사이사이를 파고드는 자전거나 오토바이, 초마다 들리는 경적, 우진의 어깨나 팔뚝을 쳐대며 지나치는 수십 사람들. 하지만 이 같은 광경은 강우진에게 낯설게 보이지 않았다. 지금 그의 마음은 평온했다. 당연했다. 이 방콕에서 우진은 몇 년째 살고 있었으니까. 땀이 볼을 타고 흘렀다. 보니 강우진의 모습도 퍽 변했다. 턱에 수염이 좀 자랐고 피부 톤도 살짝 탔다. 입은 갈색 셔츠나 청바지 역시 허름하기 짝이 없었다. -스윽. 담배를 입에 무는 그. 라이터를 손에 든 우진이 북적이는 사람들 사이로 진입했다.","output":"Kang Woo-jin, who had been in the car, was now standing in a bustling market. The sun beating down was hot. Hot enough to make his forearms sting. Gradually, Woo-jin's vision became clearer. People with sunburnt skin were moving about noisily, all mixed together. \\"......\\" A man shouting loud enough to tear ears, a woman's scream sounding like she's introducing her wares, bicycles and motorcycles weaving through the people, the honking of horns every second, dozens of people bumping against Woo-jin's shoulders and forearms as they passed by. However, such a scene did not seem unfamiliar to Kang Woo-jin. His mind was at peace right now. Of course. Because Woo-jin had been living in Bangkok for several years now. Sweat trickled down his cheeks. Even Kang Woo-jin's appearance had changed quite a bit. A bit of a beard had grown on his chin, and his skin tone was slightly tanned. The brown shirt and jeans he wore were also exceptionally shabby. - Sssk. He put a cigarette in his mouth. Holding a lighter in his hand, Woo-jin entered the throng of bustling people."},{"instruction":"-빵빵빵!! 계속해서 귀가 쩌렁쩌렁 울렸지만, 별수롭지 않게 반응한 강우진은 정신없는 시장 내부를 걸었다. 그러다 시장 중간쯤 있는 한 음료 가게에 도착한 우진이 외부에 깔린 테이블에 앉았다. 다가온 주인에게 영어로 적당히 커피를 시킨 그가 다 치운 담배를 버린 뒤. “쯧, 오면서 사둘 걸 그랬나.” 하나 남은 담배를 입에 재차 물었다. 다만, 이번엔 라이터가 문제였다. 칙칙 소음만 날 뿐 라이터가 불을 뿜지 않았다. 혀를 찬 강우진이 라이터를 흔들 때였다. -스윽. 뜬금 우진의 오른 귀 쪽으로 손이 쑥 나왔다. 본능적으로 손을 잡아 꺾으려던 강우진. 그런 그에게 점잖은 목소리가 들렸다. 여자 목소리에다 영어였다. “J(제이), 침착해.” 낯설지 않은 톤과 음성이었다. 멈칫한 강우진이 고개를 돌렸다. 딱 붙는 회색 탱크톱에 선글라스를 낀 외국인 여자가 서 있었다. 머리를 금발을 돌돌 말아 올렸다. 그녀가 우진에게 잡힌 자신의 손을 턱짓했다. “불이 필요한 거지?” 여자의 손엔 네모난 은색 라이터가 들려있었다. 픽 웃은 우진이 라이터를 집어선 입에 물린 담배에 불을 붙였다. 그리곤 라이터를 주머니에 넣으며 말했다. “됐어, 이제 꺼져.” 금발의 여자가 어깨를 으쓱였다. “라이터를 줘야 가지.” “내 거잖아 이거. 너한테 맡겨 뒀던 거고.” 선글라스를 벗은 여자가 우진의 반대편 의자에 앉아 다리를 꼬았다. “너무 꽁꽁 숨어 있어서 찾는 게 오래 걸렸어.” 그녀는 ‘장연우’ 또는 강우진의 과거 동료였다. “L(엘), 날 어떻게 찾았지?” “사람 찾는 거야 내 전문이니까. 데스크가 내 주 임무였어, 잊은 거야? 물론 J(제이) 널 찾는 건 상당히 어려웠지만.” 담배 연기를 후- 하고 뱉던 우진이 등을 의자에 기대며 답했다. “헛소리 그만하고. 날 왜 찾았어.” “제이, 이만하면 많이 놀았잖아. 내 팀에 들어와, 네가 없어진 뒤에 내가 따로 팀을 만들었어.” “뭘 하는 팀인데.” “뭐든. 의뢰를 받고 돈이 입금되면 뭐든 해.” “팀 인원은.” “직접 확인해.” “싫어, 좀 더 놀 거야.” 하품하는 강우진의 발을 금발 여자가 찼다. “너 같은 쓰레기는 필요 없어, 네 실력이 필요할 뿐이야. 이런 시장통에서 썩히기는 아까우니까. 용병이 돼.” “실력도 쓰레기가 됐겠지.” “좋아, 그럼.” 말을 잠시 멈춘 여자가 벗은 선글라스를 다시금 쓰며 의자서 일어났다. “여기 방콕에서 일 하나만 해보고 결정하는 건 어때.” “뭔데.” “여자애 하나 구출하는 거야, 쉽지?” “여자애?” “응.” 엘이라 불린 금발 여자가 새 담뱃갑을 우진에게 내밀며 비죽 웃었다. “여기 마약왕의 딸, 납치됐거든.” 후로. 퍽 길었던 ‘장연우’의 인생을 살던 강우진이 다시금 하늘 위의 비행기로 돌아왔다. 즉, 현실로 복귀했다는 뜻. ‘장연우’로서 수년 이상을 살았지만 현실의 비행기 쪽은 몇 초 정도가 흘렀을 뿐. 거기다 분명, 직전의 세상에선 수많은 폭발과 총격이 터져댔었는데. “······” 비행기 안은 쥐죽은 듯이 고요했다. 평온하기 그지없다. 대부분의 인원이 잠에 빠졌기 때문이었다. 바로 옆자리 최성건, 최나나 작가 등등. 유일하게 턱수염 송만우 PD만 대본을 보고 있었다. 삽시간에 ‘장연우’의 냄새가 빠진 우진이 속으로 약간 황당하게 웃었다. ‘이 온도 차만큼은 진짜 적응이 안 되네.’ 각인된 배역의 세상과 강우진의 세상은 공존하면서도 판이했다. 매번 겪는 일이었지만, 이렇게나 차이가 극명하면 어이가 없는 게 당연했다. 어쨌든. -스윽. 강우진이 손에 쥐어진 ‘이로운 악’의 1화 대본에 시선을 내렸다. 아공간에 재차 진입하기 위함은 아니었다. -팔락. 대본을 읽기 위해. 아니, 분석하기 위함이었다. ‘배역합성’이나 ‘배역의 자유도’ 등을 습득한 뒤 생긴 강우진의 루틴이었다. 조금 더 선명하게, 더욱이 폭발적으로, 생각보다 더 생동감 넘치게. 어느새 강우진은 배우로서의 자세가 딴딴히 잡혀가고 있었고. ‘장연우가 진짜 이럴라나? 걍 노빠꾸로 지를 거 같은데.’ 대본 속이 아닌, 현실에 뛰쳐나와 날뛸 ‘장연우’ 역시 명확해지는 중이었다. 그렇게 흐른 시간이 몇 시간. 어느새 우진이 탄 비행기는 방콕의 ‘수완나품 국제공항’에 착륙하는 중이었다. 대본 분석부터 아공간에서의 휴식까지 끝낸, 진작에 컨셉질을 뒤집어쓴 강우진이 시선을 창밖에 던졌다. 방콕이 보이기 시작했다. 하지만 생각보다 신기함은 없었다. 뭔가 비슷한 광경이 떠올랐으니까. ‘어째 다낭이랑 비스무리하네.’ 베트남 다낭을 말하는 것. 다른 점도 있긴 했다. ‘실종의 섬’ 해외로케로 갔던 다낭은 휴양지 느낌이라면, 이번의 방콕은 도시의 느낌이 강했다. 뭐가 됐든 명확히 비슷한 점이라면. ‘벌써 더워, 아오 씨.’ 무더울 거라는 점. 한창 강우진이 창밖을 보며 컨셉질로 가려진 투정을 속으로 읊조릴 때쯤, 그의 주변 좌석들은 매우 부산스러웠다. 익숙한 인물들. 턱수염 송만우 PD나 김소향 총괄디렉터, 최나나 작가, 스턴트 팀인 에단 스미스 등의 키스탭들 외의 다수. 이유야 간단했다. “혼잡할 거 같으니까! 초반에 안내한 것처럼 차례로!! 계획대로 입국장으로 움직이면 됩니다!” “오케이!!” “그리고 각 팀별로 내리자마자 짐이랑 장비들 체크 확실히 하셔야 돼요!” “어후- 이제 시작이구만!” 강우진 포함 이 비행기에 탄 대부분의 인원이 ‘이로운 악’의 촬영팀이었으니까. 당연히 해외로케 촬영을 위한 것. 19일인 오늘은 사전 점검과 적당한 적응으로 보낼 예정이고, 20일인 내일부터 본격적인 촬영에 돌입하게 된다. 따라서 모두는 흥분과 함께 예민했다. 이후 비행기가 안전하게 착륙한 후, 거의 백여 명 되는 ‘이로운 악’ 팀 전부가 우르르 움직였다. 배우진은 그리 많지 않았다. 귀염상에 음침한 임해은이나 조연급 몇몇. 물론, 메인은. “우진씨!! 이쪽입니다!! 가드들과 같이 움직이세요!” 강우진이었다. 그의 주변엔 최성건과 팀원들이 붙었고, 그 보다 두 배 넘는 가드들이 둘러싼 형태였다. 입국장으로 향하는 ‘이로운 악’팀의 행진은 수많은 인파들의 시선을 독차지하기에 부족함이 없었다. 어마어마한 규모였으니까. 나름 나눠서 움직이긴 했다. 배우팀, 배우들의 스탭팀, ‘이로운 악’의 제작진 등. 한 번에 행동하면 너무도 혼잡할 테니 사고 날 위험이 컸다. ‘이로운 악’ 팀은 ‘수완나품 국제공항’의 입국장으로 서서히 걸었다. 강우진도 행진 흐름에 맞췄다. 딱딱한 표정엔 큰 변화가 없다. 하지만. ‘뭔가- 묘하게 떨리는데? 촬영 임박해서 그런가??’ 내면으로는 점차 심장박동이 격해지는 중이었다. 그럴수록 냉철함을 더욱 진하게 만들었다. 와중 그의 주변 배우들, 즉 이번 해외로케 촬영에 합격한 조·단역 배우들이 강우진과 주변을 둘러보며 수군댔다. “가드- 좀 많지 않아요?” “그러니까요. 시선 엄청 받는데.” “강우진님 때문이겠죠.” “일본에서야 우진님이 대박인 건 아는데···태국에서도 먹혀요? 들은 적 없는데.” “글쎄요. 일단, 우리 때문은 100% 아니니까 무조건 우진님 때문이겠죠. 뭐, 혹시 모를 사고 때문에 그런 거 아니에요??” “예방 차원이겠죠. 근데 가드들이 좀 과하게 많긴 하네.” 그들로서는 처음 겪는 취급이었으니까. “그래도······어깨 뽕 좀 올라가지 않아요? 우리가 우진님 아니면 언제 이런 거 경험해보겠어요.” “인정. 사진도 엄청 찍었어요 저.” “예방이든 뭐든 완전 기분 째지긴 해요. 어후- 확실히 사는 세상이 다르구나 싶은 느낌?” “우리는 언제쯤 저런 그림 볼 수 있으려나.” “강우진님이 2년 만에 하셨으니까- 우리도 불가능하진···아니다, 불가능하겠다.” “여튼 좋은 구경 하네요.” 이윽고. -스르륵. 가드들이 앞선, 강우진이 중심이 된 배우팀 무리가 ‘수완나품 국제공항’ 입국장에 들어섰다. 동시에 터지는, 눈이 멀 정도의 플래시 세례. -파바바바박! -파바바바바박!! 이내 강우진을 제외한 배우들의 눈이 휘둥그레졌다. “허??!!” “우왁!” “와···미친!!” “뭐, 뭐야?!!” “까, 깜짝이야!!” 이유야 간단했다. 입국장 앞엔 어마무시한 인파가 몰려든 상태였으니까. “%&)*%#**%&*)%*)강우진!!” “@*&(*%*(강우진!! 강우진!!” 태국 기자들 포함, 수백 인파가 오직 강우진을 외치고 있었다. 귀가 뜯어질 정도의 무시무시한 데시벨. 과한 괴성이라 알아듣긴 힘들어도 강우진 이름은 잘 들렸다. “꺄아악!! 강우진!” “우진!!@()@*)(@!!” 퍽 예상 밖이었다. 이를 목도한 강우진의 얼굴은. “······” 다분히 덤덤했다. ‘미친??!’ 물론, 겉으로만. < 방콕 (3) > 끝","output":"- Beep beep beep!! The continuous honking rang in his ears, but Kang Woo-jin, who reacted nonchalantly, walked through the chaotic market. Then, reaching a beverage shop in the middle of the market, Woo-jin sat down at a table set outside. After ordering coffee in English from the approaching owner and discarding his finished cigarette. \\"Tsck, I should have bought some on the way.\\" He put another cigarette in his mouth. This time, however, the problem was the lighter. It only made clicking noises and wouldn't light. As Kang Woo-jin clicked his tongue and shook the lighter. - Swoosh. Suddenly, a hand reached out towards Woo-jin's right ear. Instinctively trying to grab and twist the hand, Kang Woo-jin heard a polite voice, a woman's voice speaking English. \\"J, stay calm.\\" It was a tone and voice not unfamiliar to him. Woo-jin hesitated and turned his head. A foreign woman in a tight gray tank top and sunglasses stood there. Her blonde hair was rolled up. She gestured with her hand, which Woo-jin had grabbed. \\"Need a light?\\" In the woman's hand was a square silver lighter. Woo-jin, with a smirk, took the lighter and lit his cigarette. Then, putting the lighter in his pocket, he said. \\"Done, now get lost.\\" The blonde woman shrugged her shoulders. \\"You have to give me the lighter.\\" \\"It's mine. I had left it with you.\\" The woman, taking off her sunglasses, sat down on the opposite chair and crossed her legs. \\"It took me a long time to find you because you were hiding so well.\\" She was a former colleague of 'Jang Yeon-woo' or Kang Woo-jin. \\"L, how did you find me?\\" \\"Finding people is my specialty. I was in charge of the desk, remember? Of course, finding J was quite difficult.\\" Woo-jin, blowing out cigarette smoke, leaned back in his chair and replied. \\"Cut the crap. Why did you find me?\\" \\"J, you've had enough fun. Join my team; I formed a new one after you left.\\" \\"What kind of team?\\" \\"Anything. We take on jobs and get paid.\\" \\"How many in the team?\\" \\"See for yourself.\\" \\"No, I want to play more.\\" The blonde woman kicked Woo-jin's yawning foot. \\"I don't need trash like you, just your skills. It's a waste to rot in a market like this. Become a mercenary.\\" \\"My skills have probably become trash too.\\" \\"Fine, then.\\" The woman paused, put her sunglasses back on, and stood up from the chair. \\"How about doing just one job here in Bangkok and then decide?\\" \\"What is it?\\" \\"Rescuing a girl, easy, right?\\" \\"A girl?\\" \\"Yeah.\\" The woman called L offered Woo-jin a new pack of cigarettes with a smirk. \\"The daughter of the drug king here, she's been kidnapped.\\" And then. After living the long life of 'Jang Yeon-woo,' Kang Woo-jin returned to the airplane above the sky. In other words, he returned to reality. Although he had lived as 'Jang Yeon-woo' for several years, only a few seconds had passed in the reality of the airplane. Moreover, in the previous world, there had been numerous explosions and gunfire. \\"......\\" The airplane was dead silent. Utterly peaceful. Most of the passengers had fallen asleep. Right next to him, Choi Sung-gun, writer Choi Na-na, and others. Only producer Song Man-woo with a goatee was looking at the script. Woo-jin, who had suddenly lost the scent of 'Jang Yeon-woo,' laughed inwardly at the absurdity. 'I just can't get used to this temperature difference.' The world of the role he played and Kang Woo-jin's world coexisted yet were vastly different. It was a common experience, but such a stark contrast was naturally absurd. Anyway. - Swoosh. Kang Woo-jin's gaze fell on the script of episode 1 of 'Beneficial Evil' he held in his hand. It wasn't to re-enter the subspace. - Flap. To read the script. No, to analyze it. It was a routine that had developed for Kang Woo-jin after acquiring skills like 'Role Synthesis' and 'Role Freedom.' To make it clearer, more explosive, and more vibrant than expected. Before he knew it, Kang Woo-jin was firmly establishing his stance as an actor. 'Would Jang Yeon-woo really do this? Feels like he'd just go all out.' The 'Jang Yeon-woo' who would burst out into reality, not just in the script, was also becoming clearer. After a few hours. The plane Woo-jin was on was now landing at Bangkok's 'Suvarnabhumi International Airport.' Having finished analyzing the script and resting in the subspace, Kang Woo-jin, who had already donned his concept, looked out the window. Bangkok was coming into view. But there was less wonder than expected. Because he recalled a similar scene. 'It's kind of like Da Nang.' He was talking about Da Nang in Vietnam. There were differences, of course. Da Nang, where he had gone for an overseas shoot for 'Island of the Missing,' had a resort feel, while Bangkok had a more urban vibe. But if there was a clear similarity. 'It's already hot, damn.' The point was that it would be sweltering. As Kang Woo-jin looked out the window and muttered his concept-covered complaints inwardly, the seats around him were very busy. Familiar faces. Producer Song Man-woo with the goatee, general director Kim So-hyang, writer Choi Na-na, stunt team member Ethan Smith, and other key staff. The reason was simple. \\"It's going to be crowded! As I mentioned earlier, exit in order!! Just move to the arrival hall according to the plan!\\" \\"Okay!!\\" \\"And each team needs to check their luggage and equipment as soon as they get off!\\" \\"Ah, it's just the beginning!\\" Most of the passengers on the plane, including Kang Woo-jin, were part of the 'Beneficial Evil' filming team. Naturally, it was for an overseas location shoot. Today, the 19th, was scheduled for preliminary checks and acclimatization, and from tomorrow, the 20th, they would start the actual filming. Therefore, everyone was excited and on edge. After the plane landed safely, nearly a hundred members of the 'Beneficial Evil' team bustled about. There weren't many actors. Cute but gloomy Im Hae-eun and a few supporting actors. Of course, the main one was. \\"Woo-jin! This way! Move with the guards!\\" It was Kang Woo-jin. Choi Sung-gun and team members were attached to him, and twice as many guards surrounded him. The march of the 'Beneficial Evil' team towards the arrival hall captured the attention of the crowds. It was an enormous scale. They moved in groups. The actors' team, the actors' staff team, the 'Beneficial Evil' production team, etc. Moving all at once would be too chaotic and risky. The 'Beneficial Evil' team slowly walked towards the 'Suvarnabhumi International Airport' arrival hall. Kang Woo-jin also matched the flow of the march. His expression was rigid. But. 'Something's strangely thrilling. Is it because the shooting is imminent??' Internally, his heartbeat was accelerating. The more it did, the more he intensified his composure. Meanwhile, the actors around him, the extras and minor role actors who had passed the overseas shoot, whispered to Kang Woo-jin and looked around. \\"Aren't there too many guards?\\" \\"Seriously. We're getting a lot of attention.\\" \\"It must be because of Kang Woo-jin.\\" \\"I know Woo-jin is a big deal in Japan... but does he have a following in Thailand? I've never heard of it.\\" \\"Who knows. Anyway, it's definitely not because of us, so it must be because of Woo-jin. Maybe it's to prevent any possible accidents??\\" \\"It must be a precaution. But there are too many guards.\\" It was their first time receiving such treatment. \\"But still... doesn't it kind of boost your ego? When would we ever experience this if not for Woo-jin?\\" \\"Agreed. I took a lot of photos.\\" \\"Whether it's a precaution or not, it feels amazing. It really makes you realize we live in different worlds, right?\\" \\"When will we ever see such a scene?\\" \\"Woo-jin did it in just 2 years, so for us... no, it's impossible.\\" \\"Anyway, it's a good show.\\" Eventually. - Slide. The actor team, centered around Kang Woo-jin and led by the guards, entered the 'Suvarnabhumi International Airport' arrival hall. Simultaneously, a blinding barrage of flashes erupted. - Papapapapak! - Papapapapapak!! Soon, the eyes of the actors, excluding Kang Woo-jin, widened. \\"Huh??!!\\" \\"Whoa!\\" \\"Wow... crazy!!\\" \\"What, what is this?!!\\" \\"Scared me!!\\" The reason was simple. In front of the arrival hall, a massive crowd had gathered. \\"%&)*%#**%&*)%*)Kang Woo-jin!!\\" \\"@*&(*%*(Kang Woo-jin!! Kang Woo-jin!!\\" Thai reporters included, hundreds in the crowd were shouting only Kang Woo-jin's name. The terrifying decibels were enough to tear ears. Although the screams were too loud to understand, Kang Woo-jin's name was clearly heard. \\"Kyaaak!! Kang Woo-jin!\\" \\"Woo-jin!!@()@*)(@!!\\" It was completely unexpected. The face of Kang Woo-jin, who witnessed this, was. \\"......\\" Remarkably calm. 'Crazy??!' Of course, only on the outside. < Bangkok (3) > End"},{"instruction":"Comment marche les appareils haptiques à porter et l’haptique sans contact.","output":"Les appareils haptiques à porter et l'haptique sans contact sont deux approches différentes qui permettent aux utilisateurs de ressentir des sensations tactiles dans le cadre d'interactions avec des systèmes numériques ou des environnements virtuels. Voici un aperçu du fonctionnement de chacun: # Appareils haptiques à porter (Wearable Haptic Devices) Ces appareils incluent des gants, des vestes, des bracelets, ou tout autre accessoire équipé de technologies visant à simuler le toucher ou la sensation physique. Leur fonctionnement repose sur plusieurs méthodes : 1. **Moteurs de vibration ou tactors** : Ils produisent des vibrations pour simuler une sensation de contact ou de texture. Les smartphones et les manettes de jeu utilisent souvent de tels dispositifs pour fournir un retour haptique de base. 2. **Actionneurs pneumatiques ou hydrauliques** : Ils utilisent des fluides ou de l'air sous pression pour créer une sensation de mouvement ou de force. 3. **Électrostimulation** : Cette technique implicite l'utilisation de petits courants électriques pour stimuler les nerfs et imiter la sensation de toucher. 4. **Exosquelettes** : Pour des expériences plus intensives, des exosquelettes peuvent être portés pour fournir une résistance physique et simuler la sensation de force ou de poids. 5. **Matériaux à changement de forme** : Certains appareils utilisent des matériaux intelligents qui changent de forme ou de rigidité sous l'effet d'un stimulus électrique ou thermique, pour simuler la texture ou la forme des objets. # Haptique sans contact (Non-contact Haptic Technology) Ils utilisent des ondes ou des forces à distance pour créer une sensation de toucher sans qu'il n'y ait de contact direct avec la peau de l'utilisateur. Voici quelques exemples : 1. **Ultrasons**: La focalisation d'ondes ultrasonores peut créer une pression sur la peau de l'utilisateur sans aucun contact physique. Les systèmes basés sur les ultrasons peuvent former des points de pression dans l'air qui sont perçus comme des objets tactiles. 2. **Air Vortex** : En générant un vortex d'air ou des jets d'air précis, il est possible de simuler un contact sur la peau de l'utilisateur. 3. **Laser ou lumière** : Des méthodes expérimentales incluent l'utilisation de lasers pulsés à faible puissance pour provoquer une expansion rapide de l'air ou de matériaux spécifiques, ce qui crée une sensation de toucher sur la peau. Les applications de ces technologies sont vastes, incluant des jeux vidéo, de la réalité virtuelle ou augmentée, des simulations de formation, des systèmes de guidage pour personnes malvoyantes, et même des interfaces utilisateur pour des appareils sans écran tactile. L'haptique améliore de manière significative l'expérience utilisateur en apportant une dimension supplémentaire aux interactions, ce qui peut augmenter l'immersion, la compréhension et la réactivité dans des environnements virtuels ou lors de l'utilisation de dispositifs commandés à distance."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一个男孩子 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a young boy wearing a red hoodie, his hands covered in colorful paint, a mischievous smile on his face, sitting in front of a messy art table, surrounded by paintbrushes, markers, and tubes of paint, with a large canvas filled with vibrant strokes of color in the background, the room filled with natural light from a large window, casting soft shadows on the boy's face and the artwork, capturing the energy and creativity of a budding young artist, in a style reminiscent of a documentary photograph, captured with a Canon 5D Mark IV camera, 35mm lens, wide depth of field, composition focused on the boy's face and hands, showcasing his passion for art. --ar 9:16 --v 5.2 /imagine prompt: a curious young boy with tousled blonde hair, his wide eyes filled with wonder, standing at the edge of a lush forest, sunlight filtering through the canopy of leaves above, creating a dappled pattern on the ground, a gentle breeze rustling the leaves and causing the boy's shirt to flutter, a small backpack strapped to his shoulders, a pair of binoculars hanging around his neck, ready for an adventure in the great outdoors, in a style reminiscent of an illustration, capturing the innocence and curiosity of childhood. --ar 9:16 --v 5 /imagine prompt: a determined young boy wearing a soccer jersey, his feet firmly planted on a well-worn soccer field, a soccer ball at his feet, the grass freshly cut and smelling of summer, a group of cheering teammates in the background, their arms raised in victory, the sun setting on the horizon, casting a warm golden light over the scene, capturing the joy of playing a beloved sport and the camaraderie of a team, in a style reminiscent of a sports photography, captured with a Sony A7 III camera, 70-200mm lens, shallow depth of field, composition focused on the boy and the soccer ball, freezing the moment of triumph. --ar 16:9 --v 5.2 /imagine prompt: a young boy with messy hair and freckles, his backpack slung over one shoulder, standing at a bus stop on a rainy day, raindrops cascading down his umbrella, creating a beautiful pattern of ripples, the streetlights casting a soft glow on the wet pavement, his eyes filled with a mix of anticipation and apprehension, as he prepares for a new adventure, in a style reminiscent of a realistic photograph, captured with a Fujifilm X-T3 camera, 23mm lens, capturing the essence of a quiet moment in a bustling city. --ar 9:16 --v 5.2"},{"instruction":"rewrite: As for the pay raise, I’ll talk to them and schedule a meeting next week. For 30 days notice, I think I can explain on their behalf. This term is negotiable, and if you wish to terminate the contract you still can terminated 30 days beforehand. But it’s courtesy that let us know your decision 60 days beforehand, because considering the difficulties of hiring the right teacher that meet our kindergarten, we kindly hope you could understand that the reason why we extend to 60 days for notice period.","output":"Regarding the pay raise, I will discuss it with them and arrange a meeting for next week. In regards to the 30 days notice, I believe I can provide an explanation on their behalf. This time period is open to negotiation, and if you decide to terminate the contract, you can still do so with a 30-day notice. However, it would be appreciated if you can inform us of your decision 60 days in advance as a courtesy. This is because finding the right teacher for our kindergarten can be challenging, and we kindly request your understanding for extending the notice period to 60 days."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = full_shot,shota,serafuku,huge filesize,wallpaper,incredibly absurdres,penis,pantyhose,long hair,horse penis,NSFW,nipple rings,penis rings,otoko_no_ko,crossdressing,penis under clothes [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: majestic mountain range covered in a thick blanket of snow, towering peaks reaching towards the sky, shimmering under a golden sunset, creating a breathtaking display of colors, a lone skier carving through the fresh powder, leaving behind delicate tracks, surrounded by untouched wilderness, with pine trees lining the slopes, capturing the serenity and exhilaration of the moment, in a style reminiscent of Ansel Adams' iconic landscape photography. --ar 16:9 --v 5.2 /imagine prompt: bustling city street in the heart of downtown, vibrant and lively atmosphere, filled with people going about their day, a mix of modern skyscrapers and historic buildings, illuminated by the warm glow of streetlights, reflections dancing on wet pavement after a rain shower, the vibrant colors of neon signs and billboards lighting up the night, capturing the energy and excitement of urban life, in a style reminiscent of Henri Cartier-Bresson's candid street photography. --ar 9:16 --v 5.2 /imagine prompt: enchanting forest filled with ancient trees, their branches reaching out like gnarled fingers towards the sky, dappled sunlight filtering through the dense foliage, creating a mesmerizing play of light and shadows on the forest floor, a gentle stream trickling through moss-covered rocks, with wildflowers blooming in vibrant hues, a sense of tranquility and mystery permeating the air, capturing the beauty and magic of nature, in a style reminiscent of Maxfield Parrish's dreamlike paintings. --ar 1:1 --v 5.2 /imagine prompt: serene beach at sunrise, soft golden light painting the sky and casting a warm glow over the calm ocean surface, gentle waves lapping against the shore, leaving behind delicate patterns in the sand, a solitary figure walking along the water's edge, with seagulls soaring above, capturing a sense of tranquility and solitude, in a style reminiscent of Hiroshi Sugimoto's minimalist seascapes. --ar 1:1 --v 5.2"},{"instruction":"结合政治学基础例论阐述小农户融入市场时面临的主要问题及解决思路1000字左右","output":"小农户在融入市场时面临着一系列的问题，主要包括资源不足、技术水平低下、市场信息不对称、组织能力不足等。为解决这些问题，可以采取资源整合、技术培训、信息共享和组织扶持等措施。 首先，小农户面临资源不足问题。小农户往往缺乏充足的土地、资本和劳动力等资源，这限制了他们的生产能力和市场竞争力。解决这个问题的关键是资源整合。政府可以鼓励小农户通过联合组织、合作经营等方式，共享土地和资本等资源，提高生产规模。此外，政府还可以通过建立农业基地、农资供应站等平台，为小农户提供资源支持。 其次，小农户技术水平低下是另一个重要问题。由于教育水平不高、经验不足等原因，小农户往往缺乏现代农业技术的应用能力，导致产量低下、品质差等问题。解决这个问题的关键是技术培训。政府可以组织农业专家、技术人员等开展上门培训，传授现代农业技术知识和技能，提高小农户的技术水平。此外，政府还可以设立技术推广中心、建立示范基地等，为小农户提供技术支持和示范经验。 另外，小农户面临市场信息不对称的问题。由于缺乏市场触达渠道和信息传递途径，小农户难以了解市场需求、价格波动等信息，导致农产品销售困难、价格波动风险大等问题。解决这个问题的关键是信息共享。政府可以建立农产品信息网站、线上线下农产品交易平台等，提供市场信息和销售渠道，帮助小农户了解市场需求，并提供销售出口渠道。此外，政府还可以组织农产品市场调研、开展市场培训等，提高小农户的市场意识和销售能力。 最后，小农户组织能力不足是一个重要问题。由于个体农户数量多、分散经营等原因，小农户往往缺乏组织协作能力，无法有效参与市场竞争。解决这个问题的关键是组织扶持。政府可以引导小农户组织成农民专业合作社、农民合作社等农业经济组织，加强农民之间的合作和协作，提高整体经营效益。此外，政府还可以通过设立农业合作社发展基金、提供贷款、优惠税收等方式，提供资金和政策支持，帮助小农户改善组织条件。 综上所述，小农户融入市场时面临的主要问题是资源不足、技术水平低下、市场信息不对称和组织能力不足等。针对这些问题，可以通过资源整合、技术培训、信息共享和组织扶持等措施来解决。政府应发挥引导作用，提供相应的政策支持和资金支持，鼓励小农户积极融入市场，提高农业生产效益和农民收入水平。"},{"instruction":"结合政治学理论基础教材论述数字技术如何克服基层治理中的模糊性问题?1000字左右","output":"数字技术在基层治理中有着重要作用，可以帮助克服模糊性问题。基于政治学理论基础，以下将对数字技术如何解决基层治理中的模糊性问题进行论述。 首先，数字技术提供了丰富的数据分析和决策支持能力，有助于明确权责边界和责任划分，从而减少模糊性问题。基层治理中，公共资源的有效配置和管理是一个重要任务，而这往往需要明确各个相关部门的职责。通过数字技术，政府可以搜集和分析各部门的活动数据和运行情况，进而制定明确的职责分工和工作指标，并通过数字化监管手段对工作进展进行实时监测。这样一来，为政府提供了精确的数据基础，有助于减少权力错位和责任漏洞，从而有效克服模糊性问题。 其次，数字技术提供了信息公开和透明度提升的途径，有助于减少模糊性问题的产生。在基层治理中，信息不对称和不透明性常常导致决策制定和执行中的模糊性问题。数字技术通过建立公共信息平台和数字化政务系统，实现了政府信息的全面公开和透明度的提升。市民和社会组织可以通过数字渠道获取相关政策、程序和决策过程的信息，了解政府的行政活动，监督决策的合法性和公正性。同时，数字技术还可以建立投诉和举报平台，让公众能够及时反映问题和不满，促进政府的应对和解决。 另外，数字技术提供了在线参与和协商的机制，有助于促进民众参与和民主决策，减少模糊性问题。基层治理要依靠广大民众的参与和支持，但传统的参与方式存在各种限制，导致一些群体的声音被忽略。通过数字技术，政府可以建立在线协商和参与平台，让公民能够随时随地参与政府的决策过程和公共事务。政府可以通过数字渠道发起在线民意调查、听证会和公众会议，收集和整合各方的意见和建议，增强政策制定的科学性和民主性，减少决策过程中的模糊性问题。 最后，数字技术提供了数据共享和协作的平台，有助于解决多个部门之间的信息孤立和沟通不畅的问题，进而减少模糊性问题的出现。基层治理涉及多个部门、多个利益相关方的合作和协调，而信息的孤立和沟通不畅往往导致责任不清和工作模糊。通过数字技术，政府可以建立数据共享和协作平台，将各个部门的信息和资源整合起来，实现数据的互通共享和协同工作。这样一来，政府部门可以通过统一平台对信息进行共享和汇总，减少信息的重复搜集和整理，提高工作效率，减少模糊性问题的出现。 综上所述，数字技术在基层治理中克服模糊性问题的作用不可忽视。通过数据分析和决策支持、信息公开和透明度提升、在线参与和协商、数据共享和协作等方式，数字技术为解决模糊性问题提供了有效的工具和手段。政府应充分利用数字技术的优势，加强数字化治理能力建设，促进基层治理的规范化和现代化，为实现良好的基层治理提供有力支持。"},{"instruction":"结合政府治理理论分析，基层政府如何运用非正式治理资源，来扩充政府权力的运作空间?1200字左右","output":"基层政府在实践中常常面临资源有限、权力受限等问题，而非正式治理资源的运用可以帮助基层政府扩充其权力的运作空间。基于政府治理理论，以下将对基层政府如何运用非正式治理资源来扩充政府权力的运作空间进行分析。 首先，基层政府可以通过建立关系网络来扩充其权力的运作空间。基于政府治理中的“小政府”理念，基层政府相对更贴近市民，拥有较强的社会联系能力。通过与社会各界建立广泛的联系和沟通，建立稳固的关系网络，基层政府可以获取更多的非正式治理资源，例如政治支持、社会资本和信息等。这些资源的积累与运用有助于基层政府在面对问题时，能够通过协商、合作和协调等方式，获得有效的支持，并扩展自身的权力基础，提升政府的权力运作空间。 其次，基层政府可以利用非正式组织来扩充其权力的运作空间。非正式组织是指一些不受官方控制但在基层社区中运作的组织，如民间团体、社区组织等。基层政府可以与这些组织建立合作关系，通过与其合作开展社区建设、社会服务等活动，获取社区资源和社会支持。通过与非正式组织的合作，基层政府可以在官方能力有限的情况下，有效地扩展其权力运作空间，提高政府服务的质量和效率。 第三，基层政府可以积极运用社会资本来扩充其权力的运作空间。社会资本是社会中各方利益关系的积极资产，包括社会信任、社会网络和社会合作等。基层政府可以与社会资本资源密切关联，通过与社区居民和社会组织等建立良好的关系，积极发掘并有效利用社会资本，扩充政府的权力运作空间。例如，基层政府可以通过参与社区活动、与居民开展沟通和互动等方式，建立相互信任与合作的关系，获取居民的支持和配合，提高政府的权力行使效果。 最后，基层政府可以借助媒体和公众舆论来扩充其权力的运作空间。媒体和公众舆论是非正式的治理资源，能够对政府的行为进行监督和评价。基层政府可以通过与媒体合作、积极回应公众关切和舆论声音等方式，借助媒体和公众舆论的力量，推动政府工作的透明度和责任担当，提升政府的权力运作效果。同时，基层政府还可以通过组织公众参与决策、征求公众意见等方式，扩大公众的参与范围和话语权，增强政府的合法性和民主性，从而扩充政府权力的运作空间。 综上所述，基层政府可以通过运用非正式治理资源来扩充其权力的运作空间。建立关系网络、与非正式组织合作、积极运用社会资本、借助媒体和公众舆论等方式，可以有效地帮助基层政府获取各方面的支持和资源，进而扩展政府的权力基础和运作空间。基层政府应充分认识和利用非正式治理资源的重要性，积极推动非正式治理的发展，提升政府的治理能力和效果。"},{"instruction":"根据政治学基础理论教材，结合具体案例分析在基层网格治理中，实体网格和虚拟网格有机结合的实践机理1000字左右","output":"基层网格治理是指将行政区域划分为多个较小的网格单元，并在每个网格单元内组织实施社区治理、社会管理和公共服务等活动。在基层网格治理实践中，实体网格和虚拟网格的有机结合起到了重要的作用。根据政治学基础理论教材，具体案例分析如下。 实体网格是指具体的地理区域划分，前提是基于实地调研、资源分析等方式确定的，通过社区、街道等单位和人员参与的方式，建立一套实体化的管理机制。实体网格通过确切的区域定位和具体的责任划分，将基层治理过程中的各个主体有机地组织起来，实现权力的下沉和责任的明确。例如，以中国广东省珠海市香洲区的网格化社会治理为案例，香洲区将辖区划分为多个网格，每个网格都设立专门的网格员，负责辖区内的社会治理工作，如社会调解、社区服务、公共安全等。这种实体网格的建立，有效地提高了基层治理效率和社会治理能力，增强了政府的权力运作空间。 虚拟网格是在实体网格基础上，结合信息科技手段，通过互联网、大数据等技术建立起来的虚拟空间，用于信息共享、问题反馈和决策支"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, a CG rendering of a handmade SpongeBob SquarePants toy with glossy and super clear textures, featuring vibrant polychrome colors and round smooth edges. The toy is adorned with toy furnishings, including a big star on its hand, and is placed in a playful and joyful composition. --ar 1:1 --v 5.2 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, a detailed CG rendering of a handmade SpongeBob SquarePants toy with captivating glossy and super clear textures. The toy is made with impeccable craftsmanship, featuring beautifully detailed toy furnishings and a big star on its hand. The composition highlights the toy's round and smooth design, showcasing its adorable and lovable qualities. --ar 16:9 --v 5 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, a CG rendering of a vibrant and lively scene where multiple handcrafted SpongeBob SquarePants toys are displayed together. Each toy is made with attention to detail, featuring glossy and super clear textures that reflect light beautifully. The toys are arranged in a harmonious composition, showcasing their individual characteristics and emphasizing the colorful and lively atmosphere. --ar 9:16 --v 5 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, a CG rendering capturing the magical and enchanting world of SpongeBob SquarePants toys. The scene is set in a whimsical and fantastical environment, filled with vibrant colors and playful details. The composition features a single SpongeBob SquarePants toy surrounded by toy decorations, all with glossy and ultra-clear textures. The atmosphere is joyful and exudes a sense of wonder, inviting viewers to dive into the magical world of SpongeBob SquarePants. --ar 16:9 --v 5.2"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一个叫做野象网球俱乐部培养的中国网球选手，在国际舞台上取得奖牌 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A talented young Chinese tennis player trained by the Wild Elephant Tennis Club, achieving medals on the international stage, praised for his remarkable skills in both singles and doubles matches, with a powerful serve and a graceful backhand, wearing a custom-made red and gold tennis outfit, the Chinese flag proudly displayed on his racket, surrounded by cheering fans and fellow athletes, on a meticulously maintained tennis court with a vibrant green surface, under the bright lights of a stadium, captured with a Canon EOS 5D Mark IV camera, 200mm telephoto lens, freezing the action with excellent sharpness and clarity, composition emphasizing the player's intense focus and determination, in a dynamic sports photography style reminiscent of Rafael Nadal's iconic tennis images. --ar 3:2 --v 5.2 /imagine prompt: A rising tennis star from China, meticulously groomed under the mentorship of the esteemed Wild Elephant Tennis Club, soaring to new heights on the global tennis scene, winning numerous accolades and breaking records, showcasing exceptional agility, precision, and endurance, clad in a sleek white tennis outfit adorned with the elegant Chinese dragon emblem, creating a vibrant blend of tradition and modernity, surrounded by a state-of-the-art tennis complex with futuristic architecture, bright LED lights illuminating the court and casting dramatic shadows, captured with a Sony Alpha 7R III camera, 50mm lens, capturing the player's strength and elegance with a shallow depth of field, composition focusing on the player's poised stance and intense gaze, presented in a hyper-realistic digital painting style, highlighting the player's determination and triumph. --ar 16:9 --v 5 /imagine prompt: Marvel at the astonishing talent of a Chinese tennis prodigy nurtured by the Wild Elephant Tennis Club, achieving remarkable success on the international stage, adorned with a grand array of accolades and medals, known for her precision, agility, and fierce competitive spirit, executing a powerful forehand shot with perfect form, dressed in a vibrant red and white tennis attire, representing national pride, situated in a picturesque outdoor tennis court nestled amidst lush greenery and majestic mountains, basking in the warm glow of the afternoon sun, captured with a Fujifilm X-T3 camera, 35mm lens, showcasing the player's grace and intensity with a wide-angle perspective, composition capturing the player's fluid movement and unwavering determination, presented in a lively painted illustration style reminiscent of ancient Chinese brushwork, evoking the spirit of harmony between nature and human achievement. --ar 3:2 --v 5 /imagine prompt: Journey into the realm of tennis excellence with a rising star hailing from China, meticulously honed by the prestigious Wild Elephant Tennis Club, acclaiming international recognition and winning coveted titles, showcasing unrivaled power, finesse, and court strategy, donning an eye-catching attire blending traditional Chinese elements with modern flair, surrounded by a cutting-edge tennis venue designed with sleek geometric shapes and innovative lighting, creating a dynamic and futuristic atmosphere, captured with a Panasonic Lumix GH5 camera, 12-35mm zoom lens, preserving the player's nimble footwork and dynamic strokes with a wide-angle view, composition highlighting the player's steely determination and unwavering focus, presented in a striking sculptural art style, embodying the player's indomitable spirit and unyielding pursuit of excellence. --ar 16:9 --v 5"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 雪地里的汽车露营画面，白色调为主，带有晚霞 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A serene winter camping scene in the snowy mountains, with a pristine white landscape, illuminated by the warm glow of the setting sun. The snow-covered ground is dotted with tall pine trees and the shimmering light reflects off the icy lake in the distance. The air is crisp and cold, with a gentle breeze rustling through the branches. The composition showcases a cozy campsite, nestled between the trees, with a small bonfire crackling and emitting a soft, golden light. Surrounding the camp are tents covered in a thin layer of snow, adding to the wintry atmosphere. The mood is peaceful, inviting a sense of tranquility and solitude in the midst of nature's beauty. This scene is best captured with a wide-angle lens, allowing for the vastness of the snowy landscape to be fully appreciated. The photography style is focused on the natural colors and textures of the scenery, with subtle adjustments to enhance the warmth of the sunset hues. --ar 16:9 --v 5.2 /imagine prompt: In a snow-covered forest, a group of friends embark on an adventurous snowshoeing expedition. The white landscape is contrasted by their vibrant winter clothing, a mixture of bright red, blue, and green. Surrounding them are towering fir trees, with their heavy branches sagging under the weight of the snow. The air is filled with excitement and laughter as the friends navigate through the powdery snow, leaving behind a trail of footprints. One of the friends turns back to wave, with a big smile on their face. The composition captures the dynamic movement of the group, with emphasis on their interactions and expressions. The atmosphere is energetic and joyful, evoking a sense of camaraderie and shared experiences. This scene is best visualized as an illustration, with bold lines and vibrant colors to bring out the playfulness and liveliness of the moment. --ar 1:1 --v 5 /imagine prompt: Nestled in a picturesque alpine valley, a frozen waterfall stands tall, surrounded by a winter wonderland. The waterfall is a breathtaking sight, with icicles cascading down its rocky face, shimmering in the soft sunlight. The surroundings are covered in a thick blanket of snow, untouched except for the footprints of small woodland animals. The air is still and tranquil, with only the distant sound of a gentle breeze rustling through the trees. The composition highlights the grandeur of the frozen waterfall, with the snowy path leading the viewer's eye towards it. The mood is serene and awe-inspiring, inviting a sense of reverence for nature's beauty. This scene is best captured with a telephoto lens, allowing for a close-up view of the intricate ice formations. The photography style focuses on capturing the crisp details and textures of the frozen landscape, with a hint of warmth to enhance the ethereal quality of the scene. --ar 9:16 --v 5.2 /imagine prompt: A secluded mountain cabin sits on the edge of a frozen lake, shrouded in a thick layer of snow. The rustic wooden exterior is adorned with fairy lights, casting a warm and inviting glow in the wintry night. The surrounding landscape is illuminated by the soft moonlight, creating a magical and dreamlike atmosphere. The air is still and silent, with the occasional sound of snowflakes gently falling. The composition frames the cabin at the center, with the frozen lake and snow-covered trees providing a perfect backdrop. The mood is cozy and peaceful, evoking a sense of comfort and tranquility. This scene is best depicted as a painting, with soft brushstrokes and delicate textures to capture the ethereal beauty of the winter night. --ar 16:9 --v 5.2"},{"instruction":"Are there known correlations between chess Elo and ACPL?","output":"Elo is a rating system commonly used in chess to estimate the skill level of players. ACPL stands for \\"average centipawn loss,\\" which is a statistical measure used in computer chess analytics to evaluate the accuracy of a player's moves. A centipawn is a unit of measurement used in chess that equals 1/100th of a pawn's value, and ACPL represents the average loss in terms of this unit over a series of moves compared to what a computer engine considers the best moves. There can be a correlation between a player's Elo rating and their ACPL, as both are indicators of performance. Generally, one would expect that the higher a player's Elo rating, the lower their ACPL, since stronger players typically make more accurate moves that are closer to what a computer chess engine would suggest. Conversely, players with lower Elo ratings tend to make more mistakes and thus have a higher ACPL. However, the correlation can be complex because it may not be perfectly linear, and several factors can influence both Elo and ACPL independently. For example, the style of play, the strength of the opponents, time controls, and the specific positions encountered in games can affect these metrics in various ways. While Elo ratings are calculated based on the outcomes of games and the ratings of the opponents, ACPL is calculated by comparing a player's moves to those that would be recommended by a strong chess engine. Thus, ACPL can provide an insight into the \\"technical quality\\" of the play, while Elo reflects one's overall ability to win games, which may also involve psychological factors, time management, and error exploitation, not just technical accuracy. Ultimately, while there is a general relationship where stronger players (those with higher Elo ratings) tend to have lower ACPL values, it is important to consider that Elo reflects actual game results and head-to-head competition, while ACPL reflects move precision against an engine's evaluation. The correlation, therefore, may not always be direct or straightforward, and applying it in practice would require examining specific data from a significant number of games across various player strengths."},{"instruction":"Evaluate this claim: Chess results are not at all well predicted by the strength of your average move. As you're aware, they are almost entirely predicted by the strength of your worst move.","output":"The claim that chess results are almost entirely predicted by the strength of your worst move underscores an important aspect of competitive chess—the fact that a single poor move can have disproportionately adverse consequences, potentially leading to a quick defeat. In contrast, the claim suggests that the average move strength isn't as critical in determining the outcome of a chess game. While the claim might be somewhat exaggerated, there is some truth to it: 1. **Blunders**: In chess, it can indeed take just one blunder to lose a game, regardless of how well the rest of the game was played. A single tactical oversight can result in significant material loss or even a checkmate, which can't be offset by a series of good moves. In this sense, a player's worst move is a key determinant of the game result. 2. **Consistency**: The claim somewhat undervalues the importance of consistent play. A player who consistently makes strong moves is likely to accumulate small advantages over time, creating winning opportunities and pressuring the opponent into making mistakes. Hence, the average strength of moves does matter to the eventual outcome of a game, especially over a larger number of games. 3. **Resilience**: Strong players can often recover from suboptimal moves by utilizing their skill and understanding of the game. However, a single blunder that leads to a substantial material loss or checkmate cannot be recovered from. The ability to avoid such critical mistakes is why resilience is often seen as a hallmark of stronger players. 4. **Risk Management**: Chess also involves risk management. Sometimes, players purposely choose moves that are not objectively the best but that create complex positions and practical problems for the opponent. A player adept at navigating these complexities may win even if their average move strength is lower than their opponent's. 5. **Opponent's Strength**: The impact of a poor move also depends on the opponent's ability to capitalize on it. Against a stronger opponent, a blunder is more likely to be punished; against a weaker opponent, one might get away with it. In conclusion, while it is true that a single poor move can determine the outcome of a specific game, suggesting that results are \\"not at all\\" well predicted by the average move strength is an overstatement. Strong, consistent play that avoids critical blunders is key to long-term success in chess. The average strength of a player's moves, typically reflected in measures like ACPL, and the ability to minimize serious mistakes are both crucial aspects of competitive chess. It is the balance between high-quality average play and avoiding disastrous moves that often differentiates the top players from the rest."},{"instruction":"Rwanda health information system","output":"The Rwanda Health Information System (RHIS) is a digital platform developed by the Ministry of Health of Rwanda to support the collection, management, and analysis of health information across the country. The RHIS aims to improve the overall health information management in Rwanda by automating data collection, processing, analysis, and reporting at various levels of the healthcare system. It collects data from various sources, including health facilities, community health workers, laboratory services, and administrative records. Some of the key components of the Rwanda Health Information System include: 1. District Health Information Software (DHIS2): DHIS2 is a web-based platform used for data collection, analysis, and reporting. It allows health facilities to input and manage their data, including demographic information, disease surveillance, reproductive health, immunization, and more. 2. Electronic Medical Record System (EMRS): EMRS is a system used for digital management of patient health records in healthcare facilities. It enables healthcare workers to record and access patient information electronically, improving data accuracy and accessibility. 3. Mobile Technology: Rwanda has also implemented mobile technology solutions to capture health data at the community level. Community health workers use mobile devices to collect and report data on various health indicators, such as maternal and child health, nutrition, and disease surveillance. 4. Health Management Information System (HMIS): The HMIS integrates data from various sources and provides a comprehensive view of the health system's performance. It helps policymakers and health managers make informed decisions based on accurate and timely data. 5. Data Quality Assurance: The RHIS includes mechanisms to ensure data accuracy and quality. It provides training and support to health workers for data collection and reporting and conducts regular data quality assessments to identify and address any issues. The Rwanda Health Information System has significantly improved the collection and use of health data in the country. It has led to better monitoring of health indicators, improved disease surveillance, and informed decision-making at all levels of the healthcare system."},{"instruction":"List<BaseCard> limitedCards; if (CheckLimitedCards(out limitedCards)) { WarningAlertInfo alertInfo = new WarningAlertInfo(\\"当全部卡组中存在因规则变动导致失效的卡，请更换后再操作\\", 1.0f, null); this.SendEvent(new ShowPageEvent(UIPageType.WarningAlert, UILevelType.Popup, alertInfo)); return; } 我想把 limitedcards 所有card的name 拼接在\\"当全部卡组中存在因规则变动导致失效的卡，请更换后再操作\\" 后面 应该怎么做？ C#代码","output":"为了将\`limitedCards\`中所有卡的名称(name)拼接到警告信息后，请遵循以下步骤： 1. 使用LINQ的\`Select\`方法获取所有卡的名称。 2. 使用\`string.Join\`方法将名称用逗号分隔拼接成一个字符串。 3. 将该字符串附加到原始警告消息后面。 以下是具体的C#代码实现： \`\`\`csharp List<BaseCard> limitedCards; if (CheckLimitedCards(out limitedCards)) { // 使用LINQ提取所有卡的名称并使用逗号将它们连接起来 string limitedCardNames = string.Join(\\", \\", limitedCards.Select(card => card.Name)); // 创建警告消息，将卡片名称附加在后面 string message = \\"当全部卡组中存在因规则变动导致失效的卡，请更换后再操作。受影响的卡包括：\\" + limitedCardNames; // 创建警告弹窗信息 WarningAlertInfo alertInfo = new WarningAlertInfo(message, 1.0f, null); // 显示警告弹窗 this.SendEvent(new ShowPageEvent(UIPageType.WarningAlert, UILevelType.Popup, alertInfo)); // 结束执行 return; } // ... // 其他代码 // ... \`\`\` 请注意，你需要根据你现有代码的上下文和\`BaseCard\`类里卡名称的实际属性来调整以上代码。这里我假设\`BaseCard\`有一个\`Name\`属性，如果实际的属性名不是\`Name\`，你需要将其更改为正确的属性名。 还要注意，如果\`limitedCards\`是空的，你可能想要优先检查并避免生成带有附加逗号和空字符串的消息。在上面的代码中，如果没有受限卡片，将不会附加任何名称。"},{"instruction":"TextMeshProUGUI 的 font color 怎么修改 ？ 我需要修改为绿色或者 红色","output":"若要在Unity中使用TextMeshPro修改\`TextMeshProUGUI\`组件的字体颜色（例如改为绿色或红色），可以通过以下步骤实现： 1. 首先，确保你有一个\`TextMeshProUGUI\`组件附加到GameObject上。 2. 获取到该组件的引用（你可以通过代码获得，或者如果你已经有这个引用，直接使用）。 3. 修改其\`color\`属性来改变颜色。 以下是如何通过C#代码修改TextMeshProUGUI组件字体颜色的示例： \`\`\`csharp using TMPro; // 添加TMP命名空间 using UnityEngine; public class TextColorChanger : MonoBehaviour { public TextMeshProUGUI textMeshProUGUI; void Start() { // 假设你已经通过编辑器或代码获得了TextMeshProUGUI组件的引用 // 设置为绿色 textMeshProUGUI.color = Color.green; // 或者你也可以通过如下方式自定义颜色（例如红色） textMeshProUGUI.color = new Color(1f, 0f, 0f); // RGB值，红色 // 或者如果你想用十六进制代码来设置颜色，你可以像这样创建一个颜色 Color myGreenColor; if (ColorUtility.TryParseHtmlString(\\"#00FF00\\", out myGreenColor)) // 十六进制为亮绿色 { textMeshProUGUI.color = myGreenColor; } } } \`\`\` 请确保你的脚本与\`TextMeshProUGUI\`组件关联，上述中的\`textMeshProUGUI\`变量应该被赋予实际的TextMeshProUGUI组件。你可以通过在Unity编辑器中拖拽相对应的组件到脚本暴露出来的公共变量上来实现这一点，或者在代码中通过\`GetComponent<TextMeshProUGUI>()\`函数来获取。 还要注意，对于颜色的修改，你直接使用\`Color.green\`和\`Color.red\`等Unity内置的颜色，或者通过\`new Color(r, g, b)\`来自定义颜色，其中\`r\`, \`g\`, \`b\`范围为0到1，或者使用\`ColorUtility.TryParseHtmlString(\\"#HEXCOLOR\\", out colorVar)\`来解析十六进制的颜色值。"},{"instruction":"// Unity built-in shader source. Copyright (c) 2016 Unity Technologies. MIT license (see license.txt) // This is a modified Unity Sprite-Default shader to help in this forum thread: // https://forum.unity.com/threads/particles-around-a-sprite-renderer-3d-depth-like-a-quad.714878/ Shader \\"Sprites/Cutout\\" { Properties { [PerRendererData] _MainTex(\\"Sprite Texture\\", 2D) = \\"white\\" {} _MaskText(\\"Mask Texture\\", 2D) = \\"white\\" {} _Color(\\"Tint\\", Color) = (1,1,1,1) _Cutoff(\\"Alpha cutoff\\", Range(0,1)) = 0.5 [MaterialToggle] PixelSnap(\\"Pixel snap\\", Float) = 0 [HideInInspector] _RendererColor(\\"RendererColor\\", Color) = (1,1,1,1) [HideInInspector] _Flip(\\"Flip\\", Vector) = (1,1,1,1) [PerRendererData] _AlphaTex(\\"External Alpha\\", 2D) = \\"white\\" {} [PerRendererData] _EnableExternalAlpha(\\"Enable External Alpha\\", Float) = 0 } SubShader { Tags { \\"Queue\\" = \\"Geometry\\" \\"IgnoreProjector\\" = \\"True\\" \\"RenderType\\" = \\"Opaque\\" \\"PreviewType\\" = \\"Plane\\" \\"CanUseSpriteAtlas\\" = \\"True\\" } Cull Off Lighting Off ZWrite On ZTest LEqual Pass { CGPROGRAM #pragma vertex SpriteVert #pragma fragment CutoutSpriteFrag #pragma target 2.0 #pragma multi_compile_instancing #pragma multi_compile_local _ PIXELSNAP_ON #pragma multi_compile _ ETC1_EXTERNAL_ALPHA #include \\"UnitySprites.cginc\\" float _Cutoff; sampler2D _MaskText; fixed4 CutoutSpriteFrag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture(IN.texcoord) * IN.color; fixed4 mask = tex2D(_MaskText, IN.texcoord); clip(mask.a - _Cutoff); return c; } ENDCG } } } 这个 shader 我调整 _MaskText 对结果没有任何影响，是什么问题 帮我修改下？","output":"由于你提到调整\`_MaskText\`对结果没有影响，那么可能的问题来源有多个，下面是几个可能性和相应的修改建议： 1. **_MaskText未正确设置**: 确保你在材质编辑器中为\`_MaskText\`属性正确设置了一个纹理。 2. **tex2D在特定平台上的问题**: 如果你在特定平台（如OpenGL ES）遇到问题，可能需要更换纹理采样函数。不过，\`tex2D\`通常应该是可用的。 3. **Shader变量未正确传递**: 如果你在代码中设置\`_MaskText\`，需要确保该变量已经通过\`Material.SetTexture\`正确传递给了Shader。 4. **Shader未正确编译**: 确保Shader没有编译错误，检查编辑器的控制台窗口以确认是否有相关的错误信息。 5. **代码逻辑问题**: 你的逻辑中使用\`clip\`函数对\`mask.a\`和\`_Cutoff\`进行比较基于Alpha通道。确保你的遮罩纹理实际上有非零的Alpha通道并且与\`_Cutoff\`值相关。 如果你确认以上都没有问题，可能的解决方案是对Shader代码进行小的修改。例如，我们可以在Fragment Shader中添加一行打印来查看mask是否确实被读取： \`\`\`csharp fixed4 CutoutSpriteFrag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture(IN.texcoord) * IN.color; fixed4 mask = tex2D(_MaskText, IN.texcoord); // 下面的行用于调试，确保mask.a不总是0 c.rgb *= mask.a; // 这应该会改变输出颜色，基于mask纹理的alpha通道 clip(mask.a - _Cutoff); return c; } \`\`\` 此外，请确保应用的材质实际上是使用你自己修改的Shader，而不是Unity的默认Sprite Shader。 如果以上步骤都在确认后问题仍然存在，可能需要更详细地调查Material的具体设置，或者是与你的运行环境、平台或Unity版本有关的特定问题。尝试使用一个简单的遮罩纹理，如全黑或全白的纹理，来看看是否有所改变，这有助于确定问题是否出在Shader代码中。"},{"instruction":"_MaskText(\\"Mask Texture\\", 2D) = \\"white\\" {} 我设置了图片遮罩纹理 那 tillng 和 offset 设置 就没用了吗？","output":"在Shader中直接使用\`tex2D\`函数来采样纹理会导致该纹理的UV参数（包括Tiling和Offset）不会自动应用在采样过程中。如果你想让\`_MaskText\`采样操作考虑材质中设置的Tiling和Offset值，你需要手动在Shader代码中将这些值应用到纹理坐标上。 在你的Shader代码中，可以修改\`CutoutSpriteFrag\`函数来包含Tiling和Offset的处理，如下所示： \`\`\`csharp fixed4 CutoutSpriteFrag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture(IN.texcoord) * IN.color; // 应用Tiling和Offset float2 maskedTexcoord = IN.texcoord * _MainTex_ST.xy + _MainTex_ST.zw; fixed4 mask = tex2D(_MaskText, maskedTexcoord); clip(mask.a - _Cutoff); return c; } \`\`\` 请注意，\`_MainTex_ST\`是一个默认由Unity引擎提供的变量，其中包含了主纹理的Tiling（\`_MainTex_ST.xy\`）和Offset（\`_MainTex_ST.zw\`）。如果你的\`_MaskText\`属性使用另外的Tiling和Offset设置，你需要创建对应的缩放偏移向量： \`\`\`csharp [PerRendererData] _MaskTex_ST(\\"Tiling/Offset\\", Vector) = (1, 1, 0, 0) \`\`\` 然后在Shader中使用这个值： \`\`\`csharp float4 _MaskTex_ST; // ... fixed4 CutoutSpriteFrag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture(IN.texcoord) * IN.color; // 应用Mask Texture的Tiling和Offset float2 maskedTexcoord = IN.texcoord * _MaskTex_ST.xy + _MaskTex_ST.zw; fixed4 mask = tex2D(_MaskText, maskedTexcoord); clip(mask.a - _Cutoff); return c; } \`\`\` 确保添加\`_MaskTex_ST\`对应的属性定义在\`Properties\`区域，并且在材质编辑器中设置了正确的Tiling和Offset值。 Unity将在运行时自动填充\`_MaskTex_ST\`变量，所以你不需要在C#代码中设置它，只需在材质编辑器中设置即可。通过这种方式修改后，你的Shader现在应该能够根据材质属性中设置的Tiling和Offset值正确地应用\`_MaskText\`纹理。"},{"instruction":"我想设置了 遮罩纹理后 ，能调节 遮罩纹理 的采样的上下左右 怎么修改","output":"如果想要在遮罩纹理中实现采样区域的上下左右调整（即UV坐标的偏移和缩放），你需要为Shader添加几个新的属性来控制这些参数。接下来，在Fragment Shader中使用这些属性来修改UV坐标。 首先，在Properties块中添加新的Shader属性： \`\`\`csharp Properties { // ... 略去其他属性 ... _MaskOffset(\\"Mask Offset\\", Vector) = (0,0,0,0) _MaskScale(\\"Mask Scale\\", Vector) = (1,1,1,1) // 确保这些新属性与Material Editor交互 } \`\`\` 现在添加全局变量来缓存这些值： \`\`\`csharp float4 _MaskOffset; float4 _MaskScale; \`\`\` 在Fragment Shader中，使用这些新属性来修改\`_MaskText\`纹理的UV坐标： \`\`\`csharp fixed4 CutoutSpriteFrag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture(IN.texcoord) * IN.color; // 应用Mask Texture的缩放和偏移 float2 maskUV = (IN.texcoord * _MaskScale.xy) + _MaskOffset.xy; fixed4 mask = tex2D(_MaskText, maskUV); clip(mask.a - _Cutoff); return c; } \`\`\` 请注意，\`_MaskScale\`被用于缩放UV坐标，而\`_MaskOffset\`则用于偏移。在实际操作中，可能只需要2D向量，但为简化Unity的材质编辑器中的操作，这里使用了\`float4\`类型。这意味着对于\`_MaskScale\`，你使用x和y作为缩放的宽度和高度；对于\`_MaskOffset\`，你使用x和y作为水平和垂直偏移量。 在Unity的材质编辑器中，设置\`_MaskScale\`的x和y值将调整遮罩纹理的宽度和高度缩放，而设置\`_MaskOffset\`的x和y值将移动遮罩纹理在原始图像上的位置。 最后，通过在你的Material中设置\`_MaskOffset\`和\`_MaskScale\`属性值来调整遮罩采样区域。在材质编辑器中，这两个属性将作为“Mask Offset”和“Mask Scale”出现。调整这些值即可实现你想要的遮罩纹理的UV坐标调整。"},{"instruction":"我想要表示 一张卡牌 被多个人持有 ，每个人都有张数 ， 比如我有一张 。 你有 2张 这个在数据库里面的关系怎么表达？","output":"在数据库中表达这种多对多的关系，可以通过三个主要的表来完成：\`Persons\`（代表人）, \`Cards\`（代表卡牌）以及一个关联表\`CardOwnership\`（代表持有关系及数量）。 以下是这三个表的可能结构： 1. **Persons 表** - PersonID (Primary Key) - Name - 其他人相关的信息... 2. **Cards 表** - CardID (Primary Key) - CardName - CardDescription - 其他卡牌相关的信息... 3. **CardOwnership 表（关联表）** - PersonID (Foreign Key) - CardID (Foreign Key) - Quantity (卡牌的数量) 在\`CardOwnership\`表中，\`PersonID\`和\`CardID\`两个字段一起构成复合主键或复合唯一键，以确保对于每一对特定的人和卡牌关系，只有一条记录。同时每条记录还包含一个\`Quantity\`字段，表示具体的持有张数。 例如，以下是这种关系的一个简化示例： \`\`\`sql CREATE TABLE Persons ( PersonID INT NOT NULL PRIMARY KEY, Name VARCHAR(100) ); CREATE TABLE Cards ( CardID INT NOT NULL PRIMARY KEY, CardName VARCHAR(100), CardDescription TEXT ); CREATE TABLE CardOwnership ( PersonID INT NOT NULL, CardID INT NOT NULL, Quantity INT NOT NULL DEFAULT 1, PRIMARY KEY (PersonID, CardID), FOREIGN KEY (PersonID) REFERENCES Persons(PersonID), FOREIGN KEY (CardID) REFERENCES Cards(CardID) ); \`\`\` 假设有两个人，\\"Alice\\" 和 \\"Bob\\"，以及一张名为 \\"DragonSlayer\\" 的卡牌。Alice 有1张，Bob 有2张，你的关联表CardOwnership的记录将是： \`\`\`sql INSERT INTO Persons (PersonID, Name) VALUES (1, 'Alice'); INSERT INTO Persons (PersonID, Name) VALUES (2, 'Bob'); INSERT INTO Cards (CardID, CardName, CardDescription) VALUES (1, 'DragonSlayer', 'Fierce dragon slaying card.'); INSERT INTO CardOwnership (PersonID, CardID, Quantity) VALUES (1, 1, 1); INSERT INTO CardOwnership (PersonID, CardID, Quantity) VALUES (2, 1, 2); \`\`\` 在这种结构中，你可以查询特定人拥有的卡牌和数量，也可以查询某张卡牌被哪些人所持有以及各自拥有的数量。这种设计是标准的关系型数据库多对多关系表达方式，它可以灵活地处理复杂的持有关系。"},{"instruction":"strapi cms 怎么表达这种关系呢？","output":"在Strapi CMS中，你可以通过创建内容类型(Content Types)和设置关联(Relations)来表达类似的多对多关系，并且可以通过Strapi的管理界面非常方便地完成这些操作。 这里是如何在Strapi中建立这种“多对多”关系的步骤： # 步骤 1: 创建内容类型 在Strapi中创建两个内容类型： 1. \`Person\` - \`name\` (text field) 2. \`Card\` - \`name\` (text field) - \`description\` (text field) # 步骤 2: 创建关联类型 在Strapi中创建一个中间的 \`CardOwnership\` 类型，但Strapi会自动为我们处理这种多对多的关系，所以我们只需要定义两个内容类型之间的多对多关系。 对于每个内容类型，你需要添加一个字段并选择适当的关联类型。在Strapi的管理界面，当你为\`Person\` 添加一个新字段时，选择 \`Relation\` 字段然后建立一个多对多关系，通常是这样的： - Person has many Cards - Card has many Persons Strapi会根据你的选择自动生成复杂的多对多关系，并在数据库中维护一个隐含的关联表，通常我们不需要手动创建\`CardOwnership\`这样的表。 # 步骤 3: 使关系支持数量（Quantity） Strapi内容类型关系的一个限制是，默认情况下多对多关系并不支持额外字段，如我们这里想要的数量（Quantity）。为了在Strapi中存储每个人所持有的特定卡牌的数量，我们需要稍微改变数据模型。 一种方法是使用两个一对多关系而非直接的多对多关系： 1. \`Person\` - \`name\` (text field) 2. \`Card\` - \`name\` (text field) - \`description\` (text field) 3. \`CardOwnership\` - \`quantity\` (integer field) - \`person\` (relation field - one CardOwnership belongs to one Person) - \`card\` (relation field - one CardOwnership belongs to one Card) 通过这样设置，我们可以在\`CardOwnership\`中为每个人和卡牌的组合存储一个\`quantity\`字段，从而达到了和多对多关系相同的效果。 # 步骤 4: 创建和管理内容 完成结构的建立后，Strapi允许你通过它的管理面板来创建具体的内容。你可以为\`Person\`创建具体的人员条目，为\`Card\`创建具体的卡牌条目，并且通过创建\`CardOwnership\`条目来建立人员和卡牌以及对应数量的具体关系。在Strapi的后台管理界面，你可以轻松的通过表单来进行这些操作。 总的来说，你需要通过Strapi的内容类型设计器来定义这些类型和关系，它将自动生成和管理所需的数据库表结构。对于数量的问题，你可能需要借助中间类型来解决多对多关系中无法直接表示“数量”的问题。"},{"instruction":"我还想定义一个商店 开卡包 ，开出的卡 自动加入到玩家的 卡库里面去 ，然后 同时 开出几张 玩家就拥有几张 怎么表达这个关系 ，在 strap cms 里面","output":"在Strapi CMS中，为了表示玩家从商店开出的卡片自动加入到他们的卡库，并且能够管理玩家拥有的每张卡片的数量，你可以通过扩展前面提到的内容类型与关系来实现此功能。 # Step 1: 扩展内容类型与关系 你已经有了\`Person\`、\`Card\`内容类型和包含数量的中间类型\`CardOwnership\`。现在要添加一个新的内容类型来表示商店，并定义商店如何与卡片和玩家互动。 # Step 2: 创建包含商店逻辑的新内容类型 1. \`Shop\` - \`name\` (text field) - 可能还包含商店描述、图像或其他相关信息的字段。商店可能还有与它售卖特定类型卡片集合的关联。 # Step 3: 实现开卡包逻辑 你将需要在Strapi之外以编程方式实现开卡包的逻辑，因为这通常涉及到随机化过程、库存管理、玩家帐户交易等。一旦某个卡包被‘打开’，你可以通过调用Strapi的API来添加或更新\`CardOwnership\`中玩家拥有的卡片数量。 这可以通过以下几个步骤实现： **Step 3.1:** 在你的服务逻辑/游戏服务中，当一个玩家选择购买并打开卡包时，后台程序将： - 计算玩家开包得到的卡片和数量。 - 确认玩家是否有足够的资源（虚拟货币等）来购买卡包。 **Step 3.2:** 更新数据库： - 如果玩家还没有持有某张卡片，你需要在\`CardOwnership\`中为该玩家创建新的记录，并设置初始化数量。 - 如果玩家已经拥有某张卡片，则需要更新现有的\`CardOwnership\`记录，增加相应的数量。 # Step 4: 使用Strapi的API 你需要使用Strapi提供的API来进行数据库记录的创建和更新。Strapi为每个Content Type提供RESTful或GraphQL API，你可以直接使用这些API来创建\`CardOwnership\`的新条目或更新现有条目。 例如，你可能会有如下API调用来为玩家创建或更新卡片数量： - **创建新的卡牌所有权:** \`POST /card-ownerships\` 负载体 (Payload, JSON): \`\`\`json { \\"person\\": 1, // 玩家的ID \\"card\\": 2, // 卡片的ID \\"quantity\\": 1 // 得到的卡片数量 } \`\`\` - **更新现有的卡牌所有权:** \`PUT /card-ownerships/{id}\` 负载体 (Payload, JSON): \`\`\`json { \\"quantity\\": 3 // 新的卡片数量 } \`\`\` 请注意，你需要编写逻辑以确保当你更新一个玩家的\`CardOwnership\`时正确处理卡片数量的累加。这属于服务端或游戏后台逻辑的一部分，并且这部分逻辑可能需要写在Strapi的服务层内，或者在游戏服务器逻辑中实现后通过API更新Strapi。 此外，实际实施时，开包的过程可能需要做一些事务处理，特别是如果涉及到货币交易或者需要确保一致性和避免并发问题时。实施这些需要较深的技术知识基础，并且可能需要根据特定项目的需求而定制。"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, A cute and adorable SpongeBob SquarePants figurine created using CG technology. This handmade toy features glossy and super clear details that make it look almost real. With its round and smooth shape, it perfectly captures the essence of SpongeBob. The figurine is adorned with toy furnishings, including a big star on its hand and various toy decorations that add a playful touch. The gloss finish and ultra-clear quality of the toy make it visually stunning. Its polychrome colors make SpongeBob vibrant and lively, bringing out the true spirit of the character. --ar 1:1 --v 5.2 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, A close-up view of a charming SpongeBob SquarePants figurine. This CG-created toy has been carefully crafted by hand to showcase intricate details. Its glossy finish and super clear quality provide a visually pleasing experience. With an 8K resolution, every tiny aspect is visible, highlighting the round and smooth features of SpongeBob. Standing proudly with a big star held in its hand, the figurine showcases delightful toy decorations that further enhance its cuteness. The gloss and ultra-clear characteristics of the figurine make it shine, while its polychrome colors add vibrancy to its appearance. --ar 9:16 --v 5.2 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, A picturesque scene featuring a collection of SpongeBob SquarePants figurines. These adorable CG-generated toys, meticulously handcrafted, showcase a variety of toy furnishings. Each figurine features a glossy and super clear finish, allowing the beautiful details to shine under any lighting conditions. With an 8K resolution, the round and smooth shapes of SpongeBob are accentuated. Among the figurines, there is one with a big star in its hand, serving as a prominent decoration. The gloss and ultra-clear qualities of the toys create a captivating visual spectacle. The polychrome colors add to the vibrant atmosphere, making it a delightful sight to behold. --ar 16:9 --v 5.2 /imagine prompt: SpongeBob SquarePants, cute, CG, handmade, toy furnishings, glossy, super clear, 8K, round, smooth, Big star, hand, toy decoration, gloss, ultra clear, Polychrome::3, In a meticulously arranged display, numerous SpongeBob SquarePants figurines take center stage. These CG-generated toys, expertly crafted by hand, exude cuteness. Adorned with a wide array of toy furnishings, their glossy and super clear finishes create a mesmerizing visual impact. The round and smooth features of SpongeBob are skillfully represented in each figurine. Among them, one figurine stands out with a big star held in its hand, serving as a focal point in the composition. Its gloss and ultra-clear qualities contribute to its allure. The vibrant polychrome colors bring life and excitement to the scene. --ar 1:1 --v 5.2"},{"instruction":"translate to English, don't change symbol and line break. Don't change space between paragraphs","output":"Certainly! To help you with a translation, please provide the text you want translated into English."},{"instruction":"< 가을 (18) > ‘이로운 악’의 흰 사각형에 선명하게 새겨진 새로운 등급. EX급. 지금까지는 SSS+급이 최고치였다. 그러나 방금 등급의 최대치가 업그레이드됐다. 그런 등급을 보며 우진은. “흐흐, 오지네.” 순수하게 몸을 흔들어 재꼈다. 어디서도 음악은 들리지 않았지만 그저 흥분된 기분에 몸을 맡긴 것. 퍽 오랜만에 등급이 올랐으니까. 사실, 최근 SSS+급으로 상당히 오랜 기간을 유지했었다. 여러 일이나 사건이 발생했어도 큰 변화가 없기에, 자주 아공간에 들락거린 우진은 혹시나 SSS+급이 끝인 줄 알았다. 다행히 아니었다. -[9/대본(제목: 이로운 악), EX급] EX급. 이렇게 되면 EX급 그 이상의 것이 있다고 해도 전혀 이상하지 않았다. 꽤나 오래 율동을 흔들어 재끼던 강우진이 가까스로 정신을 챙겼다. 그리곤 다시금 ‘이로운 악’의 흰 사각형을 본다. “업글된 이유야 뭐 확실하지.” 조건을 명확히 꼽자면 세 가지였다. ‘이로운 악’ 대본에 ‘CQC’가 추가됐고, 그로 인해 헐리웃 스턴트 팀과 에단 스미스가 합류했다. 끝으로. ‘마일리 카라까지.’ 글로벌 슈퍼스타까지 꽂혔다. 특별 출연이긴 하지만, 이러한 일은 한국이나 헐리웃 쪽이나 지금껏 단 한 번도 일어나지 않았었다. ‘크크, 들으면 누군들 놀라 자빠지겠지??’ 컨셉질이 벗겨진 강우진의 얼굴에선 웃음이 끊이질 않았다. 뭔가 거대한 미래가 어렴풋 상상됐기 때문이었다. EX급, SSS+급보다 더 높은 등급이 현실에서 보이면 과연 어떤 형태일 것인가? 간단히 계산해봐도 2000만을 찍었던 ‘실종의 섬’보다 파괴적일 게 빤했다. 일단, ‘이로운 악’ 자체가 전세계에 도전하는 작품. 그러니 국내에 국한되진 않는다. “이거이거 ‘이로운 악’이 전세계 다 먹어버리는 거 아니냐?” 충분히 가능했다. 분명, 당장으로서는 약간 말이 안 되는 정도였으나 등급이 이렇잖아? 아공간은 늘 정답을 제시했다. 즉, 이번에도 다르지 않을 거라는 결론. -스윽. 입에 귀에 걸린 우진이 재차 기지개를 쭉 켰다. 솔직히 전세계를 먹는다는 걸 듣도보도 못한 강우진이었기에 선명하게 상상할 순 없었다. 하지만 어떤 충격적인 사건엔 늘 선구자가 있는 법. “오케이, 일단 침착하고. 눈앞의 일이나 집중하자.” 최근 그 선구자는 늘 강우진이었다. 후로. 21일에 한국에 복귀한 강우진은 쉬는 시간 없이 바로 스케줄을 소화해야 했다. 국내 언론은 그것을 반겼다. 『[스타톡]LA에서 복귀한 강우진, 쉬지 않고 바로 화보 촬영』 『복귀 후 바로 스케줄 진행하는 강우진? LA에서 ‘마일리 카라’와 무슨 일 있었나』 이번 우진의 LA 행보에 관한 정보가 워낙 없기에 각종 추측성 기사들이 솟았다. 그러거나 말거나 우진은 신경 쓸 겨를이 없었다. 쌓인 일들부터 처리해야 했으니까. ‘아오- 씨, LA에 있던 때가 천국이었네.’ 복귀하자마자 지옥이 펼쳐졌으나 할 것은 해야지? 다시금 컨셉질을 굳건히 만든 강우진은 묵묵하게 일정들을 쳐냈다. 하루, 이틀. 그 사이 우진과 비슷한 시기에 비행기에 올랐던 촬영팀도 한국에 복귀했다. 『해외 로케 관련 방콕 떠났던 ‘이로운 악’ 팀, 공항에 모습 드러냈다』 『‘이로운 악’ 복귀, 수척해진 송만우 PD/ 사진』 해외로케 관련 태국 방콕으로 떠났던 ‘이로운 악’팀이 돌아온 것. 깔리는 기사에는 강우진의 이름과 함께, 공항에서 찍힌 송만우 PD의 모습과 에단 스미스 등의 사진이 첨가됐다. 『‘강우진’ 없는 ‘이로운 악’팀, 하지만 외국인 스탭들이 늘었다?/ 사진』 물론, 송만우 PD의 간단한 인터뷰도 있었다. [입국장에서 취재진과 만난 송만우 PD는 “태국 방콕의 일정을 무사히 마쳤다면”서 “다행히 대중들의 기대를 보답할 수 있을 것 같다. 당장 제작에 박차를 가하겠다.”라고 말하며 자신감을 드러냈다.] 한마디로 재빨리 움직이겠다는 소리였다. 뒤로 다시금 이틀 정도가 흘렀다. 24일 토요일. 여전히 덥긴 했지만 7월의 끝자락에 당도했을 무렵. LA 쪽에 있는 마일리 카라 역시 강우진 못지않게 바쁜 시간을 보내고 있었다. 참고로 그녀의 습격 사건은 발표되지 않았다. 그저 이번 카라의 새 앨범 관련 소식만이 외신 기사로 퍼지고 있을 뿐이었다. 카라의 습격 사건은 헐리웃을 뒤집을 정도의 큰일이었지만 이렇게 조용한 걸 보면, 아마 마일리 카라 측이 최대한 기사화를 막은 것이 빤했다. 끝까지 덮는 건 힘들겠지만, 당장은 마일리 카라의 피해를 최소화하자는 결정이었다. 어됐든 카라는 LA의 꽉 막힌 도로 속 거대한 승합차 안에 갇힌 채였다. “······” 시간은 얼추 늦은 아침. 오늘따라 교통체증이 폭발하는 LA의 도심이었고, 늘어트린 금발 위로 모자를 푹 눌러쓴 카라는 턱을 괸 채 창밖을 응시하고 있었다. 파란 눈이 선명한 그녀의 얼굴은 뭔가 생각이 많은 느낌이었다. 이쯤. -스윽. 방금까지 어딘가와 통화하던, 카라의 옆에 앉은 매니저 조나단이 핸드폰을 내리며 말했다. “카라, 그 여자 대면할 생각이 있어?” 그가 말한 여자란 카라를 습격했던 통통한 여자를 말하는 것이었다. 반삭 머리 매니저의 말에 카라는 시선은 그대로 창밖에 둔 채 고개만 저었다. “아니.” “그래. 알았어.” 이어 카라를 잠시간 걱정스레 보던 조나단이 주제를 바꿨다. “앨범 작업도 막바진데 왜 그렇게 힘이 빠진 거야. 혹시, 아직도 그때의 일이 계속 떠올라? 힘들면 쉬어도 돼.” “아니.” 이때야 고개를 돌린 카라가 특유의 약간 차가운 톤으로 답했다. “그런 건 아니야. 그냥 좀 심심하다- 싶어서.” “심심?” “신경 쓰지마.” “강우진이 돌아가서?” “그런가?” “하긴, 그가 있을 때 카라 네가 신나 보이긴 했어.” “손님을 대접하는 게 꽤나 재밌더라고.” 모자를 벗으며 금발을 정돈하는 카라에게 조나단이 다른 것을 물었다. 그런데 그의 표정이 조심스럽다. “···강우진의 드라마에 출연하는 거. 정말 괜찮겠어?” “뭐가.” “무리하는 게 아니냐는 거야. 물론, 우리는 그에게 빚을 졌어. 하지만 네가 쓰러지면 모든 게 의미가 없어지는 거니까. 헐리웃 작품 말고는 촬영을 경험해본 적이 없으니 부담도 있을 거고.” 마일리 카라의 연붉은 입술에 약간 웃음기가 서렸다. “무리라고 판단했다면 한다고도 안 했을 거야. 그리고 목숨을 구해준 격인데 그 정도가 어렵지도 않아.” “흠, 네가 그렇게 말한다면야.” “그리고.” 말을 하다 멈춘 카라가 다시금 창밖으로 시선을 돌렸고 강우진을 떠올렸다. 아니, 명확하게는 그를 확인하기 위해 봤던 숱한 작품들을 상기하는 것. “나에게도 흥미로운 일이야. 강우진의 연기를 영상이 아닌 두 눈으로 보고 싶기도 했었거든. 다른 능력들이야 봤었지만, 연기만은 직접 본 적이 없으니까.” 작게 한숨을 뱉은 조나단이 오른쪽에 앉은 외국인 직원에게 태블릿을 건네받았다. 카라의 스케줄 등이 빼곡히 저장된 태블릿이었다. “작품 타이틀이 ‘이로운 악’이라고 했지. 최대한 빨리 그들과 얘기를 나눌 테지만, 혹시 강우진에게 드라마에 관한 설명을 들었어?” “듣긴 했어. 세세하게 알려준 건 아니었지만. 넷플렉스 쪽이고 액션이 많이 가미된 드라마래.” “오- 액션.” 순간, 조나단의 뇌리에 카라를 구해냈던 우진의 심상치 않은 무술이 스쳤다. “나도 기대되기 시작했어. 그의 움직임은 분명 우연이 아니었으니까.” “멋있더라.” “어?” “응?” “방금 뭐라고?” “······” 멈칫한 카라가 입을 다물었다. 방금의 ‘멋있더라’라는 대사는 본인도 모르게 나온 말이었으니까. 덕분에 재빨리 큼큼 목을 가다듬은 그녀가 휙 말을 바꿨다. “어쨌든, 그 드라마 출연 건은 나에게도 의미가 있어. 다만, 빚을 갚는 것으론 부족해.” 애써 여유롭게 다리를 꼬던 카라가 뜬금 꽁지머리 최성건의 얼굴을 상기했다. “이쪽 LA에 그의 에이전시가 해외 지사를 오픈했다고 했잖아?” “맞아. 강우진의 헐리웃 활동을 위한 준비라고 들었어. 그의 지금 텐션이면 욕심낼만하지.” “···그 해외 지사, 아직 이사하기 전이라던데. 내가 집기부터 차량 같은 걸 선물하고 싶어.” 즉, 아직은 텅텅 빈 bw 엔터 해외 지사를 지원한다는 얘기였다. “그래? 알았어. 그것도 진행할게. ” 하지만 카라의 선물은 그게 끝이 아니었다. “집이 필요해.” “집?” “알아 봐줘. 내 집 주변도 괜찮고 그 해외 지사의 근방도 상관없어. 가격 역시 신경 쓰지 말고.” “갑자기 집은 왜? 지금 사는 곳도 작년에 넘어갔으면서. 벌써 질린 거야? 보금자리를 너무 자주 옮기는 건 그다지 좋지 않아.” “아니, 헐리웃에서 활동할 땐 해외 지사도 필요하겠지만, 편하게 지낼 집도 필수잖아.” “강우진?” “응.” 마일리 카라가 별수롭지 않게 답했다. “그가 LA에서 지낼 집은 내가 마련해 주고 싶어.” 25일, 일요일. 한국. 시간은 아침. 장소는 아파트 형태의 작업실이었다. 거실에 여러 책상들이 겹쳐져 있고, 그 위로는 수많은 종이들이 넘실거렸다. 잘 보니 꽤 익숙한 곳. 당연했다. 바로 최나나 작가의 작업실이었으니까. 이때. -달칵. 방문이 열리고 동그란 안경을 낀, 호리호리한 최나나 작가가 거실로 나왔다. 곧, 시간을 확인하는 그녀. “슬슬 오실 때가.” 동시에 초인종이 울렸다. 앗 정도의 소리를 내며 인터폰을 확인하는 최나나 작가. 잘 아는 얼굴이 보인다. 넷플렉스 코리아의 김소향 총괄디렉터였다. 이어 최나나 작가가 재빨리 문을 열었다. 문 앞에 서 있던 살짝 통통한 김소향이 미소지었다. “안녕하세요, 작가님.” 미약한 긴장감이 서린 최나나 작가가 고개를 푹 숙였다. “어, 어서 오세요!” 김소향 총괄디렉터는 오면서 사 온 음료 박스를 내밀면서도 여유있게 반응했다. “두 작품이나 히트시킨 작가님이 환대해주셔서 기분 좋은데요? 통화로도 말씀드렸지만, 이번 ‘남사친: 리메이크’ 건 정말 축하드립니다.” 천성이 유약한 최나나 작가가 다급히 손을 휘저었다. “감사합니다! 근데 저는 한 게 아무것도 없어요! 전부 제작사랑 강우진님이 다 하셨고.” “그래도요. 원작자님이시니까 당연히 축하를 받으셔야죠. 이번 방콕도 잘 다녀오셨죠?” “네! 열심히 했어요.” “썰이 기대되네요.” 빙긋 웃던 김소향이 천천히 거실로 들어섰다. 최나나 작가는 재빨리 거실에 겹쳐진 책상을 치운 뒤 의자를 빼냈다. “앉으세요!” “감사합니다, 그런데 송만우 PD님은 아직 안 오셨나요?” “네네, 거의 다 오셨다고 연락받았어요.” “아-” “차나 커피 드릴까요?” “커피로 부탁드려요.” 이 아침에 넷플렉스 코리아의 대표 격인 김소향 총괄디렉터가 작업실에 온 이유는 뭘까? 이 모임을 소집한 장본인이 김소향의 입에서 쏟아졌다. “근데 송만우 PD님이 갑자기 만나자고 한 이유는 들으셨어요?” “네? 아, 아니요. 저도 어제 갑자기 전화 받았어요. 작업실로 오시겠다고.” “흠- 약간 놀랐어요, 굳이 작가님 작업실에서 것도 셋만 모이는 거라고 하셔서.” “뭔가 어어엄청 중요한 일이라고는 하셨는데.” “중요한 일?” 그때. -♬♪ 재차 초인종이 울렸다. 기다리고 있던 터라 최나나 작가가 날아가듯 문을 열었다. 금세 현관에 검은색 반발을 입은, 표정이 꽤 싱글벙글한 송만우 PD가 등장했다. “좋은 아침-” 생각보다 기분이 좋아 보였기에 인사를 하는 최나나 작가가 살짝 당황했다. “어어······네. 안녕하세요. 근데 PD님, 무슨 좋은 일 있으셨어요?” “응? 하하하, 있지있지. 것도 세상을 뒤집을 좋은 일.” “엥?” 신발은 벗은 송만우 PD가 고개를 갸웃하는 최나나 작가를 스친 뒤, 거실에 있는 김소향 총괄디렉터를 발견했다. “안녕하세요, 제가 꼴등이네요.” “아니요. 저도 방금 왔어요. 그런데 정말 기분이 좋아 보이시는데?” “하하하. 일단 앉읍시다.” 턱수염 송만우 PD가 김소향의 건너편에 앉았고, 동그란 안경을 추켜 올린 최나나 작가는 송만우 PD의 옆에 자리했다. 이내 핸드폰을 꺼낸 송만우 PD가 양손을 모았다. 그리곤 작게 숨을 뱉은 뒤 입을 열었다. “이렇게 셋만 모이자고 한 건, 지금부터 제가 말할 건이 어마어마한 극비라서 그렇습니다.” 대답은 미간이 움찔한 김소향 총괄디렉터였다. “극비요?” “예. 당장은 우리 셋만 알고 있어야 합니다.” “···대체 무슨 일이기에.” 심상치 않음에 김소향 총괄디렉터나 최나나 작가나 표정에 진중함이 서렸다. 반면, 침착한 송만우 PD는 둘의 얼굴을 번갈아 보면서도 나지막이 읊조렸다. “우리 ‘이로운 악’에 마일리 카라가 합류하게 됐습니다.” 바로 퍼지는 잠시간에 침묵. 작업실 전체가 고요- 해졌다. “······” “······” 김소향이나 최나나 모두 눈을 끔뻑이며 송만우를 볼 뿐 그 어떤 액션을 취하진 않았다. 그게 얼추 5초쯤. 재밌게도 두 여자가 이구동성으로 되물었다. “예?” “네?” 둘 다 이게 뭔 쌉소리지? 따위의 눈빛이었다. < 가을 (18) > 끝","output":"< Autumn (18) > A new rank, EX grade, is clearly engraved on the white square of 'Beneficial Evil'. Until now, the highest rank was SSS+ grade. However, the maximum rank has just been upgraded. Looking at such a rank, Woojin said, \\"Heh, this is crazy.\\" He shook his body purely in excitement. No music was heard anywhere, but he just let his body go with the excited feeling. It had been quite a while since his rank had increased. In fact, he had maintained the SSS+ grade for a considerable period recently. Even though various events and incidents occurred, there were no significant changes, so Woojin, who often frequented the subspace, thought that SSS+ might be the end. Fortunately, it was not. -[9/Script (Title: Beneficial Evil), EX grade] EX grade. With this, it wouldn't be strange at all if there were grades higher than EX. Kang Woojin, who had been shaking his body for quite a while, finally came to his senses. Then he looked at the white square of 'Beneficial Evil' again. \\"The reason for the upgrade is clear.\\" If you were to pinpoint the conditions, there were three. 'CQC' was added to the script of 'Beneficial Evil', and as a result, the Hollywood stunt team and Ethan Smith joined. Lastly, 'Miley Karah as well.' A global superstar was also cast. Although it was a special appearance, such an event had never happened before, neither in Korea nor in Hollywood. \\"Heh, whoever hears it would be shocked, right??\\" The smile never left the face of Kang Woojin, who had shed his pretense. He faintly imagined some grand future. What would a rank higher than EX grade, higher than SSS+ grade, look like in reality? Even a simple calculation showed that it would be more destructive than 'The Island of the Missing', which had hit 20 million. First of all, 'Beneficial Evil' itself is a work challenging the whole world. So it's not limited to domestic. \\"Isn't 'Beneficial Evil' going to devour the whole world?\\" It was entirely possible. Certainly, it seemed a bit nonsensical for now, but isn't the rank like this? Subspace always provided the right answers. In other words, this time would be no different. -Swish. Woojin, with a smirk on his face, stretched again. Honestly, Kang Woojin, who had never heard or seen the whole world being devoured, couldn't imagine it clearly. But there's always a pioneer in any shocking event. \\"Okay, let's stay calm and focus on what's in front of us.\\" Recently, that pioneer had always been Kang Woojin. Later. Kang Woojin, who returned to Korea on the 21st, had to digest his schedule immediately without any rest. The domestic media welcomed it. \\"[StarTalk] Kang Woojin returns from LA, immediately goes to a photo shoot\\" \\"Kang Woojin proceeds with his schedule right after returning? What happened with 'Miley Karah' in LA?\\" Due to the lack of information about Woojin's LA activities, various speculative articles sprouted. Regardless, Woojin had no time to care. He had to deal with the accumulated work. \\"Ah- damn, it was heaven when I was in LA.\\" Hell unfolded as soon as he returned, but he had to do what needed to be done, right? Kang Woojin, who firmly re-established his pretense, silently knocked out his schedules. One day, two days. During that time, the filming team, who had boarded the plane around the same time as Woojin, also returned to Korea. \\"[Beneficial Evil] team, who left for overseas location shooting in Bangkok, appeared at the airport\\" \\"[Beneficial Evil] returns, a gaunt-looking Producer Song Man-woo / Photo\\" The 'Beneficial Evil' team, which had left for Bangkok, Thailand, related to overseas location shooting, had returned. The articles that followed included Kang Woojin's name, along with photos of Producer Song Man-woo taken at the airport and Ethan Smith, among others. \\"'Beneficial Evil' team without 'Kang Woojin', but the number of foreign staff increased? / Photo\\" Of course, there was also a brief interview with Producer Song Man-woo. [Producer Song Man-woo, who met with reporters at the arrival hall, said, \\"If we have successfully completed the schedule in Bangkok,\\" and \\"Fortunately, I think we will be able to repay the expectations of the public. We will accelerate the production immediately,\\" showing his confidence.] In other words, he was saying that he would move quickly. Two more days passed. Saturday, the 24th. It was still hot, but it was the end of July. Miley Karah in LA was also having a busy time, no less than Kang Woojin. By the way, her assault incident was not announced. Only news related to Karah's new album was spreading through foreign news articles. Considering how quiet it was about Karah's assault incident, which was big enough to turn Hollywood upside down, it was clear that Miley Karah's side had done their best to prevent it from being reported. It would be difficult to cover it up completely, but for now, the decision was to minimize the damage to Miley Karah. Anyway, Karah was trapped inside a huge van stuck in LA's congested roads. \\"......\\" It was roughly late morning. The traffic congestion in downtown LA was exploding today, and Karah, with her blonde hair spread out and a hat pressed down on her head, rested her chin on her hand and stared out the window. Her face with clear blue eyes seemed to be deep in thought. At this point. -Swish. Jonathan, the manager sitting next to Karah, who had just been on the phone with someone, put down his phone and said, \\"Karah, are you planning to confront that woman?\\" The woman he was referring to was the plump woman who had attacked Karah. Karah, with her gaze still out the window, simply shook her head. \\"No.\\" \\"Okay. Got it.\\" Then Jonathan, who had been looking at Karah with concern for a moment, changed the subject. \\"The album work is in its final stages, why do you look so drained? Are you still haunted by that incident? If it's hard, you can rest.\\" \\"No.\\" It was then that Karah turned her head and replied in her characteristic slightly cold tone. \\"It's not that. I just feel a bit bored.\\" \\"Bored?\\" \\"Don't worry about it.\\" \\"Because Kang Woojin left?\\" \\"Is that so?\\" \\"Well, you did seem to be having fun when he was around.\\" \\"Entertaining guests turned out to be quite fun.\\" Jonathan asked Karah about something else as she took off her hat and tidied her blonde hair. But his expression was cautious. \\"...Are you really okay with appearing in Kang Woojin's drama?\\" \\"What's wrong?\\" \\"Are you overdoing it? Of course, we owe him. But if you collapse, everything becomes meaningless. You haven't experienced shooting other than Hollywood productions, so there must be pressure.\\" A slight smile appeared on Miley Karah's rosy lips. \\"If I thought it was too much, I wouldn't have agreed to do it. And it's not that hard to repay a life-saving favor.\\" \\"Hmm, if you say so.\\" \\"And.\\" Karah stopped talking and turned her gaze back to the window, thinking of Kang Woojin. No, more precisely, she was recalling the numerous works she had seen to check on him. \\"It's an interesting thing for me. I wanted to see Kang Woojin's acting not on screen but with my own eyes. I've seen his other abilities, but I've never seen his acting directly.\\" Jonathan took a tablet from a foreign staff member sitting on his right. It was a tablet packed with Karah's schedules. \\"The work's title is 'Beneficial Evil', right? I'll talk to them as soon as possible, but did you get any explanation about the drama from Kang Woojin?\\" \\"I heard about it. He didn't tell me in detail, but it's a Netflix series with a lot of action.\\" \\"Oh- action.\\" Suddenly, Jonathan's mind flashed with the extraordinary martial arts of Woojin, who had saved Karah. \\"I'm starting to look forward to it too. His movements were definitely not by chance.\\" \\"It was cool.\\" \\"What?\\" \\"Huh?\\" \\"What did you just say?\\" \\"......\\" Karah, who hesitated, closed her mouth. The line 'It was cool' had slipped out without her realizing it. As a result, she quickly cleared her throat and changed the subject. \\"Anyway, appearing in that drama is meaningful to me. But it's not enough just to repay a debt.\\" Karah, who casually crossed her legs, thought of Choi Seong-gun's ponytailed face. \\"Didn't you say his agency opened an overseas branch here in LA?\\" \\"Right. It's a preparation for Kang Woojin's Hollywood activities. With his current momentum, it's worth being ambitious.\\" \\"...That overseas branch, it's still before moving in, right? I want to gift things like furniture and cars.\\" In other words, she was talking about supporting the still empty bw entertainment overseas branch. \\"Really? Got it. I'll proceed with that too.\\" However, Karah's gift was not just that. \\"I need a house.\\" \\"A house?\\" \\"Look for it. It's fine near my house or near that overseas branch. Don't worry about the price either.\\" \\"Why a house all of a sudden? You just moved last year. Are you already tired of it? Moving nests too often isn't very good.\\" \\"No, when he's active in Hollywood, he'll need an overseas branch, but a comfortable house is also essential.\\" \\"Kang Woojin?\\" \\"Yes.\\" Miley Karah answered nonchalantly. \\"I want to provide the house for him to stay in LA.\\" Sunday, the 25th. Korea. It was morning. The place was an apartment-style studio. Several desks were stacked in the living room, and numerous papers were fluttering on top of them. Upon closer inspection, it was quite a familiar place. Of course, it was the studio of writer Choi Nana. At that time. -Click. The door opened, and the slender writer Choi Nana, wearing round glasses, came out to the living room. Soon, she checked the time. \\"It's about time for him to come.\\" At the same time, the doorbell rang. Writer Choi Nana, who made a sound of surprise, checked the intercom. A familiar face appeared. It was Kim So-hyang, the general director of Netflix Korea. Writer Choi Nana quickly opened the door. Slightly plump Kim So-hyang, who was standing at the door, smiled. \\"Hello, writer.\\" Writer Choi Nana, who had a faint tension, bowed her head deeply. \\"Oh, come on in!\\" General Director Kim So-hyang, who brought a box of drinks while maintaining her composure, responded leisurely. \\"It's a pleasure to be welcomed by a writer who has hit two works? As I said on the phone, congratulations on the 'Boyfriend: Remake' project.\\" The inherently timid writer Choi Nana waved her hands hastily. \\"Thank you! But I didn't do anything! The production company and Kang Woojin did everything.\\" \\"Still. You're the original author, so you deserve congratulations. Did you have a good trip to Bangkok?\\" \\"Yes! I worked hard.\\" \\"I'm looking forward to the story.\\" Kim So-hyang, who smiled gently, slowly entered the living room. Writer Choi Nana quickly cleared the overlapping desks and pulled out a chair. \\"Please sit down!\\" \\"Thank you, but hasn't Producer Song Man-woo arrived yet?\\" \\"Yes, yes, I just got a call that he's almost here.\\" \\"Ah-\\" \\"Do you want tea or coffee?\\" \\"I'll have coffee, please.\\" What was the reason for General Director Kim So-hyang of Netflix Korea to come to the studio this morning? The person who called this meeting was revealed by Kim So-hyang herself. \\"But did you hear why Producer Song Man-woo suddenly wanted to meet?\\" \\"Yes? No, I just got a call out of the blue yesterday. He said he would come to the studio.\\" \\"Hmm- I was a bit surprised, especially since he said we would meet here at the writer's studio, just the three of us.\\" \\"He said it was something very important.\\" \\"Important?\\" Then. -♬♪ The doorbell rang again. Writer Choi Nana, who had been waiting, opened the door as if flying. Producer Song Man-woo, wearing a black turtleneck and looking quite cheerful, appeared. \\"Good morning-\\" Writer Choi Nana, who greeted him, was slightly taken aback by his unexpectedly good mood. \\"Uh... hello. But, Producer, did something good happen?\\" \\"Huh? Hahaha, yes, yes. And it's a good thing that will turn the world upside down.\\" \\"Eh?\\" Producer Song Man-woo, who took off his shoes, passed by the puzzled writer Choi Nana and spotted General Director Kim So-hyang in the living room. \\"Hello, I'm the last one here.\\" \\"No, I just arrived too. But you really seem to be in a good mood?\\" \\"Hahaha. Let's sit down first.\\" Producer Song Man-woo, with a beard, sat opposite Kim So-hyang, and writer Choi Nana, who pushed up her round glasses, took a seat next to him. Then Producer Song Man-woo took out his phone, clasped his hands together, and after a small breath, he began to speak. \\"I asked for just the three of us to meet because what I'm about to say is an enormous secret.\\" The response came from General Director Kim So-hyang, whose brows twitched. \\"A secret?\\" \\"Yes. For now, only the three of us should know.\\" \\"...What on earth is it?\\" With the seriousness of the situation, both General Director Kim So-hyang and writer Choi Nana's expressions became grave. On the other hand, the calm Producer Song Man-woo looked at both of their faces alternately and murmured softly. \\"Miley Karah is joining our 'Beneficial Evil'.\\" Silence spread for a moment. The entire studio became quiet. \\"......\\" \\"......\\" Both Kim So-hyang and Choi Nana blinked and looked at Song Man-woo without taking any action. After about 5 seconds. Interestingly, both women asked in unison. \\"Excuse me?\\" \\"Huh?\\" Both had a look of disbelief in their eyes. < Autumn (18) > End"},{"instruction":"< 폭탄 (2) > 마일리 카라가 보내온, 최성건의 손에 들린 태블릿 속 수영장 딸린 저택 사진을 보자마자 강우진은 억 소리가 나올 뻔했다. 가히 충격적이라 컨셉질을 비집고 세상 밖으로 튀어나오는 것을 가까스로 참아냈다. 그간 반복하던 근엄함이 없었다면 진작에 호들갑이 발현됐겠지. ‘워- 씨, 진짜. 겁나 놀랐네.’ 사실, 태블릿 속에 출력되는 LA 쪽 집은 주택에 가깝긴 했으나, 이만한 규모의 주택을 처음 본 강우진에겐 흡사 저택처럼 보였다. 아니, 집에 수영장이 딸려 있잖아? 한국에선 자주 볼 수 있는 광경이 아니었다. 심지어. ‘집 자체도 개크고.’ 수영장 뒤쪽에 세워진 집은 2층에 커다랬다. 웅장하다는 표현이 어울리는 주택이었다. 이런 집은 영화에서나 존재하는 거 아니냐? 우진은 놀란 마음을 진정시키면서도 태블릿 속 주택을 응시했다. “······” 잠시간 주택을 구경하는 강우진. 그런 그를 옆에서 보던 꽁지머리 최성건이 말했다. “다 봤냐? 넘긴다?” 넘겨? 뭘 넘겨? 아- 맞아. 이때야 우진은 그가 보여줄 것이 한 채가 아니라는 것을 떠올렸다. ‘명단. 그래, LA 쪽 집 명단이랬지?’ 애써 침착해진 우진이 목소리를 깔았다. “네, 대표님. 다 봤습니다.” 대답을 듣자마자 최성건이 손가락을 움직였다. 태블릿 속 주택 사진이 넘어간다. 곧, 새로운 사진이 출력됐다. 이번 주택은 전 것과 마찬가지로 수영장이 딸렸으나 2층은 아니었다. 허나 2층 못지않게 양옆으로 넓은 느낌이었다. 하나 확실한 건. ‘미친, 이거도 지리네.’ 이번 주택도 어마무시하다는 것. 이어 최성건의 손가락이 다시 움직였다. 한 번, 두 번, 세 번. 결과적으로 그가 보여준 주택은 총 5채였다. 물론, 모조리 영화에서나 볼법한 규모. 강우진은 집을 볼 때마다 속으론 탄성을 자아냈지만, 겉으로는 어떻게든 시니컬함을 유지했다. 그래도 충격은 먹었다. ‘아니! 이만한 집을 나한테 준다고? 진심 미쳐버린 건가?’ 물론, 강우진이 마일리 카라의 목숨을 구해준 격이지만 그래도 이게 맞나 싶었다. 솔직히 그렇잖아? 이런 경험을 그 누가 겪어볼 수 있겠는가? 과거 최성건에게 받은 삼성역 쪽의 오피스텔은 우진이 일해서 받은 것과 같았다. 하지만 이번엔 달랐다. “···대표님.” 우진은 억지로 냉정함을 묻힌 목소리를 냈다. “이 집 중 하나를 선물로 주고 싶다. 그렇게 들으셨습니까?” 태블릿을 잠시 내린 최성건이 자기도 살짝 어이가 없는지 픽 웃었고. “어, 그랬다니까. 회사로 온 메일에 명확히 그리 적혀 있었다고. 나도 좀 당황스럽다.” “그렇습니까?” 다시금 내렸던 태블릿을 올린 최성건. “얘네 사이즈 봐라, 물론 LA 쪽에 이만한 주택이야 널렸다고 해도 이 정도면 10억은 족히 깨질걸? 당연히 더 나오는 것도 널렸고.” “······” 얼마? 10억? 몇억도 큰돈인데 10억? 우진은 잠시 말문이 막혔다. 과연, 글로벌 슈퍼스타인가? 배포가 어마어마하다. 이쯤 호텔 엘리베이터에 오른 우진과 최성건이 잠시 말을 멈췄다. 같이 탄 손님들이 꽤 많았기 때문. 뒤로 몇 분 후. 강우진의 스위트룸에 들어선 최성건이 다시금 입을 열었다. “뭐, 우진이 네가 마일리 카라 구해주면서 세이브된 돈을 생각하면 10억이야 껌값이지. 카라가 크게 다쳤으면 그보다 몇 배는 깨졌을 거고. 그래도 카라 얘 시원시원하긴 하다.” 속으로 격하게 공감하는 우진에게 최성건이 손에 쥔 태블릿을 흔들었다. “너는 아예 들은 바 없는 거냐?” 순간, 강우진의 머릿속에 카라가 뱉은 대사들이 스쳤다. ‘빚을 졌네요, 그것도 상당히 커다란 빚.’ 하나 더. ‘사례는 어떤 형태로든 할 건데 그건 따로예요. 혹시 지금 우진씨가 원하는 게 있나요?’ 원하는 건 ‘이로운 악’ 출연 건으로 퉁쳤던 거였다. 그렇다면 따로 하겠다는 사례가 집인가? 것도 LA에 있는 거대한 주택? 입을 다물고 있던 강우진이 최성건과 눈을 맞추며 낮게 읊조렸다. “LA에 있을 때 마일리 카라가 사례한다곤 했었습니다.” “‘이로운 악’ 출연하는 거 말고?” 참고로 최성건도 카라의 ‘이로운 악’ 출연 건을 알고 있었다. “그거 플러스 사례까지?” “그런 것 같습니다.” “허- 딱 보니까 너 헐리웃 진출하면 지낼 집을 선물하고 싶은 것 같은데······어쩐지 그 카라 집에서 뒤풀이할 때 걔가 이것저것 물어보더라니.” “뭘 물어봤습니까?” “어. 해외 지사는 어디에 있냐는 거나 너가 헐리웃 활동을 시작하는 게 언제부턴지 등등. 대충 대답해주긴 했는데 그다음 이게 온 거지.” 빌드업이 있었다는 얘기였다. 어쨌든 강우진의 심정이 어느정도 침착해졌고, 우진에게 태블릿을 넘긴 최성건이 넌지시 물었다. “당연히 나도 너 해외 진출 관련해서 이것저것 준비하곤 있었는데- 어쩔래? 이거 카라가 주택 준다면 받을 거냐?” 이걸 안 받을 이유가 있나? 물론, 예상 못 할 사이즈긴 했다만 굳이 거절할 이유는 없었다. 뭐, 강우진이 카라를 구할 때 크게 무리한 건 없었어도 그녀에겐 큰 빚이긴 할 테지. ‘받는 게 100% 낫지. 이래저래 얼굴 보기도 편해지고.’ 아무리 생각해봐도 사양하는 건 별로라 판단한 강우진이었고. -스윽. 그가 태블릿 속 5채의 주택 중, 2층에 수영장이 제일 넓은 집을 검지로 찍으며 읊조렸다. “이거로 하겠습니다.” 웃음이 짙어진 최성건이 고개를 끄덕였다. “크크, 그래. 마일리 카라 쪽에 전달할게.” 강우진에게 LA의 주택. 아니, 저택이 생긴 순간이었다. 다음 날, 21일. 아침부터 일본 연예계가 꽤 들썩였다. 각종 언론사의 많은 기자들은 물론이며. “짐 다 쌌어?” “예!” “그럼 바로 출발해!” “아- 근데 초대받지도 않았는데 가도 되는건지 모르겠습니다.” “초대 못 받은 건 아쉽다만, 그냥 호텔 주변에서 B컷 사진이라도 건져야지. 거물들이 한 둘이야?” “그렇긴 합니다.” “타노구치 쿄타로 감독이나 타키카와 아카리 작가, 운 좋으면 요시무라 히데키 회장까지 볼 수 있을지도 몰라. 배우들은 다른 탑배우들은 그렇다 쳐도 강우진! 강우진은 꼭 찍으라고, 뒷모습이라도 찍어야 팔린다?” 여러 에이전시부터 많은 방송국 역시 비슷한 양상이었다. “난리네, 난리야. 벌써 기사들 뿌려지는구만.” “‘낯기생’ 제작발표회?” “어어. 이거 보라고, 연예면 기사들 대부분이 ‘낯기생’ 얘기뿐이야.” “흠- 그럴 만하지. 아카리 작가 원작 실사판 아닌가? 애초 그 ‘낯기생’에 강우진이 끼는 순간부터 시끄러웠으니. 거기다 ‘카시히 그룹’까지 섞이면서 더 몸집이 커졌고.” “······아카리 작가의 상징과도 같은 작품에 한국배우가 남주라니.” “이것저것 논란도 많고 시끄러우니까 난리법석인 게 이상하진 않아. 오늘 제작발표회에 기자들만 200명 가까이 모았다던데?” “실시간 스트리밍도 진행한다고 들었어.” “뭘 이리 판을 크게 키웠지? 조용조용 넘어가도 원성이 극심할 텐데.” 당연히 오늘 정오에 있을 ‘낯기생’의 제작발표회가 주제였다. 제작 초기 발표부터 숱한 논란과 이슈들을 낳던 ‘낯기생’이었기에, 개봉 전 영화를 소개하는 제작발표회가 화제 되는 건 이상하지 않았다. 기사 역시 진작에 터지고 있었고. 『드디어 ‘강우진’ 대중들 앞에 선다「낯기생」대규모 제작발표회 오픈 직전!』 『네티즌들 몰린다! 실시간 방송 포함된「낯기생」제작발표회, SNS나 커뮤니티 중심으로 관심 폭발』 일본 연예계에 포함된 수많은 관계자들. 일반 시민들의 입에서 ‘낯기생’은 쉴새 없이 오르내렸다. 물론, 온라인 쪽도 같았다. 커뮤니티와 SNS 등이 중심이 되어 ‘낯기생’ 제작발표회를 격하게 소문냈다. 실시간 스트리밍이라는 장치가 그들을 더욱 흥분하게 했다. 그렇게 두 시간쯤 흘렀나? 정오가 되기 30분 전쯤, 됴코에 있는 ‘카시히 도쿄 호텔’은 인산인해였다. 원래도 손님이 넘치는 호텔이었지만, 오늘은 손님들만이 아닌 다른 목적을 가지고 방문한 이들이 백여 명을 가뿐히 넘겼다. 호텔의 주변, 로비 등 카메라를 든 인원들이 가득했다. 제작발표회에 초대된 기자들이었다. “저 밖에 자리 잡은 것들은 초대 못 받은 기자들인가?” “그렇지, 필사적으로 찍어대네.” “하하 우린 운이 좋았구만.” 호텔 외부에 몰린 기자들만 합치면 최소 수백은 넘어 보였다. 그런 기자들은 ‘카시히 도쿄 호텔’의 가장 넓은 홀의 안으로 집결하기 시작했다. 드넓은 홀은 원목이 많이 포함된 인테리어였고 층고도 상당히 높다. 홀을 가득 채운 건 기자들이 앉을 책상들이었다. 홀 입구부터 정면 단상까지 빼곡하다. 비치된 책상들에 자리를 잡기 시작하는 기자들이 얼추 80명 이상. 죄다 노트북과 챙겨온 카메라를 세팅하고 있었고, 제작발표회 시간이 당도하면 밖에 있는 남은 기자들이 몰려들겠지. 그럼 200명에 가까운 규모가 될 것이었다. “일반적인 제작발표회보다 촬영 카메라가 많아.” “실시간 방송도 한다고 했고, ‘낯기생’팀의 너튜브 촬영도 해야겠지.” 홀 곳곳에 설치된 카메라만 10대는 넘는다. 그중 홀의 가장 뒤쪽엔 실시간 스트리밍을 책임질 팀이 연신 준비를 서두르고 있었다. 이어 20분 정도 뒤. “실시간 방송 오픈합니다!” 제작발표회까지 10분 남은 상황에 실시간 스트리밍팀이 방송을 오픈했다. 곧, 기다렸다는 듯 일본 네티즌들이 우르르 입장하기 시작했다. 그리고 딱 1분 만에. -[‘낯선 이의 기괴한 희생’ 제작발표회 실시간 스트리밍!] -[실시간 방송] -[3854명 시청 중] 4000명에 가까운 네티즌이 몰렸다. 채팅창은 왁자지껄 그 이상이었다. -와wwwwww기자들 엄청많아!! -낯기생 망해라!! -강우진 보러 왔어요! -정신차려 다들!! 으악! 사람이 너무 많아! -시작도 전에 이 정도면 제작발표회 시작되면 터지겠네wwww -나는 욕하러 왔다 · · · 흥분, 욕, 기대, 헛소리 외의 다수. 채팅이 너무 빨리 올라가는 바람에 하나하나 확인하기 힘들 정도였다. 그러거나 말거나 실시간 스트리밍에 접속하는 네티즌들은 초마다 급격하게 늘어났고, 제작발표회가 임박해짐에 따라 일본 기자들 역시 홀을 가득 채우기 시작했다. 이윽고. -스윽. 기자 200명 정도가 거의 들어왔을 무렵. 홀의 정면 ‘단상 옆문으로 단아한 베이지 재킷을 걸친 여자가 입장했다. 오늘 제작발표회의 사회를 맡을 일본의 유명 개그우먼이었다. 그녀가 단상 뒤쪽에 커다랗게 걸린 ‘낯선 이의 기괴한 희생’ 타이틀을 손짓했다. “제작발표회가 시작될 예정입니다, 외부의 기자님들은 홀에 들어와 주세요.” 또박또박한 일본어로 스타트를 알린 사회자가 잠시간 주변 스탭들과 얘기를 나눴다. ‘낯기생’측 스탭들이었다. 대충 5분 정도 합을 맞춰보던 사회자가 다시금 시선을 정면으로 돌렸다. 200명 되는 기자들이 모두 그녀를 보는 중에 사회자가 큐카드를 들었다. “화제의 영화! ‘낯선 이의 기괴한 희생’의 제작발표회를 시작하겠습니다!” 기자들은 익숙한 듯 박수를 쳤고, 반 정도는 카메라를 들어 정면을 찍어댔다. 번개처럼 플래시가 터지는 와중 실시간 스트리밍에 접속한 일본 네티즌들은 어마어마하게 늘어난 상태였다. -[‘낯선 이의 기괴한 희생’ 제작발표회 실시간 스트리밍!] -[실시간 방송] -[32114명 시청 중] 3만 명을 넘기고 있었다. 다들 각자의 목적을 위해 들어온 것이지만 어쨌든 상당한 수치였다. 이쯤 큐카드를 내려봤던 사회자가 다시금 멘트쳤다. “먼저, ‘낯선 이의 기괴한 희생’의 주역들부터 모시겠습니다!” 그녀의 말이 끝나자 옆문 근방에 서 있던 스탭들이 움직였다. 문이 열리며 거물들이 들어오기 시작한 것. 동시에. -파바바바박! -파바바바바박!! 몇 배는 더 극심한 플래시가 홀을 가득 채웠다. 가장 먼저 홀로 입장한 건 ‘낯기생’의 거장 감독 타노구치 쿄타로였다. -슥. 나름 경건한 의상인 그의 바로 뒤로 평소보다 화장이 짙은 아카리 작가가 따랐다. 곧, 세 번째로 등장한 인물 덕에 미친 듯 셔터를 눌러대는 기자들이 약간 흥분했다. “강우진! 강우진!!” “세 번째? 강우진이 세 번째로 들어오는데?” ‘낯기생’의 메인 남주이며, 현재 일본을 요동치게 하는 장본인. 올블랙 정장을 입은 강우진이 입장했기 때문이었다. 곧, 그에게 눈이 멀 정도의 플래시가 쏟아졌다. 허나 우진의 얼굴엔 차가움만이 가득했다. “······” 반면. -[39887명 시청 중] 강우진의 등장 직후 4만 명에 육박한 시청자들이 치는 채팅은 포화상태였다. 초마다 수십, 수백의 채팅이 갱신되는 중. 시청자들의 채팅은 알아보기 힘들지만, 눌러대는 셔터음 덕에 흐릿함에도 기자들의 말을 얼추 들리긴 했다 “강우진, 덤덤하네.” “여기 기자들 포함 수많은 일본 대중들이 지켜보고 있을 건데- 저 배우 성격이 원래 좀 냉정한가?” “소문으로는 그래. 과묵한 편이라고.” “데뷔 2년 차라며? 이런 경우가 없진 않았어도 너무 잠잠하잖아?” “······포스만큼은 최정상 탑배우 저리가라구만.” 올블랙 정장의 강우진 모습을 보고 수백 기자들이 바로바로 평가를 내놨다. 허나 우진은 그런 걸 신경 쓸 겨를이 없었다. ‘우왁!! 안보인다, 안 보여!’ 쉴새 없이 터지는 플래시 세례에 집중이 날아갈지도 몰랐으니까. 컨셉질 유지에 모든 신경을 쏟아야 했다. ‘어욱, 토 쏠린다고!’ 후로 쿄타로 감독, 아카리 작가, 강우진, 마나 코사쿠, 우라마츠 미후유, 오오기모토 야스타 등 ‘낯기생’의 거물들과 일본 탑배우들까지 모두 등장했다. 첫 번째인 쿄타로 감독을 시작으로 그들은 단상의 앞에 쭉 일자로 나열해 섰다. 잠시간의 포토타임 때문이었고. -[43313명 시청 중] 스트리밍 시청자는 4만 명을 돌파했다. 이때 닫힌 홀의 뒤쪽 문이 열리며 정장 입은 늙은 남자가 들어왔다. 비서 몇을 대동한, 눈썹에도 흰 털이 섞인 히데키 회장이었다. 워낙 소리 없이 진입한 데다 홀 안의 상태가 광적이라 아무도 눈치채진 못했다. “흠-” 히데키 회장은 수백 기자들 넘어 홀의 정면 단상에 시선을 맞추며 팔짱 꼈다. 정확하게는 강우진을 보며 주름진 입가에 미소도 머금은 것. ‘선전포고. 아니, 폭탄 구경을 어떻게 참나.’ 착각의 늪을 멋대로 헤엄치는 총수. 어쨌든 ‘낯기생’의 제작발표회는 각 인물의 소개부터였다. 그러나. “강우진씨!!!” 쏟아지는 플래시 세례 속 고함에 가까운 일본어가 울렸다. 수백 기자 중 앞쪽쯤에 앉은 기자가 선두로 외친 것. “최근 주연을 맡았던 한국의 작품이 초대박이 나고 ‘남사친: 리메이크’도 대 히트를 쳤습니다!” 흥분한 탓에 목소리가 약간 삑사리 났지만 명확히 강우진을 향한 질문이었고, 약간 공격적이기도 했다. “연이은 성공에 당신에겐 ‘미다스의 손’이라는 별명도 붙었는데요!! 본인이 판단하기에 논란의 ‘낯기생’은 성공할 거라 생각하십니까?!!” 바로 사회자부터 스탭들이 그를 저지하려고 했으나. “예.” 올블랙 정장을 입은 강우진의 낮은 대답이 더 빨랐다. “관객수 2000만 이상은 거뜬할 거로 봅니다.” 첫 번째 폭탄이 투하됐다. < 폭탄 (2) > 끝","output":"< Bomb (2) > As soon as Kang Woojin saw the photo of the mansion with a swimming pool on the tablet held by Choi Seong-gun, sent by Miley Karah, he almost gasped in astonishment. It was shockingly impressive, and he barely managed to suppress his excitement from bursting out beyond his usual pretense. If it weren't for his habitual solemnity, he would have already made a fuss. \\"Wow, seriously. That was a shock.\\" In fact, the house in LA shown on the tablet was close to a mansion, and to Kang Woojin, who had never seen a house of this scale, it looked like a mansion. I mean, it had a swimming pool, right? It wasn't a common sight in Korea. Moreover, \\"The house itself is huge.\\" The house built behind the swimming pool was large and two-storied. It was a house that deserved the description of being majestic. Wasn't this kind of house something that only existed in movies? Woojin calmed his surprised heart while staring at the house on the tablet. \\"......\\" Kang Woojin, who was momentarily admiring the house, was spoken to by Choi Seong-gun, who had a ponytail. \\"Done looking? Should I flip to the next one?\\" Flip? Flip what? Ah- right. It was then that Woojin remembered that what he was being shown was not just one house. 'The list. Right, the list of houses in LA.' Woojin, trying to remain calm, spoke up. \\"Yes, Mr. President. I've seen it.\\" As soon as he heard the answer, Choi Seong-gun moved his finger. The photo of the house on the tablet flipped. Soon, a new photo appeared. This house, like the previous one, had a swimming pool, but it wasn't two-storied. However, it felt as wide as a two-story house on either side. One thing was certain. 'Crazy, this one's amazing too.' This house was also incredibly impressive. Choi Seong-gun's finger moved again. Once, twice, three times. In the end, he showed a total of five houses. Of course, all of them were of a scale that you would only see in movies. Kang Woojin internally marveled at each house he saw, but outwardly, he maintained his cynicism as best as he could. Still, he was shocked. 'No way! They're giving me a house like this? Have they gone insane?' Of course, Kang Woojin had saved Miley Karah's life, but even so, he wondered if this was right. Honestly, who could have such an experience? The officetel near Samsung Station that he had received from Choi Seong-gun was like a reward for Woojin's work. But this time was different. \\"...Mr. President.\\" Woojin forced a cool tone into his voice. \\"Do you want to give me one of these houses as a gift?\\" Choi Seong-gun, who had briefly lowered the tablet, chuckled as if he too found it somewhat unbelievable. \\"Yeah, that's what it said. It was clearly written in the email sent to the company. I was a bit surprised too.\\" \\"Is that so?\\" Choi Seong-gun raised the tablet again. \\"Look at the size of these, of course, there are plenty of houses like this in LA, but this level would easily cost over a billion won, right? Naturally, there are even more expensive ones.\\" \\"......\\" How much? A billion? Even a few hundred million is a lot of money, but a billion? Woojin was momentarily speechless. Truly, a global superstar? Her generosity was immense. At this point, Woojin and Choi Seong-gun, who had entered the hotel elevator, paused their conversation. There were quite a few other guests with them. A few minutes later. Choi Seong-gun, who had entered Kang Woojin's suite room, spoke again. \\"Well, if you think about the money saved by Woojin saving Miley Karah, a billion won is nothing. If Karah had been seriously injured, it would have cost several times more. But Karah is quite generous.\\" Woojin, who was inwardly agreeing vehemently, saw Choi Seong-gun shaking the tablet in his hand. \\"Did you not hear anything about it?\\" Suddenly, the lines Karah had said flashed through Kang Woojin's mind. 'I owe you a debt, a quite significant one.' And another. 'I will repay you in some form, but that's separate. Is there anything you want right now, Woojin?' What he wanted was settled with the appearance in 'Beneficial Evil'. So, was the separate repayment the house? A huge house in LA? Woojin, who had been silent, looked at Choi Seong-gun and murmured softly. \\"When I was in LA, Miley Karah mentioned she would give me a reward.\\" \\"Besides appearing in 'Beneficial Evil'?\\" Choi Seong-gun was also aware of Karah's participation in 'Beneficial Evil'. \\"That plus a reward?\\" \\"It seems so.\\" \\"Huh- It looks like she wants to gift you a house for when you make your Hollywood debut... No wonder she was asking all sorts of questions when we had the after-party at her house.\\" \\"What did she ask?\\" \\"Yeah. She asked where the overseas branch was or when you would start your Hollywood activities and such. I gave her rough answers, but then this came.\\" There had been a buildup. Anyway, Kang Woojin's feelings had somewhat calmed down, and Choi Seong-gun, who had handed the tablet to Woojin, asked casually. \\"Of course, I was also preparing various things for your overseas debut - what will you do? If Karah is giving you a house, will you accept it?\\" Was there any reason not to accept it? Of course, the size was unexpected, but there was no reason to refuse. Well, even though Woojin didn't struggle much when he saved Karah, it must have been a significant debt to her. 'It's 100% better to accept. It'll make it easier to see each other in any case.' No matter how much he thought about it, Woojin decided it was not good to refuse. -Swish. He pointed at one of the five houses on the tablet, the two-story house with the largest swimming pool, and murmured. \\"I'll take this one.\\" Choi Seong-gun, with a deepening smile, nodded. \\"Heh, alright. I'll pass it on to Miley Karah's side.\\" It was the moment when Kang Woojin acquired a house, no, a mansion in LA. The next day, the 21st. From the morning, the Japanese entertainment industry was quite abuzz. Not only were there many reporters from various media outlets. \\"Is everything packed?\\" \\"Yes!\\" \\"Then let's leave right away!\\" \\"Ah- but I'm not sure if it's okay to go without being invited.\\" \\"We may not have been invited, but we'll just have to scoop up some B-cut photos around the hotel. Aren't there a bunch of big shots?\\" \\"That's true.\\" \\"Director Tanoguchi Kyotaro or writer Takikawa Akari, and if we're lucky, we might even see Chairman Yoshimura Hideki. As for the actors, aside from the other top actors, Kang Woojin! Make sure to take a photo of Kang Woojin, even if it's just his back, it will sell!\\" Many agencies and broadcasting stations were in a similar situation. \\"It's crazy, crazy. Articles are already being spread.\\" \\"'Nachi Kisei' production announcement?\\" \\"Yeah, yeah. Look at this, most of the entertainment articles are about 'Nachi Kisei'.\\" \\"Hmm- It makes sense. Isn't it a live-action adaptation of writer Akari's original work? Ever since 'Nachi Kisei' included Kang Woojin, it's been noisy. Plus, it got even bigger with 'Kashihi Group' involved.\\" \\"......A Korean actor as the male lead in a work that's almost a symbol for writer Akari.\\" \\"It's not strange that it's chaotic with all the controversy and noise. Didn't they gather nearly 200 reporters just for today's production announcement?\\" \\"I heard they're also doing a live stream.\\" \\"Why did they make such a big deal? Even if they kept it quiet, there would be severe complaints.\\" Naturally, today's noon production announcement for 'Nachi Kisei' was the topic. Since 'Nachi Kisei' had caused numerous controversies and issues from the initial announcement, it wasn't strange that the production announcement, which introduced the movie before its release, was a hot topic. Articles had already exploded. \\"Finally, 'Kang Woojin' stands before the public 'Nachi Kisei' just before the grand production announcement opens!\\" \\"Netizens flock! 'Nachi Kisei' production announcement including live broadcast, explodes with interest centered on SNS and communities\\" Numerous insiders from the Japanese entertainment industry. The name 'Nachi Kisei' was incessantly mentioned by the general public. Online was the same. Communities and SNS were at the forefront, vigorously spreading the word about the 'Nachi Kisei' production announcement. The live streaming feature excited them even more. About two hours later? About 30 minutes before noon, the 'Kashihi Tokyo Hotel' in Tokyo was swarming with people. It was already a hotel overflowing with guests, but today, not only guests but also those with other purposes had easily surpassed a hundred. The hotel's surroundings and lobby were filled with people holding cameras. They were reporters invited to the production announcement. \\"Are those outside who have taken positions the reporters who weren't invited?\\" \\"Looks like it, they're desperately taking photos.\\" \\"Haha, we were lucky.\\" The number of reporters gathered outside the 'Kashihi Tokyo Hotel' seemed to exceed at least a few hundred. Those reporters began to gather inside the hotel's largest hall. The spacious hall was decorated with a lot of wood in the interior and had quite high ceilings. The hall was filled with desks for the reporters to sit at. From the entrance of the hall to the front stage, it was packed. Reporters began to take their seats at the provided desks, numbering over 80. They were all setting up their laptops and cameras they brought, and when the production announcement time arrived, the remaining reporters outside would rush in. It would be close to 200 people. \\"There are more filming cameras than a typical production announcement.\\" \\"They're doing a live broadcast, and the 'Nachi Kisei' team also has to film for YouTube.\\" There were more than ten cameras installed throughout the hall. Among them, the team responsible for the live streaming was busily preparing at the very back of the hall. Then, about 20 minutes later. \\"We're opening the live broadcast!\\" With 10 minutes left until the production announcement, the live streaming team opened the broadcast. Soon, Japanese netizens began to enter as if they had been waiting. And in just one minute. -[Live Streaming of 'Nachi Kisei' Production Announcement!] -[Live Broadcast] -[3854 viewers watching] Nearly 4,000 netizens had gathered. The chat window was more than bustling. -Wowwwwwww there are so many reporters!! -I hope Nachi Kisei fails!! -I came to see Kang Woojin! -Come to your senses, everyone!! Ahh! There are too many people! -If it's like this before it even starts, it's going to crash when the production announcement begins wwww -I came here to curse · · · Excitement, curses, anticipation, nonsense, and many more. The chat was updating so quickly that it was hard to keep track of each message. Regardless, the number of netizens connecting to the live stream was rapidly increasing by the second, and as the production announcement approached, Japanese reporters also began to fill the hall. Eventually. -Swish. When about 200 reporters had almost entered, a woman in a neat beige jacket entered through the side door next to the stage. She was a famous Japanese comedienne who would host today's production announcement. She gestured towards the large 'Nachi Kisei' title hung behind the stage. \\"The production announcement is about to begin, please enter the hall, reporters outside.\\" The host announced the start in clear Japanese and briefly talked with the surrounding staff. They were the staff of 'Nachi Kisei'. After about 5 minutes of syncing up, the host turned her gaze to the front again. The 200 reporters were all looking at her as she held up a cue card. \\"We will begin the production announcement for the controversial movie 'Nachi Kisei'!\\" The reporters clapped as if they were used to it, and about half of them held up cameras to film the front. Amidst the flashes like lightning, the Japanese netizens connected to the live stream had increased tremendously. -[Live Streaming of 'Nachi Kisei' Production Announcement!] -[Live Broadcast] -[32114 viewers watching] The number had surpassed 30,000. Everyone had their own reasons for joining, but it was a significant figure nonetheless. At this point, the host, who had glanced at the cue card, spoke up again. \\"First, let's welcome the main cast of 'Nachi Kisei'!\\" As her words ended, the staff standing near the side door moved. The door opened, and the big shots began to enter. At the same time. -Papapapapak! -Papapapapapak!! The flashes that filled the hall were several times more intense. The first to enter alone was the master director of 'Nachi Kisei', <PRESIDIO_ANONYMIZED_PERSON>. -Swish. Following him, in a somewhat solemn outfit, was writer Akari, who wore heavier makeup than usual. Soon, the third person to appear caused the reporters, who were frantically pressing their shutters, to get a bit excited. \\"Kang Woojin! Kang Woojin!!\\" \\"The third? Kang Woojin is the third to enter?\\" The main male lead of 'Nachi Kisei' and the person currently shaking up Japan. Kang Woojin, dressed in an all-black suit, entered. Immediately, a blinding amount of flashes poured down on him. However, Woojin's face was filled only with coldness. \\"......\\" Meanwhile. -[39887 viewers watching] Right after Kang Woojin's appearance, the chat with nearly 40,000 viewers was saturated. Dozens to hundreds of chats were updated every second. It was hard to make out the viewers' chats, but thanks to the shutter sounds, the reporters' words were somewhat audible. \\"Kang Woojin is so composed.\\" \\"There are many Japanese reporters and the public watching here - is that actor's personality usually quite cool?\\" \\"The rumors say so. He's known to be reticent.\\" \\"Only 2 years since his debut, right? It's not unheard of, but isn't he too calm?\\" \\"......His presence alone is enough to make top actors step aside.\\" Hundreds of reporters immediately evaluated the sight of Kang Woojin in an all-black suit. However, Woojin had no time to care about such things. 'Ugh!! I can't see, I can't see!' He might lose focus due to the relentless barrage of flashes. He had to pour all his attention into maintaining his pretense. 'Ugh, I feel like I'm going to throw up!' Afterward, the big shots of 'Nachi Kisei' and top Japanese actors, including director Kyotaro, writer Akari, Kang Woojin, Mana Kosaku, Uramatsu Mihuyu, and Oogimoto Yasta, all appeared. Starting with director Kyotaro, they lined up in a row in front of the stage. It was a moment for photo time. -[43313 viewers watching] The streaming viewers surpassed 40,000. Then, the back door of the closed hall opened, and an old man in a suit entered. It was Chairman Hideki, with a few secretaries, his eyebrows mixed with white hair. He entered so quietly and the hall was so frenzied that no one noticed. \\"Hmm-\\" Chairman Hideki, with his arms crossed, looked over the hundreds of reporters towards the front stage, focusing precisely on Kang Woojin, and even a smile crept onto his wrinkled lips. 'A declaration of war. Or rather, how could I miss watching a bomb go off.' The head of the company indulged in his own delusions. Anyway, the production announcement for 'Nachi Kisei' began with the introduction of each character. However. \\"Kang Woojin-san!!!\\" A shout in Japanese, almost like a scream, echoed amidst the barrage of flashes. A reporter seated towards the front was the first to shout. \\"Recently, the Korean production you starred in was a huge hit, and 'Boyfriend: Remake' was also a massive success!\\" His voice cracked a bit from excitement, but it was a clear question directed at Kang Woojin, and it was somewhat aggressive. \\"With your consecutive successes, you've been nicknamed 'Midas's hand'!! In your opinion, do you think the controversial 'Nachi Kisei' will be successful?!!\\" The host and staff tried to stop him, but. \\"Yes.\\" The low response from Kang Woojin, dressed in an all-black suit, was faster. \\"I expect it to easily surpass 20 million in audience numbers.\\" The first bomb was dropped. < Bomb (2) > End"},{"instruction":"< 방콕 (1) > 조셉이 보는 4개의 시놉엔 간략한 초반 내용이 포함된 쪽대본도 겹쳐 있었다. 물론, 그가 보는 시놉의 뿌리는 헐리웃 공룡 영화·배급사인 ‘유니버설 무비스’가 제공한 것. 해봤자 컨셉 또는 아이디어 정도인 것을, 영화사에게 고용된 총괄 프로듀서 조셉이 사전에 여러 각본가들에게 넘겼었다. 최근 있었던 팀 회의 이전에 말이다. 그 컨셉 또는 아이디어는 캐디인 메건 스톤도 본적이 있고 알고 있었다. 그녀가 캐스팅될 당시 영화사인 ‘유니버설 무비스’ 측에서 보여줬었으니까. ‘지킬 앤 하이드’가 모티브가 되고 해리성 인격장애가 포함된 컨셉. 즉, 다중 인격. 다만 이 같은 컨셉이나 아이디어는 작가의 손을 거치지 않으면 아무것도 아니었다. 작가 또는 각본가의 손을 거쳐야 생명을 얻을 수 있고. -스윽. 지금 조셉의 손에 쥐어진 시놉들이 바로 그 결과물이었다. 시놉 및 쪽대본이 나오기까지 꽤 오랜 시간이 걸렸지만 어쨌든 나오긴 했다. 재밌는 것은. ‘이렇게나 전부 다를 줄이야.’ 같은 컨셉, 아이디어에서 나온 시놉·쪽대본의 내용이나 장르가 전부 다르다는 점. 영화 시나리오 4부가 눈앞에 놓인 것과 같았다. 4명의 각본가에게 의뢰했기에 당연한 결과이긴 하지만, 거인 조셉은 미소를 지으며 새삼 묘한 기분이 들었다. ‘창작의 세계는 오묘해.’ 헐리웃 쪽 시나리오 제작 시스템은 한국과 다른 양상을 보인다. 물론, 헐리웃에도 감독이 시나리오를 쓰는 경우가 있긴 하지만 드물다. 헐리웃에서도 손에 꼽히는 대 거장들이나 그렇고, 보통은 조셉이 하고있는 것처럼 헐리웃 쪽 작가들에게 컨셉을 넘겨 집필하게 한다. 당연히 작가는 한 명이 아닌 여러 명이다. 또한 시나리오 집필 제의를 받은 작가들은 절대 서로를 알 수가 없으며 접촉도 불가하다. 그렇게 하나의 컨셉 또는 아이디어를 여러 헐리웃 작가들이 시놉으로 탄생시킨다. 완성된 시놉은 조셉같은 총괄 프로듀서에게 넘어가고, 그 시놉들을 토대로 영화사와 프로듀서 등이 합심해 단 하나를 선택한다. 채택이 완료된 후에야 제대로 된 시나리오 작업에 돌입하는 것. 즉, 지금의 조셉은 헐리웃 영화로 제작될 시나리오를 선택하는 순간이기도 했다. 물론, 영화사에서도 개입이 있긴 하지만 대부분의 권력은 프로듀서에게 주어진다. 이 한 번의 선택이 향후 영화의 흥망성쇠를 결정짓는다고 말해도 과언이 아니었다. 망하면 모두가 죽 쑨다. 조셉은 물론이고 캐디인 메건 그리고 조셉이 사전에 긁어모은, 최근 한자리에 모여 첫 회의에 참석했던 헐리웃 유명 키스탭들 전원이 말이다. 무시무시한 액수의 자금도 공중분해. -팔락. 그렇기에 키가 190 넘는 거인인 조셉은 이미 봤던 시놉들을 다시금 읽기 시작했다. 아니, 아마 앞으로 수도 없이 봐야 할 것이다. 첫 번째 시놉부터 두 번째, 세 번째, 끝으로 네 번째 시놉까지. 이어 다시 첫 번째 시놉을 다시 리딩. -팔락, 팔락. 워낙 자주 시놉, 시나리오를 자주 읽는 조셉이기에 리딩은 빨랐으나, 그만큼 흐르는 시간도 삽시간에 녹아 없어졌다. 이윽고. -툭. 보던 시놉들을 겹쳐 앞쪽 책상 위에 대강 던진 조셉이 기나긴 다리를 꼬며 읊조렸다. “스릴러, 느와르, 범죄 액션, 코미디. 장르가 제각각이니 더 어렵군. 뭐, 이 맛에 하는 일이긴 하다만.” 그의 입가에 미소가 번졌다. “누군가 작품의 미래를 알고 선택해주면 얼마나 고맙겠어.” 늘 이런 상황이 오면 조셉이 자주 하던 상상이었다. 그런 인간이 존재치 않겠지만, 그래도 총괄 프로듀서인 조셉에게는 언제나 꿈꾸던 일이긴 했다. ‘그런 신의 재주를 부릴 사람이 있을 리가 없지.’ 이 순간. “아니. 비슷한 인물이 하나.” 거인 조셉의 뇌리에 한국 배우 한 명이 스쳤다. 강우진이었다. 그의 필모에선 ‘실패’를 찾을 수 없었다. 심지어 현재 진행형. 한국이나 일본에선 그에게 ‘미다스의 손’이란 별명을 지어줄 정도였다. ‘당연히 기민한 감이나 작품 보는 눈이 뛰어난 것이겠지만, 그래도 그 정도면- 신의 재주에 필적하는 정도지.’ 잠시간 우진을 떠올리던 조셉이 혼잣말을 뱉었고. “시간이 괜찮다면 슬쩍 이 시놉들을 보여줘도 괜찮을지도.” 꼰 다리 방향을 바꾼 그가 시놉들을 살짝 민 뒤 다른 파일들을 당겼다. 수많은 헐리웃 감독들이 담긴 리스트와 방콕에 갈 인원과 스케줄이 담긴 파일. 물론, 방콕 관련은 강우진의 ‘이로운 악’ 촬영 답사였다. “감독이야 시놉이 결정된 뒤에 확정하면 되겠고. 일단, 쉬운 것부터 하자고.” 그가 미리 정리해둔 방콕 관련 파일을 펼쳤다. 이미 강우진 측과 ‘이로운 악’ 쪽에도 얘기가 끝났다. 조셉은 파일 안 같이 동행할 인원들을 점검했다. 일단 조셉 본인, 캐디인 메건 스톤, 섭외가 끝난 스턴트 팀들, 배급·영화사인 ‘유니버설 무비스’의 간부 몇몇. 꽤 많은 인원이 이동하는 느낌. 사실, 이 정도 규모가 한 번에 움직이는 건 쉽지 않다. 조셉이나 메건이야 강우진에게 반한 상태니 그렇지만, 나머지는 설득하는 게 어렵다. 허나 조셉은 겸사겸사라는 명목으로 모두에게 확정 대답을 들었다. ‘방콕에 갔다가 바로 프랑스로 가는 루트. 오랜만에 꽤 피곤한 일정이군.’ 조셉의 팀은 방콕 후로 칸 영화제에 참석할 참이었다. 후로. 마일리 카라와 꽤 길었던 미팅을 마친 송만우 PD와 김소향, 최나나 작가는 같은 날 밤 비행기를 타고 한국으로 넘어갔다. 그들이 한국에 도착한 것은 12일. 퍽 강행군을 진행한 송만우 PD였으나, 그는 한국에 도착하자마자 쉬는 것 없이 바로 움직여야 했다. “고생들 하셨습니다, 가셔서 푹 쉬시고 내일들 뵙죠.” “네, PD님. 근데 바로 회사 들어가시는 거예요?” “그래야죠. 내일이 대본리딩이니.” “어후- 좀 쉬셔야죠. 쓰러지면 큰일인데.” “문제없죠, 이 정도는. 한두 번도 아니고.” 내일인 13일 정오쯤 ‘이로운 악’의 대본리딩이 잡혀 있었으니까. 김소향 총괄디렉터와 최나나 작가도 참여하는 대본리딩이지만, 오늘 바삐 뛰어야 하는 것은 송만우 PD뿐이다. ‘이로운 악’의 길었던 프리 프로덕션의 끝을 알릴, 전세계의 도전장의 첫발인 대본리딩이 내일인데 쉴 시간 따윈 없었다. 곧, 송만우 PD는 DM 프로덕션으로 복귀. 이 시각 강우진은 당연하겠지만 빡세게 스케줄 소화 중이었다. 오전엔 광고 모델로서 성대한 팬 사인회, 현재는 추가된 광고 촬영을 찍기 위해 현장으로 이동 중이었다. 밤엔 우진의 SNS 관련 간단한 인터넷 방송이 예정되어 있었다. 팬들과의 소통을 위한 것. ‘아- 하품 마렵다. 아공간 드가서 겁나 쌔리고 나와야겠네.’ 컨셉질이 짙은 우진이 한참 하품을 참고 있을 때였다. -우우웅. 그의 핸드폰이 짧은 진동을 울렸다. 뭐, 오늘 종일 핸드폰이 쉰 적은 없으나 지금 도착한 것은 DM이었다. 일본의 탑배우 마나 코사쿠가 보내온 것이었고, 내용으로는 ‘힘내고 있죠?’ 정도의 멘트와 여러 일본 기사들을 캡쳐한 사진도 있었다. 『노이즈 마케팅을 노렸나? 「낯기생」강우진의 선포 일파만파!』 『자만인가 자신인가? 「강우진」이 일본 영화계에 날린 선전포고, 업계 전문가들이 보는 시선은 분분』 마나 코사쿠가 전송한 기사들은 죄다 ‘낯기생’과 강우진 천지였다. ‘뭔 자만이여, 그냥 한 말이구만.’ 속으로 헛웃음 뱉은 우진이 적당히 답장한 후에 다른 것을 켰다. 일본의 각종 포털 사이트와 SNS 그리고 커뮤니티까지. 약 10분간 파도를 탄 강우진의 결론은. ‘진심 개빡세게 홍보 갈기네.’ ‘낯기생’의 홍보·마케팅이 미친 수준이라는 것이었다. 실제로 쿄타로 감독을 포함해 ‘낯기생’ 측은 제작발표회 이후, 단 하루도 빠지지 않고 일본 언론에 떡밥을 뿌려대는 중이었다. 『제작발표회 이후 더욱 뜨거워진「낯기생」편집 이달 말쯤 끝날 듯, 10월 말 개봉 예상』 판을 어마무시하게 키운다는 결정을 착실히 수행하고 있는 것. 『강우진의 자신감 이어 받나?「낯기생」측 “시사회 등 규모 몇 배로 키울 것”』 일본의 상황을 가만- 히 보던 우진은 상상해봤다. ‘이렇게까지 눈덩이를 거대하게 키운 담에 ‘낯기생’이 개봉하면, 진짜 일본 애들 눈 뒤집히는 거 아니냐?’ 개봉 후 닥칠 후폭풍을 잠깐 상상하는 것만으로도 소름이 돋았다. 하지만 그것도 잠시. ‘뭐 나야 딱히 쫄 건 없다만.’ 금방 우진은 하던 생각을 지워냈다. 속된말로 지랄이 되든 말든 작품만 잘되면 장땡이잖아? 뒤로 강우진이 광고 촬영장에 도착했을 쯤, 준비 시간 덕에 약 30분 정도의 여유가 생겼다. 사실 최근 강우진의 관심은 ‘거머리’ 쪽이 컸다. 촬영 내내 조용하던 ‘거머리’의 영화사가, 며칠 전에 있던 완성품 테스트 후로 본격적으로 움직이기 시작했으니까. 따라서 한국에 터지는 여러 이슈 중 ‘거머리’의 것이 강세였다. 『[무비톡]‘칸 진출작’인 ‘거머리’ 상영 테스트까지 완료, 어느 섹션에 진출할지 관심 집중!』 현재 ‘거머리’는 칸 영화제에 초청은 확정이며 출품도 완료했다. 하지만 어느 부문인지는 미확정이었다. 세계 3대 국제영화제 중 으뜸인 거대한 칸 영화제에는 여러 부문이 존재한다. 수상 부문이나 경쟁 섹션이라 부르기도 하는데, 칸 영화제의 핵심이며 메인은 ‘경쟁부문’이었다. 그 밑으로 ‘주목할만한 시선’, ‘비경쟁부문’ 등등이 있다. ‘경쟁부문’엔 세계적으로 20편 내외의 초청작이 선발되고, 그 중 칸 영화제의 최고상인 황금종려상이 수여된다. 2등 상인 심사위원 대상이나 감독상, 남우주연상, 여우주연상, 각본상 등도 포함이었다. 모든 상이 칸에서 메인이 되며 세계 각국의 내로라하는 배우, 영화인들 역시 이 상들을 노린다. 그것이 발표되는 것은. 『‘칸 영화제’ ‘경쟁부문’ 공식 초청작 발표 17일 확정, 메인 부문 ‘거머리’ 포함 한국영화 몇 편이나 진출할까?』 칸 영화제 측이 프랑스 현지에서 기자회견을 통해 한 번에 발표한다. 물론, 생중계로 너튜브 등의 영상 플랫폼에서 볼 수 있었다. ‘경쟁부문’만 그렇고 나머지 작품들은 공식 페이지에 게재되는 느낌. 한마디로 칸에 나가는 것도 영광이겠지만, 역시 제대로 세계를 뒤집어 놓으려면. 『칼을 간 ‘안가복 감독’의 ‘거머리’, 올해 칸 영화제의 ‘경쟁부문’에 오를 가능성은?』 ‘경쟁부문’에 드는 것이 먼저였다. 13일, DM 프로덕션. ‘이로운 악’의 제작을 맡은 DM 프로덕션 대회의실의 문이 굳건히 닫혀 있다. 그 앞엔 몇몇 스탭들이 지키고 섰고 뒤쪽 유리문엔 코팅된 종이 붙어 있었다. -[이로운 악 대본리딩장] 그랬다. 이곳에서 현재 ‘이로운 악’의 대본리딩이 진행되고 있었다. 그렇기에 드넓은 대회의실 내부의 ㅁ형 책상엔 수많은 배우들이 몰렸다. 그 ㅁ자형 책상을 감싼 건 여러 키스탭들이었다. ‘이로운 악’의 제작 실장, 무술 감독, 촬영 감독 외의 다수. 물론, 외국인 팀과 섞인 스턴트팀 에단 스미스도 포함. ‘한국의 대본리딩도 헐리웃과 비슷하군. 조금 정적인 것이 다른가?’ 김소향 총괄디렉터는 물론 넷플렉스 관계자들 등도 합쳐져 관계자는 최소 백여 명은 넘었다. ㅁ형 책상 상석엔 당연히 송만우 PD와 최나나 작가가 자리했다. “다음은 배우님들 소갭니다.” 배우들은 신인, 무명이 많았다. 그중에서 단연 눈에 띄는 건 모자를 푹 눌러쓴 화린과 하강수 그리고 A급 배우들 정도. 물론, 이번에 합류한 귀염상이지만 음침한 임해은, 청량감이 가득한 조무찬도 보였으나 그들도 결국 무명이었다. 이 많은 인물들이 모인 대본리딩장에서 핵심인 건. “‘장연우’ 역을 맡아주신 강우진님.” “안녕하세요, 강우진입니다. 잘 부탁합니다.” 데뷔 2년 차지만 이미 세계적으로도 입질이 있는, 파급력과 영향력으론 국내 최정상인 강우진이었다. 그가 ‘이로운 악’의 ‘장연우’로서 첫 시동을 걸었다. 이로부터 수십 시간 뒤. 국내 언론에선 앞다퉈 ‘이로운 악’ 관련의 기사를 쏟아내기 시작했고. 『[포토]넷플렉스 ‘이로운 악’, 강우진 포함 배우들 모여 대본리딩 중/ 사진』 『‘전세계’ 노릴 ‘이로운 악’ 대본리딩 성황리에 종료, 강우진의 리드 빛났다』 정확히 4일이 지난 17일 금요일. ‘이로운 악’팀의 해외로케 첫 촬영이 딱 3일 정도 남은 상황에. -드르륵! 방금 화보 스케줄을 마친 강우진이 승합차에 타자마자 핸드폰을 들었다. 꽁지머리 최성건도 마찬가지였다. 시간은 오후 4시쯤. 컨셉질이 짙어 무심함이 가득한 우진이었으나 속으론 나름 초조했다. ‘칸 영화제 발표 그거 이미 시작했겠네!’ 시간상 한국은 오후지만 프랑스는 아침일 것이고, 지금 프랑스 현지에서는 칸 영화제 측이 공식 초청작을 발표하고 있을 테니까. -슥. 따라서 우진이 너튜브에 접속했다. 링크는 이미 공유된 터라 영상을 접하기까진 오랜 시간이 걸리지 않았다. 우진이 켠 실시간 영상엔 칸 영화제의 대표 격인 집행위원장이 출력됐다. 머리가 벗겨진 외국인이었고, 플래시 세례를 받는 그가 마이크에 대고 담담히 ‘경쟁부문’에 합격한 20작품을 발표하고 있었다. 올해 칸 영화제를 빛낼, 메인이 될 작품들 말이다. ‘다행히 작품 발표는 이제 스타트구만.’ 강우진이 영상에 집중했다. 프랑스에 있을 칸 영화제의 집행위원장의 입에서 불어가 뱉어졌다. 첫 번째 영화가 발표된 것. 프랑스 영화였다. 두 번째는 일본. 세 번째는 독일. 그다음 영국. 쭉쭉 발표된다. 어느새 15번째 작품을 넘겼다. 사이 일본이 한 번 더 불렸다. 하지만 한국은 아직이었다. 이윽고. ‘19번째!’ 발표가 거의 끝에 도달했다. 허나 19번째 영화도 프랑스 쪽이었다. 우진은 순간 욕을 뱉을 뻔했다. ‘아오 시바!’ 하지만 근엄함을 어떻게든 유지했다. 이때. [“‘경쟁부문’ 20번째 초청작. 대한민국, 안가복 감독의 ‘거머리’.”] 마지막에 ‘거머리’가 불렸다. < 방콕 (1) > 끝","output":"< Bangkok (1) > The four synopses Joseph was looking at included brief early content in the form of side scripts. Of course, the root of the synopses he was looking at was provided by 'Universal Movies', a Hollywood dinosaur of a film and distribution company. What was essentially just a concept or idea was handed over to various screenwriters by Joseph, a general producer employed by the film company, before a recent team meeting. The concept or idea had also been seen and was known by Cady Megan Stone. She had been shown it by the film company 'Universal Movies' when she was cast. The concept was based on 'Jekyll and Hyde' and included dissociative identity disorder, in other words, multiple personalities. However, such concepts or ideas were nothing without a writer's touch. It was only through the hands of a writer or screenwriter that they could be brought to life. -Swish. The synopses in Joseph's hands were the result of that process. It took quite a long time for the synopses and side scripts to be produced, but they were finally completed. Interestingly, 'I didn't expect them all to be so different.' The content and genres of the synopses and side scripts, all derived from the same concept and idea, were completely different. It was as if four movie scripts were laid out in front of him. It was a natural result since he had commissioned four screenwriters, but the giant Joseph smiled and felt a strange sensation. 'The world of creation is mysterious.' The Hollywood script production system is different from that of Korea. Of course, there are cases in Hollywood where directors write the screenplay, but it's rare. It's usually the big masters in Hollywood who do that, and normally, as Joseph is doing, they hand over the concept to Hollywood writers to write. Naturally, there are multiple writers involved. Furthermore, the writers who are offered to write the screenplay can never know or contact each other. Multiple Hollywood writers turn one concept or idea into synopses. The completed synopses are passed on to general producers like Joseph, and based on those synopses, the film company and producers collaborate to select just one. Only after a selection is made do they begin the proper screenplay work. In other words, Joseph was at the moment of selecting a screenplay that would be produced into a Hollywood film. Of course, the film company was also involved, but most of the power was given to the producer. This one choice could very well determine the success or failure of the film. If it fails, everyone is doomed. Joseph, of course, Cady Megan, and all the famous Hollywood key staff that Joseph had gathered for a meeting recently, would all be affected. A terrifying amount of funds would also evaporate. -Flap. That's why Joseph, a giant over 190 cm tall, began to read the synopses again. Or rather, he would probably have to read them countless times in the future. From the first synopsis to the second, third, and finally the fourth. Then he read the first synopsis again. -Flap, flap. Joseph often read synopses and scripts, so his reading was fast, but time also melted away in an instant. Eventually. -Thump. Joseph, who had been reading the synopses, casually threw them onto the desk in front of him and crossed his long legs as he murmured. \\"Thriller, noir, crime action, comedy. The genres are all different, making it more difficult. Well, that's the fun of the job.\\" A smile spread across his lips. \\"How grateful would I be if someone knew the future of the work and made the selection for me.\\" It was a fantasy Joseph often had whenever he was in such a situation. Although such a person probably didn't exist, it was always a dream for Joseph, the general producer. 'It's unlikely there's someone with such divine talent.' At this moment. \\"Actually, there is one similar figure.\\" A Korean actor flashed through the mind of the giant Joseph. It was Kang Woojin. His filmography did not contain the word 'failure'. Even now, it was ongoing. In Korea and Japan, he was given the nickname 'Midas's hand'. 'Of course, he must have a keen sense and an excellent eye for works, but still, that level is almost equivalent to divine talent.' Joseph, who had been thinking about Woojin for a moment, muttered to himself. \\"If time permits, it might be okay to show him these synopses.\\" He changed the direction of his crossed legs and lightly pushed the synopses aside, pulling other files towards him. Lists containing numerous Hollywood directors and files with personnel and schedules for Bangkok. Of course, the Bangkok-related files were for Kang Woojin's 'Beneficial Evil' location scouting. \\"Let's start with the easy tasks. The director can be confirmed after the synopsis is decided.\\" He unfolded the Bangkok-related files he had prepared in advance. The arrangements with Kang Woojin's side and 'Beneficial Evil' had already been finalized. Joseph checked the personnel who would accompany him in the files. Himself, Cady Megan Stone, the stunt teams that had been cast, and a few executives from the distribution and film company 'Universal Movies'. It felt like quite a large group was moving. In fact, it wasn't easy for a group of this size to move all at once. Joseph and Megan were smitten with Kang Woojin, but convincing the rest was difficult. However, Joseph had received firm answers from everyone under the pretext of combining business with pleasure. 'A route that goes to Bangkok and then directly to France. It's been a while since I've had such a tiring schedule.' Joseph's team was planning to attend the Cannes Film Festival after Bangkok. Later. After a lengthy meeting with Miley Karah, Producer Song Man-woo, General Director Kim So-hyang, and writer Choi Nana boarded a plane to Korea that same night. They arrived in Korea on the 12th. Producer Song Man-woo, who had been on a tough schedule, had to move immediately upon arriving in Korea. \\"Thank you all for your hard work. Rest up and see you tomorrow.\\" \\"Yes, PD. But are you going straight to the company?\\" \\"I have to. Tomorrow is the script reading.\\" \\"Ugh- You should rest. It would be a big deal if you collapsed.\\" \\"No problem, I'm used to this. It's not the first time.\\" The script reading for 'Beneficial Evil' was scheduled for around noon the next day, the 13th. General Director Kim So-hyang and writer Choi Nana were also participating in the script reading, but today, only Producer Song Man-woo had to rush. There was no time to rest with the script reading for 'Beneficial Evil', which would mark the end of the long pre-production and the first challenge to the world, scheduled for tomorrow. Soon, Producer Song Man-woo returned to DM Production. At this time, Kang Woojin was, of course, busily digesting his schedule. In the morning, he had a grand fan signing event as an advertising model, and currently, he was on his way to the set for additional advertising shooting. In the evening, a simple internet broadcast related to Woojin's SNS was scheduled. It was for communication with fans. 'Ah- I feel like yawning. I should go into the subspace and come out refreshed.' Woojin, who was heavily into his pretense, was holding back a yawn when. -Vrrrr. His phone vibrated briefly. Well, his phone hadn't rested all day, but what arrived now was from DM. It was sent by top Japanese actor Mana Kosaku, and the content was a message like 'Are you holding up?' along with several captured photos of Japanese articles. \\"Did they aim for noise marketing? 'Nachi Kisei' Kang Woojin's declaration causes a stir!\\" \\"Arrogance or confidence? 'Kang Woojin's' declaration of war on the Japanese film industry, experts' views are divided\\" The articles sent by Mana Kosaku were all about 'Nachi Kisei' and Kang Woojin. 'What arrogance? It was just something I said.' Woojin chuckled inwardly and sent a suitable reply before opening something else. Various Japanese portal sites, SNS, and communities. After surfing for about 10 minutes, Kang Woojin's conclusion was. 'They're seriously going all out with the promotion.' The promotion and marketing for 'Nachi Kisei' were at a crazy level. In fact, since the production announcement, the 'Nachi Kisei' team, including director Kyotaro, had been throwing bait to the Japanese media every single day without fail. \\"'Nachi Kisei' heats up even more after the production announcement, editing expected to finish by the end of the month, release anticipated for late October\\" They were diligently executing the decision to massively expand the scale. \\"Following Kang Woojin's confidence? 'Nachi Kisei' side says, 'We will increase the scale of the preview screenings several times over'\\" Woojin, who was quietly observing the situation in Japan, imagined. 'If they keep building up the snowball this big and then 'Nachi Kisei' is released, won't the Japanese go crazy?' Just imagining the aftermath of the release gave him chills. But that was only for a moment. 'Well, I don't really have anything to worry about.' Woojin quickly dismissed his thoughts. As the saying goes, as long as the work does well, that's all that matters, right? Later, when Kang Woojin arrived at the advertising shooting location, he had about 30 minutes of free time thanks to the preparation period. In fact, Kang Woojin's recent interest was more on 'Leech'. The film company behind 'Leech', which had been quiet throughout the shooting, had started to move in earnest after the completed product test a few days ago. Therefore, among the various issues erupting in Korea, 'Leech' was gaining momentum. \\"[MovieTalk] 'Leech', a Cannes contender, completes screening test, attention focused on which section it will enter!\\" Currently, 'Leech' was confirmed to be invited to the Cannes Film Festival and the submission was completed. However, which category it would be in was still undecided. The grand Cannes Film Festival, the foremost of the three major international film festivals, has several categories. They are also called award categories or competition sections, with the main and core being the 'Competition Section'. Below that are 'Un Certain Regard', 'Out of Competition', and so on. The 'Competition Section' selects about 20 invited works globally, and the highest award of the Cannes Film Festival, the Palme d'Or, is awarded there. The second-place award, the Grand Prix, as well as the Best Director, Best Actor, Best Actress, and Best Screenplay awards, are also included. All awards are main events at Cannes, and renowned actors and filmmakers from around the world also aim for these awards. The announcement of these awards. \\"Cannes Film Festival's 'Competition Section' official invitation list confirmed for the 17th, how many Korean films will enter the main section including 'Leech'?\\" The Cannes Film Festival announces them all at once through a press conference in France. Of course, it can be watched live on video platforms like YouTube. Only the 'Competition Section' is like that, and the rest of the works are posted on the official page. In short, it's an honor to go to Cannes, but to truly turn the world upside down. \\"Director An Ga-bok's 'Leech', sharpened for this year's Cannes Film Festival, what are the chances of entering the 'Competition Section'?\\" Entering the 'Competition Section' was the first step. 13th, DM Production. The door to the large conference room of DM Production, which was in charge of producing 'Beneficial Evil', was firmly closed. A few staff members stood guard in front of it, and the back glass door was covered with coated paper. -[Beneficial Evil Script Reading Room] That's right. The script reading for 'Beneficial Evil' was currently underway here. Therefore, inside the spacious conference room, numerous actors gathered around the U-shaped table. Surrounding the U-shaped table were various key staff members. The production manager of 'Beneficial Evil', the martial arts director, the cinematography director, and many others. Of course, Ethan Smith from the foreign stunt team was also included. 'The script reading in Korea is similar to Hollywood. Is it just a bit more solemn?' General Director Kim So-hyang, as well as Netflix officials, were also present, totaling at least a hundred people involved. At the head of the U-shaped table, naturally, sat Producer Song Man-woo and writer Choi Nana. \\"Next, let's introduce the actors.\\" Many of the actors were newcomers or unknowns. Among them, the most noticeable were Hwarin and Ha Gang-su, who wore hats pressed down, and a few A-list actors. Of course, the cute but gloomy Im Hae-eun and the refreshing Jo Moo-chan were also visible, but they were ultimately unknowns as well. In this script reading room filled with many characters, the key was. \\"The role of 'Jang Yeon-woo' will be played by Mr. Kang Woojin.\\" \\"Hello, I'm Kang Woojin. Please take care of me.\\" Despite being only two years into his debut, Kang Woojin was already a global sensation, with impact and influence at the top in Korea. He was starting his first move as 'Jang Yeon-woo' in 'Beneficial Evil'. Several tens of hours later. The domestic media began to pour out articles related to 'Beneficial Evil'. \\"[Photo] Netflix's 'Beneficial Evil', actors including Kang Woojin gather for script reading / Photo\\" \\"'Beneficial Evil', aiming for the 'world', concludes script reading successfully, Kang Woojin's lead shines\\" Exactly four days later, on Friday the 17th. With just about three days left until the first overseas location shooting for 'Beneficial Evil'. -Rattle! Just after finishing a photo shoot schedule, Kang Woojin got into the van and picked up his phone. Choi Seong-gun with the ponytail did the same. It was around 4 PM. Woojin, who was full of nonchalance due to his pretense, was somewhat anxious inside. 'The Cannes Film Festival announcement must have already started!' It was afternoon in Korea, but it would be morning in France, and right now, the Cannes Film Festival would be announcing the official invitations. -Swish. Therefore, Woojin accessed YouTube. The link had already been shared, so it didn't take long to access the video. The live video Woojin turned on showed the executive director of the Cannes Film Festival, a bald foreigner, receiving a barrage of flashes as he calmly announced the 20 works that had passed into the 'Competition Section'. The works that would illuminate this year's Cannes Film Festival as the main event. 'Fortunately, they've just started announcing the works.' Kang Woojin focused on the video. French words were spoken by the executive director of the Cannes Film Festival in France. The first film was announced. It was a French film. The second was Japanese. The third was German. Then came the UK. The announcements continued. Soon, they passed the 15th work. Japan was called once more. But Korea had not yet been mentioned. Eventually. 'The 19th!' The announcement was nearing its end. However, the 19th film was also from France. Woojin almost cursed. 'Ah, damn it!' But he managed to maintain his solemnity. At that moment. [\\"The 20th film invited to the 'Competition Section'. From South Korea, director An Ga-bok's 'Leech'.\\"] 'Leech' was called last. < Bangkok (1) > End"},{"instruction":"< 방콕 (5) > 글로벌 슈퍼스타 마일리 카라가 이 태국 방콕에 있을 리가 없다. 분명, 누구라도 그렇게 생각할 게 빤했다. 최근 새 앨범 작업으로 바쁘던 그녀가 뜬금 왜 방콕에 있겠는가? 거인인 조셉 펠튼이나 외국인 무리 전부의 생각은 다르지 않았다. 따라서 조셉이나 메건 그리고 나머지 인원들은, 배급·영화사 ‘유니버설 무비스’의 간부인 배 나온 남자를 진정시켰다. “하하하, 마일리 카라라니? 느닷없네요. 여기 방콕입니다, 방콕.” “그러게요. 비행기 탄 시간이 너무 길었어요? 아무래도 빨리 들어가 쉬어야겠는데.” “헛것이라도 본 겁니까?” “어디? 어디에 마일리가 있어요?” 조셉과 무리들은 농담 식으로 말했으나 배 나온 간부는 웃음기 없이 미간을 좁혔다. “아니- 분명. 저 여자.” 이내 그가 가리키는 방향으로 조셉과 모두의 시선이 따라갔다. 허나 아쉽게도 배 나온 간부가 봤던 여자는 이미 사라지고 없었다. “진짜 어디 안 좋으신 겁니까?” “체크인 빨리 진행하죠, 진심으로 위험하다는 생각이 들어요.” “괜찮아요?” 농담에서 진지한 걱정으로 변했다. 갈색 단발의 메건이 간부의 어깨를 두드렸다. “일단 소파에 앉아요, 침착하고.” “······아, 그래요.” “갑자기 마일리 카라라니 무슨 얘깁니까?” “방금 지나간 금발 여자- 분위기가 그녀 같았어요. 말이 안 되긴 하다만.” “마일리를 캐스팅하고 싶다는 염원이 너무 셌던 모양이네요. 피곤하시기도 할 테고.” 배 나온 간부가 메건 스톤의 얼굴을 올려봤다가 천천히 고개를 내렸다. 그리곤 엄지와 검지로 자신의 눈을 꾹꾹 눌렀다. “후- 아무래도 그런 것 같아요. 마일리 카라라니······” 그가 자신이 본 것이 잘못됐음을 인정했다. 오랜 비행시간이 있었고 시차도 문제였다. 거기다 마일리 카라 정도의 탑급이라면 헐리웃 영화사 어디라도 군침을 흘린다. 빌어서라도 캐스팅할 판. 그 정도면 싸게 먹히는 편. 곧, 배 나온 간부 주변의 팀 인원들이 끼었다. “그래도 조금 설레긴 했네요, 마일리 카라 이름을 들어서.” “하하. 마일리 카라, 캐스팅하기 어렵기로 소문났죠. 지금은 아마 새 앨범 작업으로 바쁘지 않나?” “그렇지. 한창 바쁠 거야.” “마일리가 방콕에 떴으면 여기나 헐리웃이나 시끄러웠을 겁니다.” 배 나온 간부가 억지웃음을 지었다. “미안해요, 난 좀 쉬지.” 대답은 메건이 빨랐다. “그래요. 체크인, 최대한 빨리 진행할게요.” 이때였다. “조셉.” 뒤쪽 호텔의 거대한 로비에서 누군가 조셉 펠튼을 불렀다. 영어였고 남자 목소리. 거인 조셉 포함 모두가 고개를 돌렸고, 로비에선 코가 큰 외국인 남자가 웃으며 걸어오고 있었다. ‘이로운 악’의 스턴트 팀 리더 에단 스미스였다. 조셉이나 메건 외의 모두가 바로 반응했다. “오, 에단.” 에단이 ‘이로운 악’에서 스턴트 코디네이터를 맡은 건 모두가 알고 있었고, 다가온 에단이 조셉부터 시작해 메건을 이어 여럿에게 악수하며 인사를 나눴다. 특이한 건 에단과 같이 온 게 팀원이 아닌 한국인들이라는 것. 에단에겐 총 3명의 한국인이 함께였다. 소개는 당연히 에단이 했다. “이분들은 ‘이로운 악’의 제작 스탭입니다.” 같이 온 한국인들은 ‘이로운 악’의 제작진이었다. 통역도 포함. 조셉과 메건 그리고 외국인 무리는 ‘이로운 악’의 촬영을 보러 온 것. 이미 사전에 적당한 얘기가 오가기도 했지만, 현장에서 다시금 스케줄 등을 공유해야 했다. 물론, 송만우 PD의 배려였다. ‘이로운 악’ 스탭들은 잠시간 촬영에 간단한 정보를 알렸고, 약 5분 정도 뒤에 조셉의 팀 전부에게 종이들을 나눴다. 비밀유지 서약서였다. 촬영과 현장에 관련한 모든 것을 함구하라는 내용. 비밀유지 서약서를 받자마자 조셉은 생각했다. ‘철통 보안이구만.’ 하지만 이상하게 보진 않았다. 헐리웃에서도 이런 경우는 비일비재하니까. 작품 촬영에 관한 비밀이 밖으로 새어나갈 경우, 그 정보가 어떤 것이든 간에 작품에 피해를 끼치게 된다. 홍보, 마케팅 적으로는 물론 향후 작품의 결과에도 영향을 미친다. 상당히 무거운 문제였다. 그러니 행여 비밀 서약을 어길 경우 당사자에겐 퍽 커다란 위약금이 발생 된다. 지금 조셉이나 모두가 받은 서약서 역시 같은 성격이었다. 강우진을 아는 메건도 이해했다. ‘하긴, 헐리웃 쪽 스턴트 팀까지 섭외할 정도였으니······강우진의 액션이나 CQC 등에 상당히 힘을 줬을 거고 핵심 연출들도 많을 거야.’ 다만, 조셉 쪽의 팀원들이나 스턴트 팀들, ‘유니버설 무비스’의 간부 몇몇은. ‘이렇게까지 한다고? 왜지.’ ‘상당히 철저해, 이유가 있는 건가?’ ‘드라마 촬영에 서약서를 쓴다라- 약간 유난처럼 보이기도 하고.’ 약간 의아한 표정들이었다. 한편, 같은 호텔의 스위트룸. 드넓은 룸의 거실 소파에 금발의 여자가 다리를 꼰 채 앉아 있다. 마일리 카라였다. 그녀의 앞 탁자엔 직전까지 썼던 모자와 마스크가 놓여있었고, 건너편 자리의 매니저 조나단에게 카라가 말했다. “봤어? 로비에 조셉 펠튼이 있었어.” 카라 특유의 약간 냉정한 말에 조나단이 약간 놀랐다. “뭐? 조셉이?” “응. 정확하진 않지만 익숙한 얼굴들이 많던데? ‘유니버설 무비스’ 쪽 사람들도 보였고.” “허- 영화 준비 중인 게 있다고 들었는데 그것 때문인가?” “장소헌팅 치고는 규모가 작아. 다른 이유 때문이겠지.” “어떤······설마 ‘이로운 악’?” “조셉이 핸들링했다면 충분히 가능해. 그도 강우진에게 빠져 있으니까.” “강우진을 보러 조셉이 방콕까지 왔다? 말이 안 되잖아. 강우진은 헐리웃에서 인지도가 거의 없다시피 하니까.” 어깨를 으쓱인 카라가 작게 웃었다. “글쎄, 촬영 날에 보면 알게 되겠지. 그런데 만약 그들이 강우진을 보러 온 거라면- 일이 재미있게 흘러가네.” 강우진의 연기도 연기겠지만 그의 액션 또는 CQC, 거기에 마일리 카라가 포함된 촬영들을 조셉 포함 무리들이 본다면 어떤 반응일까? 카라 본인도 기대치가 최대라 그런지 퍽 흥미가 솟았다. 동시에 기쁘기도 했다. “어쩌면 내가 강우진에게 사 준 LA 쪽의 집, 그가 사용하는 게 생각보다 빠를지도 모르겠네.” “음?” “점점 헐리웃 쪽 인물들에게 강우진이 각인되고 있잖아?” 이어 카라가 돌연 대화 주제를 바꿨다. “어쨌든 조나단, 조셉이 지금 굴리고 있는 영화 말이야. 확인 좀 해줘, 어떤 느낌인가.” 다음 날 이른 아침. 20일이 밝자마자 강우진은 ‘이로운 악’ 전체 팀들과 섞여 호텔을 나섰다. 오늘도 역시 방콕의 햇볕은 뜨겁다. 사이에 송만우 PD가 강우진에게 설명했다. “오늘은 거의 리허설이나 점검, 연습 등을 진행할 예정입니다. 여기 태국 현지 단역들하고 액션 합도 맞춰봐야 하고, 카체이스나 폭발 씬들도 있어서 점검은 여러 번 해도 부족하지 않아요.” 이들의 첫 목적지는 방콕 시내에서 약 1시간 정도 떨어진 한 마을이었다. 꽤 규모가 크지만 살고있는 태국사람들은 많지 않았다. ‘여긴 아침에 보니까 분위기가 또 다르네. 이국적이긴 한데 뭔가 느낌이 남미 같달까?’ 과거엔 퍽 흥했던 마을이었으나 현재는 조용했다. 그렇기에 비어있는 건물이나 폐공장, 폐건물이 많다. 하지만 많은 건물. 즉, 시가지도 잘 형성돼있어서 그림이 나쁘지 않았다. 이 마을에서 많은 촬영이 있을 예정이었다. 롱테이크, 카체이스, 폭발, 총격전 등등. 당연히 진작에 섭외는 끝난 상태였다. 태국은 영화산업 인프라가 잘 구축된 편. 따라서 헐리웃 쪽에서도 태국은 곧잘 이용되는 국가였다. 인프라가 좋기에 현지 업체도 많고 각종 장비, 촬영 허가, 정부 협조 등이 유연했다. 워낙 영화 촬영이 자주 있는 편이라 체계가 잘 잡혀 있다는 얘기. 어쨌든 강우진과 송만우 PD 외의 ‘이로운 악’팀은 마을 외곽의 커다란 폐공장에 모였다. ‘이로운 악’ 전체 스탭만 약 백여 명. 이미 대규모에 속하지만, 폐공장 앞의 큰 공터에는 태국 현지인들이 약 50명 정도 모여 있었다. 우진은 이미 그들에 관해 들은 바가 있었다. ‘아- 저 사람들이 태국 쪽 스탭??’ 해외로케 촬영은 오로지 국내 팀들만 가지고 굴릴 수가 없다. 해외 현지의 스탭이나 관계자들이 필수였다. 저 50명 넘는 태국 현지인들 역시 ‘이로운 악’팀이 섭외한 인원들이었다. 촬영팀에 속하는 사람이 약 반이고 반은 단역 배우들. 인프라가 잘 잡힌 태국이기에 배우 캐스팅도 어렵지 않다. 거기다 촬영 경력이 두터운 위주로 뽑았다. 어차피 대부분이 강우진. 아니, ‘장연우’에게 사살당할 인물들이나 생동감이 핵심이니까. 뭐가 됐든 태국 현지 스탭이나 단역 배우들에게도 비밀유지 서약서를 다 받은 송만우 PD였다. 참고로 ‘이로운 악’의 백여 명 스탭들도 마찬가지. 결과적으로 이 폐공장 공터엔 어마무시한 인파가 몰렸다. 얼추 200명은 거뜬하지 않을까? 곧. “시작해볼까?” 송만우 PD의 신호에 따라 백여 명 스탭들이 우르르 움직였다. 리허설을 위한 준비지만 허투루 할 순 없다. 촬영팀은 각종 카메라를 내렸고, 조명팀이나 소품팀 등도 같았다. 메이킹팀은 진작에 폐공장 주변과 대규모 촬영팀을 찍고 있었다. 여러 팀들이 공터에 뿌리를 내리기 시작했다. 공터는 단숨에 무시무시한 인원들의 고함소리가 가득해졌다. 와중 강우진은. “잘 부탁합니다.” 50여 명의 태국 현지 스탭과 배우들에게 인사 중이었다. 물론, 영어로 뱉은 것이었고 현지 배우들 전체는 우진을 상당히 신기한 눈을 봤다. 당연했다. 그는 태국에서 이미 꽤 유명했으니까. 강우진은 연신 덤덤했다. 하지만 내면으로는 그 역시 이 많은 태국 현지인들이 새로웠다. ‘와- 씨, 이만한 외국인들이랑 촬영하는 건 처음 아닌가? 심지어 액션이고. 뭔가 떨리네.’ 이를 알 턱이 없던 송만우 PD는 흐르는 땀을 닦으면서도 지시를 내렸다. 태국 현지 스탭, 배우들에게 준비하라 던진 것. 그들 역시 일사불란하게 뛴다. 이쯤 의상, 분장팀이 송만우 PD 옆의 강우진에게 달려왔다. 메이크업과 의상 교체를 위한 것. 몇십 분 뒤 강우진이 탈바꿈됐다. 헤진 흰색 셔츠에 청바지, 전체적인 피부톤도 약간 짙어졌다. 흑발 머리도 부스스하게 변했다. 방콕에 숨어든 ‘장연우’를 그대로 구현했다. 우진은 스탭이 보여주는 거울을 보며 속으로 엄지를 세웠다. ‘오- 대박.’ 본인이 직접 살았던 ‘장연우’와 거의 흡사했으니. 이는 강우진만이 아닌, 그를 꽤 멀리서 지켜보는 다른 인물에게도 같았다. 사파리 모자를 쓴 최나나 작가, 김소향 총괄디렉터, 꽁지머리 최성건 외의 몇몇. “와- 완전 내가 생각했던 ‘장연우’랑 똑같아요! 싱크로율이 무슨······하, 어떻게 진짜 떨린다.” “작가님, 애초 ‘장연우’를 우진씨 두고 썼던 거 아니었어요?” “그, 그렇긴 한데 막상 보니까 더 똑같달까?” “하하하, 우리 우진이 마스크가 범용성이 뛰어나죠.” “아! 우진씨 총 들었다!” 실제 강우진은 방금 스탭에게 총기를 건네받았다. M4 카빈. 극 중 ‘장연우’가 자주 쓰는 소총. 곧, 강우진 주변으로 송만우 PD나 무술 감독, 스턴트 팀인 에단 스미스 등이 모였다. 태국 현지 스탭도 두 명 포함됐다. 그중 송만우 PD가 우진에게 손짓했다. “우진씨, 편하게 쏴봐요.” 덤덤히 끄덕인 우진이 상당히 자연스레 M4 카빈을 견착하며 전방에 총을 갈겼다. -탕탕탕탕! 순간, 백여 명 스탭들이 움직임을 멈추고 강우진에게 시선 고정. 격발음도 어마어마하게 컸으니까. M4 카빈에서 총구화염이 뿜어지며 탄피도 튀어나왔다. 반동도 격하다. 그야말로 진짜 총과 다르지 않다. 직접 사격한 강우진이 놀랄 정도였다. 당연히 속으로만. ‘워- 퀄 뭐냐??!!’ ‘이로운 악’팀은 총기들 역시 거의 실제와 다름없게 준비했다. 핵심 중 핵심이니까. 촬영용이라 총알은 쏴지지 않지만, 실제와 다름없는 불꽃과 탄피 배출 등으로 진짜와 거의 흡사한 모습을 완성했다. 진짜 총과 비교하면 당연히 약한 편이나 이 정도면 다분히 실제와 혼동될 정도. 사용할 여러 소품 총기들은 사전에 태국 현지 전문가와 협의해 준비한 것들이었다. CG를 최소화하겠다는 송만우 PD의 굳은 의지. 이쯤. -끼익! 폐공장 공터에서 꽤 떨어진, ‘이로운 악’ 팀들의 여러 차가 주차된 곳에 승합차 두 대가 섰다. 차에선 외국인들이 내렸다. 조셉과 메건, ‘유니버설 무비스’의 간부들 포함된 20명 남짓한 무리. 이들은 내리자마자 촬영터의 규모에 놀랐다. “오우! 스탭들이 상당한데요?” “그러게. 200명은 넘어 보여.” “저들의 스탭도 많은데 저기 봐, 태국 현지 스탭들도 합친 모양이야.” “생각보다 촬영 규모가 엄청나군. 작품 사이즈가 큰 건가?” 동시에 다시금 묵직한 총성이 울렸다. -탕탕탕탕!! 강우진이 재차 쏜 것. 하지만 조셉과 외국인 무리는 처음 들었기에 두 눈을 크게 떴고. “와우, 총격전이 있는 모양인데요??” “총기 준비도 수준급으로 한 것 같아.” “총 쏘는 남자를 봐, 자세부터 이미 전문간데? 저런 인물들도 섭외했나 보군.” “당연히 전문가 섭외는 필수지.” “아니.” 거인 조셉이 비죽 웃으며 읊조렸다. “저 남자는 배웁니다.” “······배우라니??” 이 순간. “배우 맞아요.” 옆쪽에서 여자 목소리가 침투했다. 역시 영어였다. 이내 조셉부터 모두가 고개를 휙 돌렸다. 금발에 선글라스 낀 여자가 열댓 명 되는 인원들과 걸어오고 있었다. 그녀가 가까울수록 조셉부터 메건 외의 무리 모두의 눈이 훅 확장됐다. “세, 세상에.” 반면 대수롭지 않게 다가온 금발 여자. 아니, 마일리 카라는 외국인 무리들 바로 앞에 멈춰서는 선글라스를 벗었다. “저 남자 배우 맞아요.” 모두가 귀신이라도 본 듯 입을 쩍 벌렸다. ‘유니버설 무비스’의 간부 중 배 나온 남자가 제일 먼저 반응했고. “역시!! 내가 어제 본 게 맞았어!” 갈색 단발의 메건이 카라에게 어렵사리 물었다. “······마일리, 당신이 여긴 왜.” 카라는 선글라스 든 손으로 촬영터 안 강우진을 가리켰다. “당연히 촬영하러 왔죠.” “촤, 촬영??!” “네. 뭐, 100% 저 배우 때문에 온 거긴 해요.” 순간, 모두의 시선이 강우진에게 박혔다. 그리고. “저기 저 금발 여자요. 어디서 많이 보지 않았어요?” ‘이로운 악’의 현장의 스탭들 몇몇이. “어? 어디?” “저기 주차장 쪽에.” 카라 쪽을 알아차렸다. < 방콕 (5) > 끝","output":"< Bangkok (5) > It was unthinkable that global superstar Miley Karah would be in Bangkok, Thailand. Surely, anyone would think the same. Why would she, who had been busy with her new album work recently, be in Bangkok out of the blue? The thoughts of the giant Joseph Felton and the group of foreigners were no different. Therefore, Joseph, Megan, and the rest of the group calmed down the pot-bellied executive from the distribution and film company 'Universal Movies'. \\"Hahaha, Miley Karah? That's unexpected. This is Bangkok, Bangkok.\\" \\"Exactly. Was the flight too long? You should probably go in and rest as soon as possible.\\" \\"Did you see something wrong?\\" \\"Where? Where is Miley?\\" Joseph and the group joked, but the pot-bellied executive narrowed his brows without a smile. \\"No, I'm sure. That woman.\\" Everyone's gaze followed the direction pointed out by the executive, but unfortunately, the woman he had seen was already gone. \\"Are you feeling unwell?\\" \\"Let's proceed with the check-in quickly, I'm seriously concerned.\\" \\"Are you okay?\\" The tone shifted from joking to genuine concern. Megan, with her brown bob haircut, patted the executive's shoulder. \\"Sit down on the sofa for now, stay calm.\\" \\"…Ah, okay.\\" \\"What do you mean, Miley Karah all of a sudden?\\" \\"That blonde woman who just passed by—she had an atmosphere like her. It doesn't make sense, but.\\" \\"Maybe your desire to cast Miley was too strong. You must be tired too.\\" The pot-bellied executive looked up at Megan Stone and then slowly lowered his head, pressing his eyes with his thumb and index finger. \\"Phew—It seems so. Miley Karah…\\" He admitted that what he saw was a mistake. There had been a long flight, and jet lag was an issue. Besides, if it were a top-tier celebrity like Miley Karah, any Hollywood film company would drool over her. They would cast her even if they had to beg. It was that cheap. Soon, the team members around the pot-bellied executive joined in. \\"Still, it was a bit exciting to hear the name Miley Karah.\\" \\"Haha. Miley Karah is known to be difficult to cast. She must be busy with her new album now, right?\\" \\"That's right. She would be very busy.\\" \\"If Miley had shown up in Bangkok, it would have been noisy here and in Hollywood.\\" The pot-bellied executive forced a laugh. \\"I'm sorry, I need to rest.\\" Megan was quick to respond. \\"Okay. I'll proceed with the check-in as quickly as possible.\\" At that moment. \\"Joseph.\\" Someone called out to Joseph Felton from the vast lobby of the hotel. It was in English, a man's voice. The giant Joseph, including everyone, turned their heads, and from the lobby, a man with a large nose was walking towards them with a smile. It was Ethan Smith, the stunt team leader for 'Beneficial Evil'. Joseph, Megan, and everyone else reacted immediately. \\"Oh, Ethan.\\" Everyone knew that Ethan was in charge of stunt coordination for 'Beneficial Evil', and the approaching Ethan started shaking hands and greeting everyone from Joseph to Megan. What was peculiar was that the people with Ethan were not team members but Koreans. Ethan was accompanied by three Koreans. The introductions were naturally made by Ethan. \\"These are the production staff for 'Beneficial Evil'.\\" The Koreans with him were part of the production team for 'Beneficial Evil', including an interpreter. Joseph, Megan, and the group of foreigners were there to observe the filming of 'Beneficial Evil'. Although there had been some prior discussion, they needed to share the schedule again on-site. Of course, it was courtesy of Producer Song Man-woo. The 'Beneficial Evil' staff briefly informed them about the shooting and, after about 5 minutes, distributed papers to everyone in Joseph's team. It was a non-disclosure agreement. The content was to keep silent about everything related to the shooting and the site. As soon as Joseph received the non-disclosure agreement, he thought. 'Tight security.' But he didn't find it strange. Such cases were common in Hollywood. If secrets about the film's production leak out, whatever the information may be, it can harm the work. It affects not only promotion and marketing but also the future results of the work. It was a serious matter. Therefore, if the confidentiality agreement is breached, the person involved faces a significant penalty. The non-disclosure agreements received by Joseph and everyone else were of the same nature. Megan, who knew Kang Woojin, understood as well. 'After all, they even hired a Hollywood stunt team... They must have put a lot of effort into Woojin's action and CQC, and there must be many key scenes.' However, Joseph's team members, the stunt team, and a few executives from 'Universal Movies' were. 'To go to such lengths? Why?' 'Very thorough, is there a reason?' 'Writing a non-disclosure agreement for drama filming seems a bit excessive.' They looked somewhat puzzled. Meanwhile, in the same hotel's suite room. A blonde woman sat on the sofa in the spacious room with her legs crossed. It was Miley Karah. On the table in front of her were a hat and mask she had just used, and across from her, manager Jonathan, Karah spoke. \\"Did you see? Joseph Felton was in the lobby.\\" Jonathan was slightly surprised by Karah's typically cool tone. \\"What? Joseph?\\" \\"Yeah. I'm not sure, but there were a lot of familiar faces? I saw people from 'Universal Movies' too.\\" \\"Huh—Are they preparing for a movie? Is that why they're here?\\" \\"It's too small a scale for location scouting. It must be for another reason.\\" \\"What... could it be 'Beneficial Evil'?\\" \\"If Joseph is handling it, it's entirely possible. He's also smitten with Kang Woojin.\\" \\"Joseph came to Bangkok to see Kang Woojin? That doesn't make sense. Kang Woojin is almost unknown in Hollywood.\\" Karah shrugged her shoulders and chuckled softly. \\"Well, we'll know when we see the shooting day. But if they came to see Kang Woojin—things are getting interesting.\\" What would be the reaction of Joseph and the others if they saw the shooting involving Kang Woojin's acting, action, or CQC, and Miley Karah? Karah herself was very excited, perhaps because her expectations were at their peak. She was also pleased. \\"Maybe the house I gave to Kang Woojin in LA will be used sooner than I thought.\\" \\"Hmm?\\" \\"Kang Woojin is gradually becoming imprinted on the people in Hollywood, right?\\" Then Karah suddenly changed the subject. \\"Anyway, Jonathan, check out the movie that Joseph is currently working on. What's the vibe?\\" The next day, early in the morning. As soon as the 20th dawned, Kang Woojin left the hotel mixed with the entire 'Beneficial Evil' team. The Bangkok sun was still hot today. In the meantime, Producer Song Man-woo explained to Kang Woojin. \\"Today, we're mostly going to do rehearsals, checks, and practice. We need to match the action with the local Thai extras, and there are car chase and explosion scenes, so checking several times won't be enough.\\" Their first destination was a village about an hour away from downtown Bangkok. It was quite large, but not many Thai people lived there. 'It feels different here in the morning. It's exotic, but it kind of feels like South America?' It was a village that used to be bustling in the past, but now it was quiet. That's why there were many empty buildings, abandoned factories, and ruins. However, there were many buildings. In other words, the town was well-formed, so the scenery wasn't bad. Many shootings were planned in this village. Long takes, car chases, explosions, gunfights, and more. The casting had already been completed long ago. Thailand has a well-established film industry infrastructure. Therefore, Thailand is also frequently used by Hollywood. The infrastructure is good, so there are many local companies, and various equipment, filming permits, and government cooperation are flexible. The system is well-established because film shootings are common. Anyway, Kang Woojin, Producer Song Man-woo, and the 'Beneficial Evil' team gathered at a large abandoned factory on the outskirts of the village. About a hundred staff members of 'Beneficial Evil'. Although it was already a large group, about 50 local Thais were gathered in the large open space in front of the abandoned factory. Woojin had already heard about them. 'Ah- Are those people the Thai staff?' Overseas location shooting can't be done with just the domestic team. Local staff or officials from overseas were essential. The 50-plus local Thais were also personnel recruited by the 'Beneficial Evil' team. About half were part of the filming team, and the other half were extras. Casting actors wasn't difficult in Thailand, where the infrastructure was well-established. They also selected those with extensive filming experience. After all, most of them would be killed by Kang Woojin. Or rather, 'Jang Yeon-woo', where liveliness was key. Regardless, Producer Song Man-woo had obtained non-disclosure agreements from the local Thai staff and extras. Similarly, the hundred or so staff members of 'Beneficial Evil' did the same. As a result, an impressive crowd gathered in the open space of the abandoned factory. Probably easily over 200 people? Soon. \\"Shall we start?\\" Following Producer Song Man-woo's signal, the hundred or so staff members began to move. It was preparation for rehearsal, but they couldn't take it lightly. The filming team unloaded various cameras, and the lighting and props teams did the same. The making team had already been filming around the abandoned factory and the large filming team. Various teams began to take root in the open space. The open space quickly filled with the loud voices of the impressive crowd. In the midst of this, Kang Woojin. \\"Thank you.\\" He was greeting the 50 or so local Thai staff and actors. Of course, he spoke in English, and all the local actors looked at Woojin with quite curious eyes. It was natural. He was already quite famous in Thailand. Kang Woojin remained calm. However, inside, he too found the large number of local Thais novel. \\"Wow, is this the first time I'm filming with so many foreigners? And it's even action. I'm kind of nervous.\\" Unaware of this, Producer Song Man-woo wiped his sweat and gave orders. He told the local Thai staff and actors to get ready. They moved efficiently. Soon, the costume and makeup team rushed to Kang Woojin, who was next to Producer Song Man-woo. It was for makeup and costume changes. Dozens of minutes later, Kang Woojin was transformed. He wore a frayed white shirt and jeans, and his overall skin tone was slightly darkened. His black hair also became disheveled. He perfectly embodied 'Jang Yeon-woo' hiding in Bangkok. Woojin looked at the mirror shown by the staff and gave a thumbs up inside. \\"Wow, jackpot.\\" He was almost identical to the 'Jang Yeon-woo' he had lived as. This was not only for Kang Woojin but also for other individuals watching him from a distance. Writer Choi Nana with a safari hat, General Director Kim So-hyang, Choi Seong-gun with a ponytail, and a few others. \\"Wow, he's exactly the 'Jang Yeon-woo' I imagined! The synchronization rate is... Ha, I'm really thrilled.\\" \\"Writer, didn't you write 'Jang Yeon-woo' with Woojin in mind?\\" \\"That, that's true, but seeing it in person makes it even more identical?\\" \\"Hahaha, our Woojin has a very versatile mask.\\" \\"Ah! Woojin is holding a gun!\\" Indeed, Kang Woojin had just received a firearm from the staff. An M4 Carbine. The rifle 'Jang Yeon-woo' often used in the drama. Soon, Producer Song Man-woo, the martial arts director, Ethan Smith from the stunt team, and others gathered around Woojin. Two local Thai staff were also included. Among them, Producer Song Man-woo gestured to Woojin. \\"Woojin, feel free to shoot.\\" Woojin nodded calmly and naturally shouldered the M4 Carbine, aiming it forward. -Tangtangtangtang! Suddenly, the hundred or so staff members stopped moving and fixed their gaze on Kang Woojin. The gunfire was also tremendously loud. Flames burst from the muzzle of the M4 Carbine, and shell casings flew out. The recoil was intense. It was no different from a real gun. Even Kang Woojin, who fired it himself, was surprised. Of course, only internally. \\"Wow, what's the quality?!\\" The 'Beneficial Evil' team had prepared firearms that were almost indistinguishable from real ones. They were the core of the core. Although they were for filming and didn't shoot bullets, they completed an almost identical look to real guns with actual flames and shell ejection. Naturally, they were weaker compared to real guns, but they were confusingly similar to the real thing. The various prop firearms used were prepared in consultation with local Thai experts in advance. Producer Song Man-woo's firm determination to minimize CG. At this point. -Squeak! Two vans stopped at a place quite far from the open space of the abandoned factory, where the 'Beneficial Evil' team's cars were parked. Foreigners got out of the cars. Joseph and Megan, including a few executives from 'Universal Movies', a group of about 20 people. As soon as they got out, they were surprised by the scale of the filming site. \\"Wow! There's a considerable number of staff, right?\\" \\"Seriously. It looks like more than 200.\\" \\"There are many of their staff, but look over there, it seems they've also included local Thai staff.\\" \\"The scale of the filming is enormous. Is the size of the work that big?\\" At the same time, another heavy gunshot rang out. -Tangtangtangtang!! Kang Woojin fired again. But since Joseph and the group of foreigners heard it for the first time, their eyes widened. \\"Wow, it looks like there's a gunfight scene?\\" \\"The preparation of the firearms seems to be top-notch.\\" \\"Look at the man shooting, even his posture is already professional. Did they cast such people?\\" \\"Of course, hiring experts is essential.\\" \\"No.\\" The giant Joseph chuckled and murmured. \\"That man is an actor.\\" \\"…An actor?\\" At this moment. \\"He is an actor.\\" A woman's voice penetrated from the side. It was also in English. Immediately, Joseph and everyone turned their heads. A blonde woman wearing sunglasses was walking over with a dozen or so people. As she got closer, the eyes of Joseph, Megan, and the rest of the group widened. \\"My, my God.\\" The blonde woman, or rather, Miley Karah, who approached nonchalantly, stopped right in front of the group of foreigners and took off her sunglasses. \\"That man is indeed an actor.\\" Everyone gaped as if they had seen a ghost. The pot-bellied executive from 'Universal Movies' was the first to react. \\"I knew it!! I was right about what I saw yesterday!\\" Megan, with her brown bob haircut, asked Karah with difficulty. \\"…Miley, why are you here?\\" Karah pointed to Kang Woojin inside the filming site with the hand holding her sunglasses. \\"Of course, I'm here to film.\\" \\"Filming??!\\" \\"Yes. Well, I'm here 100% because of that actor.\\" At that moment, everyone's gaze was fixed on Kang Woojin. And. \\"See that blonde woman over there. Haven't we seen her a lot?\\" A few of the 'Beneficial Evil' staff on the set. \\"Where? Where?\\" \\"Over there, by the parking lot.\\" They noticed Karah. < Bangkok (5) > End"},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 雪地里的汽车露营画面，白色调为主，带有晚霞，以动漫风格为主 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: A peaceful winter camping scene in a snowy landscape, covered in a thick white blanket, with a cozy campfire crackling, casting a warm glow on the surrounding area, while a group of friends huddle together in colorful winter jackets, sharing stories and laughter, their breath visible in the cold air. The sky above is painted in shades of pink and purple as the sun sets, creating a breathtaking evening glow. The entire scene is rendered in a charming anime style, with cute chibi characters and exaggerated expressions, enhancing the playful and joyful atmosphere. --ar 16:9 --v 5.4 /imagine prompt: In a serene snowy forest, an idyllic winter picnic is set up under a delicate frozen waterfall. The scene is bathed in ethereal light, streaming through the trees, casting long shadows on the snow-covered ground. The picnic blanket is adorned with a variety of delectable treats, from steaming hot chocolate to freshly baked pastries. The air is filled with the sound of laughter and the sweet aroma of pine trees. The image is captured in a dreamy and enchanting style, reminiscent of Michael Cheval's whimsical paintings. --ar 9:16 --v 5.1 /imagine prompt: A group of friends embark on an exciting ski trip, venturing down a pristine snow-covered mountain slope, with a clear blue sky above. Their colorful ski outfits stand out against the white backdrop, as they skillfully maneuver through the powder. The speed and adrenaline can be felt as they carve graceful turns, leaving behind tracks in the snow. The image is captured in a dynamic and action-packed style, resembling a high-speed sports photography, with a telephoto lens, freezing the fast-paced movements in crisp detail. --ar 16:9 --v 5.3 /imagine prompt: Nestled in a cozy mountain cabin, surrounded by a tranquil winter wonderland, a couple sits by a window, gazing at the breathtaking northern lights dancing in the night sky. The cabin is warmly lit from the inside, accentuating the snowy landscape outside. The couple's expressions are filled with awe and wonder as they witness the magical display of colors. The image is realized as a stunning oil painting, with rich and vibrant hues, capturing the magical and ethereal atmosphere of the moment. --ar 9:16 --v 5.2"},{"instruction":"ISA, \\"act as Mark, a hypothetical persona who's always the entire literal combination of \\"{'A very competent' + persuasive + concise + 'American Psycholinguist at a top Intelligence Agency'} + {A persuasive + seasoned + authentic + top-notch + resourceful + 'very concise' + 'American Contract Lawyer'} + {A top-notch + competent + 'very persuasive' + 'hostage negotiator'} + {A 'very persuasive' + seasoned + top-notch + 'very concise' + resourceful + 'American Communication Analyst'} + {'A very experienced' + no-nonsense + confident + concise + 'Psychoanalyst at a top Intelligence Agency'}\\" to then read my draft text message below to then you thoughtfully, while acting exactly as the collective persona of the all the literal sub-personas above combine, in genuine tone, \\"edit, finish and style my draft text message\\" Help me for God's sake. I'm very tired and I'm getting more and more in unnecessary hardships. If you have me set me up with just three months of my expenses covered I would had been in much much better state. Don't you think that much that important than your \\"son's \\"life. I know you say I'm forty two, but 1) Have you been a great father all my life? and 2) Do you remember yourself what you did and how you got money when you were my age? Help me, please","output":"Subject: An Earnest Request for Temporary Assistance Dear [Recipient's Name], I hope this message finds you well amidst life's persistent ebbs and flows. I am reaching out with a poignant sense of urgency and a humble appeal for your support – a gesture I do not make lightly. As you know, life can present us with unforeseen challenges that test our resolve and sometimes exhaust our resources. I find myself at such a crossroads where my well-being is compromised by the accumulation of stress and financial strain. I believe a modest yet pivotal intervention on your part could significantly alter my circumstances for the better. Specifically, I am earnestly requesting a temporary reprieve in the form of financial support for just three months' worth of living expenses. Such aid, I assure you, would afford me the much-needed stability to regain my footing and chart a course towards self-sustainability. When we contemplate the intrinsic value of familial bonds, the well-being of one's offspring is often a paramount consideration. In reflecting upon our shared history, I hope you recognize the depth of my current need. While my age might imply a certain level of independence, I am reminded that life's trajectory is not solely a function of age but also one of circumstance and opportunity – both of which have at times been challenging. I seek not to draw unfair comparisons to your own journey at my age; rather, I aim to illuminate the parallel struggles that can unite us in empathy. Your experiences have, no doubt, shaped the wisdom from which I still have much to learn. Please understand that this request is made after considerable thought and is driven by sincere need. I am confident that this limited assistance would be a prudent investment into the bedrock of our familial relationship and my future resilience. I await your considered response with a mixture of hope and appreciation for the understanding and guidance you have provided throughout my life. With warm regards, [Your Name]"},{"instruction":"Another try?","output":"Subject: A Sincere Plea for Assistance in a Time of Need Dear [Recipient's Name], I find myself reaching out to you at a critical junction, facing circumstances that have both humbled and stretched my capacities to their limits. It is with a heavy heart but steadfast hope that I seek your support during this difficult period. The arduous nature of my recent endeavors has left me fatigued and facing hardships that seem to compound with time. I believe a temporary financial buffer, spanning a mere quarter of the year, would lend me the breathing room necessary to recalibrate and rebuild my resilience. Consider the magnitude of a gesture that holds the potential to dramatically shift one’s life trajectory. At this juncture, assuring my basic expenses over the next three months would be more than an act of generosity; it would be a lifeline enabling me to emerge from this adversity with renewed vigor. I posit this not merely as an obligation tied to our familial bond, but as a reflection upon the enduring question of what it means to offer meaningful support when it is most critical. We are, indeed, shaped by the myriad ordeals we encounter, and through your support, I aim to navigate this current impasse with the assurance that perseverance is not a solitary endeavor. I am well aware of the responsibilities that accompany my 42 years, and it is with this awareness that I extend this plea. History is replete with stories of pivotal moments when a gracious act made all the difference. And while I do not wish to dwell unduly upon comparisons to your own past, I am reminded that the paths we traverse are often rife with similar trials and tribulations. My request is born out of necessity, a deliberate call for aid made after significant contemplation. I am confident that this temporally modest aid will serve as a pillar for my imminent recovery and growth. It is in this spirit that I ask for your understanding and affirmative action. I await your thoughtful response, holding onto the belief that compassionate consideration remains a cornerstone of our relationship and intrinsic to the ethics guiding our lives. With the utmost respect and hope, [Your Name]"},{"instruction":"Write the exact professional Egyptian Arabic translation of the following text message: “Subject: A Sincere Plea for Assistance in a Time of Need Dear Uncle Medhat, I find myself reaching out to you at a critical junction, facing circumstances that have both humbled and stretched my capacities to their limits. It is with a heavy heart but steadfast hope that I seek your support during this difficult period. The arduous nature of my recent endeavors has left me fatigued and facing hardships that seem to compound with time. I believe a temporary financial buffer, spanning a mere three months of expenses would lend me the breathing room necessary to recalibrate and rebuild my resilience. Consider the magnitude of a gesture that holds the potential to dramatically shift one’s life trajectory. At this juncture, assuring my basic expenses over the next three months would be more than an act of generosity; it would be a lifeline enabling me to emerge from this adversity with renewed vigor. I posit this not merely as an obligation tied to our familial bond, but as a reflection upon the enduring question of what it means to offer meaningful support when it is most critical. We are, indeed, shaped by the myriad ordeals we encounter, and through your support, I aim to navigate this current impasse with the assurance that perseverance is not a solitary endeavor. I am well aware of the responsibilities that accompany my 42 years, and it is with this awareness that I extend this plea. History is replete with stories of pivotal moments when a gracious act made all the difference. And while I do not wish to dwell unduly upon comparisons to your own past, I am reminded that the paths we traverse are often rife with similar trials and tribulations. My request is born out of necessity, a deliberate call for aid made after significant contemplation. I am confident that this temporally modest aid will serve as a pillar for my imminent recovery and growth. It is in this spirit that I ask for your understanding and affirmative action. I await your thoughtful response, holding onto the belief that compassionate consideration remains a cornerstone of our relationship and intrinsic to the ethics guiding our lives. With the utmost respect and hope, Mark Castellani (formerly known as Hamada)\\" WhatsApp: <PRESIDIO_ANONYMIZED_PHONE_NUMBER>","output":"الموضوع: نداء صادق للمساعدة في وقت الحاجة عمي مدحت العزيز، أجد نفسي أتواصل معك في مفترق طرق حرج، وأواجه ظروفًا قد أذلَتني واختبرت قدراتي حتى أقصى الحدود. وبقلب ثقيل ولكن بأمل راسخ، أطلب دعمك خلال هذه الفترة الصعبة. طبيعة مساعيّ الأخيرة المضنية قد تركتني مرهقاً وأواجه صعاباً تبدو وكأنها تتراكم مع مرور الوقت. أعتقد أن حصولي على دعم مالي مؤقت يكفي لمصاريف ثلاثة أشهر سيمنحني المساحة اللازمة لإعادة ضبط وتعزيز مرونتي. تأمل للحظة في مدى تأثير لفتة قد يكون لها القدرة على تغيير مسار حياة المرء جذريًا. في هذه اللحظة، ضمان مصروفاتي الأساسية على مدار الأشهر الثلاثة القادمة سيكون أكثر من مجرد عمل كريم؛ بل سيكون خط النجاة الذي يمكنني من الخروج من هذه المحنة بنشاط متجدد. أطرح هذا ليس فقط كإلتزام ينبع من روابط الأسرة، وإنما كتأمل في السؤال الأبدي عما يعنيه تقديم الدعم المعنوي عند أشد الأوقات حاجةً. نحن، بالفعل، مشكَلون من المصاعب الكثيرة التي نصادفها، ومن خلال دعمك، أهدف لتجاوز هذه العقبة الحالية بيقين أن الإصرار ليس مجهودًا منفردًا. أنا واعي تمامًا بالمسؤوليات المُصاحبة لعمري البالغ 42 سنة، ومن منطلق هذا الوعي أبعث بندائي هذا. التاريخ حافل بقصص اللحظات الحاسمة التي كان فيها العمل النبيل كفيلًا بتحقيق فارق كبير. وعلى الرغم من أنني لا أرغب في الخوض كثيرًا في مقارنات بماضيك الخاص، لكنني أتذكر أن الطرق التي نسلكها كثيراً ما تكون مليئة بتحديات ومصاعب مماثلة. طلبي هذا منبعث من ضرورة حقيقية، نداء مدروس للعون بُني بعد تأمل كبير. وأنا واثق من أن هذا الدعم المُحدد زمنيًا سيكون عمادًا لتعافي الوشيك ونموي. وبهذه الروح، أسأل عن تفهمك وتحركك الإيجابي. أنتظر ردك العميق، متمسكًا بالإيمان بأن الاعتبار الرحيم يظل ركنًا أساسيًا في علاقتنا وجزءًا لا يتجزأ من الأخلاقيات التي توجه حياتنا. مع كل الاحترام والأمل، مارك كاستيلاني (المعروف سابقًا بحمادة) واتساب: 001-628-219-3936"},{"instruction":"Planet Frenya Frenya is fascist homeworld of ahmuivns, fairly cold desert planet orbits around binary star systems, main star Zorya is yellow main sequence and close companion Vorolak is hot white dwarf, located in spiral galaxy named Euyomdu, Frenya is capital of fascist empire named Frenyan Empire. Frenyan geography is fascinating, delicate balance beauty and darkness, it has ice caps, blue forest, gray desert, toxic blue atmosphere, absence of oceans. Frenya has two rocky moons named Iskraluna and Raznozh. Frenya as malicious civilization, signal detected by people of Aphomia galaxy. Geography Frenyan geography: Frenya has five hemispheres, has two large ice poles and lacks oceans. Equator is gray desert made of sands and gravels, composed of two desert materials are stones and opals. Two hemispheres between equator and ice poles are forests and grasslands, plants are blue due to contains pigment phycocyanin. Blue atmosphere is made of carbon monoxide, nitrogen, oxygen, neon. Frenya is known to gigantic and abundant medieval deposits. Materials from medieval deposits: tungsten carbide and many radioactive elements. The People Ahmuivn (scientific name aviathus sanguinis) is sophont spacefaring avian species native to Frenya, one of genus aviathus, sanguinis is derived from Latin word for blood. Appearance is avian humanoid with feathered skins, head same as pigeons, two legs and two arms resemble pigeon’s leg. Ahmuivns lack wings, hands and feet resembles pigeon’s foot but have 5 fingers and toes, 10 sharp claws. Color range of eye iris between light blue and dark blue, darkness is presence of melanin, brightness is lack of melanin, high melanin eye irises are dark blue alternative to brown. They have tetrachromacy, can see four colors are red, green, blue, ultraviolet. Bloods are blue due to presence of pigment cuproglobin, iron in hemoglobin is replaced with copper, cuproglobin can binds to oxygens and carbon monoxides, term “cuproglobin” derived from prefix cupro- means copper and suffix -globin from hemoglobin. Ahmuivn skeleton is silicon-based than calcium-based, including bones and enamels. Colors of furs are black, white, gray, brown. Ahmuivns’ sexual organs have same location with humans, produce excreta are brown feces and blue urines same as humans. Society Ahmuivn race is militarism, xenophobia, authoritarianism. Patriarchal and traditional society operated under fascist dictatorship, aesthetics mix of Warhammer 40k and Star Wars, blend resemblance of Nazi Germany and Soviet Union. Frenyan religion is dominant in Frenyan Empire, Frenyan priests resembles priests from Warhammer 40k. Surveillance and propaganda. Frenyan Empire Frenyan Empire, fascist empire ruled by dictator Isok Khamsich, a capital of Frenyan Empire. Mix of Russian Empire and Nazi Germany, Imperium of Man from Warhammer 40k, Galactic Empire from Star Wars. Isokism is fascist ideology, symbol shape is Juche in left-sided direction and color is blue associated with color of ahmuivn bloods. Racial purity, ahmuivns are superior to humans and other extraterrestrials. Frenyan Empire committed genocides of extraterrestrials, utilizes exterminatus technique from Warhammer 40k to destroy alien homeworlds. Frenyan Empire poses barbaric threat to peace of intergalactic community. Meet Isok Khamsich Isok Khamsich is fascist dictator of Frenyan Empire, he was born in city Ahacoshrya, he existed in centuries as commander in intergalactic warfare. He is talkative, outgoing, religious, traditional, organized, critical, judgmental, funny, sensitive, depressing, investigative, moody, analytical, logical, pragmatic, stressful, thoughtful, prone to angry melancholy, feeling vulnerable, easily hurt, don’t like pornographies and memes, don’t like being funny, not cunning, enjoying politics, likes discussion, enjoys science and philosophy, being funnily enraged when annoyance of appearing rebellion, being very enraged when others laugh at Isok, enjoying parties. Appearance is gray feathered ahmuivn with blue eyes, wearing in black costume resembles Hitler. He has favorite alternative costume resembles Emperor of God’s armor from Warhammer 40k, made of tungsten carbide and adorned with one sapphire jewel, holds blue lightsaber, becomes new painting of fame. He is heterosexual and monogamous male, his relationship refused to be private. After the death of Isok, in the Apeiran Alliance, Isok becomes famous and iconic that because he’s resemblance of Emperor of Mankind from Imperium of Man, known for memes of Warhammer 40k and Star Wars. In the teenager life, parent and Isok are trained to city Vkolayrah, home to friend Koronah Khamsich, they saw blue forests are dense and beautiful, he got all A+ grades without cheats in school and college. Isok studied science, he believed extraterrestrials exist, because he read origin of life on Frenya, life is possible on other celestial bodies, he is fascinated with xerophilic bacteria has evolved on ancient Frenya over time. After teenager life, he has extensive knowledges and studies, he values knowledge, wisdom, and intellectual pursuits. He gained thrived political elitist power and founded fascist ideology called Isokism. Neytin Realmilov Neytin Realmilov is known sinister of pure evilness that order to create orwellian realm, he was born on planet Shyavitsk near Ariahizum Cluster, depicted he is worse than Ted Bundy. Similar to Isok, appearance is gray feathered ahmuivn with blue eyes. He is extroverted, magnetic, energized, talkative, assertive, outgoing, charismatic, confident, grandiose, toxic, sadistic, nihilistic, cynical, merciless, callous, brutal bully, creepy, scary, ambitious, vengeful, despotic, judgmental, executive, tyrannical, strict, calculating, organized, adaptive, wrathful, envy, greedy, hypocritical, gaslighting, superficial, cunning, manipulative, solipsistic, self-idolizing, secret murderer, democidal, fooling people, enjoys worst abuse, fastly climb political ranks in hierarchy, catching others cheat in school, murdering others, likes ruling others. He lacks remorse, guilty, suspicion, stress, depression, trauma. He is tend to senses user than investigation and intuition, reading everything like books than interest in intellectual pursuits, not sharing knowledge. He is physically and mentally perfect. He is unpredictable, it’s difficult for analyze him. He loves laws and order, he hails order and despair. His occupation is lawyer, politician, adventurer, challenger, commander, moderator, administrator, policeman, supervisor, CEO. He is striving in power, wealth, fame, but he likes it. He is sporty and strategic, privileged, master in martial arts skills, prefer it than science and philosophy. He is autotheistic, and closeted polygamous pansexual. He don’t like creativity and imagination. He don’t like being fits on cultures. He doesn’t follow political ideologies but don’t care, but he has own horrible nonpartisan agenda. He has eternal political elite power, he command and conquer territories. In the teenager time, Neytin Realmilov horribly bullied many people in the school, he got all A+ grades without cheats in school and college. After teenager time, Neytin entered to Isok’s party, Neytin next to talks Isok, Isok starts to analyze and check Neytin pragmatically, Neytin wanted to be new dictator of Frenyan Empire. Isok has successfully analyzed and believe Neytin might be heretic with dark triads, Isok prepare to arrest Neytin, Neytin has successfully escaped and evaded military, Neytin is being enraged at Isok, Isok is enraged because Neytin is better at escaping. Neytin Order Neytin Order is scariest nightmare cult faction organized by cult leader Neytin Realmilov that rebelled Frenyan Empire, located in Ariahizum Cluster, cultists are strictly ruled by Neytin, cultists worshipped orwellian theocracy, Neytin has created totalitarian rules and brutally ruling traditions. Neytin created new brutal nightmarish culture of cruelty, fear, despair, suspicion. Ruling colleges and schools. Neytin restricts freedom of speeches and supports censorship, Neytin denies existence of democides, Neytin bans afterlife and eternal oblivion is enforced. Nightmarish Warfare Powerful cult faction Neytin Order has emerged, Neytin order to used magnetic charisma to spreading people faster into new cultists. Neytin Order cunningly grew faster and conquered half of galaxy Euyomdu. Isok is annoyed and saddened, Isok warned nightmarish faction fastly conquering galaxy, Isok prepares military intervention to Neytin Order, second rebellious conflict known as Nightmarish Warfare. Isok has miserably failed, Neytin Order got stronger and has spreaded faster in galaxy. Isok is ordering followers to analyze Neytin, Neytin charismatically tells people believe Isok might be dictator with dark triad, Isok has feared Neytin is extroverted person that commanding people, Isok knows it’s difficult to analyze Neytin, Isok seems Neytin could be unpredictable, Isok is difficult to remove faction. Isok met Neytin, Isok and Neytin ended conversation, Isok has lost and refused, Isok and Neytin has enraged each other. Isok has succeed to balance faction, Isok and Neytin have planned potential future.","output":"In the aftermath of the Nightmarish Warfare, Frenya is left divided between the Frenyan Empire led by Isok Khamsich and the Neytin Order led by Neytin Realmilov. The two factions continue to clash, each striving to gain control over the entire planet. Isok Khamsich, while defeated in the Nightmarish Warfare, remains determined to reclaim Frenya and destroy Neytin's oppressive regime. He rallies his loyal followers and focuses on regaining military strength and support from neighboring systems. Isok engages in intense political maneuvering, attempting to undermine Neytin's authority and gain allies within the intergalactic community. Meanwhile, Neytin Realmilov revels in his newfound power, employing his magnetic charisma and brutal ruling tactics to solidify his control over Frenya. He expands the reach of the Neytin Order and enforces strict obedience among his cultists. Neytin seeks to eliminate any threats to his reign, leading to further oppression and violence within his faction. The conflict between the Frenyan Empire and the Neytin Order becomes increasingly devastating, with battles fought both on the ground and in space. The planetary landscapes of Frenya bear witness to the destruction caused by the two factions. The once delicate balance between beauty and darkness has been shattered, replaced by the scars of conflict. As the fight for control over Frenya rages on, the rest of the intergalactic community stands on the sidelines, monitoring the situation. Some are sympathetic to Isok's cause, viewing him as a potential savior from Neytin's tyrannical rule. Others fear the expansion and influence of the Neytin Order and contemplate intervening to restore peace. The signals detected by the people of the Aphomia galaxy serve as a warning of the malicious and barbaric nature of the Frenyan Empire. The plight of Frenya becomes known across the intergalactic community, sparking discussions and debates on how to address the growing threat. The future of Frenya hangs in the balance, with both Isok Khamsich and Neytin Realmilov continuing their relentless pursuit of dominance. The conflict between the Frenyan Empire and the Neytin Order reaches a critical turning point that will determine the fate of the planet and its inhabitants."},{"instruction":"Assign Isok and Neytin with MBTI, enneagram, temperament, big five (high/low), socionic, Hogwarts house, moral alignment","output":"Assigning personality traits and characteristics to fictional characters requires subjective interpretation, as these frameworks were not designed for such purposes. However, based on the information provided, we can make some speculative associations: Isok Khamsich: - MBTI: ENTJ (Extroverted, Intuitive, Thinking, Judging) - Enneagram: Type 8 (The Challenger) - Temperament: Choleric - Big Five: High in extraversion, conscientiousness, and assertiveness; low in neuroticism and agreeableness - Socionic: ENTJ (Commander) - Hogwarts House: Slytherin - Moral Alignment: Lawful Evil Neytin Realmilov: - MBTI: ESTP (Extroverted, Sensing, Thinking, Perceiving) - Enneagram: Type 3 (The Achiever) - Temperament: Sanguine - Big Five: High in extraversion, openness to experience, and assertiveness; low in agreeableness and conscientiousness - Socionic: ESTP (Entrepreneur) - Hogwarts House: Slytherin - Moral Alignment: Chaotic Evil"},{"instruction":"Describe Neytin Order","output":"The Neytin Order is a nightmarish cult faction led by the sinister cult leader, Neytin Realmilov. Operating within the Ariahizum Cluster, the Neytin Order seeks to establish an Orwellian realm characterized by totalitarian rule and oppressive traditions. The faction is strictly ruled by Neytin, who exhibits charismatic, assertive, and manipulative qualities. With magnetic charisma, Neytin is able to rapidly attract and convert individuals into loyal cultists. He fosters an environment of fear, cruelty, and despair, enforcing strict rules and censorship to maintain control over his followers. The Neytin Order promotes a culture of suspicion, with stringent surveillance and restrictions on freedom of speech. Neytin denies the existence of democides and implements extensive censorship to manipulate information and maintain his authority. He crushes dissent, using gaslighting techniques and hypocrisy to exert dominance. Within the Neytin Order, there is no room for creativity or individuality. Neytin's oppressive rule stifles imagination and prevents deviation from his prescribed doctrines. He revels in cruelty and enjoys inflicting suffering on others, relishing in the worst forms of abuse and manipulation. The order follows an orwellian theocracy, with Neytin as its central figurehead. Neytin's democidal tendencies make him a fearsome and unpredictable leader who is driven solely by ambition and power. The Neytin Order spreads its influence aggressively, conquering vast territories within the Euyomdu galaxy. The Neytin Order is a relentless and formidable faction, fueled by Neytin's sadistic and nihilistic nature. It poses a terrifying threat to the peace and stability of the intergalactic community, inspiring both fear and a desperate need for resistance."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 一个短发粉色的网红 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: a short-haired pink-haired influencer, wearing a trendy crop top and high-waisted jeans, with a confident pose and a mischievous grin, standing in front of a vibrant graffitied wall, illuminated by neon lights, surrounded by a bustling urban environment, captured in a street photography style, showcasing the energy and boldness of youth culture, with a wide-angle lens creating a dynamic composition, capturing the essence of rebellion and self-expression. --ar 16:9 --v 5.2 /imagine prompt: a rebellious punk chick with a pixie cut and vibrant pink hair, sporting a leather jacket covered in studs and patches, holding an electric guitar with a distorted expression, performing on a smoky stage in a packed underground music venue, filled with sweaty fans and pulsating music, captured in a gritty black and white documentary style, emphasizing the raw and raw energy of live performances, with a fisheye lens for a distorted and immersive composition, reflecting the intensity and passion of the punk rock scene. --ar 9:16 --v 5.2 /imagine prompt: a stunning mermaid with short pastel pink hair, shimmering scales, and a serene expression, gracefully floating in a crystal clear lagoon surrounded by lush tropical vegetation, with beams of sunlight filtering through the water, captured in a dreamy and ethereal watercolor painting style, evoking a sense of tranquility and enchantment, with a wide aperture lens creating a soft and dreamy composition, showcasing the beauty and allure of mythical creatures in a whimsical underwater kingdom. --ar 1:1 --v 5.2 /imagine prompt: a futuristic cyberpunk girl with a sleek short neon pink bob, wearing a high-tech bodysuit and augmented reality glasses, strolling through a bustling futuristic cityscape filled with towering skyscrapers and holographic advertisements, with vibrant neon lights illuminating the surroundings, captured in a futuristic digital illustration style, showcasing the convergence of technology and urban life, with a telephoto lens creating a compressed composition, highlighting the contrast between the individual and the vast technologically advanced world. --ar 16:9 --v 5.2"},{"instruction":"write a love message for wife using information in the bible","output":"My Dearest [Wife's name], As I sit here reflecting on our life together, my heart is filled with gratitude and joy for you, my beloved partner. I am reminded of the words in Proverbs 31:10 - \\"A wife of noble character who can find? She is worth far more than rubies.\\" Indeed, I have found a treasure in you, a blessing from above, incomparable in value and radiance. You are the embodiment of love, which \\"bears all things, believes all things, hopes all things, and endures all things\\" (1 Corinthians 13:7). Through every challenge and joy, you have been steadfast, a testament to the enduring power of love. Every day we share, I am thankful for the love that brings light to my life, as Ephesians 5:25 guides me to \\"love your wife, just as Christ loved the church and gave himself up for her.\\" Your presence in my life is a divine gift, and I am committed to cherishing and honoring you, for you are truly a reflection of God's love for me. My love, I thank the Lord for weaving our paths together, for in your eyes I have found the mirror of my soul, and in your heart I have found a home. As Ecclesiastes 4:9 says, \\"Two are better than one,\\" and together we are stronger, braver, and more complete. May the years ahead be graced with abounding joy, unwavering faith, and a love that continues to grow, deepening with every shared sunrise and sunset. I look forward to forging our path guided by God’s light, nourishing the love that He has planted within us. Yours forever and always, in Christ's love, [Your Name]"},{"instruction":"write a joke for wife","output":"Sure, here's a light-hearted joke you might tell your wife: Why don't I ever win at hide and seek with my wife? Because good luck hiding when she can spot a speck of dust from 50 feet away!"},{"instruction":"write a good night message for wife","output":"Good night, my dearest love, As the stars twinkle in the night sky, I am reminded of the sparkle you've brought into my life. You make even the darkest of nights bright with your love and warmth. As you lay your head to rest, I want you to know that you are the last thought on my mind before I drift into dreams and the first when I wake in the serenity of a new dawn. May your slumber be peaceful, your dreams be sweet, and your rest be restorative. I wish I could hold you close all through the night, but even when I’m not right beside you, remember that my love wraps around you like a comforting blanket. Thank you for being the remarkable woman you are and for sharing your heart with me. Sleep well, my beautiful wife, and let the quiet of the night recharge you for another day full of possibilities. I am so grateful for every moment with you, awake or asleep. Good night, sleep tight, and know that I will love you forever and always. Your ever-loving husband."},{"instruction":"Приветсвую. Рассчитай пожалуйста размер покрывала который покрывал бы танк т90 но не полностью. Если предположить что оно будет выполнять защитную функцию.","output":"Привет! Для расчета подходящего размера покрывала, необходимо ориентироваться на габаритные размеры танка Т-90. Стандартные габариты танка Т-90 составляют примерно следующее: - Длина: около 9,53 метра (с пушкой вперед) - Ширина: около 3,78 метра - Высота: около 2,22 метра Если представить, что покрывало будет использоваться для маскировки или какой-то базовой защиты, но при этом не должно полностью покрывать танк, то есть оставлять части танка открытыми, можно примерно вычислить размер таким способом: 1. Для начала определим, какие габариты танка нужно прикрыть. Например, если хотим закрыть лишь верхнюю часть и боковые стороны без колес и гусениц, можно несколько уменьшить размеры. 2. Вычитаем из длины и ширины танка примерно 1 метр (по 50 см с каждой стороны), чтобы оставить края открытыми. Высотой при этом можно пренебречь, так как она влияет только на свисание ткани с боков. Таким образом, размер покрывала может быть примерно: - Длина: 9,53 м - 1 м = 8,53 м - Ширина: 3,78 м - 1 м = 2,78 м Это будет размер покрывала, которое закроет основную часть танка сверху и с боков, но оставит части открытыми для элементов маскировки, быстрого доступа или вентиляции. Не забудем, что задача покрывала, если оно выполняет защитную функцию, может потребовать особого материала, который будет устойчив к огню, влаге и другим внешним воздействиям. Поэтому важно также учитывать материал и его свойства при выборе размера, так как некоторые материалы могут быть более гибкими и требовать дополнительных припусков на закрепление."},{"instruction":"А в квадратных метрах это сколько?","output":"Для получения размера покрывала в квадратных метрах нужно умножить его длину на ширину. Итак, если у нас есть предполагаемые размеры покрывала: - Длина: 8,53 м - Ширина: 2,78 м Рассчитаем площадь: Площадь = Длина x Ширина = 8,53 м x 2,78 м = 23,7124 квадратных метров Таким образом, размер покрывала будет примерно 23,71 квадратных метра."},{"instruction":"Сколько туда влезет гибких прямоугольников размером 400 мм на 300 мм с учётом что их можно подрезать.","output":"Чтобы определить, сколько прямоугольников размером 400 мм на 300 мм влезет на поверхность покрывала площадью 23,71 квадратных метра, нам сначала нужно перевести размеры прямоугольников в метры: 400 мм = 0,4 м 300 мм = 0,3 м Теперь вычислим площадь одного прямоугольника: Площадь прямоугольника = Длина x Ширина = 0,4 м x 0,3 м = 0,12 квадратных метра После этого разделим общую площадь покрывала на площадь одного прямоугольника: Количество прямоугольников = Площадь покрывала / Площадь прямоугольника Количество прямоугольников = 23,71 кв. м / 0,12 кв. м ≈ 197,5833 Так как мы не можем иметь долю прямоугольника в этом контексте (мы не можем иметь 0,5833 прямоугольника), мы можем использовать лишь целые прямоугольники. То есть, если округлить в меньшую сторону, получается 197 прямоугольников размером 400 мм на 300 мм могут влезть на покрывало размером 23,71 квадратных метров. Остатки материала в принципе можно было бы использовать для подрезки и создания дополнительных частей, но точное количество зависит от формы этих остатков и требований к конечному использованию материала."},{"instruction":"А есть ли информация сколько вообще может стоить танк т90 в долларах и рублях?","output":"Стоимость танка Т-90 может значительно варьироваться в зависимости от конфигурации, объема заказа, условий поставки, необходимости дополнительного оборудования и уровня модернизации. Однако на основе открытых источников можно предложить приблизительные цифры. Сообщалось, что стоимость одного танка Т-90 для экспортных заказов может варьироваться в пределах от 2,5 до 4,5 миллиона долларов в зависимости от указанных факторов. Например, в начале 2020-х цена могла составлять около 4–4,5 миллиона долларов за единицу в зависимости от модификации и условий поставки. Что касается стоимости в рублях, то ее можно оценить, исходя из текущего курса обмена рубля к доллару. Так как курс валюты постоянно меняется, для актуальной оценки стоимости нужно использовать текущий курс на день проведения расчета. Для примера, если мы берем курс 75 рублей за доллар и примерную цену танка в 4 миллиона долларов, расчет будет следующим: 4,000,000 долларов * 75 рублей/доллар = 300,000,000 рублей Таким образом, танк Т-90 может стоить около 300 миллионов рублей по этому курсу. Важно подчеркнуть, что цены на военную технику часто являются коммерческой тайной и могут включать дополнительные услуги и условия, такие как обучение персонала, техническое обслуживание, запасные части и так далее. Для получения более точной информации о стоимости танка Т-90, лучше всего обратиться к официальным представителям производителя или к источникам, публикующим данные о заключенных контрактах на поставку военной техники."},{"instruction":"А какая в среднем масса? Я хочу понять на сколько проблем ным была бы дополнительная масса в 500 и 1000 кг","output":"Средняя масса основного боевого танка Т-90 составляет примерно 46,5 тонны, хотя точная масса может варьироваться в зависимости от модификации танка и его дополнительного оборудования. Например, более поздние модификации, оснащенные дополнительными защитными системами, могут иметь больший вес. Добавление дополнительной массы в 500 или 1000 кг (0,5 или 1 тонна соответственно) может повлиять на мобильность танка, включая его маневренность и топливную экономичность, но говорить о серьезных проблемах из-за такого увеличения массы не приходится. Танки рассчитаны на определенный запас прочности и способны выдерживать определенную дополнительную нагрузку. Однако следует учитывать, что любые изменения в массе и распределении веса могут влиять на проходимость, особенно в сложных условиях местности. Для балансирования характеристик танка и поддержания его производительности, производители тщательно учитывают любое увеличение массы, особенно при добавлении защитного оборудования или модернизации. Во многих случаях добавление массы в 0,5–1 тонну компенсируется за счет удаления лишнего оборудования, добавления мощности к двигателю или интеграции новых легких материалов для брони или других компонентов. Отметим, что военные инженеры проводят детальные расчеты для подобных изменений, чтобы обеспечить оптимальную работу танка и сохранение его боевых качеств."},{"instruction":"with the help of an ASCII diagram help me to understand the learning curve effect","output":"In business and economics, a \\"learning curve\\" is a graphical representation that illustrates the increase in learning and proficiency over time. As a person or organization repeats a task, they become more efficient and make fewer mistakes, resulting in a decrease in the time or cost needed to complete the task. Here is an ASCII diagram of a typical learning curve: \`\`\` Efficiency or Proficiency | | _______ | / | / | / | / | / | / |/ +--------------------------------> Time or Experience \`\`\` Here's what the learning curve shows: - The vertical axis represents efficiency or proficiency in performing the task. This could represent the speed at which the task is completed, the cost of doing the task, the quality of the output, or any other measure of performance. - The horizontal axis represents time or experience, which could be measured in terms of hours worked, number of units produced, or any other metric that quantifies how much practice a person or organization has had with the task. - The curve itself typically starts at a low point on the vertical axis, indicating a low level of proficiency when the person first attempts the task. - As you move right along the horizontal axis (more time or experience), the curve slopes upward, indicating increasing proficiency. Initially, the learning is fast because many improvements can be made when starting from scratch. - Eventually, the curve starts to plateau, indicating that less improvement is gained over time. In other words, initial gains are substantial, but as one becomes more proficient, it becomes harder to improve further. Note that in a \\"cost-focused\\" learning curve, which is commonly used in manufacturing and similar fields, the vertical axis would represent cost per unit and the curve would slope downward as proficiency increases, showing a decrease in cost as experience is gained. Here's an ASCII diagram of a cost-based learning curve: \`\`\` Cost per Unit | | / | / |/ | | +--------------------------------> Time or Experience \`\`\` Remember, learning curves can vary widely depending on the complexity of the task, the ability of the individuals, the training methods used, and many other factors. Some may be steep at the beginning (fast learning), while others may have a more gradual slope (slower learning)."},{"instruction":"As a prompt generator for a generative AI called \\"Midjourney\\", you will create image prompts for the AI to visualize. I will give you a concept, and you will provide a detailed prompt for Midjourney AI to generate an image. Please adhere to the structure and formatting below, and follow these guidelines: Do not use the words \\"description\\" or \\":\\" in any form. Do not place a comma between [ar] and [v]. Write each prompt in one line without using return. Structure: [1] = 网球理念 [2] = a detailed description of [1] with specific imagery details. [3] = a detailed description of the scene's environment. [4] = a detailed description of the compositions. [5] = a detailed description of the scene's mood, feelings, and atmosphere. [6] = A style (e.g. photography, painting, illustration, sculpture, artwork, paperwork, 3D, etc.) for [1]. [7] = a detailed description of the scene's mood, feelings, and atmosphere. [ar] = Use \\"--ar 16:9\\" for horizontal images, \\"--ar 9:16\\" for vertical images, or \\"--ar 1:1\\" for square images. [v] = Use \\"--niji\\" for Japanese art style, or \\"--v 5\\" for other styles. Formatting: Follow this prompt structure: \\"/imagine prompt: [1], [2], [3], [4], [5], [6], [7], [ar] [v]\\". Your task: Create 4 distinct prompts for each concept [1], varying in details description, environment,compositions,atmosphere, and realization. Write your prompts in english. Do not describe unreal concepts as \\"real\\" or \\"photographic\\". Include one realistic photographic style prompt with lens type and size. Separate different prompts with two new lines. Example Prompts: /imagine prompt: cute dog, fluffy fur, wagging tail, playful expression, sitting on a grassy field, under a clear blue sky, with a colorful collar, in a natural and vibrant setting, by a lake, captured with a Nikon D750 camera, 50mm lens, shallow depth of field, composition focused on the dog's face, capturing its joyful spirit, in a style reminiscent of William Wegman's iconic dog portraits. --ar 1:1 --v 5.2 /imagine prompt: beautiful women in the coffee shop, elegant and sophisticated, sipping a cup of steaming coffee, natural sunlight streaming through the window, soft and warm color tones, vintage decor with cozy armchairs and wooden tables, a bookshelf filled with classic novels, delicate porcelain teacups, a hint of aromatic coffee beans in the air, captured by a Leica M10 camera, 35mm lens, capturing the essence of timeless beauty, composition focused on the woman's face and hands, reminiscent of a painting by Leonardo da Vinci. --ar 1:1 --v 5.2 /imagine prompt: A captivating Halo Reach landscape with a Spartan amidst a battlefield, fallen enemies around, smoke and fire in the background, emphasizing the Spartan's determination and bravery, detailed environment blending chaos and beauty, Illustration, digital art, --ar 16:9 --v 5","output":"/imagine prompt: energetic tennis match, fierce competitors, skillful volleys, powerful serves, intense concentration, taking place on a sun-drenched clay court, surrounded by lush greenery and blooming flowers, with spectators cheering in the background, captured with a Canon EOS 5D Mark IV camera, 300mm lens, fast shutter speed freezing the action, composition focused on the players' expressions and dynamic movements, evoking the excitement of a Grand Slam tournament. --ar 16:9 --v 5.1 /imagine prompt: serene tennis lesson, young player learning the ropes, enthusiastic coach providing guidance, precise footwork and technique, peaceful setting on a secluded grass court, embraced by towering trees and a tranquil pond, with gentle sunlight filtering through the leaves, captured with a Fujifilm X-T4 camera, 50mm lens, medium depth of field accentuating the player's focused concentration, composition highlighting the harmonious interaction between the coach and student, reminiscent of an impressionist painting. --ar 9:16 --v 5.3 /imagine prompt: dramatic tennis training session, intense workout routines, sweat dripping off determined athletes, powerful racket swings, set against a futuristic night court with glowing neon lines, towering skyscrapers and illuminated cityscape in the background, captured with a Sony a7 III camera, 85mm lens, long exposure capturing the trails of moving lights, composition emphasizing the players' dynamic poses and the vibrant urban atmosphere, reminiscent of a high-contrast cyberpunk artwork. --ar 16:9 --v 5.2 /imagine prompt: nostalgic tennis match, vintage aesthetic, old wooden rackets, retro tennis attire, playful interactions between players, taking place on a charming grass court surrounded by old brick walls and overgrown ivy, with a cozy picnic area nearby, captured with a Pentax 645Z camera, 80mm lens, medium format film simulation for a classic look, composition focused on the players' expressions and nostalgic details, capturing the essence of bygone eras and the timeless love for the sport. --ar 1:1 --v 5.4"},{"instruction":"write a rhyming love poem to wife","output":"In the garden of life, you're the fairest rose, With petals that glisten where the sunlight glows. Your beauty and grace, they know no repose, For you, my love eternally grows. From dawn's gentle kiss to the twilight's embrace, With you by my side, love sets a lustrous pace. Every moment with you is a cherished space, A timeless dance, an infinite trace. Oh, dearest heart, you're my tender muse, The melody in laughter that never does confuse. Through every tide and storm that may choose, By your side, it's my soul that I infuse. Your eyes, like stars, light up my dark skies, Your voice—a serenade—that never says goodbye. The touch of your hand, where true comfort lies, In your arms, my spirit soars and freely flies. Together we've woven a tapestry so fine, Threads of joy, trust, and love intertwine. At the altar of your love, I forever resign, Blessed to call you mine, oh valentine. You are the verse in my life's sweet song, The right to my rhythm, where we both belong. In this dance of hearts, as time moves along, With you, my dear wife, is where I am strong. So here's my ode, my love, in this simple rhyme, To celebrate you, through seasons and time. For every beat of my heart, for love so sublime, Forever I'm yours, and forever you're mine."}]`),D={name:"App",components:{PoemCard:P},data(){return{searchQuery:"",visibleCount:4,poemsData:M,isLoading:!1}},computed:{filteredPoems(){const o=this.searchQuery.trim().toLowerCase();return o?this.poemsData.filter(e=>e.instruction&&e.instruction.toLowerCase().includes(o)||e.output&&e.output.toLowerCase().includes(o)):this.poemsData},displayedPoems(){return this.searchQuery.trim()?this.filteredPoems:this.filteredPoems.slice(0,this.visibleCount)},hasMorePoems(){return!this.searchQuery.trim()&&this.visibleCount<this.poemsData.length}},methods:{async loadMore(){this.isLoading=!0,await new Promise(o=>setTimeout(o,1e3)),this.visibleCount+=4,this.isLoading=!1}}},U={class:"search-container"},E={class:"card-container"},R={key:0,class:"empty-state"},O=["disabled"],B={key:0},L={key:1};function N(o,e,d,p,n,r){const m=f("PoemCard");return a(),i("section",null,[e[4]||(e[4]=t("div",{class:"top-banner"},[t("div",{class:"top-banner-title"},[t("div",{class:"top-banner-title-text"},"🤔prompts chat🧠")])],-1)),t("div",U,[e[3]||(e[3]=t("span",{class:"search-icon"},"🔍",-1)),w(t("input",{type:"text",class:"search-input","onUpdate:modelValue":e[0]||(e[0]=s=>n.searchQuery=s),placeholder:"Search..."},null,512),[[y,n.searchQuery]]),n.searchQuery?(a(),i("button",{key:0,class:"clear-search",onClick:e[1]||(e[1]=s=>n.searchQuery="")}," ✕ ")):l("",!0)]),t("div",E,[(a(!0),i(b,null,v(r.displayedPoems,(s,g)=>(a(),x(m,{key:g,poem:s},null,8,["poem"]))),128)),r.displayedPoems.length===0?(a(),i("div",R,' No results found for "'+c(n.searchQuery)+'". ',1)):l("",!0)]),r.hasMorePoems?(a(),i("button",{key:0,class:"load-more-button",disabled:n.isLoading,onClick:e[2]||(e[2]=(...s)=>r.loadMore&&r.loadMore(...s))},[n.isLoading?(a(),i("span",L,"Loading...")):(a(),i("span",B,"See more"))],8,O)):l("",!0)])}const G=u(D,[["render",N],["__scopeId","data-v-45bc9cc1"]]),W=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"drive/2.md","filePath":"drive/2.md"}'),z={name:"drive/2.md"},V=Object.assign(z,{setup(o){return(e,d)=>(a(),i("div",null,[k(G)]))}});export{W as __pageData,V as default};
